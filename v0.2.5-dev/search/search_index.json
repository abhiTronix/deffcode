{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":"<p>A cross-platform  High-performance Video Frames Decoder that flexibly executes FFmpeg pipeline inside a subprocess pipe for generating real-time, low-overhead, lightning fast video frames with robust error-handling in just a few lines of python code </p> <p>Highly Adaptive - DeFFcode APIs implements a standalone highly-extensible wrapper around FFmpeg multimedia framework. These APIs supports a wide-ranging media streams as input source such as live USB/Virtual/IP camera feeds, regular multimedia files, screen recordings, image sequences, network protocols (such as HTTP(s), RTP/RSTP, etc.), so on and so forth.</p> <p>Highly Flexible - DeFFcode APIs gains an edge over other Wrappers by providing complete control over the underline pipeline including access to almost any FFmpeg specification thinkable such as specifying framerate, resolution, hardware decoder(s), filtergraph(s), and pixel-format(s) that are readily supported by all well known Computer Vision libraries.</p> <p>Highly Convenient -  FFmpeg has a steep learning curve especially for users unfamiliar with a command line interface. DeFFcode helps users by providing similar to OpenCV, Index based Camera Device Capturing and the same OpenCV-Python (Python API for OpenCV) coding syntax for its APIs, thereby making it even easier to learn, create, and develop FFmpeg based apps in Python.</p> <p> </p>"},{"location":"#key-features-of-deffcode","title":"Key features of DeFFcode","text":"<p>Here are some key features that stand out:</p> <ul> <li> High-performance, low-overhead video frames decoding with robust error-handling.</li> <li> Flexible API with access to almost any FFmpeg specification thinkable.</li> <li> Supports a wide-range of media streams/devices/protocols as input source. </li> <li> Curated list of well-documented recipes ranging from Basic to Advanced skill levels.</li> <li> Hands down the easiest Index based Camera Device Capturing, similar to OpenCV.</li> <li> Memory efficient Live Simple &amp; Complex Filtergraphs. (Yes, You read it correctly \"Live\"!)</li> <li> Lightning fast dedicated  GPU-Accelerated Video Decoding &amp; Transcoding.</li> <li> Enables precise FFmpeg Frame Seeking with pinpoint accuracy.</li> <li> Effortless Metadata Extraction from all streams available in the source.</li> <li> Maintains the standard easy to learn OpenCV-Python coding syntax.</li> <li> Out-of-the-box support for all prominent Computer Vision libraries.</li> <li> Cross-platform, runs on Python 3.7+, and easy to install. </li> </ul> Still missing a key feature in DeFFcode? <p>Please review DeFFcode's Roadmap. If you still can't find the desired feature there, then you can request one simply by Commenting  or Upvoting an existing comment  on that issue.</p> <p> </p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>In case you're run into any problems, consult our Help section.</p>"},{"location":"#installation-notes","title":"Installation Notes","text":"<p>If this is your first time using DeFFcode, head straight to the Installation Notes to install DeFFcode on your machine.</p>"},{"location":"#recipes-aka-examples","title":"Recipes a.k.a Examples","text":"<p>Once you have DeFFcode installed, checkout our Well-Documented Recipes  for usage examples:</p> How to Begin? <p>If you\u2019re just starting, check out the Beginner Basic Recipes  and as your confidence grows, move up to Advanced Recipes . </p> <ul> <li> Basic Recipes : Recipes for beginners of any skill level to get started.</li> <li> Advanced Recipes : Recipes to take your skills to the next level.</li> </ul>"},{"location":"#api-in-a-nutshell","title":"API in a nutshell","text":"<p>As a user, you just have to remember only two DeFFcode APIs, namely:</p> <p>See API Reference for more in-depth information.</p>"},{"location":"#a-ffdecoder-api","title":"A. FFdecoder API","text":"<p>The primary function of FFdecoder API is to decode 24-bit RGB video frames from the given source:</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\n# formulate the decoder with suitable source\ndecoder = FFdecoder(\"https://abhitronix.github.io/html/Big_Buck_Bunny_1080_10s_1MB.mp4\").formulate()\n# grab RGB24(default) 3D frames from decoder\nfor frame in decoder.generateFrame():\n# lets print its shape\nprint(frame.shape) # (1080, 1920, 3)\n# terminate the decoder\ndecoder.terminate()\n</code></pre>"},{"location":"#b-sourcer-api","title":"B. Sourcer API","text":"<p>The primary function of Sourcer API is to gather information from all multimedia streams available in the given source:</p> <pre><code># import the necessary packages\nfrom deffcode import Sourcer\n# initialize and formulate the decoder using suitable source\nsourcer = Sourcer(\"https://abhitronix.github.io/html/Big_Buck_Bunny_1080_10s_1MB.mp4\").probe_stream()\n# print metadata as `json.dump`\nprint(sourcer.retrieve_metadata(pretty_json=True))\n</code></pre> The resultant Terminal Output will look something as following on  Windows machine: <pre><code>{\n\"ffmpeg_binary_path\": \"C:\\\\Users\\\\foo\\\\AppData\\\\Local\\\\Temp\\\\ffmpeg-static-win64-gpl/bin/ffmpeg.exe\",\n\"source\": \"https://abhitronix.github.io/html/Big_Buck_Bunny_1080_10s_1MB.mp4\",\n\"source_extension\": \".mp4\",\n\"source_video_resolution\": [\n1920,\n1080\n],\n\"source_video_framerate\": 60.0,\n\"source_video_pixfmt\": \"yuv420p\",\n\"source_video_decoder\": \"h264\",\n\"source_duration_sec\": 10.0,\n\"approx_video_nframes\": 600,\n\"source_video_bitrate\": \"832k\",\n\"source_audio_bitrate\": \"\",\n\"source_audio_samplerate\": \"\",\n\"source_has_video\": true,\n\"source_has_audio\": false,\n\"source_has_image_sequence\": false\n}\n</code></pre> <p> </p>"},{"location":"#contribution-guidelines","title":"Contribution Guidelines","text":"<p>Contributions are welcome, and greatly appreciated!  </p> <p>Please read our Contribution Guidelines for more details.</p> <p> </p>"},{"location":"#community-channel","title":"Community Channel","text":"<p>If you've come up with some new idea, or looking for the fastest way troubleshoot your problems. Please checkout our Gitter community channel \u27b6</p> <p> </p>"},{"location":"#become-a-stargazer","title":"Become a Stargazer","text":"<p>You can be a  Stargazer   by starring us on Github, it helps us a lot and you're making it easier for others to find &amp; trust this library. Thanks!</p> <p> </p>"},{"location":"#donations","title":"Donations","text":"<p>DeFFcode is free and open source and will always remain so. </p> <p>It is something I am doing with my own free time. But so much more needs to be done, and I need your help to do this. For just the price of a cup of coffee, you can make a difference </p> kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw(); <p> </p>"},{"location":"#citation","title":"Citation","text":"<p>Here is a Bibtex entry you can use to cite this project in a publication:</p> <p></p> <pre><code>@software{deffcode,\nauthor       = {Abhishek Singh Thakur},\ntitle        = {abhiTronix/deffcode: v0.2.4},\nmonth        = oct,\nyear         = 2022,\npublisher    = {Zenodo},\nversion      = {v0.2.4},\ndoi          = {10.5281/zenodo.7155399},\nurl          = {https://doi.org/10.5281/zenodo.7155399}\n}\n</code></pre> <p> </p>"},{"location":"changelog/","title":"Release Notes","text":""},{"location":"changelog/#v024-2022-10-07","title":"v0.2.4 (2022-10-07)","text":"New Features <ul> <li> FFdecoder API:<ul> <li>Implemented new comprehensive support for both discarding key default FFmpeg parameters from Decoding pipeline simply by assigning them <code>null</code> string values, and concurrently using values extracted from Output Stream metadata properties (available only when FFmpeg filters are defined) for formulating pipelines.<ul> <li>Added <code>null</code> string value support to <code>-framerate</code> and <code>-custom_resolution</code> attributes, as well as <code>frame_format</code> parameter for easily discarding them.</li> <li>Re-Implemented calculation of rawframe pixel-format.<ul> <li>Reconfigured default rawframe pixel-format, Now rawframe pixel-format will always default to <code>source_video_pixfmt</code> with <code>frame_format=\"null\"</code>.</li> <li>Now with <code>frame_format</code> parameter value either \"null\" or invalid or undefined, rawframe pixel-format value is taken from <code>output_frames_pixfmt</code> metadata property extracted from Output Stream (available only when filters are defined). If valid <code>output_video_resolution</code>  metadata property is found then it defaults to default pixel-format(calculated variably).</li> <li>With <code>frame_format=\"null\"</code>, <code>-pix_fmt</code> FFmpeg parameter will not be added to Decoding pipeline.</li> </ul> </li> <li>Re-Implemented calculation of rawframe resolution value.<ul> <li>Now with <code>-custom_resolution</code> dictionary attribute value either \"null\" or invalid or undefined, rawframe resolution value is first taken from <code>output_video_resolution</code> metadata property extracted from Output Stream (available only when filters are defined), next from <code>source_video_resolution</code> metadata  property(extracted from Input Source Stream). If neither <code>output_video_resolution</code> nor <code>source_video_resolution</code> valid metadata properties are found then <code>RuntimeError</code> is raised.</li> <li>With <code>-custom_resolution</code> dictionary attribute value \"null\", <code>-s/-size</code> FFmpeg parameter will not be added to Decoding pipeline.</li> </ul> </li> <li>Re-Implemented calculation of output framerate value.<ul> <li>Now with <code>-framerate</code> dictionary attribute either null or invalid or undefined, output framerate value is first taken from <code>output_video_framerate</code> metadata property extracted from Output Stream (available only when filters are defined), next from <code>source_video_framerate</code> metadata  property(extracted from Input Source Stream). If neither <code>output_video_resolution</code> nor <code>source_video_framerate</code> valid metadata properties are found then <code>RuntimeError</code> is raised.</li> <li>With <code>-framerate</code> dictionary attribute value \"null\", <code>-r/-framerate</code> FFmpeg parameter will not be added to Decoding pipeline.</li> </ul> </li> </ul> </li> <li>Implemented passing of simple <code>-vf</code> filters, complex <code>-filter_complex</code> filters, and pre-headers(via <code>-ffprefixes</code>) directly to Sourcer API's <code>sourcer_params</code> parameter for probing Output Stream metadata and filter values.</li> </ul> </li> <li> Sourcer API:<ul> <li>Implemented new comprehensive approach to handle <code>source_demuxer</code> parameter w.r.t  different <code>source</code> parameter values.<ul> <li>The <code>source_demuxer</code> parameter now accepts \"auto\" as its value for enabling Index based Camera Device Capture feature in Sourcer API.</li> <li>Sourcer API auto-enforces <code>source_demuxer=\"auto\"</code> by default, whenever a valid device index (uses <code>validate_device_index</code> method for validation) is provided as its <code>source</code> parameter value.<ul> <li>\u26a0\ufe0f Sourcer API will throw <code>Assertion</code> error if <code>source_demuxer=\"auto\"</code> is provided explicitly without a valid device index at its <code>source</code> parameter.</li> </ul> </li> <li>Source API now accepts all +ve and -ve device indexes (e.g. <code>-1,0,1,2</code> etc.) to its <code>source</code> parameter, both as in integer and string of integer types as source in Index based Camera Device Capture feature.<ul> <li>Sourcer API imports and utilizes <code>extract_device_n_demuxer()</code> method for discovering and extracting all Video-Capture device(s) name/path/index present on system. <ul> <li>\u26a0\ufe0f Sourcer API will throw <code>RuntimeError</code> on failure to identify any device.</li> </ul> </li> <li>Sourcer API auto verifies that the specified source device index is in range of the devices discovered. <ul> <li>\u26a0\ufe0f Sourcer API will raise <code>ValueError</code> if value goes out of valid range.</li> </ul> </li> <li>Sourcer API also automatically handle -ve indexes if specified within the valid range.</li> <li>Implemented patch to auto-add <code>video=</code> suffix to selected device name before using it as video source on Windows OSes.</li> <li>Added patch for handling dictionary of devices paths(with devices names as values) and log messages on Linux Oses.</li> <li>Added <code>copy</code> import for shallow copying various class parameters.</li> </ul> </li> <li>Implemented new Support for additional FFmpeg parameters and Output metadata.<ul> <li>Added three new metadata properties: <code>output_video_resolution</code>, <code>output_video_framerate</code>, <code>output_frames_pixfmt</code> for handling extracted Output Stream values, whenever additional FFmpeg parameters(such as FFmpeg filters) are defined.</li> <li>Added support for auto-handling additional FFmpeg parameters defined by <code>sourcer_params</code> dictionary parameters.</li> <li>Implement new separate pipeline for parsing Output Stream metadata by decoding video source using <code>null</code> muxer for few microseconds whenever additional FFmpeg parameters(such as <code>-vf</code> filters) are defined by the user.</li> <li>Included new <code>metadata_output</code> internal parameter for holding Output Stream metadata splitted from original Sourcer Metadata extracted from new pipeline.</li> <li>Included new <code>output_video_resolution</code>, <code>output_video_framerate</code>, <code>output_frames_pixfmt</code> internal parameters for metadata properties, whenever Output Stream Metadata available.</li> <li>Added new <code>extract_output</code> boolean parameter to <code>extract_video_pixfmt</code> and <code>extract_resolution_framerate</code> internal methods for extracting output <code>pixel-format</code>, <code>framerate</code> and <code>resolution</code> using Output Stream metadata instead of Sourcer Metadata, whenever available.</li> </ul> </li> <li>Added <code>tuple</code> datatype to <code>sourcer_params</code> exception.</li> <li>Added <code>dict2Args</code> import. </li> </ul> </li> <li>Added <code>enumerate_devices</code> property object to enumerate all probed Camera Devices connected to a system names along with their respective \"device indexes\" or \"camera indexes\" as python dictionary.</li> <li>Added new <code>force_retrieve_missing</code> parameter to <code>retrieve_metadata()</code> method for returning metadata missing in current Pipeline as <code>(metadata, metadata_missing)</code> tuple value instead of just <code>metadata</code>, when <code>force_retrieve_missing=True</code>.</li> <li>Added various output stream metadata properties that are only available when additional FFmpeg parameters(such as filters) are defined manually, by assigning them counterpart source stream metadata property values</li> </ul> </li> <li> FFhelper:<ul> <li>Implemented new <code>extract_device_n_demuxer()</code> method for discovering and extracting all Video-Capture device(s) name/path/index present on system and supported by valid OS specific FFmpeg demuxer.<ul> <li>Added support for three OS specific FFmpeg demuxers: namely <code>dshow</code> for Windows, <code>v4l2</code> for Linux, and <code>avfoundation</code> for Darwin/Mac OSes.</li> <li>Implemented separate code for parsing outputs of python <code>subprocess</code> module outputs provided with different commands for discovering all Video-Capture devices present on system.<ul> <li>Processed <code>dshow</code> (on Windows) and <code>avfoundation</code> (on Darwin) demuxers in FFmpeg commands with <code>-list_devices true</code> parameters using <code>subprocess</code> module and applied various brute-force pattern matching on its output for discovering and extracting all devices names/indexes.</li> <li>Used <code>v4l2-ctl</code> submodule command on Linux machines for listing all Video-Capture devices using <code>subprocess</code> module and applied various brute-force pattern matching on its output for discovering and extracting all devices names and true system <code>/dev/video</code> paths.<ul> <li>Added patch for a single device with multiple <code>/dev/video</code> paths (each for metadata, video, controls), where it iterates on each path to find the exact path that contains valid video stream. </li> <li>Added elaborated checks for catching all possible system errors that can occur while running <code>v4l2-ctl</code> submodule command.</li> <li>The method will return discovered devices as list of dictionaries with device paths(<code>/dev/video</code>) as keys and respective device name as the values, instead of default list of device names.</li> <li>Added patch for handling Linux specific log messages.</li> </ul> </li> </ul> </li> <li>Added various logging messages to notify users about all discover devices names/paths w.r.t indexes.</li> <li>\u26a0\ufe0f The <code>extract_device_n_demuxer</code> method will raise <code>RuntimeError</code> if it fails to identify any device.</li> <li>Added various checks to assert invalid input parameters and unsupported OSes.</li> <li>Added <code>machine_OS</code> parameter to specify OS running on the system, must be value of <code>platform.system()</code> module. If invalid the method will raise ValueError.</li> </ul> </li> </ul> </li> <li> Utilities: <ul> <li>Added new <code>new validate_device_index()</code> method to verify if given device index is valid or not?<ul> <li>Only Integers or String of integers are valid indexes. </li> <li>Returns a boolean value, confirming whether valid(If <code>true</code>), or not(If <code>False</code>).</li> </ul> </li> <li>Added checks to support all +ve and -ve integers, both as integer and string types.</li> </ul> </li> <li> Docs:<ul> <li>Added <code>new validate_device_index()</code> method and its parameters description.</li> <li>Added <code>new extract_device_n_demuxer()</code> method and its parameters description.</li> <li>Added Decoding Camera Devices using Indexes support docs.<ul> <li>Added <code>decode-camera-devices.md</code> doc for Decoding Camera Devices using Indexes.<ul> <li>Added <code>Enumerating all Camera Devices with Indexes</code> example doc with code.</li> <li>Added <code>Capturing and Previewing frames from a Camera using Indexes</code> example doc with code.</li> </ul> </li> <li>Added Camera Device Index support docs to FFdecoder and Sourcer API params.</li> </ul> </li> </ul> </li> <li> CI:<ul> <li>Added check exception for <code>mandelbrot</code> virtual source in Sourcer API's <code>test_probe_stream_n_retrieve_metadata</code> unittest.</li> <li>Added new <code>test_discard_n_filter_params</code> unittest for test recently added supported for both discarded parameters and filter values.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> FFdecoder API:<ul> <li>Extended range of supported output frame pixel-formats. <ul> <li>Added new pixel-formats to supported group by extending raw bits-per-component range.</li> </ul> </li> <li>Simplified raw frame dtype calculation based on selected pixel-format.<ul> <li><code>output_frames_pixfmt</code> metadata property(if available) will be overridden to <code>rgb24</code>.</li> </ul> </li> <li>Replaced <code>continue</code> with <code>break</code> in <code>generateFrame()</code> method.</li> <li>Improved handling of <code>frame_format</code> parameter.</li> </ul> </li> <li> Sourcer API:<ul> <li>Simplified JSON formatting and returning values logic.</li> <li>Updated logging messages text and position.</li> <li>Removed redundant variable definitions.</li> <li>Changed related internal variable names w.r.t metadata property names.</li> <li>Replaced <code>os_windows</code> internal parameter with <code>machine_OS</code>, and changed its input from <code>os.name</code> to more flexible <code>platform.system()</code>. </li> <li>Removed <code>source_extension</code> internal parameter and assigned values directly.</li> </ul> </li> <li> FFhelper:<ul> <li>Implemented more robust pattern matching for Linux machines.</li> <li>Updated logs in <code>check_sp_output()</code> method for improving error output message.</li> <li>Implemented \"Cannot open device\" v4l2-ctl command Error logs. </li> </ul> </li> <li> Maintenance: <ul> <li>Bumped version to <code>0.2.4</code>.</li> <li>Updated code comments.</li> </ul> </li> <li> CI:<ul> <li>Updated FFdecoder API's <code>test_camera_capture</code> unittest to test new Index based Camera Device Capturing on different platforms.<ul> <li>Added various parametrize <code>source</code> and <code>source_demuxer</code> parameter data to attain maximum coverage.</li> <li>Added <code>result</code> field to <code>fail</code> and <code>xfail</code> unittest according to parametrize data provided on different platforms.</li> <li>Removed <code>pytest.mark.skipif</code> to support all platforms.</li> </ul> </li> <li>Added and updated various parametrize test data to attain maximum coverage.</li> <li>Limited range of extracted frames, for finishing tests faster.</li> <li>Updated unittests to reflect recent name changes.</li> <li>Disabled capturing of stdout/stderr with <code>-s</code> flag in pytest. </li> </ul> </li> <li> Setup:<ul> <li>Updated description metadata. </li> </ul> </li> <li> Bash Script: <ul> <li>Created undeleteable <code>undelete.txt</code> file for testing on Linux envs.</li> <li>Updated <code>undelete.txt</code> file path.</li> <li>Made FFmpeg output less verbose.</li> </ul> </li> <li> Docs:<ul> <li>Updated FFdecoder  API params docs w.r.t recent changes and supported for both discarded parameters and filter values.<ul> <li>Added new admonitions to explain handling of \"null\" and (special-case), undefined, or invalid type values in various parameters/attributes.</li> <li>Added new footer reference explaining the handling of Default pixel-format for <code>frame_format</code> parameter.</li> <li>Added missing docs for <code>-default_stream_indexes</code> ffparams attribute.</li> </ul> </li> <li>Added docs for recently added additional FFmpeg parameter in Sourcer API's <code>sourcer_params</code> parameter.<ul> <li>Removed unsupported <code>-custom_resolution</code> sourcer_params attributes from <code>sourcer_params</code> parameter docs.</li> <li>Removed redundant <code>-vcodec</code> and <code>-framerate</code> attributes from <code>sourcer_params</code> parameter docs.</li> </ul> </li> <li>Updated both basic and advanced project Index hyperlinks.</li> <li>Moved <code>decoding-live-feed-devices.md</code> doc from basic to advanced directory.</li> <li>Updated page navigation in <code>mkdocs.yml</code>.</li> <li>Update announcement bar to feature Index based Camera Device Capture support.</li> <li>Updated Project description and Key features of DeFFcode.</li> <li>Updated README.md with latest information.</li> <li>Updated <code>source</code> and <code>source_demuxer</code> param doc.</li> <li>Updated Hardware-Acceleration docs.<ul> <li>Updated Hardware-Accelerated Video Decoding and Transcoding docs to inform users about DeFFcode generated YUV frames not yet supported by OpenCV and its APIs.</li> </ul> </li> <li>Updated recipes docs to reflect recent changes in APIs. </li> <li>Updated parameter docs to reflect recent name changes.</li> <li>Updated parameters/attributes introductory descriptions.</li> <li>Updated various parametrize data to attain maximum coverage. </li> <li>Updated Zenodo badge and the BibTeX entry.</li> <li>Updated method description texts and logging messages.</li> <li>Update title headings, icons and admonition messages.</li> <li>Updated code comments.</li> <li>Updated <code>changelog.md</code>.</li> </ul> </li> </ul> Breaking Updates/Changes <ul> <li>API:<ul> <li>  Implemented new Index based Camera Device Capture feature (Similar to OpenCV), where the user just have to assign device index as integer (<code>-n</code> to <code>n-1</code>) in source parameter of DeFFcode APIs to directly access the given input device in few seconds.</li> </ul> </li> <li>FFdecoder API<ul> <li>  Unsupported dtype pixel-format always defaults to <code>rgb24</code>.</li> </ul> </li> <li>Sourcer API:<ul> <li>  Renamed <code>output_video_resolution</code> metadata property to <code>output_frames_resolution</code>.</li> <li>  Renamed <code>output_video_framerate</code> metadata property to <code>output_framerate</code>.</li> </ul> </li> </ul> Bug-fixes <ul> <li> FFdecoder API:<ul> <li>Removed redundant dummy value for <code>output_frames_pixfmt</code> metadata property.</li> <li>Fixed critical KeyError bug arises due to missing output metadata properties.<ul> <li>Enforced <code>force_retrieve_missing</code> parameter in Sourcer API's <code>retrieve_metadata()</code> method for returning metadata missing in current Pipeline as <code>(metadata, metadata_missing)</code> tuple value instead of just <code>metadata</code>.</li> <li>Added new <code>missing_prop</code> internal class variable for handling metadata properties missing,  received from Sourcer API.</li> <li>Moved <code>ffdecoder_operational_mode</code> to missing metadata properties that cannot be updated but are read only.</li> <li>Added missing metadata properties to metadata class property object for easy printing along with other metadata information.</li> <li>Implemented missing metadata properties updation via. overridden metadata class property object.<ul> <li>Added <code>counterpart_prop</code> dict to handle all counterpart source properties for each missing output properties.</li> <li>Implemented missing output properties auto-updation w.r.t counterpart source property.</li> <li>Added separate case for handling only missing metadata properties and notifying user about counterpart source properties.</li> </ul> </li> </ul> </li> <li>Fixed source metadata properties update bug causing non-existential missing metadata properties to be added to source metadata properties dictionary along with source metadata property.<ul> <li>Replaced <code>update()</code> calling  on <code>value</code> dict directly with explicitly assigning values to source metadata properties dictionary.</li> <li>Simplified <code>missing_prop</code> validation.</li> <li>Removed unwanted <code>continue</code> in middle of loop.</li> </ul> </li> <li>Remove unusable exclusive <code>yuv</code> frames patch.</li> <li>Fixed <code>KeyError</code> bug arises due to wrong variable placement.</li> <li>Fixed <code>approx_video_nframes</code> metadata property check.</li> <li>Fixed <code>av_interleaved_write_frame(): broken pipe</code> warning bug by switching <code>process.terminate()</code> with <code>process.kill()</code>.</li> <li>Fixed <code>AttributeError</code> bug caused due to typo in logger.</li> </ul> </li> <li> FFhelper:<ul> <li>Fixed <code>check_sp_output()</code> method returning Standard Error (stderr) even when Nonetype.</li> <li>Fixed logger requiring <code>utf-8</code> decoding.</li> <li>Fixed missing <code>force_retrieve_stderr</code> argument to <code>check_sp_output</code> in <code>extract_device_n_demuxer</code> method on Linux platforms.</li> <li>Fixed logger message bug. </li> </ul> </li> <li> Utils: <ul> <li>Fixed logger name typo.</li> </ul> </li> <li> Maintenance:<ul> <li>Fixed hyperlinks to new GitHub's form schemas. </li> <li>Fixed typos in logs messages.</li> <li>Removed redundant code.</li> <li>Updated code comments.</li> </ul> </li> <li> Setup:<ul> <li>Rearranged <code>long_description</code> patches to address unused patch bug.</li> </ul> </li> <li> Bash Script:<ul> <li>Fixed <code>chattr: No such file or directory</code> bug.</li> </ul> </li> <li> CI:<ul> <li>Fixed missing <code>lavfi</code> demuxer for <code>mandelbrot</code> virtual source in Sourcer API's <code>test_probe_stream_n_retrieve_metadata</code> unittest.</li> <li>Fixed missing <code>ffparams</code> parameter bug in <code>test_discard_n_filter_params()</code> unittest.</li> <li>Fixed <code>test_camera_capture</code> test.</li> <li>Removed redundant similar <code>ValueError</code> checks.</li> <li>Fixed typo in pytest arguments.</li> <li>Fixed missing arguments.</li> </ul> </li> <li> Docs:<ul> <li>Fixed invalid hyperlinks in ReadMe.md</li> <li>Fixed bad formatting and context.</li> <li>Fixed typos in code comments.</li> <li>Fixed several typos in docs.</li> </ul> </li> </ul> Pull Requests <ul> <li>PR #29</li> <li>PR #32</li> </ul>"},{"location":"changelog/#v023-2022-08-11","title":"v0.2.3 (2022-08-11)","text":"New Features <ul> <li> Docs:<ul> <li>Added Zenodo Bibtex entry and badge in docs for easy citation.</li> <li>Added new <code>&lt;div&gt;</code> tag bounding-box style to the Static FFmpeg binary download links in FFmpeg Installation Doc for better accessibility.</li> </ul> </li> <li> Maintenance: <ul> <li>Switched to new Issue GitHub's form schema using YAML:<ul> <li>Added new <code>bug_report.yaml</code> Issue GitHub's form schema for Bug Reports.</li> <li>Added new <code>idea.yaml</code> Issue GitHub's form schema for new Ideas.</li> <li>Added new <code>question.yaml</code> Issue GitHub's form schema for Questions.</li> <li>Deleted old depreciated markdown(<code>.md</code>) files.</li> <li>Polished forms.</li> </ul> </li> </ul> </li> </ul> Updates/Improvements <ul> <li> Maintenance: <ul> <li>Added new patterns to <code>.gitignore</code> to ignore vim files.</li> </ul> </li> <li> CI:<ul> <li>Updated <code>test_FFdecoder_params</code> unittest to include <code>with</code> statement access method.</li> </ul> </li> <li> Setup:<ul> <li>Added new patches for using README.md text as <code>long_description</code> metadata.  <ul> <li>Implemented new patch to remove GitHub README UI specific text.</li> </ul> </li> <li>Simplified multiple <code>str.replace</code> to chained <code>str.replace</code> of better readability.</li> <li>Bumped version to <code>0.2.3</code>.</li> </ul> </li> <li> Docs:<ul> <li>Updated recipes to include <code>with</code> statement access method.<ul> <li>Updated existing recipes to include <code>with</code> statement access method in FFdecoder APIs.</li> <li>Included new example code of accessing RGB frames using <code>with</code> statement access method.</li> <li>Updated Recipe title to \"Accessing RGB frames from a video file\" across docs.</li> </ul> </li> <li>Included warning admonition for advising users to always use <code>trim</code> with <code>reverse</code> filter.</li> <li>Updated docs text font to <code>Libre Franklin</code>.</li> <li>Updated method description texts and logging messages.</li> <li>Update icons and admonition messages.</li> <li>Updated code comments.</li> <li>Updated <code>changelog.md</code>.</li> </ul> </li> </ul> Bug-fixes <ul> <li> FFdecoder API:<ul> <li>Fixed Context Manager methods.<ul> <li>Fixed <code>__enter__</code> method returning class instance instead of formulating pipeline.</li> <li>Fixed <code>__exit__</code> method calling wrong non-existent method.</li> </ul> </li> </ul> </li> <li> Setup:<ul> <li>Fixed missing <code>comma(,)</code> in keywords metadata.</li> <li>Fixed bug in patch string.</li> </ul> </li> <li> Docs:<ul> <li>Fixed typos in code comments.</li> <li>Fixed several typos in docs.</li> </ul> </li> </ul> Pull Requests <ul> <li>PR #26</li> </ul>"},{"location":"changelog/#v022-2022-08-09","title":"v0.2.2 (2022-08-09)","text":"New Features <ul> <li> Sourcer API:<ul> <li>Added support for <code>-ffprefixes</code> attribute through Sourcer API's <code>sourcer_param</code> dictionary parameter (similar to FFdecoder API).</li> </ul> </li> <li> FFdecoder API: <ul> <li>Added new <code>output_frames_pixfmt</code> metadata property to preview and handle output frames pixel-format.</li> </ul> </li> <li> Docs:<ul> <li>Added separate \"Basic\" and \"Advanced\" Recipes markdowns files with self-explanatory text, related usage code, asset (such as images, diagrams, GIFs, etc.), and UI upgrades for bringing standard quality to visual design. </li> <li>Added separate <code>index.md</code> for Basic and Advanced Recipes with introductory text and curated hyperlinks for quick references to various recipes (separated with sub-categories \"Decoding\", \"Transcoding\", and \"Extracting Video Metadata\").</li> <li>Added related admonitions to specify python dependencies as well as other requirements and relevant information required for each of these recipes.</li> <li>Added new Basic Decoding Recipes:<ul> <li>Added Decoding Video files with various pixel formats recipes.</li> <li>Added Decoding Live Feed Devices recipes with <code>source_demuxer</code> FFdecoder API parameter.</li> <li>Added Decoding Image sequences recipes supporting Sequential, Glob pattern , Single (looping) image.</li> <li>Added Decoding Network Streams recipes.</li> </ul> </li> <li>Added new Basic Transcoding Recipes:<ul> <li>Added Transcoding Live frames recipes with OpenCV and WriteGear.</li> <li>Added Transcoding Live Simple Filtergraphs recipes with OpenCV.</li> <li>Added Saving Key-frames as Image recipes with different image processing libraries.</li> </ul> </li> <li>Added new Basic Extracting Video Metadata Recipes:<ul> <li>Added Extracting Video Metadata recipes with FFdecoder and Sourcer APIs.</li> </ul> </li> <li>Added new Advanced Decoding Recipes:<ul> <li>Added Hardware-Accelerated Video Decoding recipe using NVIDIA's H.264 CUVID Video-decoder(<code>h264_cuvid</code>).</li> <li>Added Decoding Live Virtual Sources recipes with many test patterns using <code>lavfi</code> input virtual device.</li> </ul> </li> <li>Added new Advanced Decoding Recipes:<ul> <li>Added lossless Hardware-Accelerated Video Transcoding recipe with WriteGear API.</li> <li>Added Transcoding Live Complex Filtergraphs recipes with WriteGear API.</li> <li>Added Transcoding Video Art with Filtergraphs recipes with WriteGear API for creating real-time artistic generative video art using simple and complex filtergraphs.</li> </ul> </li> <li>Added new Advanced Updating Video Metadata Recipes:<ul> <li>Added Updating Video Metadata recipes with user-defined as well as source metadata in FFdecoder API.</li> </ul> </li> <li>Added new dark and light theme logo support.</li> <li>Added new recipes GIF assets to <code>gifs</code> folder.</li> <li>Added new dark logo <code>deffcode-dark.png</code> asset to <code>images</code> folder.</li> <li>Added new <code>ffdecoder.png</code> and <code>sourcer.png</code> Image assets to <code>images</code> folder.</li> <li>Added new <code>navigation.tabs</code> feature.</li> <li>Added Material Announcement-Bar notifying recent changes.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> Sourcer API:<ul> <li>Implemented new validation checks to ensure given <code>source</code> has usable video stream available by checking availability of either <code>video bitrate</code> or both <code>frame-size</code> and <code>framerate</code>_ properties in the source metadata.</li> <li>Improved <code>extract_resolution_framerate</code> method for making framerate extraction more robust by falling back to extracting <code>TBR</code> value when no framerate value available in the source metadata.</li> </ul> </li> <li> FFdecoder API:<ul> <li>Updated <code>metadata</code> property object to validate and override source metadata properties directly by overloading same property object before formulating Frames Decoder Pipeline:<ul> <li>Implemented validation checks to verify each validate manually assigned source metadata property against specific datatype before overriding.</li> <li>Updated logging to notify invalid datatype values when assigned through <code>metadata</code> property object.</li> <li>Added support for overriding <code>source_video_resolution</code> source metadata property to control frame-size directly through metadata.</li> <li>Added support for overriding <code>output_frames_pixfmt</code> metadata attribute to be used as default pixel-format, when <code>frame_format</code> parameter value is None-type.</li> <li>Improved handling of source metadata keys in metadata property object.</li> </ul> </li> <li>Updated <code>metadata</code> property object to handle and assign User-defined metadata directly by overloading the same property object:<ul> <li>Added new internal <code>user_metadata</code> class variable to handle all User-defined metadata information separately.            </li> <li>FFdecoder API's <code>metadata</code> property object now returns User-defined metadata information merged with Source Video metadata.</li> <li>Added <code>tuple</code> value warning log to notify users <code>json</code> module converts Python <code>tuples</code> to JSON <code>lists</code>.</li> </ul> </li> <li>Improved logic to test validity of <code>-custom_resolution</code> attribute value through <code>ffparams</code> dictionary parameter.</li> <li>Improved handling of FFmpeg pipeline framerate with both user-defined and metadata defined values.</li> <li>Added <code>tuple</code> to exception in datatype check for <code>ffparams</code> dictionary parameter.</li> <li>Added datatype validation check for <code>frame_format</code> parameter.</li> <li>Improved handling of <code>-framerate</code> parameter. </li> </ul> </li> <li> Maintenance:<ul> <li>Reformatted all Core class and methods text descriptions:<ul> <li>Rewritten introductory each API class description.</li> <li>Moved reference block from <code>index.md</code> to class description.</li> <li>Fixed missing class and methods parameter description.</li> <li>Fixed typos and context in texts.</li> <li>Reformatted code comments.</li> </ul> </li> <li>Simplified <code>for</code> loop with <code>if</code> condition checking in metadata property object.</li> <li>Updated logging comments.</li> </ul> </li> <li> Setup:<ul> <li>Updated project description in metadata.</li> <li>Bumped version to <code>0.2.2</code>.</li> </ul> </li> <li> Docs:<ul> <li>Updated Introduction doc:<ul> <li>Added new text sections such as \"Getting Started\", \"Installation Notes\", \"Recipes a.k.a Examples\" and \"API in a nutshell\".</li> <li>Rewritten Introduction(<code>index.md</code>) with recent Information, redefined context, UI changes, updated recipe codes, curated hyperlinks to various recipes(separated with categories), and relatable GIFs.</li> <li>Updated spacing in <code>index.md</code> using <code>spacer</code> class within <code>&lt;div&gt;</code> tag and <code>&amp;nbsp;</code>.</li> <li>Reformatted and centered DeFFcode Introductory description.</li> <li>Reformatted FFmpeg Installation doc and Issue &amp; PR guidelines.</li> <li>Updated static FFmpeg binaries download URLs in FFmpeg Installation doc.</li> <li>Refashioned text contexts, icons, and recipes codes.</li> <li>Updated Key Features section with reflecting new features.</li> </ul> </li> <li>Updated README.md:<ul> <li>Updated README.md w.r.t recent changes in Introduction(<code>index.md</code>) doc.</li> <li>Simplified and Reformatted text sections similar to Introduction doc. </li> <li>Imported new \"Contributions\" and \"Donations\" sections from VidGear docs.</li> <li>Added collapsible text and output section using <code>&lt;summary&gt;</code> and <code>&lt;detail&gt;</code> tags.</li> <li>Added experimental note GitHub blockquote to simulate admonition in README.md.</li> <li>Removed tag-line from README.md and related image asset.</li> <li>Simplified and Grouped README URL hyperlinks.</li> <li>Removed Roadmap section.</li> </ul> </li> <li>Updated Recipes docs:<ul> <li>Revamped DeFFcode Introduction <code>index.md</code> with new Information, Context and UI changes, Updated example codes and hyperlinks.</li> <li>Updated Announcement Bar to fix <code>announcement_link</code> variable and text.</li> <li>Updated footer note to notify users regarding <code>tuple</code> value warning in FFdecoder API.</li> <li>Rewritten recipes w.r.t breaking changes in APIs.</li> </ul> </li> <li>Updated Reference docs:<ul> <li>Completely revamped API's parameter reference docs.</li> <li>Added new Functional Block Diagrams to FFdecoder and Sourcer API References.</li> <li>Rewritten and Reformatted FFdecoder and Sourcer API's parameter reference docs with new information w.r.t recent changes.</li> <li>Implemented new admonitions explaining new changes, related warnings/errors, usage examples etc.</li> <li>Removed redundant <code>advanced.md</code> and <code>basic.md</code> docs.</li> <li>Added new abstracts to FFhelper and Utils docs.</li> </ul> </li> <li>Updated docs site navigation and titles:<ul> <li>Reformatted <code>index.md</code> and <code>installation/index.md</code>.</li> <li>Renamed <code>help/index.md</code> to <code>help/help.md</code>.</li> <li>Moved basic and advanced recipes from <code>example</code> to <code>recipes</code> folder.</li> <li>Imported \"Donations\" sections from VidGear docs to <code>help.md</code>.</li> <li>Added updated page-title and navigation hyperlinks in <code>mkdocs.yml</code> to new markdown files incorporated recently.</li> <li>Updated internal navigation hyperlinks in docs and removed old redundant file links.</li> </ul> </li> <li>Updated docs UI:<ul> <li>Added custom <code>spacer</code> class in CSS for custom vertical spacing.</li> <li>Imported new \"New\", \"Advance\", \"Alert\", \"Danger\" and \"Bug\" admonitions custom CSS UI patches from vidgear.</li> <li>Updated all admonitions icons with new custom icon SVG+XML URLs.</li> <li>Reformatted <code>custom.css</code> and added missing comments.</li> <li>Updated docs fonts:<ul> <li>Updated text font to <code>Heebo</code>.</li> <li>Updated code font to <code>JetBrains Mono</code>.</li> </ul> </li> <li>Updated primary and accent colors:<ul> <li>Updated primary light color to <code>light green</code>.</li> <li>Updated primary dark color to <code>amber</code>.</li> <li>Updated accent light color to <code>green</code>.</li> <li>Updated accent dark color to <code>lime</code>.</li> </ul> </li> <li>Replaced admonitions with appropriate ones.</li> <li>Changed Color palette toggle icons.</li> <li>Updated icons in title headings.</li> </ul> </li> <li>Updated admonitions messages.</li> <li>Updated <code>changelog.md</code>.</li> </ul> </li> <li> CI:<ul> <li>Pinned <code>jinja2</code> version to <code>&lt;3.1.0</code>, since <code>jinja2&gt;=3.1.0</code> breaks mkdocs (mkdocs/mkdocs#2799).</li> <li>Updated unittests w.r.t recent changes in APIs: <ul> <li>Updated <code>test_frame_format</code> unittest to include manually assign output pixel-format via <code>metadata</code> property object.</li> <li>Updated <code>test_metadata</code> unittest to include new <code>checks</code> parameter to decide whether to perform Assertion test on assigned <code>metadata</code> properties in FFdecoder API.</li> <li>Added new parametrize attributes in <code>test_metadata</code> and <code>test_seek_n_save</code> unittests to cover every use-cases.</li> <li>Replaced <code>IOError</code> with <code>ValueError</code> in Sourcer API unittests.</li> </ul> </li> <li>Updated <code>test_metadata</code> unittest to verify <code>tuple</code> value warning.</li> <li>Updated unittests to increase code coverage significantly.</li> </ul> </li> </ul> Breaking Updates/Changes <ul> <li>Sourcer API:<ul> <li>  Sourcer API's  <code>retrieve_metadata()</code> method now returns parsed metadata either as JSON string or dictionary type.<ul> <li>Added new <code>pretty_json</code> boolean parameter to <code>retrieve_metadata()</code>, that is when <code>True</code>, returns metadata formatted as JSON string instead of default python dictionary.</li> </ul> </li> <li>  Changed <code>IOError</code> to <code>ValueError</code> in Sourcer API, raised when source with no decodable audio or video stream is provided.</li> </ul> </li> <li>FFdecoder API:<ul> <li>  Rename <code>extraparams</code> dictionary parameter to <code>ffparams</code> in FFdecoder API. </li> <li>  The <code>source</code> metadata value cannot be altered through <code>metadata</code> property object in FFdecoder API. </li> <li>  Removed <code>-ffpostfixes</code> attribute support from <code>ffparams</code> dictionary parameter in FFdecoder API, since totally redundant in favor of similar <code>-ffprefixes</code> and <code>-clones</code> attributes.</li> </ul> </li> </ul> Bug-fixes <ul> <li> FFdecoder API:<ul> <li>Fixed <code>metadata</code> property object unable to process user-defined keys when any source metadata keys are defined.</li> <li>Fixed <code>TypeError</code> bug with string type <code>-framerate</code> parameter values.</li> </ul> </li> <li> Sourcer API:<ul> <li>Fixed Sourcer API throws <code>IOError</code> for videos containing streams without both source bitrate and framerate defined (such as from <code>lavfi</code> input virtual device).</li> <li>Fixed <code>AttributeError</code> bug due to typo in variable name.</li> </ul> </li> <li> CI:<ul> <li>Fixed support for newer mkdocstring version in DeFFcode Docs Deployer workflow.<ul> <li>Added new <code>mkdocstrings-python-legacy</code> dependency.</li> <li>Replaced <code>rendering</code> variable with <code>options</code>.</li> <li>Removed pinned <code>mkdocstrings==0.17.0</code> version.</li> <li>Removed redundant variables.</li> </ul> </li> <li>Updated <code>test_metadata</code> unittest to fix <code>AssertionError</code> Bug.</li> </ul> </li> <li> Docs:<ul> <li>Fixed some admonitions icons not showing bug using <code>!important</code> rule in CSS.</li> <li>Fixed <code>404.html</code> static page not showing up.</li> <li>Fixed invalid internal navigation hyperlinks and asset paths.</li> <li>Removed <code>quote/cite/summary</code> admonition custom UI patches.</li> <li>Removed redundant information texts.</li> <li>Fixed typos in code comments.</li> <li>Fixed typos in example code.</li> </ul> </li> </ul> Pull Requests <ul> <li>PR #23</li> </ul>"},{"location":"changelog/#v021-2022-07-14","title":"v0.2.1 (2022-07-14)","text":"New Features <ul> <li> Sourcer API:<ul> <li>Implemented support for extracting metadata from live input devices/sources.</li> <li>Added new <code>source_demuxer</code> and <code>forced_validate</code> parameters to <code>validate_source</code> internal method.</li> <li>Implemented logic to validate <code>source_demuxer</code> value against FFmpeg supported demuxers.</li> <li>Rearranged metadata dict.</li> <li>Updated Code comments.</li> </ul> </li> <li> FFdecoder API: <ul> <li>Implemented functionality to supported live devices by allowing device path and respective demuxer into pipeline.</li> <li>Included <code>-f</code> FFmpeg parameter into pipeline to specify source device demuxer.</li> <li>Added special case for discarding <code>-framerate</code> value with Nonetype.</li> </ul> </li> <li> CI:<ul> <li>Added new unittest <code>test_camera_capture()</code> to test support for live Virtual Camera devices.</li> <li>Added new <code>v4l2loopback-dkms</code>, <code>v4l2loopback-utils</code> and kernel related APT dependencies. </li> </ul> </li> <li> Bash Script:<ul> <li>Added new FFmpeg command to extract image datasets from given video on Linux envs.</li> <li>Created live Virtual Camera devices through <code>v4l2loopback</code> library on Github Actions Linux envs. <ul> <li>Added <code>v4l2loopback</code> modprobe command to setup Virtual Camera named <code>VCamera</code> dynamically at <code>/dev/video2</code>.</li> <li>Added <code>v4l2-ctl --list-devices</code> command for debugging.</li> <li>Implemented FFmpeg command through <code>nohup</code>(no hangup) to feed video loop input to Virtual Camera in the background.</li> </ul> </li> </ul> </li> </ul> Updates/Improvements <ul> <li> Sourcer API:<ul> <li>Only either <code>source_demuxer</code> or <code>source_extension</code> attribute can be present in metadata.</li> <li>Enforced <code>forced_validate</code> for live input devices/sources in <code>validate_source</code> internal method.</li> </ul> </li> <li> FFdecoder API:<ul> <li>Rearranged FFmpeg parameters in pipeline.</li> <li>Removed redundant code.</li> <li>Updated Code comments.</li> </ul> </li> <li> FFhelper API:<ul> <li>Logged error message on metadata extraction failure.</li> </ul> </li> <li> CI:<ul> <li>Restricted <code>test_camera_capture()</code> unittest to Linux envs only.</li> <li>Removed <code>return_generated_frames_path()</code> method support for Linux envs. </li> <li>Pinned jinja2 <code>3.1.0</code> or above breaking mkdocs. <ul> <li><code>jinja2&gt;=3.1.0</code> breaks mkdocs (mkdocs/mkdocs#2799), therefore pinned jinja2 version to <code>&lt;3.1.0</code>.</li> </ul> </li> </ul> </li> <li> Bash Script:<ul> <li>Updated to latest FFmpeg Static Binaries links. <ul> <li>Updated download links to abhiTronix/ffmpeg-static-builds * hosting latest available versions.</li> <li>Updated date/version tag to <code>12-07-2022</code>.</li> <li>Removed depreciated binaries download links and code.</li> </ul> </li> </ul> </li> <li> Setup:<ul> <li>Bumped version to <code>0.2.1</code>.</li> </ul> </li> <li> Docs:<ul> <li>Updated <code>changelog.md</code>.</li> </ul> </li> </ul> Breaking Updates/Changes <ul> <li> Implement support for live input devices/sources.<ul> <li><code>source</code> parameter now accepts device name or path.</li> <li>Added <code>source_demuxer</code> parameter to specify demuxer for live input devices/sources.</li> <li>Implemented Automated inserting of <code>-f</code> FFmpeg parameter whenever <code>source_demuxer</code> is specified by the user.</li> </ul> </li> </ul> Bug-fixes <ul> <li> Sourcer API:<ul> <li>Fixed Nonetype value bug in <code>source_demuxer</code> assertion logic.</li> <li>Fixed typos in parameter names.</li> <li>Added missing import.</li> </ul> </li> <li> FFhelper API:<ul> <li>Logged error message on metadata extraction failure.</li> <li>Fixed bug with <code>get_supported_demuxers</code> not detecting name patterns with commas.</li> <li>Removed redundant logging.</li> </ul> </li> <li> CI:<ul> <li>Fixed critical permission bug causing  <code>v4l2loopback</code> to fail on Github Actions Linux envs. <ul> <li>Elevated privileges to <code>root</code> by adding <code>sudo</code> to all commands(including bash scripts and python commands).</li> <li>Updated vidgear dependency to pip install from its git <code>testing</code> branch with recent bug fixes.</li> <li>Replaced relative paths with absolute paths in unit tests.</li> </ul> </li> <li>Fixed WriteGear API unable to write frames due to permission errors.</li> <li>Fixed <code>test_source_playback()</code> test failing on Darwin envs with OLD FFmpeg binaries.<ul> <li>Removed <code>custom_ffmpeg</code> value for Darwin envs.</li> </ul> </li> <li>Fixed various naming typos.</li> <li>Fixed missing APT dependencies. </li> </ul> </li> </ul> Pull Requests <ul> <li>PR #17</li> </ul>"},{"location":"changelog/#v020-2022-03-21","title":"v0.2.0 (2022-03-21)","text":"New Features <ul> <li> Sourcer API:<ul> <li>Added a new <code>source_audio_samplerate</code> metadata parameter:<ul> <li>Re-implemented  <code>__extract_audio_bitrate</code> internal function from scratch as <code>__extract_audio_bitrate_nd_samplerate</code>.<ul> <li>Implemented new algorithm to extract both extract both audio bitrate and samplerate from given source.</li> <li>Updated regex patterns according to changes.</li> </ul> </li> <li>Updated <code>__contains_video</code> and <code>__contains_audio</code> logic to support new changes.</li> </ul> </li> <li>Added metadata extraction support:<ul> <li>Added <code>retrieve_metadata</code> class method to Sourcer API for extracting source metadata as python dictionary.<ul> <li>Populated private source member values in dictionary with distinct keys.</li> </ul> </li> </ul> </li> <li>Added new <code>-force_validate_source</code> attribute to Sourcer API's <code>sourcer_params</code> dict parameter for special cases.</li> <li>Implemented check whether <code>probe_stream()</code> called or not in Sourcer API.</li> </ul> </li> <li> FFdecoder API:<ul> <li>Added metadata extraction and updation support:<ul> <li>Added <code>metadata</code> property object function to FFdecoder API for retrieving source metadata form Sourcer API as dict and return it as JSON dump for pretty printing.<ul> <li>Added Operational Mode as read-only property in metadata.</li> </ul> </li> <li>Added <code>metadata</code> property object with <code>setter()</code> method for updating source metadata with user-defined dictionary.<ul> <li>Implemented way to manually alter metadata keys and values for custom results.</li> </ul> </li> </ul> </li> </ul> </li> <li> Docs:<ul> <li>Added new comprehensive documentation with Mkdocs:<ul> <li>Added new image assets:<ul> <li>Added new Deffcode banner image, logo and tagline</li> <li>Added new icon ICO file with each layer of the favicon holds a different size of the image.</li> <li>Added new png images for best compatibility with different web browsers.</li> </ul> </li> <li>Added new docs files: <ul> <li>Added new index.md with introduction to project.</li> <li>Added new changelog.md.</li> <li>Added license.md</li> <li>Added new index.md with instructions for contributing in DeFFcode.<ul> <li>Added <code>issue.md</code> with Issue Contribution Guidelines.</li> <li>Added <code>PR.md</code> with PR Contribution Guidelines.</li> </ul> </li> <li>Added new <code>custom.js</code> to add gitter sidecard support.</li> <li>Added new <code>custom.css</code> that brings standard and quality visual design experience to DeFFcode docs.<ul> <li>Added new admonitions <code>new</code> and <code>alert</code>.</li> </ul> </li> <li>Added separate LICENSE(under CC creative commons) and REAME.md for assets.</li> <li>Added new <code>main.html</code> extending <code>base.html</code> for defining custom site metadata.</li> <li>Added deFFcode banner image to metadata.</li> <li>Added twitter card and metadata.</li> <li>Added version warning for displaying a warning when the user visits any other version.</li> <li>Added footer sponsorship block.</li> <li>Added gitter card official JS script dist.</li> <li>Added new custom <code>404.html</code> to handle HTTP status code <code>404</code> Not Found.<ul> <li>Implemented custom theming with new CSS style.</li> <li>Added custom 404 image asset.</li> </ul> </li> <li>Added new <code>index.md</code> with DeFFcode Installation notes.<ul> <li>Added info about Supported Systems, Supported Python legacies, Prerequisites, Installation instructions.</li> <li>Added Pip and Source Installation instructions.</li> </ul> </li> <li>Added new <code>ffmpeg_install.md</code> with machine-specific instructions for FFmpeg installation.</li> <li>Added new <code>index.md</code> with different ways to help DeFFcode, other users, and the author.<ul> <li>Added info about Starring and Watching DeFFcode on GitHub, Helping with open issues etc.</li> <li>Added Tweeter intent used for tweeting <code>#deffode</code> hastags easily.</li> <li>Added Kofi Donation link button.</li> <li>Added author contact links and left align avatar image.</li> </ul> </li> <li>Added new <code>get_help.md</code> to get help with DeFFcode.<ul> <li>Added DeFFcode gitter community link.</li> <li>Added other helpful links.</li> </ul> </li> </ul> </li> <li>Added new assets folders.</li> <li>Added Basic Recipes with basic.md </li> <li>Added Advanced Recipes with advanced.md </li> <li>Added all API References. <ul> <li>Added <code>mkdocstrings</code> automatic documentation from sources.</li> <li>Added new <code>index.md</code> for FFdecoder API with its description and explaining its API.</li> <li>Added new <code>index.md</code> for Sourcer API with its description and explaining its API.</li> <li>Added ffhelper methods API references.</li> <li>Added utils methods API references.</li> </ul> </li> <li>Added all API Parameters. <ul> <li>Added new <code>params.md</code> for FFdecoder API explaining all its parameters.</li> <li>Added new <code>params.md</code> for Sourcer API explaining all its parameters.</li> <li>Added Mkdocs support with mkdocs.yml </li> </ul> </li> <li>Implemented new <code>mkdocs.yml</code> with relevant parameters.<ul> <li>Added extended material theme with overridden parts.</li> <li>Added site metadata with site_name, site_url, site_author, site_description, repo_name, repo_url, edit_uri, copyright etc.</li> <li>Added navigation under sections for easily accessing each document.</li> <li>Implemented Page tree for DeFFcode docs.</li> <li>Added features like navigation.tracking, navigation.indexes, navigation.top, search.suggest, search.highlight, search.share, content.code.annotate.</li> <li>Added separate palette [default]light(with primary:green accent: dark green) and [slate]dark(with primary:teal accent: light green) mode.</li> <li>Added Color palette toggle switch with icon <code>material/home-lightning-bolt</code>.</li> <li>Added support for all pymarkdown-extensions.</li> <li>Added google fonts for text: <code>Quicksand</code> and code: <code>Fira Code</code>.</li> <li>Added custom logo and icon for DeFFcode.</li> <li>Added support for plugins like search, git-revision-date-localized, minify.</li> <li>Added support for <code>mkdocstrings</code> plugin for auto-built API references.<ul> <li>Added python handler for parsing python source-code to <code>mkdocstrings</code>.</li> <li>Improved source-code docs for compatibility with <code>mkdocstrings</code>.</li> </ul> </li> <li>Added support for extensions like <code>admonition</code>, <code>attr_list</code>, <code>codehilite</code>, <code>def_list</code>, <code>footnotes</code>, <code>meta</code>, and <code>toc</code>.</li> <li>Added social icons and links.</li> <li>Added custom <code>extra_css</code> and <code>extra_javascript</code>.</li> <li>Added support for <code>en</code> (English) language.</li> </ul> </li> <li>Added new badges to README.md for displaying current status of CI jobs and coverage.</li> <li>Added Roadmap to README.md</li> </ul> </li> </ul> </li> <li> CI:<ul> <li>Automated CI support for different environments:<ul> <li>Implemented auto-handling of dependencies installation, unit testing, and coverage report uploading.</li> <li>Added GitHub Action workflow for Linux envs:<ul> <li>Added and configured <code>CIlinux.yml</code> to enable GitHub Action workflow for Linux-based Testing Envs.</li> <li>Added <code>3.7+</code> python-versions to build matrix.</li> <li>Added code coverage through <code>codecov/codecov-action@v2</code> workflow for measuring unit-tests effectiveness.<ul> <li>Implemented behavior to about coverage upload on timeout(error code <code>124</code>) in pytests.</li> </ul> </li> </ul> </li> <li>Added Appveyor workflow for Windows envs: <ul> <li>Add and configured <code>appveyor.yml</code> to enable Appveyor workflow for Windows-based Testing Envs.</li> <li>Added <code>3.7+</code> 64-bit python-versions to build matrix.</li> <li>Enabled <code>fast_finish</code> to exit immediately on error.</li> </ul> </li> <li>Added Azure-Pipelines workflow for MacOS envs: <ul> <li>Add and configured <code>azure-pipelines.yml</code> to enable Azure-Pipelines workflow for MacOS-based Testing Envs.</li> <li>Added code coverage through <code>codecov</code> workflow for measuring unit-tests effectiveness.<ul> <li>Added online auto validation of <code>codecov</code> bash script using <code>SH256SUM</code> and <code>sig</code> files as recommended.</li> </ul> </li> <li>Implemented behavior to about coverage upload on timeout(error code <code>124</code>) in pytests.</li> <li>Added <code>3.7+</code> python-versions to build matrix.</li> </ul> </li> <li>Added automated flake8 testing to discover any anomalies in code.</li> <li>Added <code>master</code> branches for triggering CI.</li> </ul> </li> <li>Implement new automated Docs Building and Deployment on <code>gh-pages</code> through GitHub Actions workflow:<ul> <li>Added new workflow yaml <code>docs_deployer.yml</code> for automated docs deployment.</li> <li>Added different jobs with ubuntu-latest environement to build matrix.</li> <li>Added <code>actions/checkout@v2</code> for repo checkout and <code>actions/setup-python@v2</code> for python environment.</li> <li>Pinned python version to <code>3.8</code> for python environment in docs building.</li> <li>Added <code>GIT_TOKEN</code>, <code>GIT_NAME</code>, <code>GIT_EMAIL</code> environment variables through secrets.</li> <li>Added Mkdocs Material theme related python dependencies and environments.</li> <li>Added push on <code>master</code> and <code>dev</code> branch <code>release</code> with <code>published</code> as triggers.</li> <li>Pinned <code>mkdocstrings==0.17.0</code>.</li> </ul> </li> <li>Added new Automated Docs Versioning:<ul> <li>Implemented Docs versioning through <code>mike</code>.</li> <li>Separate new workflow steps to handle different versions.</li> <li>Added step to auto-create <code>RELEASE_NAME</code> environment variable from DeFFcode version file.</li> <li>Update docs deploy workflow to support <code>latest</code>, <code>release</code> and <code>dev</code> builds.</li> <li>Added automatic release version extraction from GitHub events.</li> </ul> </li> <li>Added Skip Duplicate Actions Workflow to DeFFcode Docs Deployer:<ul> <li>Added Skip Duplicate Actions(<code>fkirc/skip-duplicate-actions@master</code>) Workflow to DeFFcode Docs Deployer to prevent redundant duplicate workflow-runs.</li> </ul> </li> </ul> </li> <li> Maintenance: <ul> <li>New DeFFcode project issue and PR templates:<ul> <li>Added PR template:<ul> <li>Added a pull request template(<code>PULL_REQUEST_TEMPLATE.md</code>) for project contributors to automatically see the template's contents in the pull request body.</li> <li>Added Brief Description, Requirements / Checklist, Related Issue, Context, Types of changes blocks.</li> </ul> </li> <li>Added Proposal, Bug-Report and Question templates:<ul> <li>Created an <code>ISSUE_TEMPLATE</code> subdirectory to contain multiple issue templates.</li> <li>Add manually-created Proposal(<code>proposal.md</code>) and Question(<code>question.md</code>) issue template for project contributors to automatically see the template's contents in the issue body.<ul> <li>Added Brief Description, Acknowledgment, Context, Current Environment, Any Other Information like blocks.</li> </ul> </li> <li>Add an manually-created Bug Report(<code>bug_report.md</code>) issue template to <code>ISSUE_TEMPLATE</code> subdirectory for project contributors to automatically see the template's contents in the issue body.<ul> <li>Added Brief Description, Acknowledgment, Context, Current Environment, Expected Behavior, Actual Behavior, Possible Fix, Steps to reproduce, Miscellaneous like blocks.</li> </ul> </li> <li>Added YAML frontmatter to each issue template to pre-fill the issue title, automatically add labels and assignees, and give the template a name and description.</li> <li>Added a <code>config.yml</code> file to the <code>.github/ISSUE_TEMPLATE</code> folder to customize the issue template chooser that people see when creating a new issue.</li> <li>Set <code>blank_issues_enabled</code> parameter to <code>false</code> to encourage contributors to use issue templates.</li> <li>Added <code>contact_links</code> parameter with gitter community link to receive regular issues outside of GitHub.</li> </ul> </li> <li>Added new <code>FUNDING.yml</code> with ko-fi donation link.</li> <li>Added <code>.gitattributes</code> for DeFFcode, that set the default behavior, in case people don't have <code>core.autocrlf</code> set.</li> <li>Imported Codecov config(<code>codecov.yml</code>) from vidgear to modify coverage parameters.</li> </ul> </li> </ul> </li> <li> Tests:<ul> <li>Added DeFFcode unit tests with <code>pytest</code>:<ul> <li>Added <code>essential.py</code> for defining all essential functions necessary for DeFFcode unit tests.</li> <li>Added <code>return_static_ffmpeg</code>, <code>remove_file_safe</code>, <code>return_testvideo_path</code>, return_generated_frames_path, <code>actual_frame_count_n_frame_size</code> essential functions.</li> <li>Added <code>is_windows</code> global variable.</li> <li>Added related imports and logging.</li> <li>Added <code>__init__.py</code>.</li> <li>Moved all files to <code>test</code> folder.</li> <li>Added DeFFcode's utils unit tests with pytest. <ul> <li>Added new <code>test_loggerhandler</code> and <code>test_dict2Args</code> tests.</li> </ul> </li> <li>Added DeFFcode's ffhelper unit tests with pytest. <ul> <li>Added new <code>test_ffmpeg_binaries_download</code>, <code>test_validate_ffmpeg</code>, <code>test_get_valid_ffmpeg_path</code>, <code>test_check_sp_output</code>, <code>test_is_valid_url</code>, <code>test_is_valid_image_seq</code>, and <code>test_validate_imgseqdir</code> parametrize tests.</li> </ul> </li> <li>Added DeFFcode's Sourcer API unit tests with pytest. <ul> <li>Added new <code>test_source</code> and <code>test_probe_stream_n_retrieve_metadata</code> parametrize tests.</li> </ul> </li> <li>Added DeFFcode's FFdecoder API unit tests with pytest. <ul> <li>Added new <code>test_source_playback</code>, <code>test_frame_format</code>, <code>test_metadata</code>, <code>test_seek_n_save</code>,  and <code>test_FFdecoder_params</code> parametrize unit tests.</li> </ul> </li> <li>Added related imports and logging.</li> <li>Added unit test for <code>delete_file_safe</code> utils function.</li> </ul> </li> </ul> </li> <li> Bash: <ul> <li>\ud83d\udd27 Imported prepare_dataset.sh from vidgear for downloading pytest datasets to <code>temp</code> dir.</li> </ul> </li> </ul> Updates/Improvements <ul> <li> FFdecoder API:<ul> <li>Removed redundant forcing <code>-r</code> FFmpeg parameter for image sequences as source.</li> <li>Removed redundant checks on <code>-vf</code> FFmpeg parameter.</li> <li>FFmpeg parameter <code>-s</code> will be discarded in favor of <code>-custom_resolution</code> attribute.</li> <li>Replaced <code>-constant_framerate</code> with FFmpeg <code>-framerate</code> attribute.</li> <li>Replaced <code>-custom_source_params</code> with correct <code>-custom_sourcer_params</code> attribute.</li> <li>Renamed <code>operational_mode</code> metadata parameter to <code>ffdecoder_operational_mode</code>.</li> </ul> </li> <li> Sourcer API:<ul> <li>Converted all Sourcer APIs public available variables into private ones for stability.</li> <li>All Sourcer's publicly accessed variable metadata values in FFdecoder, therefore replaced with dictionary counterparts.</li> <li>Moved FFmpeg path validation and handling to Sourcer from FFdecoder API.</li> <li>Moved <code>-ffmpeg_download_path</code> dictionary attribute to Sourcer API's <code>sourcer_params</code> parameter.</li> <li>Moved dependencies and related functions.</li> </ul> </li> <li> CI:<ul> <li>Excluded <code>dev</code> branch from triggering workflow on any environment. <ul> <li>Updated yaml files to exclude beta <code>dev</code> branch from  triggering workflow on any environment.</li> <li>Restricted codecov  to use only <code>master</code> branch.</li> </ul> </li> <li>Re-implemented <code>fkirc/skip-duplicate-actions@master</code> to Skip individual deploy steps instead of Skip entire jobs</li> </ul> </li> <li> Docs:<ul> <li>Updated PR.md <ul> <li>Added instructions to download <code>prepare_dataset.sh</code> using curl.</li> <li>Updated dependencies for <code>pytest</code>.</li> </ul> </li> <li>Updated advanced.md <ul> <li>Updated generating Video from Image sequence to save video using OpenCV writer instead of WriteGear API.</li> <li>Added <code>frame_format=\"bgr24\"</code>and additional instructions regarding OpenCV writer.</li> <li>Updated example codes with new changes.</li> <li>Rearranged examples placement.</li> </ul> </li> <li>Updates to custom.css <ul> <li>Added donation sponsor link in page footer with heart animation.</li> <li>Added bouncing heart animation through pure CSS.</li> <li>Added Bold property to currently highlighted link in Navigation Bar.</li> <li>Updated Navigation Bar title font size.</li> <li>Updated version list text to uppercase and bold.</li> <li>Updated icon for task list unchecked.</li> <li>Added more top-padding to docs heading.</li> <li>Updated Block quote symbol and theming.</li> <li>Updated Custom Button theming to match docs.</li> <li>Added new custom classes to create shadow effect in dark mode for better visibility.</li> <li>Updated dark mode theme \"slate\" hue to 285.</li> </ul> </li> <li>Updated admonitions colors.</li> <li>Updated gitter sidecard UI colors and properties.</li> <li>Reflected recent changes in Sourcer and FFdecoder API's metadata.</li> <li>Updated sample code formatting from <code>sh</code> to <code>json</code>.</li> <li>Added missing docs for <code>delete_file_safe</code> utils function.</li> <li>Updated Download Test Datasets instructions.</li> <li>Updated contribution guidelines and installation docs with related changes.</li> <li>Updated License Notice.</li> <li>Updated code comments.</li> <li>Updated logging messages.</li> <li>Updated Deffcode Logo and Tagline to be dark-mode friendly.</li> <li>Adjusted asset alignment.</li> <li>Updated example code.</li> <li>Updated Installation instructions, Requirements and Roadmap.</li> <li>Corrected links to documents.</li> <li>Updated project description.</li> <li>Updated LICENSE.</li> <li>Updated indentation and code comments</li> <li>Re-aligned text and images in README.md</li> <li>Adjusted image classes and width.</li> </ul> </li> <li> Maintenance: <ul> <li>Updated LICENSE notice to add vidgear notice.</li> <li>Bumped version to <code>0.2.0</code></li> <li>Added useful comments for convenience.</li> </ul> </li> </ul> Breaking Updates/Changes <ul> <li>  Sourcer API will now raises Assertion error if <code>probe_stream()</code> not called before calling <code>retrieve_metadata()</code>.</li> <li>  Only <code>-framerate</code> values greater than <code>0.0</code> are now valid.</li> <li>  Renamed <code>decode_stream</code> to <code>probe_stream</code> in Sourcer API.</li> <li>  Any of video bitrate or video framerate are sufficient to validate if source contains valid video stream(s).</li> <li>  Any of audio bitrate or audio samplerate are sufficient to validate if source contains valid audio stream(s).</li> </ul> Bug-fixes <ul> <li> APIs:<ul> <li>Added missing <code>delete_file_safe</code> function in utils. <ul> <li>Imported <code>delete_file_safe</code> from vidgear to safely deletes files at given path.</li> </ul> </li> <li>Fixed forward slash bugs in regex patterns.</li> <li>Fixed IndexError when no bitrate was discovered in given source.</li> <li>Fixed FFmpeg subprocess pipeline not terminating gracefully in FFdecoder API.</li> <li>Fixed <code>__version__</code> not defined in DeFFcode's <code>__init__.py</code> that throws <code>AttributeError: module 'deffcode' has no attribute '__version__'</code> on query.<ul> <li>Added necessary import in <code>__init__.py</code>.</li> </ul> </li> </ul> </li> <li> Docs:<ul> <li>Fixed missing <code>\"-vcodec\": \"h264_cuvid\"</code> value in example code.</li> <li>Fixed typos in filenames in utils.py</li> <li>Fixed internal missing or invalid hyperlinks.</li> <li>Fixed improper docs context and typos.</li> <li>Fixed \"year\" in license notice.</li> <li>Fixed content spacing.</li> <li>Fixed Gitter Community Link in Mkdocs.</li> <li>Fixed typos in README.md.</li> <li>Fixed typos in license notices.</li> <li>Fixed typos in code comments.</li> <li>Fixed typos in example code.</li> </ul> </li> <li> CI:<ul> <li>Fixed missing FFmpeg dependency bug in GitHub Actions.</li> <li>Fixes typo in Docs Deployer yaml.</li> <li>Fixed if condition skipping when need is skipping</li> </ul> </li> <li> Maintenance: <ul> <li>Added missing imports.</li> <li>Fixed redundant conditional logics.</li> <li>Removed or Replaced redundant conditions and definitions.</li> <li>Fixed minor typos in templates.</li> </ul> </li> </ul> Pull Requests <ul> <li>PR #5</li> <li>PR #6</li> <li>PR #8</li> <li>PR #9</li> <li>PR #11</li> <li>PR #12</li> <li>PR #13</li> <li>PR #14</li> </ul>"},{"location":"changelog/#v010-2022-03-07","title":"v0.1.0 (2022-03-07)","text":"New Features <ul> <li>  Open-Sourced DeFFcode under the Apache 2.0 License.</li> <li> Added new Classes(APIs):<ul> <li>FFdecoder: Performant Real-time Video frames Generator for generating blazingly fast video frames(RGB ndarray by default).</li> <li>Sourcer: Extracts source video metadata (bitrate, resolution, framerate, nframes etc.) using its subprocess FFmpeg output.</li> </ul> </li> <li> Added new Helper functions:<ul> <li>ffhelper: Backend FFmpeg Wrapper that handles all subprocess transactions and gather data.</li> <li>utils: Handles all additional Utilizes required for functioning of DeFFcode.</li> </ul> </li> <li> First PyPi Release:<ul> <li>Released DeFFcode to Python Package Index (PyPI)</li> <li>Added <code>setup.py</code> and related metadata.</li> <li>Added <code>version.py</code></li> </ul> </li> <li> Docs: <ul> <li>Added abstract and related information in README.md</li> <li>Added installation instructions.</li> <li>Added preliminary usage examples.</li> </ul> </li> <li> Maintenance:<ul> <li>Added LICENSE.</li> <li>Added <code>.gitignore</code></li> </ul> </li> </ul> Updates/Improvements <ul> <li> Maintenance:<ul> <li>Bumped version to <code>0.1.0</code></li> <li>Updated LICENSE notice to add vidgear code usage notice.</li> </ul> </li> </ul> Breaking Updates/Changes <ul> <li> Fixed support for Python-3.7 and above legacies only.</li> </ul> Bug-fixes <ul> <li> Docs:<ul> <li>Fixed hyperlinks in README.</li> <li>Fixed indentation and spacing.</li> <li>Fixed typos and updated context.</li> <li>Removed dead code.</li> </ul> </li> </ul>"},{"location":"help/","title":"Helping Us","text":"<p>Liked DeFFcode? Would you like to help DeFFcode, other users, and the author?</p> <p>There are many simple ways to help us:</p>"},{"location":"help/#star-deffcode-on-github","title":"Star DeFFcode on GitHub","text":"<p>You can star  DeFFcode on GitHub: </p> <p>It helps us a lot by making it easier for others to find &amp; trust this library. Thanks!</p> <p> </p>"},{"location":"help/#help-others-with-issues-on-github","title":"Help others with issues on GitHub","text":"<p>You can see through any opened or pinned existing issues on our GitHub repository, and try helping others, wherever possible: </p> <p> </p>"},{"location":"help/#watch-the-github-repository","title":"Watch the GitHub repository","text":"<p>You can watch \ud83d\udc40 DeFFcode Activities on GitHub: </p> <p>When you watch a repository, you will be notified of all conversations for that repository, including when someone creates a new issue, or pushes a new pull request.</p> <p>You can try helping solving those issues, or give valuable feedback/review on new Pull Requests.</p> <p> </p>"},{"location":"help/#tweet-about-deffcode","title":"Tweet about DeFFcode","text":"<p>Tweet about DeFFcode and Spread the word \ud83d\udde3:</p> <p>Tweet #deffcode</p> <p>Let others know how you are using DeFFcode and why you like it!</p> <p> </p>"},{"location":"help/#helping-author","title":"Helping Author","text":"<p>Donations help keep DeFFcode's development alive and motivate me (as author). </p> <p>It is something I am doing with my own free time. But so much more needs to be done, and I need your help to do this. For just the price of a cup of coffee, you can make a difference </p> kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw(); <p>Thanks a million! </p> <p> </p>"},{"location":"help/#connect-with-author","title":"Connect with Author","text":"<p>You can connect with me, the author \ud83d\udc4b:</p> <p></p> <ul> <li>Follow author on GitHub: </li> <li>Follow author on Twitter: Follow @abhi_una12</li> <li>Get in touch with author on Linkedin: </li> </ul> <p> </p> <p> </p>"},{"location":"license/","title":"License","text":"<p>This library is released under the Apache 2.0 License.</p>"},{"location":"license/#copyright-notice","title":"Copyright Notice","text":"<pre><code>Copyright (c) 2021 Abhishek Thakur(@abhiTronix) &lt;abhi.una12@gmail.com&gt;\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n  http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n</code></pre>"},{"location":"contribution/","title":"Overview","text":""},{"location":"contribution/#contribution-overview","title":"Contribution Overview","text":"<p>Contributions are always welcomed  </p> <p>We'd love your contribution to DeFFcode in order to fix bugs or to implement new features!</p>"},{"location":"contribution/#submission-guidelines","title":"Submission Guidelines","text":"<ul> <li>Submitting an Issue Guidelines \u27b6</li> <li>Submitting Pull Request(PR) Guidelines \u27b6</li> </ul>"},{"location":"contribution/#submission-contexts","title":"Submission Contexts","text":""},{"location":"contribution/#got-a-question-or-problem","title":"Got a question or problem?","text":"<p>For quick questions, please refrain from opening an issue, instead you can reach us on Gitter community channel.</p>"},{"location":"contribution/#found-a-typo","title":"Found a typo?","text":"<p>There's no need to contribute for some typos. Just reach us on Gitter \u27b6 community channel, We will correct them in (less than) no time. </p>"},{"location":"contribution/#found-a-bug","title":"Found a bug?","text":"<p>If you encountered a bug, you can help us by submitting an issue in our GitHub repository. Even better, you can submit a Pull Request(PR) with a fix, but make sure to read the guidelines \u27b6.</p>"},{"location":"contribution/#request-for-a-featureimprovement","title":"Request for a feature/improvement?","text":"Subscribe to Github Repository <p>You can subscribe our GitHub Repository to receive notifications through email for new pull requests, commits and issues that are created in DeFFcode. Learn more about it here \u27b6</p> <p>You can request our GitHub Repository for a new feature/improvement based on the type of request:</p> <p>Please submit an issue with a proposal template for your request to explain how it benefits everyone in the community.</p> <ul> <li> <p>Major Feature Requests: If you require a major feature for DeFFcode, then first open an issue and outline your proposal so that it can be discussed. This will also allow us to better coordinate our efforts, prevent duplication of work, and help you to craft the change so that it is successfully accepted into the project. The purposed feature, if accepted, may take time based on its complexity and availability/time-schedule of our maintainers, but once it's completed, you will be notified right away. Please be patient! </p> </li> <li> <p>Minor Feature Requests:  Small features and bugs resolved on priority. You just have to submit an issue to our GitHub Repository.</p> </li> </ul> <p> </p>"},{"location":"contribution/PR/","title":"Submitting Pull Request(PR) Guidelines:","text":"<p>The following guidelines tells you how to submit a valid PR for DeFFcode:</p> <p>Working on your first Pull Request for DeFFcode?</p> <ul> <li>You can learn about \"How to contribute to an Open Source Project on GitHub\" from this doc \u27b6</li> <li>If you're stuck at something, please join our Gitter community channel. We will help you get started!</li> </ul> <p> </p>"},{"location":"contribution/PR/#clone-branch-for-pr","title":"Clone branch for PR","text":"<p>You can clone your Forked remote git to local and create your PR working branch as a sub-branch of latest <code>master</code> branch as follows:</p> <p>Make sure the <code>master</code> branch of your Forked repository is up-to-date with DeFFcode, before starting working on a Pull Request.</p> <pre><code># clone your forked repository(change with your username) and get inside\ngit clone https://github.com/{YOUR USERNAME}/DeFFcode.git &amp;&amp; cd DeFFcode\n\n# pull any recent updates\ngit pull\n\n# Now create your new branch with suitable name(such as \"subbranch_of_master\")\ngit checkout -b subbranch_of_master\n</code></pre> <p>Now after working with this newly created branch for your Pull Request, you can commit and push or merge it locally or remotely as usual.</p> <p> </p> <p> </p>"},{"location":"contribution/PR/#pr-submission-checklist","title":"PR Submission Checklist","text":"<p>There are some important checks you need to perform while submitting your Pull Request(s) for DeFFcode library:</p> <ul> <li> <p> Submit a Related Issue:</p> </li> <li> <p>The first thing you do is submit an issue with a proposal template for your work first and then work on your Pull Request.</p> </li> <li> <p> Submit a Draft Pull Request:</p> </li> <li> <p>Submit the draft pull request from the first day of your development.</p> </li> <li>Add a brief but descriptive title for your PR.</li> <li>Explain what the PR adds, fixes, or improves.</li> <li>In case of bug fixes, add a new unit test case that would fail against your bug fix.</li> <li>Provide output or screenshots, if you can.</li> <li>Make sure your pull request passed all the CI checks (triggers automatically on pushing commits against <code>master</code> branch). If it's somehow failing, then ask the maintainer for a review.</li> <li> <p>Click \"ready for review\" when finished.</p> </li> <li> <p> Test, Format &amp; lint code locally:</p> </li> <li> <p>Make sure to test, format, and lint the modified code locally before every commit. The details are discussed below \u27b6</p> </li> <li> <p> Make sensible commit messages:</p> </li> <li> <p>If your pull request fixes a separate issue number, remember to include <code>\"resolves #issue_number\"</code> in the commit message. Learn more about it here \u27b6.</p> </li> <li> <p>Keep the commit message concisely as much as possible at every submit. You can make a supplement to the previous commit with <code>git commit --amend</code> command.</p> </li> <li> <p> Perform Integrity Checks: </p> <p>Any duplicate pull request will be Rejected!</p> </li> <li> <p>Search GitHub if there's a similar open or closed PR that relates to your submission.</p> </li> <li>Check if your purpose code matches the overall direction of the DeFFcode APIs and improves it.</li> <li> <p>Retain copyright for your contributions, but also agree to license them for usage by the project and author(s) under the Apache 2.0 license \u27b6.</p> </li> <li> <p> Link your Issues:</p> <p>For more information on Linking a pull request to an issue, See this doc\u27b6</p> </li> <li> <p>Finally, when you're confident enough, make your pull request public. </p> </li> <li>You can link an issue to a pull request manually or using a supported keyword in the pull request description. It helps collaborators see that someone is working on the issue. For more information, see this doc\u27b6</li> </ul> <p> </p> <p> </p>"},{"location":"contribution/PR/#testing-formatting-linting","title":"Testing, Formatting &amp; Linting","text":"<p>All Pull Request(s) must be tested, formatted &amp; linted against our library standards as discussed below:</p>"},{"location":"contribution/PR/#requirements","title":"Requirements","text":"<p>Testing DeFFcode requires additional test dependencies and dataset, which can be handled manually as follows:</p> <ul> <li> <p> Install additional python libraries:</p> <p>You can easily install these dependencies via pip:</p> <pre><code># Install opencv(only if not installed previously)\n$ pip install opencv-python\n\n# install rest of dependencies\n$ pip install --upgrade flake8 black pytest vidgear[core]\n</code></pre> </li> <li> <p> Download Tests Dataset: </p> <p>To perform tests, you also need to download additional dataset (to your temp dir) by running <code>prepare_dataset.sh</code>  bash script as follows:</p> On Linux/MacOSOn Windows <pre><code>$ chmod +x scripts/bash/prepare_dataset.sh\n$ ./scripts/bash/prepare_dataset.sh\n</code></pre> <pre><code>$ sh scripts/bash/prepare_dataset.sh\n</code></pre> </li> </ul>"},{"location":"contribution/PR/#running-tests","title":"Running Tests","text":"<p>All tests can be run with <code>pytest</code>(in DeFFcode's root folder) as follows:</p> <pre><code>$ pytest -sv  #-sv for verbose output.\n</code></pre>"},{"location":"contribution/PR/#formatting-linting","title":"Formatting &amp; Linting","text":"<p>For formatting and linting, following libraries are used:</p> <ul> <li> <p> Flake8: You must run <code>flake8</code> linting for checking the code base against the coding style (PEP8), programming errors and other cyclomatic complexity:</p> <pre><code>$ flake8 {source_file_or_directory} --count --select=E9,F63,F7,F82 --show-source --statistics\n</code></pre> </li> <li> <p> Black:  DeFFcode follows <code>black</code> formatting to make code review faster by producing the smallest diffs possible. You must run it with sensible defaults as follows: </p> <pre><code>$ black {source_file_or_directory}\n</code></pre> </li> </ul> <p> </p> <p> </p>"},{"location":"contribution/PR/#frequently-asked-questions","title":"Frequently Asked Questions","text":"<p>Q1. Why do my changes taking so long to be Reviewed and/or Merged?</p> <p>Submission Aftermaths</p> <ul> <li>After your PR is merged, you can safely delete your branch and pull the changes from the main (upstream) repository.</li> <li>The changes will remain in <code>dev</code> branch until next DeFFcode version is released, then it will be merged into <code>master</code> branch.</li> <li>After a successful Merge, your newer contributions will be given priority over others. </li> </ul> <p>Pull requests will be reviewed by the maintainers and the rationale behind the maintainer\u2019s decision to accept or deny the changes will be posted in the pull request. Please wait for our code review and approval, possibly enhancing your change on request.</p> <p>Q2. Would you accept a huge Pull Request with Lots of Changes?</p> <p>First, make sure that the changes are somewhat related. Otherwise, please create separate pull requests. Anyway, before submitting a huge change, it's probably a good idea to open an issue in the DeFFcode Github repository to ask the maintainers if they agree with your proposed changes. Otherwise, they could refuse your proposal after you put all that hard work into making the changes. We definitely don't want you to waste your time!</p> <p> </p>"},{"location":"contribution/issue/","title":"Submitting an Issue Guidelines","text":"<p>If you've found a new bug or you've come up with some new feature which can improve the quality of the DeFFcode, then related issues are welcomed! But, Before you do, please read the following guidelines:</p> First Issue on GitHub? <p>You can easily learn about it from creating an issue wiki.</p> <p>Info</p> <p>Please note that your issue will be fixed much faster if you spend about half an hour preparing it, including the exact reproduction steps and a demo. If you're in a hurry or don't feel confident, it's fine to report issues with less details, but this makes it less likely they'll get fixed soon.</p>"},{"location":"contribution/issue/#search-the-docs-and-previous-issues","title":"Search the Docs and Previous Issues","text":"<ul> <li>Remember to first search GitHub for a open or closed issue that relates to your submission or already been reported. You may find related information and the discussion might inform you of workarounds that may help to resolve the issue. </li> <li>For quick questions, please refrain from opening an issue, as you can reach us on Gitter community channel.</li> <li>Also, go comprehensively through our dedicated FAQ &amp; Troubleshooting section.</li> </ul>"},{"location":"contribution/issue/#gather-required-information","title":"Gather Required Information","text":"<ul> <li>All DeFFcode APIs provides a <code>verbose</code> boolean flag in parameters, to log debugged output to terminal. Kindly turn this parameter <code>True</code> in the respective API for getting debug output, and paste it with your Issue. </li> <li>In order to reproduce bugs we will systematically ask you to provide a minimal reproduction code for your report. </li> <li>Check and paste, exact DeFFcode version by running command <code>python -c \"import deffcode; print(deffcode.__version__)\"</code>.</li> </ul>"},{"location":"contribution/issue/#follow-the-issue-template","title":"Follow the Issue Template","text":"<ul> <li>Please format your issue by choosing the appropriate template. </li> <li>Any improper/insufficient reports will be marked Invalid \u26d4, and if we don't hear back from you we may close the issue.</li> </ul>"},{"location":"contribution/issue/#raise-the-issue","title":"Raise the Issue","text":"<ul> <li>Add a brief but descriptive title for your issue.</li> <li>Keep the issue phrasing in context of the problem.</li> <li>Attach source-code/screenshots if you have one.</li> <li>Finally, raise it by choosing the appropriate Issue Template: Bug report \ud83d\udc1e, Idea \ud83d\udca1, Question \u2754.</li> </ul>"},{"location":"help/get_help/","title":"Getting Help","text":"Courtesy - tenor <p>Would you like to get help with DeFFcode?</p> <p>There are several ways to get help with DeFFcode:</p>"},{"location":"help/get_help/#join-our-gitter-community-channel","title":"Join our Gitter Community channel","text":"<p>Have you come up with some new idea \ud83d\udca1 or looking for the fastest way troubleshoot your problems</p> <p>Join and chat on our Gitter Community channel: </p> <p>There you can ask quick questions, swiftly troubleshoot your problems, help others, share ideas &amp; information, etc. </p> <p> </p>"},{"location":"help/get_help/#this-is-what-you-do-when","title":"This is what you do when...","text":"<ul> <li> Got a question or problem?</li> <li> Found a typo?</li> <li> Found a bug?</li> <li> Missing a feature/improvement?</li> </ul>"},{"location":"help/get_help/#reporting-an-issues","title":"Reporting an issues","text":"<p>Want to report a bug? Suggest a new feature?</p> <p>Before you do, please read our guidelines \u27b6</p> <p> </p>"},{"location":"help/get_help/#preparing-a-pull-request","title":"Preparing a Pull Request","text":"<p>Interested in contributing to DeFFcode?</p> <p>Before you do, please read our guidelines \u27b6</p> <p> </p>"},{"location":"installation/","title":"Overview","text":""},{"location":"installation/#installation-notes","title":"Installation Notes","text":""},{"location":"installation/#supported-systems","title":"Supported Systems","text":"<p>DeFFcode is well-tested and supported on the following systems(but not limited to), with python 3.7+ and pip installed:</p>  Upgrade your <code>pip</code> <p>It strongly advised to upgrade to latest pip before installing deffcode to avoid any undesired installation error(s).</p> <p>There are two mechanisms to upgrade <code>pip</code>:</p> <code>pip</code><code>ensurepip</code> <p>You can use existing <code>pip</code> to upgrade itself:</p> Install <code>pip</code> if not present <ul> <li>Download the script, from https://bootstrap.pypa.io/get-pip.py.</li> <li>Open a terminal/command prompt, <code>cd</code> to the folder containing the <code>get-pip.py</code> file and run:</li> </ul> Linux/MacOSWindows <pre><code>python get-pip.py\n</code></pre> <pre><code>py get-pip.py\n</code></pre> <p>More details about this script can be found in pypa/get-pip\u2019s README.</p> Linux/MacOSWindows <pre><code>python -m pip install pip --upgrade\n</code></pre> <pre><code>py -m pip install pip --upgrade\n</code></pre> <p>Python also comes with an <code>ensurepip</code> module1, which can easily upgrade/install <code>pip</code> in any Python environment.</p> Linux/MacOSWindows <pre><code>python -m ensurepip --upgrade\n</code></pre> <pre><code>py -m ensurepip --upgrade\n</code></pre> <ul> <li>Any  Linux distro released in 2016 or later</li> <li> Windows 7 or later</li> <li> MacOS 10.12.6 (Sierra) or later</li> </ul> <p> </p>"},{"location":"installation/#supported-python-legacies","title":"Supported Python legacies","text":"<p> Python 3.7+ are only supported legacies for installing DeFFcode <code>v0.1.0</code> and above.</p> <p> </p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p> DeFFcode APIs requires FFmpeg binaries to be installed for all of its core functionality.</p>"},{"location":"installation/#ffmpeg","title":"FFmpeg","text":"<p>When installing DeFFcode, FFmpeg is the only prerequisites you need to configure/install manually. You could easily do it by referring FFmpeg Installation doc.</p> <p> </p>"},{"location":"installation/#installation","title":"Installation","text":""},{"location":"installation/#a-installation-using-pip-recommended","title":"A. Installation using pip (Recommended)","text":"<p>Best option for easily getting stable DeFFcode installed.</p> <p>Installation is as simple as:</p>  Windows Installation <p>If you are using Windows, some of the commands given below, may not work out-of-the-box.</p> <p>A quick solution may be to preface every Python command with <code>python -m</code> like this:</p> <pre><code># Install latest stable release\npython -m pip install -U deffcode\n</code></pre> <p>And, If you don't have the privileges to the directory you're installing package. Then use <code>--user</code> flag, that makes pip install packages in your home directory instead:</p> <pre><code># Install latest stable release\npython -m pip install --upgrade --user deffcode\n</code></pre> <p>Or, If you're using <code>py</code> as alias for installed python, then:</p> <pre><code># Install latest stable release\npy -m pip install --upgrade --user deffcode\n</code></pre> <pre><code># Install latest stable release\npip install -U deffcode\n</code></pre> <p>And you can also download its wheel (<code>.whl</code>) package from our repository's releases section, thereby can be installed as follows:</p> <pre><code># Install latest release\npip install deffcode-0.2.0-py3-none-any.whl\n</code></pre> <p> </p>"},{"location":"installation/#b-installation-from-source","title":"B. Installation from Source","text":"<p>Best option for trying latest patches(maybe experimental), forking for Pull Requests, or automatically installing all prerequisites(with a few exceptions). </p> Installation using <code>dev</code> banch  <p>If you're looking for latest work-in-progress  enhancements or bug-fixes, then you want to checkout our beta <code>dev</code> branch with the following commands:</p> <p>The beta <code>dev</code> branch at times can be very unstable or even unusable, User discretion is advised!</p> <pre><code># clone the repository and get inside\ngit clone https://github.com/abhiTronix/deffcode.git &amp;&amp; cd deffcode\n\n# checkout the dev beta branch\ngit checkout dev\n\n# Install it\npip install -U .\n</code></pre>  Windows Installation <p>If you are using Windows, some of the commands given below, may not work out-of-the-box.</p> <p>A quick solution may be to preface every Python command with <code>python -m</code> like this:</p> <pre><code># Install latest beta branch\npython -m pip install -U .\n</code></pre> <p>And, If you don't have the privileges to the directory you're installing package. Then use <code>--user</code> flag, that makes pip install packages in your home directory instead:</p> <pre><code># Install latest beta branch\npython -m pip install --upgrade --user .\n</code></pre> <p>Or, If you're using <code>py</code> as alias for installed python, then:</p> <pre><code># Install latest beta branch\npy -m pip install --upgrade --user .\n</code></pre> <pre><code># clone the repository and get inside\ngit clone https://github.com/abhiTronix/deffcode.git &amp;&amp; cd deffcode\n\n# Install it\npip install -U .\n</code></pre> <p> </p> <ol> <li> <p> The <code>ensurepip</code> module is missing/disabled on Ubuntu. Use <code>pip</code> method only.\u00a0\u21a9</p> </li> </ol>"},{"location":"installation/ffmpeg_install/","title":"FFmpeg Installation Doc","text":"<p> DeFFcode APIs requires FFmpeg binaries to be installed for all of its core functionality.</p> <p>You can following machine-specific instructions for its configuration/installation:</p> <p>DeFFcode APIs will throw RuntimeError, if they failed to detect valid FFmpeg executables on your system.</p> <p>Enable verbose (<code>verbose=True</code>) for debugging FFmpeg validation process.</p> <p> </p>"},{"location":"installation/ffmpeg_install/#linux-ffmpeg-installation","title":"Linux FFmpeg Installation","text":"<p>DeFFcode APIs supports Auto-Detection and Manual Configuration methods on a Linux OS machines:</p>"},{"location":"installation/ffmpeg_install/#a-auto-detection","title":"A. Auto-Detection","text":"<p>This is a recommended approach on Linux Machines</p> <p>If DeFFcode APIs do not receive any input from the user on <code>custom_ffmpeg</code> parameter, then they try to auto-detect the required FFmpeg installed binaries through a validation test that employs <code>subprocess</code> python module on the Linux OS systems.</p> <p>You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6</p>"},{"location":"installation/ffmpeg_install/#b-manual-configuration","title":"B. Manual Configuration","text":"<ul> <li> <p>Download: You can also manually download the latest Linux Static Binaries (based on your machine architecture) from the link below:</p> <p>  Linux Static Binaries: http://johnvansickle.com/ffmpeg/ </p> </li> <li> <p>Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables(<code>for e.g 'ffmpeg/bin'</code>)  or path of <code>ffmpeg</code> executable itself to the <code>custom_ffmpeg</code> parameter in the DeFFcode APIs.</p> <p>If binaries were not found at the manually specified path, DeFFcode APIs will throw RuntimeError!</p> </li> </ul> <p> </p> <p> </p>"},{"location":"installation/ffmpeg_install/#windows-ffmpeg-installation","title":"Windows FFmpeg Installation","text":"<p>DeFFcode APIs supports Auto-Installation and Manual Configuration methods on Windows OS machines:</p>"},{"location":"installation/ffmpeg_install/#a-auto-installation","title":"A. Auto-Installation","text":"<p>This is a recommended approach on Windows Machines</p> <p>If DeFFcode APIs do not receive any input from the user on <code>custom_ffmpeg</code> parameter, then they try to auto-generate the required FFmpeg Static Binaries from our dedicated Github Server into the temporary directory(e.g. <code>C:\\Temp</code>) of your machine on the Windows OS systems.</p> <p>Active Internet connection is required while downloading required FFmpeg Static Binaries from our dedicated Github Server onto your  Windows machine.</p> Important Information regarding Auto-Installation <ul> <li> <p>The files downloaded to a temporary directory (e.g. <code>C:\\TEMP</code>), may get erased if your machine shutdowns/restarts in some cases.</p> </li> <li> <p>You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through exclusive <code>-ffmpeg_download_path</code> attribute in Sourcer API.</p> How to use  <code>-ffmpeg_download_path</code> attribute in FFdecoder API? <p><code>-ffmpeg_download_path</code> is also available in FFdecoder API through the <code>-custom_sourcer_params</code> attribute of its <code>ffparams</code> dictionary parameter.</p> </li> <li> <p>If binaries were found at the specified path, DeFFcode APIs automatically skips the Auto-Installation step.</p> </li> <li> <p>If the required FFmpeg static binary fails to download, extract, or validate during Auto-Installation, then DeFFcode APIs will exit with RuntimeError!</p> </li> </ul>"},{"location":"installation/ffmpeg_install/#b-manual-configuration_1","title":"B. Manual Configuration","text":"<ul> <li> <p>Download: You can also manually download the latest Windows Static Binaries (based on your machine arch(x86/x64)) from the link below:</p> <p>  Windows Static Binaries: https://ffmpeg.org/download.html#build-windows </p> </li> <li> <p>Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables(<code>for e.g 'C:/foo/Downloads/ffmpeg/bin'</code>) or path of <code>ffmpeg.exe</code> executable itself to the <code>custom_ffmpeg</code> parameter in the DeFFcode APIs.</p> <p>If binaries were not found at the manually specified path, DeFFcode APIs will throw RuntimeError!</p> </li> </ul> <p> </p> <p> </p>"},{"location":"installation/ffmpeg_install/#macos-ffmpeg-installation","title":"MacOS FFmpeg Installation","text":"<p>DeFFcode APIs supports Auto-Detection and Manual Configuration methods on MacOS OS machines:</p>"},{"location":"installation/ffmpeg_install/#a-auto-detection_1","title":"A. Auto-Detection","text":"<p>This is a recommended approach on MacOS Machines</p> <p>If DeFFcode APIs do not receive any input from the user on <code>custom_ffmpeg</code> parameter, then they try to auto-detect the required FFmpeg installed binaries through a validation test that employs <code>subprocess</code> python module on the MacOS systems.</p> <p>You can easily install FFmpeg on your MacOS machine by following this tutorial \u27b6</p>"},{"location":"installation/ffmpeg_install/#b-manual-configuration_2","title":"B. Manual Configuration","text":"<ul> <li> <p>Download: You can also manually download the latest MacOS Static Binaries (only x64 Binaries) from the link below:</p> <p>  MacOS Static Binaries: https://ffmpeg.org/download.html#build-mac </p> </li> <li> <p>Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables(<code>for e.g 'ffmpeg/bin'</code>) or path of <code>ffmpeg</code> executable itself to the <code>custom_ffmpeg</code> parameter in the DeFFcode APIs.</p> <p>If binaries were not found at the manually specified path, DeFFcode APIs will throw RuntimeError!</p> </li> </ul> <p> </p>"},{"location":"recipes/advanced/","title":"Advanced Recipes","text":"<p>The following challenging recipes will take your skills to the next level and will give access to new DeFFcode techniques, tricky examples, and advanced FFmpeg parameters:</p> Courtesy - tenor <p>Refer Basic Recipes first!</p> <p>If you're just getting started, check out the Beginner's Basic Recipes  first before trying these advanced recipes.</p> Any proficiency with OpenCV-Python will be Helpful <p>Any proficiency with OpenCV-Python (Python API for OpenCV) surely help you with these recipes. </p> Wanna suggest any improvements or additional recipes? <p>Please feel free to suggest any improvements or additional recipes on our Gitter community channel \u27b6</p> <p> </p>"},{"location":"recipes/advanced/#advanced-decoding-recipes","title":"Advanced  Decoding Recipes","text":"<ul> <li>  Decoding Live Virtual Sources<ul> <li>Generate and Decode frames from Sierpinski pattern</li> <li>Generate and Decode frames from Test Source pattern</li> <li>Generate and Decode frames from Gradients with custom Text effect</li> <li>Generate and Decode frames from Mandelbrot test pattern with vectorscope &amp; waveforms</li> <li>Generate and Decode frames from Game of Life Visualization</li> </ul> </li> <li>  Decoding Live Feed Devices<ul> <li>Capturing and Previewing frames from a Webcam using Custom Demuxer</li> <li>Capturing and Previewing frames from your Desktop (Screen Recording)</li> </ul> </li> <li>  Hardware-Accelerated Video Decoding<ul> <li>CUVID-accelerated Hardware-based Video Decoding and Previewing</li> <li>CUDA-accelerated Hardware-based Video Decoding and Previewing</li> </ul> </li> </ul>"},{"location":"recipes/advanced/#advanced-transcoding-recipes","title":"Advanced  Transcoding Recipes","text":"<ul> <li>  Transcoding Live Complex Filtergraphs<ul> <li>Transcoding video with Live Custom watermark image overlay</li> <li>Transcoding video from sequence of Images with additional filtering</li> </ul> </li> <li>  Transcoding Video Art with Filtergraphs<ul> <li>Transcoding video art with YUV Bitplane Visualization</li> <li>Transcoding video art with Jetcolor effect </li> <li>Transcoding video art with Ghosting effect</li> <li>Transcoding video art with Pixelation effect</li> </ul> </li> <li>  Hardware-Accelerated Video Transcoding<ul> <li>CUDA-accelerated Video Transcoding with OpenCV's VideoWriter API</li> <li>CUDA-NVENC-accelerated Video Transcoding with WriteGear API</li> <li>CUDA-NVENC-accelerated End-to-end Lossless Video Transcoding with WriteGear API</li> </ul> </li> </ul>"},{"location":"recipes/advanced/#advanced-metadata-recipes","title":"Advanced  Metadata Recipes","text":"<ul> <li>  Updating Video Metadata<ul> <li>Added new attributes to metadata in FFdecoder API</li> <li>Overriding source video metadata in FFdecoder API</li> </ul> </li> </ul>"},{"location":"recipes/advanced/decode-hw-acceleration/","title":"Hardware-Accelerated Video Decoding","text":"<p>FFmpeg offer access to dedicated GPU hardware with varying support on different platforms for performing a range of video-related tasks to be completed faster or using less of other resources (particularly CPU).</p> <p>By default, DeFFcode's FFdecoder API uses the Input Source's video-decoder (extracted using Sourcer API) itself for decoding its input. However, you could easily change the video-decoder to your desired specific supported Video-Decoder using FFmpeg options by way of its <code>ffparams</code> dictionary parameter. This feature provides easy access to GPU Accelerated Hardware Decoder in FFdecoder API that will generate faster video frames while using little to no CPU power, as opposed to CPU intensive Software Decoders.</p> <p>We'll discuss its Hardware-Accelerated Video Decoding capabilities briefly in the following recipes:</p> <p> </p> <p>DeFFcode APIs requires FFmpeg executable</p> <p>DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality, and any failure in detection will raise <code>RuntimeError</code> immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation.</p> Additional Python Dependencies for following recipes <p>Following recipes requires additional python dependencies which can be installed easily as below:</p> <ul> <li> <p> OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via <code>pip</code>:</p> OpenCV installation from source <p>You can also follow online tutorials for building &amp; installing OpenCV on Windows, Linux, MacOS and Raspberry Pi machines manually from its source. </p> <p> Make sure not to install both pip and source version together. Otherwise installation will fail to work!</p> Other OpenCV binaries <p>OpenCV maintainers also provide additional binaries via pip that contains both main modules and contrib/extra modules <code>opencv-contrib-python</code>, and for server (headless) environments like <code>opencv-python-headless</code> and <code>opencv-contrib-python-headless</code>. You can also install any one of them in similar manner. More information can be found here.</p> <pre><code>pip install opencv-python       </code></pre> </li> </ul> <p>Always use FFdecoder API's <code>terminate()</code> method at the end to avoid undesired behavior.</p> Never name your python script <code>deffcode.py</code> <p>When trying out these recipes, never name your python script <code>deffcode.py</code> otherwise it will result in <code>ModuleNotFound</code> error.</p> <p> </p>"},{"location":"recipes/advanced/decode-hw-acceleration/#cuvid-accelerated-hardware-based-video-decoding-and-previewing","title":"CUVID-accelerated Hardware-based Video Decoding and Previewing","text":"Example Assumptions <p>Please note that following recipe explicitly assumes:</p> <ul> <li>You're running  Linux operating system with a supported NVIDIA GPU.</li> <li> <p>You're using FFmpeg 4.4 or newer, configured with at least <code>--enable-nonfree --enable-cuda-nvcc --enable-libnpp --enable-cuvid --enable-nvenc</code> configuration flags during compilation. For compilation follow these instructions \u27b6</p> </li> <li> <p> Using <code>h264_cuvid</code> decoder: Remember to check if your FFmpeg compiled with H.264 CUVID decoder support by executing following one-liner command in your terminal, and observing if output contains something similar as follows:</p> Verifying H.264 CUVID decoder support in FFmpeg <pre><code>$ ffmpeg  -hide_banner -decoders | grep cuvid\n\nV..... av1_cuvid            Nvidia CUVID AV1 decoder (codec av1)\nV..... h264_cuvid           Nvidia CUVID H264 decoder (codec h264)\nV..... hevc_cuvid           Nvidia CUVID HEVC decoder (codec hevc)\nV..... mjpeg_cuvid          Nvidia CUVID MJPEG decoder (codec mjpeg)\nV..... mpeg1_cuvid          Nvidia CUVID MPEG1VIDEO decoder (codec mpeg1video)\nV..... mpeg2_cuvid          Nvidia CUVID MPEG2VIDEO decoder (codec mpeg2video)\nV..... mpeg4_cuvid          Nvidia CUVID MPEG4 decoder (codec mpeg4)\nV..... vc1_cuvid            Nvidia CUVID VC1 decoder (codec vc1)\nV..... vp8_cuvid            Nvidia CUVID VP8 decoder (codec vp8)\nV..... vp9_cuvid            Nvidia CUVID VP9 decoder (codec vp9)\n</code></pre> <p>You can also use any of above decoder in the similar way, if supported.</p> <p>Use <code>ffmpeg -decoders</code> terminal command to lists all FFmpeg supported decoders.</p> </li> <li> <p>You already have appropriate Nvidia video drivers and related softwares installed on your machine.</p> </li> <li>If the stream is not decodable in hardware (for example, it is an unsupported codec or profile) then it will still be decoded in software automatically, but hardware filters won't be applicable.</li> </ul> <p>These assumptions MAY/MAY NOT suit your current setup. Kindly use suitable parameters based your system platform and hardware settings only.</p> <p>In this example, we will be using Nvidia's H.264 CUVID Video decoder in FFdecoder API to achieve GPU-accelerated hardware video decoding of YUV420p frames from a given Video file (say <code>foo.mp4</code>), and preview them using OpenCV Library's <code>cv2.imshow()</code> method.</p> <p>With FFdecoder API, frames extracted with YUV pixel formats (<code>yuv420p</code>, <code>yuv444p</code>, <code>nv12</code>, <code>nv21</code> etc.) are generally incompatible with OpenCV APIs such as <code>imshow()</code>. But you can make them easily compatible by using exclusive <code>-enforce_cv_patch</code> boolean attribute of its <code>ffparam</code> dictionary parameter.</p> <p>More information on Nvidia's CUVID can be found here \u27b6</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# define suitable FFmpeg parameter\nffparams = {\n\"-vcodec\": \"h264_cuvid\",  # use H.264 CUVID Video-decoder\n\"-enforce_cv_patch\": True # enable OpenCV patch for YUV(YUV420p) frames\n}\n# initialize and formulate the decoder with `foo.mp4` source\ndecoder = FFdecoder(\n\"foo.mp4\",\nframe_format=\"yuv420p\",  # use YUV420p frame pixel format\nverbose=True, # enable verbose output\n**ffparams # apply various params and custom filters\n).formulate()\n# grab the YUV420p frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# convert it to `BGR` pixel format,\n# since imshow() method only accepts `BGR` frames\nframe = cv2.cvtColor(frame, cv2.COLOR_YUV2BGR_I420)\n# {do something with the BGR frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p>"},{"location":"recipes/advanced/decode-hw-acceleration/#cuda-accelerated-hardware-based-video-decoding-and-previewing","title":"CUDA-accelerated Hardware-based Video Decoding and Previewing","text":"Example Assumptions <p>Please note that following recipe explicitly assumes:</p> <ul> <li>You're running  Linux operating system with a supported NVIDIA GPU.</li> <li> <p>You're using FFmpeg 4.4 or newer, configured with at least <code>--enable-nonfree --enable-cuda-nvcc --enable-libnpp  --enable-cuvid --enable-nvenc</code> configuration flags during compilation. For compilation follow these instructions \u27b6</p> Verifying NVDEC/CUDA support in FFmpeg <p>To use CUDA Video-decoder(<code>cuda</code>), remember to check if your FFmpeg compiled with it by executing following commands in your terminal, and observing if output contains something similar as follows:</p> <pre><code>$ ffmpeg  -hide_banner -pix_fmts | grep cuda\n..H.. cuda                   0              0      0\n$ ffmpeg  -hide_banner -filters | egrep \"cuda|npp\"\n... bilateral_cuda    V-&gt;V       GPU accelerated bilateral filter\n... chromakey_cuda    V-&gt;V       GPU accelerated chromakey filter\n... colorspace_cuda   V-&gt;V       CUDA accelerated video color converter\n... hwupload_cuda     V-&gt;V       Upload a system memory frame to a CUDA device.\n... overlay_cuda      VV-&gt;V      Overlay one video on top of another using CUDA\n... scale_cuda        V-&gt;V       GPU accelerated video resizer\n... scale_npp         V-&gt;V       NVIDIA Performance Primitives video scaling and format conversion\n... scale2ref_npp     VV-&gt;VV     NVIDIA Performance Primitives video scaling and format conversion to the given reference.\n... sharpen_npp       V-&gt;V       NVIDIA Performance Primitives video sharpening filter.\n... thumbnail_cuda    V-&gt;V       Select the most representative frame in a given sequence of consecutive frames.\n... transpose_npp     V-&gt;V       NVIDIA Performance Primitives video transpose\nT.. yadif_cuda        V-&gt;V       Deinterlace CUDA frames\n</code></pre> </li> <li> <p>You already have appropriate Nvidia video drivers and related softwares installed on your machine.</p> </li> <li>If the stream is not decodable in hardware (for example, it is an unsupported codec or profile) then it will still be decoded in software automatically, but hardware filters won't be applicable.</li> </ul> <p>These assumptions MAY/MAY NOT suit your current setup. Kindly use suitable parameters based your system platform and hardware settings only.</p> <p>In this example, we will be using Nvidia's CUDA Internal hwaccel Video decoder(<code>cuda</code>) in FFdecoder API to automatically detect best NV-accelerated video codec and keeping video frames in GPU memory (for applying hardware filters), thereby achieving GPU-accelerated decoding of NV12 pixel-format frames from a given video file (say <code>foo.mp4</code>), and preview them using OpenCV Library's <code>cv2.imshow()</code> method.</p> <code>NV12</code>(for <code>4:2:0</code> input) and <code>NV21</code>(for <code>4:4:4</code> input) are the only supported pixel format. You cannot change pixel format to any other since NV-accelerated video codec supports only them. <p>NV12 is a biplanar format with a full sized Y plane followed by a single chroma plane with weaved U and V values. NV21 is the same but with weaved V and U values. The 12 in NV12 refers to 12 bits per pixel. NV12 has a half width and half height chroma channel, and therefore is a 420 subsampling. NV16 is 16 bits per pixel, with half width and full height. aka 422. NV24 is 24 bits per pixel with full sized chroma channel. aka 444. Most NV12 functions allow the destination Y pointer to be NULL.</p> <p>With FFdecoder API, frames extracted with YUV pixel formats (<code>yuv420p</code>, <code>yuv444p</code>, <code>nv12</code>, <code>nv21</code> etc.) are generally incompatible with OpenCV APIs such as <code>imshow()</code>. But you can make them easily compatible by using exclusive <code>-enforce_cv_patch</code> boolean attribute of its <code>ffparam</code> dictionary parameter.</p> <p>More information on Nvidia's GPU Accelerated Decoding can be found here \u27b6</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# define suitable FFmpeg parameter\nffparams = {\n\"-vcodec\": None,  # skip source decoder and let FFmpeg chose\n\"-enforce_cv_patch\": True # enable OpenCV patch for YUV(NV12) frames\n\"-ffprefixes\": [\n\"-vsync\",\n\"0\",  # prevent duplicate frames\n\"-hwaccel\",\n\"cuda\",  # accelerator\n\"-hwaccel_output_format\",\n\"cuda\",  # output accelerator\n],\n\"-custom_resolution\": \"null\",  # discard source `-custom_resolution`\n\"-framerate\": \"null\",  # discard source `-framerate`\n\"-vf\": \"scale_cuda=640:360,\"  # scale to 640x360 in GPU memory\n+ \"fps=60.0,\"  # framerate 60.0fps in GPU memory\n+ \"hwdownload,\"  # download hardware frames to system memory\n+ \"format=nv12\",  # convert downloaded frames to NV12 pixel format\n}\n# initialize and formulate the decoder with `foo.mp4` source\ndecoder = FFdecoder(\n\"foo.mp4\",\nframe_format=\"null\",  # discard source frame pixel format\nverbose=True, # enable verbose output\n**ffparams # apply various params and custom filters\n).formulate()\n# grab the NV12 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# convert it to `BGR` pixel format,\n# since imshow() method only accepts `BGR` frames\nframe = cv2.cvtColor(frame, cv2.COLOR_YUV2BGR_NV12)\n# {do something with the BGR frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p>"},{"location":"recipes/advanced/decode-live-feed-devices/","title":"Decoding Live Feed Devices","text":"<p>DeFFcode's FFdecoder API provide effortless support for any Live Feed Devices using two parameters: <code>source</code> parameter which accepts device name or its path, and <code>source_demuxer</code> parameter to specify demuxer for the given input device. </p> <p>We'll discuss the Live Feed Devices support using both these parameters briefly in the following recipes:</p> <p> </p> <p>DeFFcode APIs requires FFmpeg executable</p> <p>DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality, and any failure in detection will raise <code>RuntimeError</code> immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation.</p> Additional Python Dependencies for following recipes <p>Following recipes requires additional python dependencies which can be installed easily as below:</p> <ul> <li> <p> OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via <code>pip</code>:</p> OpenCV installation from source <p>You can also follow online tutorials for building &amp; installing OpenCV on Windows, Linux, MacOS and Raspberry Pi machines manually from its source. </p> <p> Make sure not to install both pip and source version together. Otherwise installation will fail to work!</p> Other OpenCV binaries <p>OpenCV maintainers also provide additional binaries via pip that contains both main modules and contrib/extra modules <code>opencv-contrib-python</code>, and for server (headless) environments like <code>opencv-python-headless</code> and <code>opencv-contrib-python-headless</code>. You can also install any one of them in similar manner. More information can be found here.</p> <pre><code>pip install opencv-python       </code></pre> </li> </ul> <p>Always use FFdecoder API's <code>terminate()</code> method at the end to avoid undesired behavior.</p> Never name your python script <code>deffcode.py</code> <p>When trying out these recipes, never name your python script <code>deffcode.py</code> otherwise it will result in <code>ModuleNotFound</code> error.</p> <p> </p>"},{"location":"recipes/advanced/decode-live-feed-devices/#capturing-and-previewing-frames-from-a-webcam-using-custom-demuxer","title":"Capturing and Previewing frames from a Webcam using Custom Demuxer","text":"Example Assumptions <p>FFmpeg provide set of specific Demuxers on different platforms to read the multimedia streams from a particular type of Video Capture source/device. Please note that following recipe explicitly assumes: </p> <ul> <li>You're running Linux Machine with USB webcam connected to it at node/path <code>/dev/video0</code>. </li> <li>You already have appropriate Linux video drivers and related softwares installed on your machine.</li> <li>You machine uses FFmpeg binaries built with <code>--enable-libv4l2</code> flag to support <code>video4linux2, v4l2</code> demuxer. BTW, you can list all supported demuxers using the <code>ffmpeg --list-demuxers</code> terminal command.</li> </ul> <p>These assumptions MAY/MAY NOT suit your current setup. Kindly use suitable parameters based your system platform and hardware settings only.</p> <p>In this example we will decode BGR24 video frames from a USB webcam device connected at path <code>/dev/video0</code> on a Linux Machine with <code>video4linux2</code> (or simply <code>v4l2</code>) demuxer, and preview them using OpenCV Library's <code>cv2.imshow()</code> method.</p> Identifying and Specifying Video Capture Device Name/Path/Index and suitable Demuxer on different OS platforms  Windows Linux MacOS <p>Windows OS users can use the dshow (DirectShow) to list video input device which is the preferred option for Windows users. You can refer following steps to identify and specify your input video device's name:</p> <ul> <li> <p> Identify Video Devices: You can locate your video device's name (already connected to your system) using <code>dshow</code> as follows:</p> <pre><code>c:\\&gt; ffmpeg.exe -list_devices true -f dshow -i dummy\n\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[dshow @ 03ACF580] DirectShow video devices\n[dshow @ 03ACF580]  \"Integrated Camera\"\n[dshow @ 03ACF580]  \"USB2.0 Camera\"\n[dshow @ 03ACF580] DirectShow audio devices\n[dshow @ 03ACF580]  \"Microphone (Realtek High Definition Audio)\"\n[dshow @ 03ACF580]  \"Microphone (USB2.0 Camera)\"\ndummy: Immediate exit requested\n</code></pre> </li> <li> <p> Specify Video Device's name: Then, you can specify and initialize your located Video device's name in FFdecoder API as follows:</p> <pre><code># initialize and formulate the decoder with \"USB2.0 Camera\" source for BGR24 output\ndecoder = FFdecoder(\"USB2.0 Camera\", source_demuxer=\"dshow\", frame_format=\"bgr24\", verbose=True).formulate()\n</code></pre> </li> <li> <p> [OPTIONAL] Specify Video Device's index along with name: If there are multiple Video devices with similar name, then you can use <code>-video_device_number</code> parameter to specify the arbitrary index of the particular device. For instance, to open second video device with name <code>\"Camera\"</code> you can do as follows:</p> <pre><code># define video_device_number as 1 (numbering start from 0)\nffparams = {\"-ffprefixes\":[\"-video_device_number\", \"1\"]}\n# initialize and formulate the decoder with \"Camera\" source for BGR24 output\ndecoder = FFdecoder(\"Camera\", source_demuxer=\"dshow\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n</code></pre> </li> </ul> <p>Linux OS users can use the <code>video4linux2</code> (or its alias <code>v4l2</code>) to list to all capture video devices such as from an USB webcam. You can refer following steps to identify and specify your capture video device's path:</p> <ul> <li> <p> Identify Video Devices: Linux systems tend to automatically create file device node/path when the device (e.g. an USB webcam) is plugged into the system, and has a name of the kind <code>'/dev/videoN'</code>, where <code>N</code> is a index associated to the device. To get the list of all available file device node/path on your Linux machine, you can use the <code>v4l-ctl</code> command.</p> <p>You can use <code>sudo apt install v4l-utils</code> APT command to install <code>v4l-ctl</code> tool on Debian-based Linux distros.</p> <pre><code>$ v4l2-ctl --list-devices\n\nUSB2.0 PC CAMERA (usb-0000:00:1d.7-1):\n        /dev/video1\n\nUVC Camera (046d:0819) (usb-0000:00:1d.7-2):\n        /dev/video0\n</code></pre> </li> <li> <p> Specify Video Device's path: Then, you can specify and initialize your located Video device's path in FFdecoder API as follows:</p> <pre><code># initialize and formulate the decoder with \"/dev/video0\" source for BGR24 output\ndecoder = FFdecoder(\"/dev/video0\", source_demuxer=\"v4l2\", frame_format=\"bgr24\", verbose=True).formulate()\n</code></pre> </li> <li> <p> [OPTIONAL] Specify Video Device's additional specifications: You can also specify additional specifications (such as pixel format(s), video format(s), framerate, and frame dimensions) supported by your Video Device as follows:</p> <p>You can use <code>ffmpeg -f v4l2 -list_formats all -i /dev/video0</code> terminal command to list available specifications.</p> <pre><code># define video device specifications\nffparams = {\"-ffprefixes\":[\"-framerate\", \"25\", \"-video_size\", \"640x480\"]}\n# initialize and formulate the decoder with \"/dev/video0\" source for BGR24 output\ndecoder = FFdecoder(\"/dev/video0\", source_demuxer=\"v4l2\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n</code></pre> </li> </ul> <p>MacOS users can use the AVFoundation to list input devices and is the currently recommended framework by Apple for streamgrabbing on Mac OSX-10.7 (Lion) and later as well as on iOS. You can refer following steps to identify and specify your capture video device's name or index on MacOS/OSX machines:</p> <p>QTKit is also available for streamgrabbing on Mac OS X 10.4 (Tiger) and later, but has been marked deprecated since OS X 10.7 (Lion) and may not be available on future releases.</p> <ul> <li> <p> Identify Video Devices: Then, You can locate your Video device's name and index using <code>avfoundation</code> as follows:</p> <pre><code>$ ffmpeg -f avfoundation -list_devices true -i \"\"\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation video devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] FaceTime HD camera (built-in)\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Capture screen 0\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation audio devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] Blackmagic Audio\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Built-in Microphone\n</code></pre> </li> <li> <p> Specify Video Device's name or index: Then, you can specify and initialize your located Video device in FFdecoder API using its either the name or the index shown in the device listing:</p> Using device's indexUsing device's name <pre><code># initialize and formulate the decoder with `1` index source for BGR24 output\ndecoder = FFdecoder(\"1\", source_demuxer=\"avfoundation\", frame_format=\"bgr24\", verbose=True).formulate()\n</code></pre> <p>When specifying device's name, abbreviations using just the beginning of the device name are possible. Thus, to capture from a device named \"Integrated iSight-camera\" just \"Integrated\" is sufficient:</p> <pre><code># initialize and formulate the decoder with \"Integrated iSight-camera\" source for BGR24 output\ndecoder = FFdecoder(\"Integrated\", source_demuxer=\"avfoundation\", frame_format=\"bgr24\", verbose=True).formulate()\n</code></pre> </li> <li> <p> [OPTIONAL] Specify Default Video device: You can also use the default device which is usually the first device in the listing by using \"default\" as source:</p> <pre><code># initialize and formulate the decoder with \"default\" source for BGR24 output\ndecoder = FFdecoder(\"default\", source_demuxer=\"avfoundation\", frame_format=\"bgr24\", verbose=True).formulate()\n</code></pre> </li> </ul> <p>If these steps doesn't work for you then reach us out on Gitter \u27b6 Community channel</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# initialize and formulate the decoder with \"/dev/video0\" source for BGR24 output\ndecoder = FFdecoder(\"/dev/video0\", source_demuxer=\"v4l2\", frame_format=\"bgr24\", verbose=True).formulate()\n# grab the BGR24 frames from decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p>"},{"location":"recipes/advanced/decode-live-feed-devices/#capturing-and-previewing-frames-from-your-desktop","title":"Capturing and Previewing frames from your Desktop","text":"Example Assumptions <p>Similar to Webcam capturing, FFmpeg provide set of specific Demuxers on different platforms for capturing your desktop (Screen recording). Please note that following recipe explicitly assumes: </p> <ul> <li>You're running Linux Machine with <code>libxcb</code> module installed properly on your machine.</li> <li>You machine uses FFmpeg binaries built with <code>--enable-libxcb</code> flag to support <code>x11grab</code> demuxer. BTW, you can list all supported demuxers using the <code>ffmpeg --list-demuxers</code> terminal command.</li> </ul> <p>These assumptions MAY/MAY NOT suit your current setup. Kindly use suitable parameters based your system platform and hardware settings only.</p> <p>In this example we will decode live BGR video frames from your complete screen as well as a region in FFdecoder API, and preview them using OpenCV Library's <code>cv2.imshow()</code> method.</p> Specifying suitable Parameter(s) and Demuxer for Capturing your Desktop on different OS platforms  Windows Linux MacOS <p>Windows OS users can use the gdigrab to grab video from the Windows screen. You can refer following steps to specify source for capturing different regions of your display:</p> <p>For Windows OS users <code>dshow</code> is also available for grabbing frames from your desktop. But it is highly unreliable and don't works most of the times.</p> <ul> <li> <p> Capturing entire desktop: For capturing all your displays as one big contiguous display, you can specify source, suitable parameters and demuxers in FFdecoder API as follows:</p> <pre><code># define framerate\nffparams = {\"-framerate\": \"30\"}\n# initialize and formulate the decoder with \"desktop\" source for BGR24 output\ndecoder = FFdecoder(\"desktop\", source_demuxer=\"gdigrab\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n</code></pre> </li> <li> <p> Capturing a region: If you want to limit capturing to a region, and show the area being grabbed, you can specify source and suitable parameters in FFdecoder API as follows:</p> <p><code>x_offset</code> and <code>y_offset</code> specify the offsets of the grabbed area with respect to the top-left border of the desktop screen. They default to <code>0</code>. </p> <pre><code># define suitable parameters\nffparams = {\n\"-framerate\": \"30\", # input framerate\n\"-ffprefixes\": [\n\"-offset_x\", \"10\", \"-offset_y\", \"20\", # grab at position 10,20\n\"-video_size\", \"640x480\", # frame size\n\"-show_region\", \"1\", # show only region\n],\n}\n# initialize and formulate the decoder with \"desktop\" source for BGR24 output\ndecoder = FFdecoder(\"desktop\", source_demuxer=\"gdigrab\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n</code></pre> </li> </ul> <p>Linux OS users can use the x11grab to capture an X11 display. You can refer following steps to specify source for capturing different regions of your display:</p> <p>For X11 display, the source input has the syntax: <code>\"display_number.screen_number[+x_offset,y_offset]\"</code>.</p> <ul> <li> <p> Capturing entire desktop: For capturing all your displays as one big contiguous display, you can specify source, suitable parameters and demuxers in FFdecoder API as follows:</p> <pre><code># define framerate\nffparams = {\"-framerate\": \"30\"}\n# initialize and formulate the decoder with \":0.0\" desktop source for BGR24 output\ndecoder = FFdecoder(\":0.0\", source_demuxer=\"x11grab\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n</code></pre> </li> <li> <p> Capturing a region: If you want to limit capturing to a region, and show the area being grabbed, you can specify source and suitable parameters in FFdecoder API as follows:</p> <p><code>x_offset</code> and <code>y_offset</code> specify the offsets of the grabbed area with respect to the top-left border of the X11 screen. They default to <code>0</code>. </p> <pre><code># define suitable parameters\nffparams = {\n\"-framerate\": \"30\", # input framerate\n\"-ffprefixes\": [\n\"-video_size\", \"1024x768\", # frame size\n],\n}\n# initialize and formulate the decoder with \":0.0\" desktop source(starting with the upper-left corner at x=10, y=20) \n# for BGR24 output\ndecoder = FFdecoder(\":0.0+10,20\", source_demuxer=\"x11grab\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n</code></pre> </li> </ul> <p>MacOS users can use the AVFoundation to list input devices and is the currently recommended framework by Apple for streamgrabbing on Mac OSX-10.7 (Lion) and later as well as on iOS. You can refer following steps to identify and specify your capture video device's name or index on MacOS/OSX machines:</p> <p>QTKit is also available for streamgrabbing on Mac OS X 10.4 (Tiger) and later, but has been marked deprecated since OS X 10.7 (Lion) and may not be available on future releases.</p> <ul> <li> <p> Identify Video Devices:  You can enumerate all the available input devices including screens ready to be captured using <code>avfoundation</code> as follows:</p> <pre><code>$ ffmpeg -f avfoundation -list_devices true -i \"\"\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation video devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] FaceTime HD camera (built-in)\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Capture screen 0\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation audio devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] Blackmagic Audio\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Built-in Microphone\n</code></pre> </li> <li> <p> Capturing entire desktop: Then, you can specify and initialize your located screens in FFdecoder API using its index shown:</p> <pre><code># initialize and formulate the decoder with `0:` index desktop screen for BGR24 output\ndecoder = FFdecoder(\"0:\", source_demuxer=\"avfoundation\", frame_format=\"bgr24\", verbose=True).formulate()\n</code></pre> </li> <li> <p> [OPTIONAL] Capturing mouse: You can also specify additional specifications to capture the mouse pointer and screen mouse clicks as follows:</p> <pre><code># define specifications\nffparams = {\"-ffprefixes\":[\"-capture_cursor\", \"1\", \"-capture_mouse_clicks\", \"0\"]}\n# initialize and formulate the decoder with \"0:\" source for BGR24 output\ndecoder = FFdecoder(\"0:\", source_demuxer=\"avfoundation\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n</code></pre> </li> </ul> <p>If these steps doesn't work for you then reach us out on Gitter \u27b6 Community channel</p> Capturing entire desktopCapturing a region <p>For capturing all your displays as one big contiguous display in FFdecoder API:</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# define framerate\nffparams = {\"-framerate\": \"30\"}\n# initialize and formulate the decoder with \":0.0\" desktop source for BGR24 output\ndecoder = FFdecoder(\":0.0\", source_demuxer=\"x11grab\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n# grab the BGR24 frames from decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p>For limit capturing to a region, and show the area being grabbed:</p> <p><code>x_offset</code> and <code>y_offset</code> specify the offsets of the grabbed area with respect to the top-left border of the X11 screen. They default to <code>0</code>. </p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# define suitable parameters\nffparams = {\n\"-framerate\": \"30\", # input framerate\n\"-ffprefixes\": [\n\"-video_size\", \"1024x768\", # frame size\n],\n}\n# initialize and formulate the decoder with \":0.0\" desktop source(starting with the upper-left corner at x=10, y=20) \n# for BGR24 output\ndecoder = FFdecoder(\":0.0+10,20\", source_demuxer=\"x11grab\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n# grab the BGR24 frames from decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p>"},{"location":"recipes/advanced/decode-live-virtual-sources/","title":"Decoding Live Virtual Sources","text":"<p>Instead of using prerecorded video files as streams, DeFFcode's FFdecoder API with the help of powerful <code>lavfi</code> (Libavfilter input virtual device) source that reads data from the open output pads of a libavfilter filtergraph, is also capable of creating virtual video frames out of thin air in real-time, which you might want to use as input for testing, compositing, and merging with other streams to obtain desired output on-the-fly. </p> <p>We'll discuss the recipies for generating Live Fake Sources briefly below:</p> <p> </p> <p>DeFFcode APIs requires FFmpeg executable</p> <p>DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality, and any failure in detection will raise <code>RuntimeError</code> immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation.</p> Additional Python Dependencies for following recipes <p>Following recipes requires additional python dependencies which can be installed easily as below:</p> <ul> <li> <p> OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via <code>pip</code>:</p> OpenCV installation from source <p>You can also follow online tutorials for building &amp; installing OpenCV on Windows, Linux, MacOS and Raspberry Pi machines manually from its source. </p> <p> Make sure not to install both pip and source version together. Otherwise installation will fail to work!</p> Other OpenCV binaries <p>OpenCV maintainers also provide additional binaries via pip that contains both main modules and contrib/extra modules <code>opencv-contrib-python</code>, and for server (headless) environments like <code>opencv-python-headless</code> and <code>opencv-contrib-python-headless</code>. You can also install any one of them in similar manner. More information can be found here.</p> <pre><code>pip install opencv-python       </code></pre> </li> </ul> <p>Always use FFdecoder API's <code>terminate()</code> method at the end to avoid undesired behavior.</p> Never name your python script <code>deffcode.py</code> <p>When trying out these recipes, never name your python script <code>deffcode.py</code> otherwise it will result in <code>ModuleNotFound</code> error.</p> <p> </p>"},{"location":"recipes/advanced/decode-live-virtual-sources/#generate-and-decode-frames-from-sierpinski-pattern","title":"Generate and Decode frames from Sierpinski pattern","text":"<p>The <code>sierpinski</code> graph generates a Sierpinski carpet/triangle fractal, and randomly pan around by a single pixel each frame.</p> <p> </p> Sierpinski carpet fractal <p>In this example we will generate and decode 8 seconds of a Sierpinski carpet fractal pattern of <code>1280x720</code> frame size and <code>30</code> framerate using <code>sierpinski</code> graph source with <code>lavfi</code> input virtual device in FFdecoder API, and preview decoded frames using OpenCV Library's <code>cv2.imshow()</code> method in real-time. </p> <p>By default, OpenCV expects <code>BGR</code> format frames in its <code>cv2.imshow()</code> method.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# playback time of 8 seconds\nffparams = {\"-ffprefixes\": [\"-t\", \"8\"]}\n# initialize and formulate the decoder with \"sierpinski\" source of\n# `1280x720` frame size and `30` framerate for BGR24 output\ndecoder = FFdecoder(\n\"sierpinski=size=1280x720:rate=30\",\nsource_demuxer=\"lavfi\",\nframe_format=\"bgr24\",\n**ffparams\n).formulate()\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\ncv2.imwrite('foo_image.gif', frame)\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p>"},{"location":"recipes/advanced/decode-live-virtual-sources/#generate-and-decode-frames-from-test-source-pattern","title":"Generate and Decode frames from Test Source pattern","text":"<p>The <code>testsrc</code> graph generates a test video pattern showing a color pattern, a scrolling gradient, and a timestamp. This is useful for testing purposes.</p> <p> </p> Test Source pattern <p>In this example we will generate and decode <code>10</code> seconds of a Test Source pattern (<code>1280x720</code> frame size &amp; <code>30</code> framerate) using <code>testsrc</code> graph source with <code>lavfi</code> input virtual device in FFdecoder API, all while previewing decoded frames using OpenCV Library's <code>cv2.imshow()</code> method in real-time. </p> <p>By default, OpenCV expects <code>BGR</code> format frames in its <code>cv2.imshow()</code> method.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# define parameters\nffparams = {\n\"-ffprefixes\": [\"-t\", \"10\"],  # playback time of 10 seconds\n}\n# initialize and formulate the decoder with \"testsrc\" source of\n# `1280x720` frame size and `30` framerate for BGR24 output\ndecoder = FFdecoder(\n\"testsrc=size=1280x720:rate=30\",\nsource_demuxer=\"lavfi\",\nframe_format=\"bgr24\",\n**ffparams\n).formulate()\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p>"},{"location":"recipes/advanced/decode-live-virtual-sources/#generate-and-decode-frames-from-gradients-with-custom-text-effect","title":"Generate and Decode frames from Gradients with custom Text effect","text":"<p>The <code>gradients</code> graph (as name suggests) generates several random gradients.</p> <p> </p> Gradients pattern with real-time text output <p>In this example we will generate and decode <code>15</code> seconds of Gradients using <code>gradients</code> graph source with <code>lavfi</code> input virtual device and also draw real-time text output (format <code>HH::MM::SS</code>) scrolling upward direction on it using <code>drawtext</code> filter in FFdecoder API, all while previewing decoded frames using OpenCV Library's <code>cv2.imshow()</code> method in real-time. </p> <p>This example assumes you're running  Windows machine. If not, then change <code>fontfile</code> parameter path in <code>drawtext</code> video filtergraph definition accordingly.</p> <p>By default, OpenCV expects <code>BGR</code> format frames in its <code>cv2.imshow()</code> method.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# define parameters\nffparams = {\n\"-ffprefixes\": [\"-t\", \"15\"],  # playback time of 15 seconds\n\"-vf\": \"drawtext=\"  # draw text\n+ \"text='%{localtime\\:%X}':\"  # real time text (HH::MM::SS)\n+ \"fontfile='c\\:\\/windows\\/fonts\\/arial.ttf':\"  # fontfile path (Only Windows)\n+ \"x=(w-text_w)/2:y=h-40*t:\"  # scroll upward effect\n+ \"fontsize=50:\"  # font size 50\n+ \"fontcolor=white\",  # font color white\n}\n# initialize and formulate the decoder with \n# \"gradients\" source for BGR24 output\ndecoder = FFdecoder(\n\"gradients=n=3\",\nsource_demuxer=\"lavfi\",\nframe_format=\"bgr24\",\n**ffparams\n).formulate()\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p>"},{"location":"recipes/advanced/decode-live-virtual-sources/#generate-and-decode-frames-from-mandelbrot-test-pattern-with-vectorscope-waveforms","title":"Generate and Decode frames from Mandelbrot test pattern with vectorscope &amp; waveforms","text":"<p>The <code>mandelbrot</code> graph generate a Mandelbrot set fractal, that progressively zoom towards a specfic point.</p> <p> </p> Mandelbrot pattern with a Vectorscope &amp; two Waveforms <p>In this example we will generate and decode <code>20</code> seconds of a Mandelbrot test pattern (<code>1280x720</code> frame size &amp; <code>30</code> framerate) using <code>mandelbrot</code> graph source with <code>lavfi</code> input virtual device with a vectorscope (plots 2 color component values) &amp; two waveforms (plots YUV color component intensity) stacked to it in FFdecoder API, all while previewing decoded frames using OpenCV Library's <code>cv2.imshow()</code> method in real-time. </p> <p>By default, OpenCV expects <code>BGR</code> format frames in its <code>cv2.imshow()</code> method.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# define parameters\nffparams = {\n\"-ffprefixes\": [\"-t\", \"20\"],  # playback time of 20 seconds\n\"-vf\": \"format=yuv444p,\" # change input format to yuv444p\n+ \"split=4[a][b][c][d],\" # split input into 4 identical outputs.\n+ \"[a]waveform[aa],\"  # apply waveform on first output\n+ \"[b][aa]vstack[V],\"  # vertical stack 2nd output with waveform [V]\n+ \"[c]waveform=m=0[cc],\"  # apply waveform on 3rd output\n+ \"[d]vectorscope=color4[dd],\"  # apply vectorscope on 4th output\n+ \"[cc][dd]vstack[V2],\"  # vertical stack waveform and vectorscope [V2]\n+ \"[V][V2]hstack\",  # horizontal stack [V] and [V2] vertical stacks\n}\n# initialize and formulate the decoder with \"mandelbrot\" source of\n# `1280x720` frame size and `30` framerate for BGR24 output\ndecoder = FFdecoder(\n\"mandelbrot=size=1280x720:rate=30\",\nsource_demuxer=\"lavfi\",\nframe_format=\"bgr24\",\n**ffparams\n).formulate()\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p>"},{"location":"recipes/advanced/decode-live-virtual-sources/#generate-and-decode-frames-from-game-of-life-visualization","title":"Generate and Decode frames from Game of Life Visualization","text":"<p>The <code>life</code> graph generates a life pattern based on a generalization of John Conway\u2019s life game. The sourced input represents a life grid, each pixel represents a cell which can be in one of two possible states, alive or dead. Every cell interacts with its eight neighbours, which are the cells that are horizontally, vertically, or diagonally adjacent. At each interaction the grid evolves according to the adopted rule, which specifies the number of neighbor alive cells which will make a cell stay alive or born.</p> <p> </p> Game of Life Visualization <p>In this example we will generate and decode <code>25</code> seconds of Game of Life Visualization  using <code>life</code> graph source with <code>lavfi</code> input virtual device in FFdecoder API, all while previewing decoded frames using OpenCV Library's <code>cv2.imshow()</code> method in real-time. </p> <p>By default, OpenCV expects <code>BGR</code> format frames in its <code>cv2.imshow()</code> method.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# define parameters\nffparams = {\n\"-ffprefixes\": [\"-t\", \"25\"],  # playback time of 25 seconds\n}\n# initialize and formulate the decoder with \"life\" source for BGR24 output\ndecoder = FFdecoder(\n\"life=\"  # life graph\n+ \"s=640x480:\"  # grid size (in pixels)\n+ \"mold=10:\"  # cell mold speed\n+ \"r=36:\"  # framerate\n+ \"ratio=0.5:\"  # random fill ratio for the initial random grid\n+ \"death_color=#39FF14:\"  # color of dead cells\n+ \"life_color=#1d1160\" # color of living (or new born) cells\n+ \",scale=640:480:\" # frame size\n+ \"flags=16\",\nsource_demuxer=\"lavfi\",\nframe_format=\"bgr24\",\n**ffparams\n).formulate()\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p>"},{"location":"recipes/advanced/transcode-art-filtergraphs/","title":"Transcoding Video Art with Filtergraphs","text":"What are Simple filtergraphs? <p>Before heading straight into recipes we will talk about Simple filtergraphs: </p> <p>Simple filtergraphs are those filters that have exactly one input and output, both of the same type. </p> <p>They can be processed by simply inserting an additional step between decoding and encoding of video frames:</p> <p></p> <p>Simple filtergraphs are configured with the per-stream <code>-filter</code> option (with <code>-vf</code> for video). </p> <p>DeFFcode's FFdecoder API unlocks the power of ffmpeg backend for creating real-time artistic generative video art using simple and complex filtergraphs, and decoding them into live video frames. </p> <p>We'll discuss the Transcoding Video Art with Filtergraphs in the following recipes:</p> <p> </p> <p>DeFFcode APIs requires FFmpeg executable</p> <p>DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality, and any failure in detection will raise <code>RuntimeError</code> immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation.</p> Additional Python Dependencies for following recipes <p>Following recipes requires additional python dependencies which can be installed easily as below:</p> <ul> <li> <p> OpenCV: OpenCV is required for previewing and encoding video frames. You can easily install it directly via <code>pip</code>:</p> OpenCV installation from source <p>You can also follow online tutorials for building &amp; installing OpenCV on Windows, Linux, MacOS and Raspberry Pi machines manually from its source. </p> <p> Make sure not to install both pip and source version together. Otherwise installation will fail to work!</p> Other OpenCV binaries <p>OpenCV maintainers also provide additional binaries via pip that contains both main modules and contrib/extra modules <code>opencv-contrib-python</code>, and for server (headless) environments like <code>opencv-python-headless</code> and <code>opencv-contrib-python-headless</code>. You can also install any one of them in similar manner. More information can be found here.</p> <pre><code>pip install opencv-python       </code></pre> </li> <li> <p> VidGear: VidGear is required for lossless encoding of video frames into file/stream. You can easily install it directly via <code>pip</code>:</p> <pre><code>pip install vidgear[core]       </code></pre> </li> </ul> <p>Always use FFdecoder API's <code>terminate()</code> method at the end to avoid undesired behavior.</p> <p>WriteGear's Compression Mode support for FFdecoder API is currently in beta so you can expect much higher than usual CPU utilization!</p> <p> </p>"},{"location":"recipes/advanced/transcode-art-filtergraphs/#transcoding-video-art-with-yuv-bitplane-visualization","title":"Transcoding video art with YUV Bitplane Visualization","text":"<p>Based on the QCTools bitplane visualization, this video art has numerical values ranging between <code>-1</code>(no change) and <code>10</code>(noisiest) for the <code>Y</code> (luminance), <code>U</code> and <code>V</code> (chroma or color difference) planes, yielding cool and different results for different values.</p> <p> </p> YUV Bitplane Visualization <p>This Video Art idea credits goes to ffmpeg-artschool - An AMIA workshop featuring scripts, exercises, and activities to make art using FFmpeg.</p> <p>In this example we will generate 8 seconds of Bitplane Visualization by binding the bit position of the <code>Y</code>, <code>U</code>, and <code>V</code> planes of a video file (say <code>foo.mp4</code>) by using FFmpeg's <code>lutyuv</code> filter and assigning them random values (between <code>-1</code>(no change) and <code>10</code>(noisiest)), and decode live BGR24 video frames in FFdecoder API. We'll also be encoding those decoded frames in real-time into lossless video file using WriteGear API with controlled framerate.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nfrom vidgear.gears import WriteGear\nimport cv2, json\n# define Video Filter definition\nffparams = {\n\"-ffprefixes\": [\"-t\", \"8\"],  # playback time of 8 seconds\n\"-vf\": \"format=yuv444p,\" # change input format to yuv444p\n+ \"lutyuv=\"  # use  lutyuv filter for binding bit position of the Y, U, and V planes\n+ \"y=if(eq({y}\\,-1)\\,512\\,if(eq({y}\\,0)\\,val\\,bitand(val\\,pow(2\\,10-{y}))*pow(2\\,{y}))):\".format(\ny=3 # define `Y` (luminance) plane value (b/w -1 and 10)\n)\n+ \"u=if(eq({u}\\,-1)\\,512\\,if(eq({u}\\,0)\\,val\\,bitand(val\\,pow(2\\,10-{u}))*pow(2\\,{u}))):\".format(\nu=1 # define `U` (chroma or color difference) plane value (b/w -1 and 10)\n)\n+ \"v=if(eq({v}\\,-1)\\,512\\,if(eq({v}\\,0)\\,val\\,bitand(val\\,pow(2\\,10-{v}))*pow(2\\,{v}))),\".format(\nv=3 # define `V` (chroma or color difference) plane value (b/w -1 and 10)\n)\n+ \"format=yuv422p10le\", # change output format to yuv422p10le\n}\n# initialize and formulate the decoder with suitable source\ndecoder = FFdecoder(\"foo.mp4\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n# retrieve framerate from source JSON Metadata and pass it as `-input_framerate`\n# parameter for controlled framerate and define other parameters\noutput_params = {\n\"-input_framerate\": json.loads(decoder.metadata)[\"output_framerate\"],\n}\n# Define writer with default parameters and suitable\n# output filename for e.g. `output_foo.mp4`\nwriter = WriteGear(output_filename=\"output_foo.mp4\", **output_params)\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# writing BGR24 frame to writer\nwriter.write(frame)\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"recipes/advanced/transcode-art-filtergraphs/#transcoding-video-art-with-jetcolor-effect","title":"Transcoding video art with Jetcolor effect","text":"<p>This video art uses FFmpeg's <code>pseudocolor</code> filter to create a Jetcolor effect which is high contrast, high brightness, and high saturation colormap that ranges from blue to red, and passes through the colors cyan, yellow, and orange. The jet colormap is associated with an astrophysical fluid jet simulation from the National Center for Supercomputer Applications. </p> <p> </p> Jetcolor effect <p>This Video Art idea credits goes to ffmpeg-artschool - An AMIA workshop featuring scripts, exercises, and activities to make art using FFmpeg.</p> <p>In this example we will generate 8 seconds of Jetcolor effect by changing frame colors of a video file (say <code>foo.mp4</code>) using  FFmpeg's <code>pseudocolor</code> filter in different modes (values between <code>0</code> (cleaner) [default] and <code>2</code>(noisiest)), and decode live BGR24 video frames in FFdecoder API. We'll also be encoding those decoded frames in real-time into lossless video file using WriteGear API with controlled framerate.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nfrom vidgear.gears import WriteGear\nimport cv2, json\n# define Video Filter definition\nffparams = {\n\"-ffprefixes\": [\"-t\", \"8\"],  # playback time of 8 seconds\n\"-vf\": \"format=yuv444p,\"  # change input format to `yuv444p`\n+ \"eq=brightness=0.40:saturation=8,\"  # default `brightness = 0.40` and `saturation=8`\n+ \"pseudocolor='\"  # dynamically controlled colors through `pseudocolor` filter\n+ \"if(between(val,0,85),lerp(45,159,(val-0)/(85-0)),\"\n+ \"if(between(val,85,170),lerp(159,177,(val-85)/(170-85)),\"\n+ \"if(between(val,170,255),lerp(177,70,(val-170)/(255-170))))):\"  # mode 0 (cleaner) [default]\n+ \"if(between(val,0,85),lerp(205,132,(val-0)/(85-0)),\"\n+ \"if(between(val,85,170),lerp(132,59,(val-85)/(170-85)),\"\n+ \"if(between(val,170,255),lerp(59,100,(val-170)/(255-170))))):\"  # mode 1\n+ \"if(between(val,0,85),lerp(110,59,(val-0)/(85-0)),\"\n+ \"if(between(val,85,170),lerp(59,127,(val-85)/(170-85)),\"\n+ \"if(between(val,170,255),lerp(127,202,(val-170)/(255-170))))):\"  # mode 2 (noisiest)\n+ \"i={mode}',\".format(\nmode=0  # define mode value (b/w `0` and `2`) to control colors\n)\n+ \"format=yuv422p10le\",  # change output format to `yuv422p10le`\n}\n# initialize and formulate the decoder with suitable source\ndecoder = FFdecoder(\n\"foo.mp4\", frame_format=\"bgr24\", verbose=True, **ffparams\n).formulate()\n# retrieve framerate from source JSON Metadata and pass it as `-input_framerate`\n# parameter for controlled framerate and define other parameters\noutput_params = {\n\"-input_framerate\": json.loads(decoder.metadata)[\"output_framerate\"],\n}\n# Define writer with default parameters and suitable\n# output filename for e.g. `output_foo.mp4`\nwriter = WriteGear(output_filename=\"output_foo.mp4\", **output_params)\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# writing BGR24 frame to writer\nwriter.write(frame)\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"recipes/advanced/transcode-art-filtergraphs/#transcoding-video-art-with-ghosting-effect","title":"Transcoding video art with Ghosting effect","text":"<p>This video art using FFmpeg\u2019s <code>lagfun</code> filter to create a video echo/ghost/trailing effect.</p> <p> </p> Ghosting effect <p>This Video Art idea credits goes to ffmpeg-artschool - An AMIA workshop featuring scripts, exercises, and activities to make art using FFmpeg.</p> <p>In this example we will generate 8 seconds of Ghosting effect using FFmpeg's <code>lagfun</code> filter on a video file (say <code>foo.mp4</code>), and decode live BGR24 video frames in FFdecoder API. We'll also be encoding those decoded frames in real-time into lossless video file using WriteGear API with controlled framerate.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nfrom vidgear.gears import WriteGear\nimport cv2, json\n# define Video Filter definition\nffparams = {\n\"-ffprefixes\": [\"-t\", \"8\"],  # playback time of 8 seconds\n\"-filter_complex\": \"format=yuv444p[formatted];\"  # change video input format to yuv444p\n+ \"[formatted]split[a][b];\"  # split input into 2 identical outputs\n+ \"[a]lagfun=decay=.99:planes=1[a];\"  # apply lagfun filter on first output\n+ \"[b]lagfun=decay=.98:planes=2[b];\"  # apply lagfun filter on 2nd output\n+ \"[a][b]blend=all_mode=screen:c0_opacity=.5:c1_opacity=.5,\"  # apply screen blend mode both outputs\n+ \"format=yuv422p10le[out]\",  # change output format to yuv422p10le\n\"-map\": \"[out]\",  # map the output\n}\n# initialize and formulate the decoder with suitable source\ndecoder = FFdecoder(\n\"foo.mp4\", frame_format=\"bgr24\", verbose=True, **ffparams\n).formulate()\n# retrieve framerate from source JSON Metadata and pass it as `-input_framerate`\n# parameter for controlled framerate and define other parameters\noutput_params = {\n\"-input_framerate\": json.loads(decoder.metadata)[\"output_framerate\"],\n}\n# Define writer with default parameters and suitable\n# output filename for e.g. `output_foo.mp4`\nwriter = WriteGear(output_filename=\"output_foo.mp4\", **output_params)\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# writing BGR24 frame to writer\nwriter.write(frame)\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"recipes/advanced/transcode-art-filtergraphs/#transcoding-video-art-with-pixelation-effect","title":"Transcoding video art with Pixelation effect","text":"<p>This video art uses FFmpeg\u2019s <code>overlay</code>, <code>smartblur</code> and stacks of <code>dilation</code> filters to intentionally Pixelate your video in artistically cool looking ways such that each pixel become visible to the naked eye.</p> <p> </p> Pixelation effect <p>This Video Art idea credits goes to oioiiooixiii blogspot.</p> <p>In this example we will generate 8 seconds of Pixelation effect using FFmpeg\u2019s <code>smartblur</code> and stacks of <code>dilation</code> filters overlayed on a video file (say <code>foo.mp4</code>), and decode live BGR24 video frames in FFdecoder API. We'll also be encoding those decoded frames in real-time into lossless video file using WriteGear API with controlled framerate.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nfrom vidgear.gears import WriteGear\nimport cv2, json\n# define Video Filter definition\nffparams = {\n\"-ffprefixes\": [\"-t\", \"8\"],  # playback time of 8 seconds\n\"-vf\": \"format=yuv444p,\"  # change input format to yuv444p\n+ \"split [out1][out2];\"  # split input into 2 identical outputs\n+ \"[out1][out2] overlay,smartblur,\"  # apply overlay,smartblur filter on both outputs\n+ \"dilation,dilation,dilation,dilation,dilation,\"  # apply stacks of dilation filters on both outputs\n+ \"eq=contrast=1.4:brightness=-0.09 [pixels];\"  # change brightness and contrast\n+ \"[pixels]format=yuv422p10le[out]\",  # change output format to yuv422p10le\n\"-mode\": \"[out]\",  # map the output\n}\n# initialize and formulate the decoder with suitable source\ndecoder = FFdecoder(\n\"foo.mp4\", frame_format=\"bgr24\", verbose=True, **ffparams\n).formulate()\n# retrieve framerate from source JSON Metadata and pass it as `-input_framerate`\n# parameter for controlled framerate and define other parameters\noutput_params = {\n\"-input_framerate\": json.loads(decoder.metadata)[\"output_framerate\"],\n}\n# Define writer with default parameters and suitable\n# output filename for e.g. `output_foo.mp4`\nwriter = WriteGear(output_filename=\"output_foo.mp4\", **output_params)\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# writing BGR24 frame to writer\nwriter.write(frame)\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"recipes/advanced/transcode-hw-acceleration/","title":"Hardware-Accelerated Video Transcoding","text":"What exactly is Transcoding? <p>Transcoding is the technique of transforming one media encoding format into another. </p> <p>This is typically done for compatibility purposes, such as when a media source provides a format that the intended target is not able to process; an in-between adaptation step is required:</p> <ul> <li>Decode media from its originally encoded state into raw, uncompressed information.</li> <li>Encode the raw data back, using a different codec that is supported by end user.</li> </ul> <p>DeFFcode's FFdecoder API in conjunction with VidGear's WriteGear API is able to exploit almost any FFmpeg parameter for achieving anything imaginable with multimedia video data all while allowing us to process real-time video frames with immense flexibility. Both these APIs are capable of utilizing the potential of GPU backed fully-accelerated Hardware based video Decoding(FFdecoder API with hardware decoder) and Encoding (WriteGear API with hardware encoder), thus dramatically improving the transcoding performance. At same time, FFdecoder API Hardware-decoded frames are fully compatible with OpenCV's VideoWriter API for producing  high-quality output video in real-time. </p> Limitation: Bottleneck in Hardware-Accelerated Video Transcoding performance with Real-time Frame processing <p>As we know, using the <code>\u2013hwaccel cuda -hwaccel_output_format cuda</code> flags in FFmpeg pipeline will keep video frames in GPU memory, and this ensures that the memory transfers (system memory to video memory and vice versa) are eliminated, and that transcoding is performed with the highest possible performance on the available GPU hardware.</p> <p> General Memory Flow with Hardware Acceleration </p> <p>But unfortunately, for processing real-time frames in our python script with FFdecoder and WriteGear APIs, we're bound to sacrifice this performance gain by explicitly copying raw decoded frames between System and GPU memory (via the PCIe bus), thereby creating self-made latency in transfer time and increasing PCIe bandwidth occupancy due to overheads in communication over the bus. Moreover, given PCIe bandwidth limits, copying uncompressed image data would quickly saturate the PCIe bus. </p> <p> Memory Flow with Hardware Acceleration and Real-time Processing </p> <p>On the bright side, however, GPU enabled Hardware based encoding/decoding is inherently faster and more efficient (do not use much CPU resources when frames in GPU) thus freeing up the CPU for other tasks, as compared to Software based encoding/decoding that is known to be completely CPU intensive. Plus scaling, de-interlacing, filtering, etc. tasks will be way faster and efficient than usual using these Hardware based decoders/encoders as oppose to Software ones.</p> <p>As you can see the pros definitely outweigh the cons and you're getting to process video frames in the real-time with immense speed and flexibility, which is impossible to do otherwise.</p> <p>We'll discuss its Hardware-Accelerated Video Transcoding capabilities using these APIs briefly in the following recipes:</p> <p> </p> <p>DeFFcode APIs requires FFmpeg executable</p> <p>DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality, and any failure in detection will raise <code>RuntimeError</code> immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation.</p> Additional Python Dependencies for following recipes <p>Following recipes requires additional python dependencies which can be installed easily as below:</p> <ul> <li> <p> OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via <code>pip</code>:</p> OpenCV installation from source <p>You can also follow online tutorials for building &amp; installing OpenCV on Windows, Linux, MacOS and Raspberry Pi machines manually from its source. </p> <p> Make sure not to install both pip and source version together. Otherwise installation will fail to work!</p> Other OpenCV binaries <p>OpenCV maintainers also provide additional binaries via pip that contains both main modules and contrib/extra modules <code>opencv-contrib-python</code>, and for server (headless) environments like <code>opencv-python-headless</code> and <code>opencv-contrib-python-headless</code>. You can also install any one of them in similar manner. More information can be found here.</p> <pre><code>pip install opencv-python       </code></pre> </li> <li> <p> VidGear: VidGear is required for lossless encoding of video frames into file/stream. You can easily install it directly via <code>pip</code>:</p> <pre><code>pip install vidgear[core]       </code></pre> </li> </ul> <p>Always use FFdecoder API's <code>terminate()</code> method at the end to avoid undesired behavior.</p> <p> </p>"},{"location":"recipes/advanced/transcode-hw-acceleration/#cuda-accelerated-video-transcoding-with-opencvs-videowriter-api","title":"CUDA-accelerated Video Transcoding with OpenCV's VideoWriter API","text":"Example Assumptions <p>Please note that following recipe explicitly assumes:</p> <ul> <li>You're running  Linux operating system with a supported NVIDIA GPU.</li> <li> <p>You're using FFmpeg 4.4 or newer, configured with at least <code>--enable-nonfree --enable-cuda-nvcc --enable-libnpp  --enable-cuvid --enable-nvenc</code> configuration flags during compilation. For compilation follow these instructions \u27b6</p> Verifying NVDEC/CUDA support in FFmpeg <p>To use CUDA Video-decoder(<code>cuda</code>), remember to check if your FFmpeg compiled with it by executing following commands in your terminal, and observing if output contains something similar as follows:</p> <pre><code>$ ffmpeg  -hide_banner -pix_fmts | grep cuda\n..H.. cuda                   0              0      0\n$ ffmpeg  -hide_banner -filters | egrep \"cuda|npp\"\n... bilateral_cuda    V-&gt;V       GPU accelerated bilateral filter\n... chromakey_cuda    V-&gt;V       GPU accelerated chromakey filter\n... colorspace_cuda   V-&gt;V       CUDA accelerated video color converter\n... hwupload_cuda     V-&gt;V       Upload a system memory frame to a CUDA device.\n... overlay_cuda      VV-&gt;V      Overlay one video on top of another using CUDA\n... scale_cuda        V-&gt;V       GPU accelerated video resizer\n... scale_npp         V-&gt;V       NVIDIA Performance Primitives video scaling and format conversion\n... scale2ref_npp     VV-&gt;VV     NVIDIA Performance Primitives video scaling and format conversion to the given reference.\n... sharpen_npp       V-&gt;V       NVIDIA Performance Primitives video sharpening filter.\n... thumbnail_cuda    V-&gt;V       Select the most representative frame in a given sequence of consecutive frames.\n... transpose_npp     V-&gt;V       NVIDIA Performance Primitives video transpose\nT.. yadif_cuda        V-&gt;V       Deinterlace CUDA frames\n</code></pre> Verifying H.264 NVENC encoder support in FFmpeg <p>To use NVENC Video-encoder(<code>cuda</code>), remember to check if your FFmpeg compiled with H.264 NVENC encoder support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows:</p> <pre><code>$ ffmpeg  -hide_banner -encoders | grep nvenc V....D av1_nvenc            NVIDIA NVENC av1 encoder (codec av1)\nV....D h264_nvenc           NVIDIA NVENC H.264 encoder (codec h264)\nV....D hevc_nvenc           NVIDIA NVENC hevc encoder (codec hevc)\n</code></pre> <p>You can also use other NVENC encoder in the similar way, if supported.</p> </li> <li> <p>You already have appropriate Nvidia video drivers and related softwares installed on your machine.</p> </li> <li>If the stream is not decodable in hardware (for example, it is an unsupported codec or profile) then it will still be decoded in software automatically, but hardware filters won't be applicable.</li> </ul> <p>These assumptions MAY/MAY NOT suit your current setup. Kindly use suitable parameters based your system platform and hardware settings only.</p> <p>In this example, we will be: </p> <ol> <li>Using Nvidia's CUDA Internal hwaccel Video decoder(<code>cuda</code>) in FFdecoder API to automatically detect best NV-accelerated video codec and keeping video frames in GPU memory (for applying hardware filters) for achieving GPU-accelerated decoding of a given video file (say <code>foo.mp4</code>).</li> <li>Scaling and Cropping decoded frames in GPU memory.</li> <li>Downloading decoded frames into system memory as patched NV12 frames.</li> <li>Converting NV12 frames into BGR pixel-format using OpenCV's <code>cvtcolor</code> method.</li> <li>Encoding BGR frames with OpenCV's VideoWriter API.</li> </ol> <p>You can use FFdecoder's <code>metadata</code> property object that dumps source Video's metadata information (as JSON string) to retrieve source framerate.</p> <p>With FFdecoder API, frames extracted with YUV pixel formats (<code>yuv420p</code>, <code>yuv444p</code>, <code>nv12</code>, <code>nv21</code> etc.) are generally incompatible with OpenCV APIs such as <code>imshow()</code>. But you can make them easily compatible by using exclusive <code>-enforce_cv_patch</code> boolean attribute of its <code>ffparam</code> dictionary parameter.</p> <p>More information on Nvidia's NVENC Encoder can be found here \u27b6</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport json\nimport cv2\n# define suitable FFmpeg parameter\nffparams = {\n\"-vcodec\": None,  # skip source decoder and let FFmpeg chose\n\"-enforce_cv_patch\": True # enable OpenCV patch for YUV(NV12) frames\n\"-ffprefixes\": [\n\"-vsync\",\n\"0\",  # prevent duplicate frames\n\"-hwaccel\",\n\"cuda\",  # accelerator\n\"-hwaccel_output_format\",\n\"cuda\",  # output accelerator\n],\n\"-custom_resolution\": \"null\",  # discard source `-custom_resolution`\n\"-framerate\": \"null\",  # discard source `-framerate`\n\"-vf\": \"scale_cuda=640:360,\" # scale to 640x360 in GPU memory\n+ \"crop=80:60:200:100,\" # crop a 80\u00d760 section from position (200, 100) in GPU memory\n+ \"hwdownload,\"  # download hardware frames to system memory\n+ \"format=nv12\",  # convert downloaded frames to NV12 pixel format\n}\n# initialize and formulate the decoder with `foo.mp4` source\ndecoder = FFdecoder(\n\"foo.mp4\",\nframe_format=\"null\",  # discard source frame pixel format\nverbose = False, # to avoid too much clutter\n**ffparams # apply various params and custom filters\n).formulate()\n# retrieve JSON Metadata and convert it to dict\nmetadata_dict = json.loads(decoder.metadata)\n# prepare OpenCV parameters\nFOURCC = cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\")\nFRAMERATE = metadata_dict[\"output_framerate\"]\nFRAMESIZE = tuple(metadata_dict[\"output_frames_resolution\"])\n# Define writer with parameters and suitable output filename for e.g. `output_foo_gray.avi`\nwriter = cv2.VideoWriter(\"output_foo.avi\", FOURCC, FRAMERATE, FRAMESIZE)\n# grab the NV12 frames from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# convert it to `BGR` pixel format,\n# since write() method only accepts `BGR` frames\nframe = cv2.cvtColor(frame, cv2.COLOR_YUV2BGR_NV12)\n# {do something with the BGR frame here}\n# writing BGR frame to writer\nwriter.write(frame)\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"recipes/advanced/transcode-hw-acceleration/#cuda-nvenc-accelerated-video-transcoding-with-writegear-api","title":"CUDA-NVENC-accelerated Video Transcoding with WriteGear API","text":"<p>WriteGear's Compression Mode support for FFdecoder API is currently in beta so you can expect much higher than usual CPU utilization!</p> Lossless transcoding  with FFdecoder and WriteGear API <p>VidGear's WriteGear API implements a complete, flexible, and robust wrapper around FFmpeg in compression mode for encoding real-time video frames to a lossless compressed multimedia output file(s)/stream(s). </p> <p>DeFFcode's FFdecoder API in conjunction with WriteGear API creates a high-level High-performance Lossless FFmpeg Transcoding (Decoding + Encoding) Pipeline  that is able to exploit almost any FFmpeg parameter for achieving anything imaginable with multimedia video data all while allow us to manipulate the real-time video frames with immense flexibility.</p> Example Assumptions <p>Please note that following recipe explicitly assumes:</p> <ul> <li>You're running  Linux operating system with a supported NVIDIA GPU.</li> <li> <p>You're using FFmpeg 4.4 or newer, configured with at least <code>--enable-nonfree --enable-cuda-nvcc --enable-libnpp  --enable-cuvid --enable-nvenc</code> configuration flags during compilation. For compilation follow these instructions \u27b6</p> Verifying NVDEC/CUDA support in FFmpeg <p>To use CUDA Video-decoder(<code>cuda</code>), remember to check if your FFmpeg compiled with it by executing following commands in your terminal, and observing if output contains something similar as follows:</p> <pre><code>$ ffmpeg  -hide_banner -pix_fmts | grep cuda\n..H.. cuda                   0              0      0\n$ ffmpeg  -hide_banner -filters | egrep \"cuda|npp\"\n... bilateral_cuda    V-&gt;V       GPU accelerated bilateral filter\n... chromakey_cuda    V-&gt;V       GPU accelerated chromakey filter\n... colorspace_cuda   V-&gt;V       CUDA accelerated video color converter\n... hwupload_cuda     V-&gt;V       Upload a system memory frame to a CUDA device.\n... overlay_cuda      VV-&gt;V      Overlay one video on top of another using CUDA\n... scale_cuda        V-&gt;V       GPU accelerated video resizer\n... scale_npp         V-&gt;V       NVIDIA Performance Primitives video scaling and format conversion\n... scale2ref_npp     VV-&gt;VV     NVIDIA Performance Primitives video scaling and format conversion to the given reference.\n... sharpen_npp       V-&gt;V       NVIDIA Performance Primitives video sharpening filter.\n... thumbnail_cuda    V-&gt;V       Select the most representative frame in a given sequence of consecutive frames.\n... transpose_npp     V-&gt;V       NVIDIA Performance Primitives video transpose\nT.. yadif_cuda        V-&gt;V       Deinterlace CUDA frames\n</code></pre> Verifying H.264 NVENC encoder support in FFmpeg <p>To use NVENC Video-encoder(<code>cuda</code>), remember to check if your FFmpeg compiled with H.264 NVENC encoder support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows:</p> <pre><code>$ ffmpeg  -hide_banner -encoders | grep nvenc V....D av1_nvenc            NVIDIA NVENC av1 encoder (codec av1)\nV....D h264_nvenc           NVIDIA NVENC H.264 encoder (codec h264)\nV....D hevc_nvenc           NVIDIA NVENC hevc encoder (codec hevc)\n</code></pre> <p>You can also use other NVENC encoder in the similar way, if supported.</p> </li> <li> <p>You already have appropriate Nvidia video drivers and related softwares installed on your machine.</p> </li> <li>If the stream is not decodable in hardware (for example, it is an unsupported codec or profile) then it will still be decoded in software automatically, but hardware filters won't be applicable.</li> </ul> <p>These assumptions MAY/MAY NOT suit your current setup. Kindly use suitable parameters based your system platform and hardware settings only.</p> Additional Parameters in WriteGear API <p>WriteGear API only requires a valid Output filename (e.g. <code>output_foo.mp4</code>) as input, but you can easily control any output specifications (such as bitrate, codec, framerate, resolution, subtitles, etc.) supported by FFmpeg (in use).</p> <p>You can use FFdecoder's <code>metadata</code> property object that dumps source Video's metadata information (as JSON string) to retrieve source framerate.</p> Consuming <code>BGR</code> framesConsuming <code>NV12</code> frames <p>In this example, we will be: </p> <ol> <li>Using Nvidia's CUDA Internal hwaccel Video decoder(<code>cuda</code>) in FFdecoder API to automatically detect best NV-accelerated video codec and keeping video frames in GPU memory (for applying hardware filters) for achieving GPU-accelerated decoding of a given video file (say <code>foo.mp4</code>).</li> <li>Scaling and Cropping decoded frames in GPU memory.</li> <li>Downloading decoded frames into system memory as patched NV12 frames.</li> <li>Converting patched NV12 frames into BGR pixel-format using OpenCV's <code>cvtcolor</code> method.</li> <li>Encoding BGR frames with WriteGear API using Nvidia's Hardware accelerated H.264 NVENC Video-encoder(<code>h264_nvenc</code>) into lossless video file in the GPU memory. </li> </ol> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nfrom vidgear.gears import WriteGear\nimport json\nimport cv2\n# define suitable FFmpeg parameter\nffparams = {\n\"-vcodec\": None,  # skip source decoder and let FFmpeg chose\n\"-enforce_cv_patch\": True # enable OpenCV patch for YUV(NV12) frames\n\"-ffprefixes\": [\n\"-vsync\",\n\"0\",  # prevent duplicate frames\n\"-hwaccel\",\n\"cuda\",  # accelerator\n\"-hwaccel_output_format\",\n\"cuda\",  # output accelerator\n],\n\"-custom_resolution\": \"null\",  # discard source `-custom_resolution`\n\"-framerate\": \"null\",  # discard source `-framerate`\n\"-vf\": \"scale_cuda=640:360,\"  # scale to 640x360 in GPU memory\n+ \"crop=80:60:200:100,\" # crop a 80\u00d760 section from position (200, 100) in GPU memory\n+ \"hwdownload,\"  # download hardware frames to system memory\n+ \"format=nv12\",  # convert downloaded frames to NV12 pixel format\n}\n# initialize and formulate the decoder with `foo.mp4` source\ndecoder = FFdecoder(\n\"foo.mp4\",\nframe_format=\"null\",  # discard source frame pixel format\nverbose = False, # to avoid too much clutter\n**ffparams # apply various params and custom filters\n).formulate()\n# retrieve framerate from JSON Metadata and pass it as\n# `-input_framerate` parameter for controlled framerate\noutput_params = {\n\"-input_framerate\": json.loads(decoder.metadata)[\"output_framerate\"],\n\"-vcodec\": \"h264_nvenc\", # H.264 NVENC Video-encoder\n}\n# Define writer with default parameters and suitable\n# output filename for e.g. `output_foo.mp4`\nwriter = WriteGear(output=\"output_foo.mp4\", logging=True, **output_params)\n# grab the NV12 frames from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# convert it to `BGR` pixel format\nframe = cv2.cvtColor(frame, cv2.COLOR_YUV2BGR_NV12)\n# {do something with the BGR frame here}\n# writing BGR frame to writer\nwriter.write(frame)\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.close()\n</code></pre> <p>In this example, we will be: </p> <ol> <li>Using Nvidia's CUDA Internal hwaccel Video decoder(<code>cuda</code>) in FFdecoder API to automatically detect best NV-accelerated video codec and keeping video frames in GPU memory (for applying hardware filters) for achieving GPU-accelerated decoding of a given video file (say <code>foo.mp4</code>).</li> <li>Scaling and Cropping decoded frames in GPU memory.</li> <li>Downloading decoded frames into system memory as NV12 frames.</li> <li>Encoding NV12 frames directly with WriteGear API using Nvidia's Hardware accelerated H.264 NVENC Video-encoder(<code>h264_nvenc</code>) into lossless video file in the GPU memory. </li> </ol> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nfrom vidgear.gears import WriteGear\nimport json\nimport cv2\n# define suitable FFmpeg parameter\nffparams = {\n\"-vcodec\": None,  # skip source decoder and let FFmpeg chose\n\"-ffprefixes\": [\n\"-vsync\",\n\"0\",  # prevent duplicate frames\n\"-hwaccel\",\n\"cuda\",  # accelerator\n\"-hwaccel_output_format\",\n\"cuda\",  # output accelerator\n],\n\"-custom_resolution\": \"null\",  # discard source `-custom_resolution`\n\"-framerate\": \"null\",  # discard source `-framerate`\n\"-vf\": \"scale_cuda=640:360,\"  # scale to 640x360 in GPU memory\n+ \"crop=80:60:200:100,\"  # crop a 80\u00d760 section from position (200, 100) in GPU memory\n+ \"hwdownload,\"  # download hardware frames to system memory\n+ \"format=nv12\",  # convert downloaded frames to NV12 pixel format\n}\n# initialize and formulate the decoder with `foo.mp4` source\ndecoder = FFdecoder(\n\"foo.mp4\",\nframe_format=\"null\",  # discard source frame pixel format\nverbose = False, # to avoid too much clutter\n**ffparams # apply various params and custom filters\n).formulate()\n# retrieve framerate from JSON Metadata and pass it as\n# `-input_framerate` parameter for controlled framerate\noutput_params = {\n\"-input_framerate\": json.loads(decoder.metadata)[\"output_framerate\"],\n\"-vcodec\": \"h264_nvenc\", # H.264 NVENC Video-encoder\n\"-input_pixfmt\": \"nv12\", # input frames pixel format as `NV12`\n}\n# Define writer with default parameters and suitable\n# output filename for e.g. `output_foo.mp4`\nwriter = WriteGear(output=\"output_foo.mp4\", logging=True, **output_params)\n# grab the NV12 frames from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the NV12 frame here}\n# writing NV12 frame to writer\nwriter.write(frame)\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"recipes/advanced/transcode-hw-acceleration/#cuda-nvenc-accelerated-end-to-end-lossless-video-transcoding-with-writegear-api","title":"CUDA-NVENC-accelerated End-to-end Lossless Video Transcoding with WriteGear API","text":"<p>DeFFcode's FFdecoder API in conjunction with VidGear's WriteGear API creates a High-performance Lossless FFmpeg Transcoding Pipeline </p> Courtesy - tenor"},{"location":"recipes/advanced/transcode-live-frames-complexgraphs/","title":"Transcoding Live Complex Filtergraphs","text":"What are Complex filtergraphs? <p>Before heading straight into recipes we will talk about Complex filtergraphs: </p> <p>Complex filtergraphs are those which cannot be described as simply a linear processing chain applied to one stream.  </p> <p>Complex filtergraphs are configured with the <code>-filter_complex</code> global option. </p> <p>The <code>-lavfi</code> option is equivalent to <code>-filter_complex</code>.</p> <p>A trivial example of a complex filtergraph is the <code>overlay</code> filter, which has two video inputs and one video output, containing one video overlaid on top of the other.</p> <p>DeFFcode's FFdecoder API seamlessly supports processing multiple input streams including real-time frames through multiple filter chains combined into a filtergraph (via. <code>-filter_complex</code> FFmpeg parameter), and use their outputs as inputs for other filter chains. </p> <p>We'll discuss the transcoding of live complex filtergraphs in the following recipes:</p> <p> </p> <p>DeFFcode APIs requires FFmpeg executable</p> <p>DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality, and any failure in detection will raise <code>RuntimeError</code> immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation.</p> Additional Python Dependencies for following recipes <p>Following recipes requires additional python dependencies which can be installed easily as below:</p> <ul> <li> <p> OpenCV: OpenCV is required for previewing and encoding video frames. You can easily install it directly via <code>pip</code>:</p> OpenCV installation from source <p>You can also follow online tutorials for building &amp; installing OpenCV on Windows, Linux, MacOS and Raspberry Pi machines manually from its source. </p> <p> Make sure not to install both pip and source version together. Otherwise installation will fail to work!</p> Other OpenCV binaries <p>OpenCV maintainers also provide additional binaries via pip that contains both main modules and contrib/extra modules <code>opencv-contrib-python</code>, and for server (headless) environments like <code>opencv-python-headless</code> and <code>opencv-contrib-python-headless</code>. You can also install any one of them in similar manner. More information can be found here.</p> <pre><code>pip install opencv-python       </code></pre> </li> <li> <p> VidGear: VidGear is required for lossless encoding of video frames into file/stream. You can easily install it directly via <code>pip</code>:</p> <pre><code>pip install vidgear[core]       </code></pre> </li> </ul> <p>Always use FFdecoder API's <code>terminate()</code> method at the end to avoid undesired behavior.</p> <p>WriteGear's Compression Mode support for FFdecoder API is currently in beta so you can expect much higher than usual CPU utilization!</p> <p> </p>"},{"location":"recipes/advanced/transcode-live-frames-complexgraphs/#transcoding-video-with-live-custom-watermark-image-overlay","title":"Transcoding video with Live Custom watermark image overlay","text":"Big Buck Bunny with custom watermark <p>In this example we will apply a watermark image (say <code>watermark.png</code> with transparent background) overlay to the <code>10</code> seconds of video file (say <code>foo.mp4</code>) using FFmpeg's <code>overlay</code> filter with some additional filtering, , and decode live BGR24 video frames in FFdecoder API. We'll also be encoding those decoded frames in real-time into lossless video file using WriteGear API with controlled framerate.</p> <p>You can use FFdecoder's <code>metadata</code> property object that dumps Source Metadata as JSON to retrieve source framerate and frame-size.</p> <p>To learn about exclusive <code>-ffprefixes</code> &amp; <code>-clones</code> parameter. See Exclusive Parameters \u27b6</p> <p>Remember to replace <code>watermark.png</code> watermark image file-path with yours before using this recipe.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nfrom vidgear.gears import WriteGear\nimport json, cv2\n# define the Complex Video Filter with additional `watermark.png` image input\nffparams = {\n\"-ffprefixes\": [\"-t\", \"10\"],  # playback time of 10 seconds\n\"-clones\": [\n\"-i\",\n\"watermark.png\",  # !!! [WARNING] define your `watermark.png` here.\n],\n\"-filter_complex\": \"[1]format=rgba,\"  # change 2nd(image) input format to yuv444p\n+ \"colorchannelmixer=aa=0.7[logo];\"  # apply colorchannelmixer to image for controlling alpha [logo]\n+ \"[0][logo]overlay=W-w-{pixel}:H-h-{pixel}:format=auto,\".format(  # apply overlay to 1st(video) with [logo]\npixel=5  # at 5 pixels from the bottom right corner of the input video\n)\n+ \"format=bgr24\",  # change output format to `yuv422p10le`\n}\n# initialize and formulate the decoder for BGR24 output with given params\ndecoder = FFdecoder(\n\"foo.mp4\", frame_format=\"bgr24\", verbose=True, **ffparams\n).formulate()\n# retrieve framerate from source JSON Metadata and pass it as `-input_framerate`\n# parameter for controlled framerate and define other parameters\noutput_params = {\n\"-input_framerate\": json.loads(decoder.metadata)[\"output_framerate\"],\n}\n# Define writer with default parameters and suitable\n# output filename for e.g. `output_foo.mp4`\nwriter = WriteGear(output_filename=\"output_foo.mp4\", **output_params)\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# writing BGR24 frame to writer\nwriter.write(frame)\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"recipes/advanced/transcode-live-frames-complexgraphs/#transcoding-video-from-sequence-of-images-with-additional-filtering","title":"Transcoding video from sequence of Images with additional filtering","text":"Mandelbrot pattern blend with Fish school video Available blend mode options <p>Other blend mode options for <code>blend</code> filter include: <code>addition</code>, <code>addition128</code>, <code>grainmerge</code>, <code>and</code>, <code>average</code>, <code>burn</code>, <code>darken</code>, <code>difference</code>, <code>difference128</code>, <code>grainextract</code>, <code>divide</code>, <code>dodge</code>, <code>freeze</code>, <code>exclusion</code>, <code>extremity</code>, <code>glow</code>, <code>hardlight</code>, <code>hardmix</code>, <code>heat</code>, <code>lighten</code>, <code>linearlight</code>, <code>multiply</code>, <code>multiply128</code>, <code>negation</code>, <code>normal</code>, <code>or</code>, <code>overlay</code>, <code>phoenix</code>, <code>pinlight</code>, <code>reflect</code>, <code>screen</code>, <code>softlight</code>, <code>subtract</code>, <code>vividlight</code>, <code>xor</code></p> <p>In this example we will blend <code>10</code> seconds of Mandelbrot test pattern (generated using <code>lavfi</code> input virtual device) that serves as the \"top\" layer with <code>10</code> seconds of Image Sequence that serves as the \"bottom\" layer, using <code>blend</code> filter (with <code>heat</code> blend mode), and decode live BGR24 video frames in FFdecoder API. We'll also be encoding those decoded frames in real-time into lossless video file using WriteGear API with controlled framerate.</p> Extracting Image Sequences from a video <p>You can use following FFmpeg command to extract sequences of images from a video file <code>foo.mp4</code> (restricted to 12 seconds):</p> <pre><code>$ ffmpeg -t 12 -i foo.mp4 /path/to/image-%03d.png\n</code></pre> <p>The default framerate is <code>25</code> fps, therefore this command will extract <code>25 images/sec</code> from the video file, and save them as sequences of images (starting from <code>image-000.png</code>, <code>image-001.png</code>, <code>image-002.png</code> up to <code>image-999.png</code>). </p> <p>If there are more than <code>1000</code> frames then the last image will be overwritten with the remaining frames leaving only the last frame.</p> <p>The default images width and height is same as the video.</p> How to start with specific number image? <p>You can use <code>-start_number</code> FFmpeg parameter if you want to start with specific number image:</p> <pre><code># define `-start_number` such as `5`\nffparams = {\"-ffprefixes\":[\"-start_number\", \"5\"]}\n# initialize and formulate the decoder with define parameters\ndecoder = FFdecoder('/path/to/img%03d.png', verbose=True, **ffparams).formulate()\n</code></pre> <p>FFdecoder API also accepts Glob pattern(<code>*.png</code>) as well Single looping image as as input to its <code>source</code> parameter. See this Basic Recipe  \u27b6 for more information.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nfrom vidgear.gears import WriteGear\nimport cv2, json\n# define mandelbrot pattern generator\n# and the Video Filter definition\nffparams = {\n\"-ffprefixes\": [\n\"-t\", \"10\", # playback time of 10 seconds for mandelbrot pattern\n\"-f\", \"lavfi\", # use input virtual device\n\"-i\", \"mandelbrot=rate=25\", # create mandelbrot pattern at 25 fps\n\"-t\", \"10\", # playback time of 10 seconds for video\n],  \n\"-custom_resolution\": (1280, 720), # resize to 1280x720\n\"-filter_complex\":\"[1:v]format=yuv444p[v1];\" # change 2nd(video) input format to yuv444p\n+ \"[0:v]format=gbrp10le[v0];\" # change 1st(mandelbrot pattern) input format to gbrp10le\n+ \"[v1][v0]scale2ref[v1][v0];\" # resize the 1st(mandelbrot pattern), based on a 2nd(video).\n+ \"[v0][v1]blend=all_mode='heat',\" # apply heat blend mode to output\n+ \"format=yuv422p10le[v]\", # change output format to `yuv422p10le`\n\"-map\": \"[v]\", # map the output\n}\n# initialize and formulate the decoder with suitable source\ndecoder = FFdecoder(\n\"/path/to/image-%03d.png\", frame_format=\"bgr24\", verbose=True, **ffparams\n).formulate()\n# define your parameters\n# [WARNING] framerate must match original source framerate !!!\noutput_params = {\n\"-input_framerate\": 25,  # Default\n}\n# Define writer with default parameters and suitable\n# output filename for e.g. `output_foo.mp4`\nwriter = WriteGear(output_filename=\"output_foo.mp4\", **output_params)\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# writing BGR24 frame to writer\nwriter.write(frame)\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"recipes/advanced/update-metadata/","title":"Updating Video Metadata","text":"<p>In addition of using <code>metadata</code> property object in FFdecoder API for probing metadata information (only as JSON string)  for each multimedia stream available in the given video source, you can also easily update the video metadata on-the-fly by assigning desired data as python dictionary to the same overloaded <code>metadata</code> property object. This feature can be used either for adding new custom properties to metadata, or to override source metadata properties used by FFdecoder API to formulate its default Decoder Pipeline for real-time video-frames generation.</p> <p>We'll discuss video metadata extraction using both these APIs briefly in the following recipes:</p> <p>This feature is not yet fully explored, but in the near future you'll be able to use it to dynamically override any Video frames Decoder Pipeline property (such as frame-size, pixel-format, etc.) in real-time like a pro. Stay tuned for more updates </p> <p> </p> <p>DeFFcode APIs requires FFmpeg executable</p> <p>DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality, and any failure in detection will raise <code>RuntimeError</code> immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation.</p> Never name your python script <code>deffcode.py</code> <p>When trying out these recipes, never name your python script <code>deffcode.py</code> otherwise it will result in <code>ModuleNotFound</code> error.</p> <p> </p>"},{"location":"recipes/advanced/update-metadata/#added-new-properties-to-metadata-in-ffdecoder-api","title":"Added new properties to metadata in FFdecoder API","text":"<p>In FFdecoder API, you can easily define any number of new properties for its metadata (formatted as python dictionary) with desired data of any datatype(s)1 , without affecting its default Video frames Decoder pipeline.</p> <p>In this example we will probe all metadata information available within <code>foo.mp4</code> video file on  Windows machine, thereby add new propertys  (formatted as python dictionary) with desired data of different datatype(s) through overloaded <code>metadata</code> property object, and then finally print it as JSON string using the same <code>metadata</code> property object in FFdecoder API.</p> <p>The value assigned to <code>metadata</code> property object can be of <code>dictionary</code> datatype only. Any other type will immediately raise <code>ValueError</code>!</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport json\n# initialize the decoder using suitable source\ndecoder = FFdecoder(\"foo.mp4\", verbose=True)\n# format your data as dictionary (with data of any [printable] datatype)\ndata = dict(\nmystring=\"abcd\",  # string data\nmyint=1234,  # integers data\nmylist=[1, \"Rohan\", [\"inner_list\"]],  # list data\nmytuple=(1, \"John\", (\"inner_tuple\")),  # tuple data\nmydict={\"anotherstring\": \"hello\"},  # dictionary data\nmyjson=json.loads('{\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}'),  # json data\n)\n# assign your dictionary data\ndecoder.metadata = data\n# finally formulate the decoder\ndecoder.formulate()\n# print metadata as `json.dump`\nprint(decoder.metadata)\n# terminate the decoder\ndecoder.terminate()\n</code></pre> After running above python code, the resultant Terminal Output will look something as following on Windows machine: <pre><code>{\n\"ffmpeg_binary_path\": \"C:\\\\Users\\\\foo\\\\AppData\\\\Local\\\\Temp\\\\ffmpeg-static-win64-gpl/bin/ffmpeg.exe\",\n\"source\": \"D:\\\\foo.mp4\",\n\"source_extension\": \".mp4\",\n\"source_video_resolution\": [\n1920,\n1080\n],\n\"source_video_framerate\": 29.97,\n\"source_video_pixfmt\": \"yuv420p\",\n\"source_video_decoder\": \"h264\",\n\"source_duration_sec\": 21.03,\n\"approx_video_nframes\": 630,\n\"source_video_bitrate\": \"4937k\",\n\"source_audio_bitrate\": \"256k\",\n\"source_audio_samplerate\": \"48000 Hz\",\n\"source_has_video\": true,\n\"source_has_audio\": true,\n\"source_has_image_sequence\": false,\n\"ffdecoder_operational_mode\": \"Video-Only\",\n\"output_frames_pixfmt\": \"rgb24\",\n\"mystring\": \"abcd\",\n\"myint\": 1234,\n\"mylist\": [\n1,\n\"Rohan\",\n[\n\"inner_list\"\n]\n],\n\"mytuple\": [\n1,\n\"John\",\n\"inner_tuple\"\n],\n\"mydict\": {\n\"anotherstring\": \"hello\"\n},\n\"myjson\": {\n\"name\": \"John\",\n\"age\": 30,\n\"city\": \"New York\"\n}\n}\n</code></pre> <p> </p>"},{"location":"recipes/advanced/update-metadata/#overriding-source-video-metadata-in-ffdecoder-api","title":"Overriding source video metadata in FFdecoder API","text":"<p>In FFdecoder API, you can also use its <code>metadata</code> to manually override the source properties (as frame-size, frame pixel-format, video-framerate, video-decoder etc.) that directly affects its default Video frames Decoder pipeline that decodes real-time video-frames.</p> <p>The <code>\"source\"</code> property in metadata cannot be altered in any manner.</p> Source Video metadata values must be handled carefully <p>Source Video metadata information is used by FFdecoder API to formulate its default Video frames Decoder pipeline, and any improper or invalid inputted source property could crash the pipeline with <code>RuntimeError</code>. </p> <p>Therefore to safeguard against it, FFdecoder API discards any Source Video metadata dictionary keys, if its value's datatype fails to match the exact valid datatype defined in following table:</p> <p>Only either <code>source_demuxer</code> or <code>source_extension</code> property can be present in source metadata.</p> <p>Not all Source Video metadata properties directly affects the pipeline (as mentioned in the table). But this might change in future versions.</p> Source Video Metadata Keys Valid Value Datatype Effect on Pipeline <code>\"source_extension\"</code> <code>string</code> None <code>\"source_demuxer\"</code> <code>string</code> Direct <code>\"source_video_resolution\"</code> <code>list of integers</code> e.g. <code>[1280,720]</code> Direct <code>\"source_video_framerate\"</code> <code>float</code> Direct <code>\"source_video_pixfmt\"</code> <code>string</code> Direct <code>\"source_video_decoder\"</code> <code>string</code> Direct <code>\"source_duration_sec\"</code> <code>float</code> None <code>\"approx_video_nframes\"</code> <code>integer</code> Direct <code>\"source_video_bitrate\"</code> <code>string</code> None <code>\"source_audio_bitrate\"</code> <code>string</code> None <code>\"source_audio_samplerate\"</code> <code>string</code> None <code>\"source_has_video\"</code> <code>bool</code> Direct <code>\"source_has_audio\"</code> <code>bool</code> None <code>\"source_has_image_sequence\"</code> <code>bool</code> Direct <code>\"ffdecoder_operational_mode\"</code> <code>str</code> None <code>\"output_frames_pixfmt\"</code> <code>str</code> Direct <p>Hence for instance, if \"source_video_resolution\" is assigned <code>\"1280x720\"</code> (i.e. <code>string</code> datatype value instead of <code>list</code>), then it will be discarded.</p> <p>In this example we will probe all metadata information available within <code>foo.mp4</code> video file, and override frame size (originally <code>1920x1080</code>) and pixel-format  (originally <code>rgb24</code>) to our desired values through overloaded <code>metadata</code> property object in FFdecoder API, and thereby preview them using OpenCV Library's <code>cv2.imshow()</code> method.</p> <p>The value assigned to <code>metadata</code> property object can be of <code>dictionary</code> datatype only. Any other type will immediately raise <code>ValueError</code>!</p> <p>Once the <code>formulate()</code> method is called, the metadata information present in FFdecoder API is finalized and thereby used to formulate its default pipeline for decoding real-time video-frames. Therefore make all changes to video properties beforehand.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# initialize and formulate the decoder using suitable source\ndecoder = FFdecoder(\"foo.mp4\", verbose=True)\n# override source metadata values\n# !!! [WARNING] Make sure each value datatype matches the table !!!\ndecoder.metadata = {\n\"output_frames_pixfmt\": \"gray\",  # gray frame-pixfmt\n\"source_video_resolution\": [1280, 720],  # 1280x720 frame-size\n}\n# finally formulate the decoder\ndecoder.formulate()\n# [NOTE] uncomment following line to debug values\n# print(decoder.metadata)\n# let's grab the 1280x720 sized gray frames from decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with gray frame here}\n# Show gray frames in output window\ncv2.imshow(\"Output gray\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p> <ol> <li> <p> There is no concept of <code>tuple</code> datatype in the JSON format. Thereby, Python's <code>json</code> module auto-converts all <code>tuple</code> python values into JSON <code>list</code> because that's the closest thing in JSON format to a tuple.\u00a0\u21a9</p> </li> </ol>"},{"location":"recipes/basic/","title":"Basic Recipes","text":"<p>The following recipes should be reasonably accessible to beginners of any skill level to get started with DeFFcode APIs:</p> Courtesy - tenor <p>Refer Installation doc first!</p> <p>If this is your first time using DeFFcode, head straight to the Installation Notes to install DeFFcode with required prerequisites on your machine.</p> Any proficiency with OpenCV-Python will be Helpful <p>If you've any proficiency with OpenCV-Python (Python API for OpenCV), you will find these recipes really easy. </p> Wanna suggest any improvements or additional recipes? <p>Please feel free to suggest any improvements or additional recipes on our Gitter community channel \u27b6</p> Frames are actually 3D Numpy arrays <p>In python, \"Frames\" are actually three-dimensional  NumPy <code>ndarray</code> composed of 3 nested levels of arrays, one for each dimension.</p> <p> </p>"},{"location":"recipes/basic/#basic-decoding-recipes","title":"Basic  Decoding Recipes","text":"<ul> <li>  Decoding Video files<ul> <li>Accessing RGB frames from a video file</li> <li>Capturing and Previewing BGR frames from a video file (OpenCV Support)</li> <li>Playing with any other FFmpeg pixel formats</li> </ul> </li> <li>  Decoding Camera Devices using Indexes<ul> <li>Enumerating all Camera Devices with Indexes</li> <li>Capturing and Previewing frames from a Camera using Indexes</li> </ul> </li> <li>  Decoding Network Streams<ul> <li>Capturing and Previewing frames from a HTTPs Stream</li> <li>Capturing and Previewing frames from a RTSP/RTP Stream</li> </ul> </li> <li>  Decoding Image sequences<ul> <li>Capturing and Previewing frames from Sequence of images</li> <li>Capturing and Previewing frames from Single looping image</li> </ul> </li> </ul>"},{"location":"recipes/basic/#basic-transcoding-recipes","title":"Basic  Transcoding Recipes","text":"<ul> <li>  Transcoding Live frames<ul> <li>Transcoding video using OpenCV VideoWriter API</li> <li>Transcoding lossless video using WriteGear API</li> </ul> </li> <li>  Transcoding Live Simple Filtergraphs<ul> <li>Transcoding Trimmed and Reversed video</li> <li>Transcoding Cropped video</li> <li>Transcoding Rotated video (with <code>rotate</code> filter)</li> <li>Transcoding Rotated video (with <code>transpose</code> filter) </li> <li>Transcoding Horizontally flipped and Scaled video</li> </ul> </li> <li>  Saving Key-frames as Image (Image processing)<ul> <li>Extracting Key-frames as PNG image</li> <li>Generating Thumbnail with a Fancy filter</li> </ul> </li> </ul>"},{"location":"recipes/basic/#basic-metadata-recipes","title":"Basic  Metadata Recipes","text":"<ul> <li>  Extracting Video Metadata<ul> <li>Extracting video metadata using Sourcer API</li> <li>Extracting video metadata using FFdecoder API</li> </ul> </li> </ul>"},{"location":"recipes/basic/#whats-next","title":"What's next?","text":"<p>Done already! Let's checkout Advanced Recipes  to level up  your skills! </p> <p> </p>"},{"location":"recipes/basic/decode-camera-devices/","title":"Decoding Camera Devices using Indexes","text":"<p>With DeFFcode APIs, we are able to probe and enumerate all Camera Devices names along with their respective \"device indexes\" or \"camera indexes\" no matter how many cameras are connected to your system. This makes Camera Devices decoding as simple as OpenCV, where one can effortlessly access a specific Camera Device just by the specifying the matching index of it. These indexes are much easier to read, memorize, and type, and one don't have to remember long Device names or worry about its Demuxer. </p> <p>We'll discuss the Decoding Camera Devices using Indexes briefly in the following recipes:</p> <p> </p> <p>DeFFcode APIs requires FFmpeg executable</p> <p>DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality, and any failure in detection will raise <code>RuntimeError</code> immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation.</p> Additional Python Dependencies for following recipes <p>Following recipes requires additional python dependencies which can be installed easily as below:</p> <ul> <li> <p> OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via <code>pip</code>:</p> OpenCV installation from source <p>You can also follow online tutorials for building &amp; installing OpenCV on Windows, Linux, MacOS and Raspberry Pi machines manually from its source. </p> <p> Make sure not to install both pip and source version together. Otherwise installation will fail to work!</p> Other OpenCV binaries <p>OpenCV maintainers also provide additional binaries via pip that contains both main modules and contrib/extra modules <code>opencv-contrib-python</code>, and for server (headless) environments like <code>opencv-python-headless</code> and <code>opencv-contrib-python-headless</code>. You can also install any one of them in similar manner. More information can be found here.</p> <pre><code>pip install opencv-python       </code></pre> </li> </ul> <p>Always use FFdecoder API's <code>terminate()</code> method at the end to avoid undesired behavior.</p> Never name your python script <code>deffcode.py</code> <p>When trying out these recipes, never name your python script <code>deffcode.py</code> otherwise it will result in <code>ModuleNotFound</code> error.</p> <p> </p>"},{"location":"recipes/basic/decode-camera-devices/#enumerating-all-camera-devices-with-indexes","title":"Enumerating all Camera Devices with Indexes","text":"<p>In Sourcer API, you can easily use its <code>enumerate_devices</code> property object to enumerate all probed Camera Devices (connected to your system) as dictionary object with device indexes as keys and device names as their respective values. </p> Requirement for Enumerating all Camera Devices in Sourcer API <ul> <li> <p> MUST have appropriate FFmpeg binaries, Drivers, and Softwares installed:</p> <p>Internally, DeFFcode APIs achieves Index based Camera Device Capturing by employing some specific FFmpeg demuxers on different platforms(OSes). These platform specific demuxers are as follows:</p> Platform(OS) Demuxer  Windows OS <code>dshow</code> (or DirectShow)  Linux OS <code>video4linux2</code> (or its alias <code>v4l2</code>)  Mac OS <code>avfoundation</code> <p> Important: Kindly make sure your FFmpeg binaries support these platform specific demuxers as well as system have the appropriate video drivers and related softwares installed.</p> </li> <li> <p> The <code>source</code> parameter value MUST be any Camera Device index that can be of either integer (e.g. <code>-1</code>,<code>0</code>,<code>1</code>, etc.) or string of integer (e.g. <code>\"-1\"</code>,<code>\"0\"</code>,<code>\"1\"</code>, etc.) type.</p> </li> <li> <p> The <code>source_demuxer</code> parameter value  MUST be either <code>None</code>(also means empty) or <code>\"auto\"</code>. </p> </li> </ul> <p>In this example we will enumerate all probed Camera Devices connected on a  Windows machine using <code>enumerate_devices</code> property object in Sourcer API, both as dictionary object and JSON string.</p> <pre><code># import the necessary packages\nfrom deffcode import Sourcer\nimport json\n# initialize and formulate the decoder\nsourcer = Sourcer(\"0\").probe_stream()\n# enumerate probed devices as Dictionary object(`dict`)\nprint(sourcer.enumerate_devices)\n# enumerate probed devices as JSON string(`json.dump`)\nprint(json.dumps(sourcer.enumerate_devices,indent=2))\n</code></pre> After running above python code, the resultant Terminal Output will look something as following on Windows machine: As Dictionary objectAs JSON string <pre><code>{0: 'Integrated Camera', 1: 'USB2.0 Camera', 2: 'DroidCam Source'}\n</code></pre> <pre><code>{\n\"0\": \"Integrated Camera\",\n\"1\": \"USB2.0 Camera\",\n\"2\": \"DroidCam Source\"\n}\n</code></pre> <p> </p>"},{"location":"recipes/basic/decode-camera-devices/#capturing-and-previewing-frames-from-a-camera-using-indexes","title":"Capturing and Previewing frames from a Camera using Indexes","text":"<p>After knowing the index of Camera Device with Sourcer API, One can easily Capture desired Camera Device in FFdecoder API by specifying its matching index value either as integer or string of integer type to its <code>source</code> parameter.</p> Requirement for Index based Camera Device Capturing in FFdecoder API <ul> <li> <p> MUST have appropriate FFmpeg binaries, Drivers, and Softwares installed:</p> <p>Internally, DeFFcode APIs achieves Index based Camera Device Capturing by employing some specific FFmpeg demuxers on different platforms(OSes). These platform specific demuxers are as follows:</p> Platform(OS) Demuxer  Windows OS <code>dshow</code> (or DirectShow)  Linux OS <code>video4linux2</code> (or its alias <code>v4l2</code>)  Mac OS <code>avfoundation</code> <p> Important: Kindly make sure your FFmpeg binaries support these platform specific demuxers as well as system have the appropriate video drivers and related softwares installed.</p> </li> <li> <p> The <code>source</code> parameter value MUST be exactly the probed Camera Device index (use Sourcer API's <code>enumerate_devices</code> to list them).</p> </li> <li> The <code>source_demuxer</code> parameter value  MUST be either <code>None</code>(also means empty) or <code>\"auto\"</code>. </li> </ul> <p>In this example we will decode BGR24 video frames from Integrated Camera at index <code>0</code> on a Windows Machine, and preview them using OpenCV Library's <code>cv2.imshow()</code> method.</p> Important Facts related to Camera Device Indexing <ul> <li> Camera Device indexes are 0-indexed. So the first device is at <code>0</code>, second is at <code>1</code>, so on. So if the there are <code>n</code> devices, the last device is at <code>n-1</code>.</li> <li> Camera Device indexes can be of either integer (e.g. <code>0</code>,<code>1</code>, etc.) or string of integer (e.g. <code>\"0\"</code>,<code>\"1\"</code>, etc.) type.</li> <li> Camera Device indexes can be negative (e.g. <code>-1</code>,<code>-2</code>, etc.), this means you can also start indexing from the end.<ul> <li>For example, If there are three devices:      <pre><code>{0: 'Integrated Camera', 1: 'USB2.0 Camera', 2: 'DroidCam Source'}\n</code></pre></li> <li> <p>Then, You can specify Positive Indexes and its Equivalent Negative Indexes as follows:</p> Positive Indexes Equivalent Negative Indexes <code>FFdecoder(\"0\").formulate()</code> <code>FFdecoder(\"-3\").formulate()</code> <code>FFdecoder(\"1\").formulate()</code> <code>FFdecoder(\"-2\").formulate()</code> <code>FFdecoder(\"2\").formulate()</code> <code>FFdecoder(\"-1\").formulate()</code> </li> </ul> </li> </ul> <p>Out of Index Camera Device index values will raise <code>ValueError</code> in FFdecoder API</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# initialize and formulate the decoder with \"0\" index source for BGR24 output\ndecoder = FFdecoder(\"0\", frame_format=\"bgr24\", verbose=True).formulate()\n# grab the BGR24 frames from decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p>"},{"location":"recipes/basic/decode-image-sequences/","title":"Decoding Image sequences","text":"<p>DeFFcode's FFdecoder API supports a wide-ranging media streams as input to its <code>source</code> parameter, which also includes Image Sequences such as Sequential(<code>img%03d.png</code>) and Glob pattern(<code>*.png</code>) as well as Single looping image. </p> <p>We'll discuss both briefly in the following recipes:</p> <p> </p> <p>DeFFcode APIs requires FFmpeg executable</p> <p>DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality, and any failure in detection will raise <code>RuntimeError</code> immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation.</p> Additional Python Dependencies for following recipes <p>Following recipes requires additional python dependencies which can be installed easily as below:</p> <ul> <li> <p> OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via <code>pip</code>:</p> OpenCV installation from source <p>You can also follow online tutorials for building &amp; installing OpenCV on Windows, Linux, MacOS and Raspberry Pi machines manually from its source. </p> <p> Make sure not to install both pip and source version together. Otherwise installation will fail to work!</p> Other OpenCV binaries <p>OpenCV maintainers also provide additional binaries via pip that contains both main modules and contrib/extra modules <code>opencv-contrib-python</code>, and for server (headless) environments like <code>opencv-python-headless</code> and <code>opencv-contrib-python-headless</code>. You can also install any one of them in similar manner. More information can be found here.</p> <pre><code>pip install opencv-python       </code></pre> </li> </ul> <p>Always use FFdecoder API's <code>terminate()</code> method at the end to avoid undesired behavior.</p> Never name your python script <code>deffcode.py</code> <p>When trying out these recipes, never name your python script <code>deffcode.py</code> otherwise it will result in <code>ModuleNotFound</code> error.</p> <p> </p>"},{"location":"recipes/basic/decode-image-sequences/#capturing-and-previewing-frames-from-sequence-of-images","title":"Capturing and Previewing frames from Sequence of images","text":"<p>In this example we will capture video frames from a given Image Sequence using FFdecoder API, and preview them using OpenCV Library's <code>cv2.imshow()</code> method in real-time.</p> <p>OpenCV expects <code>BGR</code> format frames in its <code>cv2.imshow()</code> method.</p> Extracting Image Sequences from a video <p>You can use following FFmpeg command to extract sequences of images from a video file <code>foo.mp4</code>:</p> <pre><code>$ ffmpeg -i foo.mp4 /path/to/image-%03d.png\n</code></pre> <p>The default framerate is <code>25</code> fps, therefore this command will extract <code>25 images/sec</code> from the video file, and save them as sequences of images (starting from <code>image-000.png</code>, <code>image-001.png</code>, <code>image-002.png</code> up to <code>image-999.png</code>). </p> <p>If there are more than <code>1000</code> frames then the last image will be overwritten with the remaining frames leaving only the last frame.</p> <p>The default images width and height is same as the video.</p> SequentialGlob pattern How to start with specific number image? <p>You can use <code>-start_number</code> FFmpeg parameter if you want to start with specific number image:</p> <pre><code># define `-start_number` such as `5`\nffparams = {\"-ffprefixes\":[\"-start_number\", \"5\"]}\n# initialize and formulate the decoder with define parameters\ndecoder = FFdecoder('img%03d.png', verbose=True, **ffparams).formulate()\n</code></pre> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# initialize and formulate the decoder with suitable source\ndecoder = FFdecoder(\"/path/to/pngs/img%03d.png\", frame_format=\"bgr24\", verbose=True).formulate()\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p>Bash-style globbing (<code>*</code> represents any number of any characters) is useful if your images are sequential but not necessarily in a numerically sequential order.</p> <p>The glob pattern is not available on Windows FFmpeg builds.</p> <p>To learn more about exclusive <code>-ffprefixes</code> parameter. See Exclusive Parameters \u27b6</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# define `-pattern_type glob` for accepting glob pattern\nffparams = {\"-ffprefixes\":[\"-pattern_type\", \"glob\"]}\n# initialize and formulate the decoder with suitable source\ndecoder = FFdecoder(\"/path/to/pngs/img*.png\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n# grab the GRAYSCALE frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p>"},{"location":"recipes/basic/decode-image-sequences/#capturing-and-previewing-frames-from-single-looping-image","title":"Capturing and Previewing frames from Single looping image","text":"<p>In this example we will capture video frames from a Single Looping image using FFdecoder API, and preview them using OpenCV Library's <code>cv2.imshow()</code> method in real-time.</p> <p>By default, OpenCV expects <code>BGR</code> format frames in its <code>cv2.imshow()</code> method.</p> <p>To learn more about exclusive <code>-ffprefixes</code> parameter. See Exclusive Parameters \u27b6</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# define `-loop 1` for infinite looping\nffparams = {\"-ffprefixes\":[\"-loop\", \"1\"]}\n# initialize and formulate the decoder with suitable source\ndecoder = FFdecoder(\"img.png\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p>"},{"location":"recipes/basic/decode-network-streams/","title":"Decoding Network Streams","text":"<p>Similar to decoding Video files, DeFFcode's FFdecoder API directly supports Network Streams with specific protocols (such as RTSP/RTP, HTTP(s), MPEG-TS, etc.) as input to its <code>source</code> parameter. </p> <p>We'll discuss Network Streams support briefly in the following recipes:</p> <p> </p> <p>DeFFcode APIs requires FFmpeg executable</p> <p>DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality, and any failure in detection will raise <code>RuntimeError</code> immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation.</p> Additional Python Dependencies for following recipes <p>Following recipes requires additional python dependencies which can be installed easily as below:</p> <ul> <li> <p> OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via <code>pip</code>:</p> OpenCV installation from source <p>You can also follow online tutorials for building &amp; installing OpenCV on Windows, Linux, MacOS and Raspberry Pi machines manually from its source. </p> <p> Make sure not to install both pip and source version together. Otherwise installation will fail to work!</p> Other OpenCV binaries <p>OpenCV maintainers also provide additional binaries via pip that contains both main modules and contrib/extra modules <code>opencv-contrib-python</code>, and for server (headless) environments like <code>opencv-python-headless</code> and <code>opencv-contrib-python-headless</code>. You can also install any one of them in similar manner. More information can be found here.</p> <pre><code>pip install opencv-python       </code></pre> </li> </ul> <p>Always use FFdecoder API's <code>terminate()</code> method at the end to avoid undesired behavior.</p> Never name your python script <code>deffcode.py</code> <p>When trying out these recipes, never name your python script <code>deffcode.py</code> otherwise it will result in <code>ModuleNotFound</code> error.</p> <p> </p>"},{"location":"recipes/basic/decode-network-streams/#capturing-and-previewing-frames-from-a-https-stream","title":"Capturing and Previewing frames from a HTTPs Stream","text":"<p>In this example we will decode live BGR24 video frames from a HTTPs protocol Stream in FFdecoder API, and preview them using OpenCV Library's <code>cv2.imshow()</code> method.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# initialize and formulate the decoder for BGR24 pixel format output\ndecoder = FFdecoder(\"https://abhitronix.github.io/html/Big_Buck_Bunny_1080_10s_1MB.mp4\", frame_format=\"bgr24\").formulate()\n# grab the BGR24 frames from decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p>"},{"location":"recipes/basic/decode-network-streams/#capturing-and-previewing-frames-from-a-rtsprtp-stream","title":"Capturing and Previewing frames from a RTSP/RTP Stream","text":"<p>In this example we will decode live BGR24 video frames from RTSP/RTP protocol Streams in FFdecoder API, and preview them using OpenCV Library's <code>cv2.imshow()</code> method.</p> <p>This example assume you already have a RSTP Server running at specified RSTP address with syntax <code>rtsp://[RTSP_ADDRESS]:[RTSP_PORT]/[RTSP_PATH]</code> and video data already being published to it.</p> <p>For creating your own RSTP Server locally and publishing video data to it, You can refer this WriteGear API's bonus example \u27b6</p> <p>Make sure to change RSTP address <code>rtsp://localhost:8554/mystream</code> with yours in following code before running</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# define suitable parameters\nffparams = {\"-rtsp_transport\": \"tcp\"}\n# initialize and formulate the decoder with RTSP protocol source for BGR24 output\n# [WARNING] Change your RSTP address `rtsp://localhost:8554/mystream` with yours!\ndecoder = FFdecoder(\"rtsp://localhost:8554/mystream\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n# grab the BGR24 frames from decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p>"},{"location":"recipes/basic/decode-video-files/","title":"Decoding Video files","text":"<p>DeFFcode's FFdecoder API readily supports multimedia Video files path as input to its <code>source</code> parameter. And with its <code>frame_format</code> parameter, you can easily decode video frames in any pixel format(s) that are readily supported by all well known Computer Vision libraries (such as OpenCV).  </p> <p>We'll discuss its video files support and pixel format capabilities briefly in the following recipes:</p> <p> </p> <p>DeFFcode APIs requires FFmpeg executable</p> <p>DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality, and any failure in detection will raise <code>RuntimeError</code> immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation.</p> Additional Python Dependencies for following recipes <p>Following recipes requires additional python dependencies which can be installed easily as below:</p> <ul> <li> <p> OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via <code>pip</code>:</p> OpenCV installation from source <p>You can also follow online tutorials for building &amp; installing OpenCV on Windows, Linux, MacOS and Raspberry Pi machines manually from its source. </p> <p> Make sure not to install both pip and source version together. Otherwise installation will fail to work!</p> Other OpenCV binaries <p>OpenCV maintainers also provide additional binaries via pip that contains both main modules and contrib/extra modules <code>opencv-contrib-python</code>, and for server (headless) environments like <code>opencv-python-headless</code> and <code>opencv-contrib-python-headless</code>. You can also install any one of them in similar manner. More information can be found here.</p> <pre><code>pip install opencv-python       </code></pre> </li> </ul> <p>Always use FFdecoder API's <code>terminate()</code> method at the end to avoid undesired behavior.</p> Never name your python script <code>deffcode.py</code> <p>When trying out these recipes, never name your python script <code>deffcode.py</code> otherwise it will result in <code>ModuleNotFound</code> error.</p> <p> </p>"},{"location":"recipes/basic/decode-video-files/#accessing-rgb-frames-from-a-video-file","title":"Accessing RGB frames from a video file","text":"<p>The default function of FFdecoder API is to decode 24-bit RGB video frames from the given source.</p> <p>FFdecoder API's <code>generateFrame()</code> function can be used in multiple methods to access RGB frames from a given source, such as as a Generator (Recommended Approach), calling <code>with</code> Statement, and as a Iterator. </p> <p>In this example we will decode the default RGB24 video frames from a given Video file (say <code>foo.mp4</code>) using above mentioned  accessing methods:</p> As a Generator (Recommended)Calling <code>with</code> StatementAs a Iterator <p>This is a recommended approach for faster and error-proof access of decoded frames. We'll use it throughout the recipes.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\n# initialize and formulate the decoder\ndecoder = FFdecoder(\"foo.mp4\").formulate()\n# grab RGB24(default) frame from decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# lets print its shape\nprint(frame.shape) # for e.g. (1080, 1920, 3)\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p>Calling <code>with</code> Statement approach can be used to make the code easier, cleaner, and much more readable. This approach also automatically handles management of <code>formulate()</code> and <code>terminate()</code> methods in FFdecoder API, so don't need to explicitly call them. See PEP343 -- The 'with' statement' for more information on this approach.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# initialize and formulate the decoder\nwith FFdecoder(\"foo.mp4\") as decoder:\n# grab the BGR24 frames from decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# lets print its shape\nprint(frame.shape)  # for e.g. (1080, 1920, 3)\n</code></pre> <p>This Iterator Approach bears a close resemblance to OpenCV-Python (Python API for OpenCV) coding syntax, thereby easier to learn and remember.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\n# initialize and formulate the decoder\ndecoder = FFdecoder(\"foo.mp4\").formulate()\n# loop over frames\nwhile True:\n# grab RGB24(default) frames from decoder\nframe = next(decoder.generateFrame(), None)\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# lets print its shape\nprint(frame.shape) # for e.g. (1080, 1920, 3)\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p>"},{"location":"recipes/basic/decode-video-files/#capturing-and-previewing-bgr-frames-from-a-video-file","title":"Capturing and Previewing BGR frames from a video file","text":"<p>In this example we will decode OpenCV supported live BGR24 video frames from a given Video file (say <code>foo.mp4</code>) in FFdecoder API, and preview them using OpenCV Library's <code>cv2.imshow()</code> method.</p> <p>By default, OpenCV expects <code>BGR</code> format frames in its <code>cv2.imshow()</code> method by using two accessing methods.</p> As a Generator (Recommended)Calling <code>with</code> Statement <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# initialize and formulate the decoder for BGR24 pixel format output\ndecoder = FFdecoder(\"foo.mp4\", frame_format=\"bgr24\").formulate()\n# grab the BGR24 frames from decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p>Calling <code>with</code> Statement approach can be used to make the code easier, cleaner, and much more readable. This approach also automatically handles management of <code>formulate()</code> and <code>terminate()</code> methods in FFdecoder API, so don't need to explicitly call them. See PEP343 -- The 'with' statement' for more information on this approach.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# initialize and formulate the decoder for BGR24 pixel format output\nwith FFdecoder(\"foo.mp4\", frame_format=\"bgr24\") as decoder:\n# grab the BGR24 frames from decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# Show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n</code></pre> <p> </p>"},{"location":"recipes/basic/decode-video-files/#playing-with-any-other-ffmpeg-pixel-formats","title":"Playing with any other FFmpeg pixel formats","text":"<p>Similar to BGR, you can input any pixel format (supported by installed FFmpeg) by way of <code>frame_format</code> parameter of FFdecoder API for the desired video frame format.</p> <p>In this example we will decode live Grayscale and YUV video frames from a given Video file (say <code>foo.mp4</code>) in FFdecoder API, and preview them using OpenCV Library's <code>cv2.imshow()</code> method.</p> <p>Use <code>ffmpeg -pix_fmts</code> terminal command to lists all FFmpeg supported pixel formats.</p> Decode GrayscaleDecode YUV frames <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# initialize and formulate the decoder for GRAYSCALE output\ndecoder = FFdecoder(\"input_foo.mp4\", frame_format=\"gray\", verbose=True).formulate()\n# grab the GRAYSCALE frames from the decoder\nfor gray in decoder.generateFrame():\n# check if frame is None\nif gray is None:\nbreak\n# {do something with the gray frame here}\n# Show output window\ncv2.imshow(\"Gray Output\", gray)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p>With FFdecoder API, frames extracted with YUV pixel formats (<code>yuv420p</code>, <code>yuv444p</code>, <code>nv12</code>, <code>nv21</code> etc.) are generally incompatible with OpenCV APIs. But you can make them easily compatible by using exclusive <code>-enforce_cv_patch</code> boolean attribute of its <code>ffparam</code> dictionary parameter.</p> <p>Let's try decoding YUV420p pixel-format frames in following python code:</p> <p>You can also use other YUV pixel formats such <code>yuv422p</code>(4:2:2 subsampling) or <code>yuv444p</code>(4:4:4 subsampling) etc. instead for more higher dynamic range in the similar manner.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# enable OpenCV patch for YUV frames\nffparams = {\"-enforce_cv_patch\": True}\n# initialize and formulate the decoder for YUV420p output\ndecoder = FFdecoder(\n\"input_foo.mp4\", frame_format=\"yuv420p\", verbose=True, **ffparams\n).formulate()\n# grab the YUV420p frames from the decoder\nfor yuv in decoder.generateFrame():\n# check if frame is None\nif yuv is None:\nbreak\n# convert it to `BGR` pixel format,\n# since imshow() method only accepts `BGR` frames\nbgr = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR_I420)\n# {do something with the bgr frame here}\n# Show output window\ncv2.imshow(\"Output\", bgr)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p>"},{"location":"recipes/basic/extract-video-metadata/","title":"Extracting Video Metadata","text":"<p>DeFFcode's Sourcer API acts as Source Probing Utility for easily probing metadata information for each multimedia stream available in the given video source, and return it as in Human-readable (as JSON string) or Machine-readable (as Dictionary object) type with its <code>retrieve_metadata()</code> class method. Apart from this, you can also use <code>metadata</code> property object in FFdecoder API to extract this metadata information (only as JSON string).</p> <p>We'll discuss video metadata extraction using both these APIs briefly in the following recipes:</p> <p> </p> <p>DeFFcode APIs requires FFmpeg executable</p> <p>DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality, and any failure in detection will raise <code>RuntimeError</code> immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation.</p> Never name your python script <code>deffcode.py</code> <p>When trying out these recipes, never name your python script <code>deffcode.py</code> otherwise it will result in <code>ModuleNotFound</code> error.</p> <p> </p>"},{"location":"recipes/basic/extract-video-metadata/#extracting-video-metadata-using-sourcer-api","title":"Extracting video metadata using Sourcer API","text":"<p>This is the recommended way for extracting video metadata.</p> <p>In this example we will probe all metadata information available within <code>foo.mp4</code> video file on  Windows machine, and print it in both Human-readable (as JSON string) and Machine-readable (as Dictionary object) types using <code>retrieve_metadata()</code> class method in Sourcer API:</p> <p>The Sourcer API's <code>retrieve_metadata()</code> class method provides <code>pretty_json</code> boolean parameter to return metadata as JSON string (if <code>True</code>) and as Dictionary (if <code>False</code>).</p> As JSON stringAs Dictionary object <pre><code># import the necessary packages\nfrom deffcode import Sourcer\n# initialize and formulate the decoder using suitable source\nsourcer = Sourcer(\"foo.mp4\").probe_stream()\n# print metadata as `json.dump`\nprint(sourcer.retrieve_metadata(pretty_json=True))\n</code></pre> After running above python code, the resultant Terminal Output will look something as following on Windows machine: <pre><code>{\n\"ffmpeg_binary_path\": \"C:\\\\Users\\\\foo\\\\AppData\\\\Local\\\\Temp\\\\ffmpeg-static-win64-gpl/bin/ffmpeg.exe\",\n\"source\": \"foo.mp4\",\n\"source_extension\": \".mp4\",\n\"source_video_resolution\": [\n1280,\n720\n],\n\"source_video_framerate\": 25.0,\n\"source_video_pixfmt\": \"yuv420p\",\n\"source_video_decoder\": \"h264\",\n\"source_duration_sec\": 5.31,\n\"approx_video_nframes\": 133,\n\"source_video_bitrate\": \"1205k\",\n\"source_audio_bitrate\": \"384k\",\n\"source_audio_samplerate\": \"48000 Hz\",\n\"source_has_video\": true,\n\"source_has_audio\": true,\n\"source_has_image_sequence\": false,\n}\n</code></pre> <pre><code># import the necessary packages\nfrom deffcode import Sourcer\n# initialize and formulate the decoder using suitable source\nsourcer = Sourcer(\"foo.mp4\").probe_stream()\n# print metadata as `dict`\nprint(sourcer.retrieve_metadata())\n</code></pre> After running above python code, the resultant Terminal Output will look something as following on Windows machine: <pre><code>{'ffmpeg_binary_path': 'C:\\\\Users\\\\foo\\\\AppData\\\\Local\\\\Temp\\\\ffmpeg-static-win64-gpl/bin/ffmpeg.exe', 'source': 'foo.mp4', 'source_extension': '.mp4', 'source_video_resolution': [1280, 720], 'source_video_framerate': 25.0, 'source_video_pixfmt': 'yuv420p', 'source_video_decoder': 'h264', 'source_duration_sec': 5.31, 'approx_video_nframes': 133, 'source_video_bitrate': '1205k', 'source_audio_bitrate': '384k', 'source_audio_samplerate': '48000 Hz', 'source_has_video': True, 'source_has_audio': True, 'source_has_image_sequence': False}\n</code></pre> <p> </p>"},{"location":"recipes/basic/extract-video-metadata/#extracting-video-metadata-using-ffdecoder-api","title":"Extracting video metadata using FFdecoder API","text":"<p>In this example we will probe all metadata information available within <code>foo.mp4</code> video file on  Windows machine, and print it as JSON string using  <code>metadata</code> property object in FFdecoder API.</p> <p>You can also update video's metadata by using the same overloaded <code>metadata</code> property object in FFdecoder API. More information can be found in this Advanced Recipe  \u27b6</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\n# initialize and formulate the decoder using suitable source\ndecoder = FFdecoder(\"foo.mp4\").formulate()\n# print metadata as `json.dump`\nprint(decoder.metadata)\n# terminate the decoder\ndecoder.terminate()\n</code></pre> After running above python code, the resultant Terminal Output will look something as following on Windows machine: <pre><code>{\n\"ffmpeg_binary_path\": \"C:\\\\Users\\\\foo\\\\AppData\\\\Local\\\\Temp\\\\ffmpeg-static-win64-gpl/bin/ffmpeg.exe\",\n\"source\": \"foo.mp4\",\n\"source_extension\": \".mp4\",\n\"source_video_resolution\": [\n1280,\n720\n],\n\"source_video_framerate\": 25.0,\n\"source_video_pixfmt\": \"yuv420p\",\n\"source_video_decoder\": \"h264\",\n\"source_duration_sec\": 5.31,\n\"approx_video_nframes\": 133,\n\"source_video_bitrate\": \"1205k\",\n\"source_audio_bitrate\": \"384k\",\n\"source_audio_samplerate\": \"48000 Hz\",\n\"source_has_video\": true,\n\"source_has_audio\": true,\n\"source_has_image_sequence\": false,\n\"ffdecoder_operational_mode\": \"Video-Only\",\n\"output_frames_pixfmt\": \"rgb24\"\n}\n</code></pre> <p> </p>"},{"location":"recipes/basic/save-keyframe-image/","title":"Saving Key-frames as Image","text":"<p>DeFFcode's FFdecoder API provide effortless and precise Frame Seeking with <code>-ss</code> FFmpeg parameter that enable us to save any frame from a specific part of our input source.  </p> <p>We'll discuss aboout it briefly in the following recipes:</p> <p> </p> <p>DeFFcode APIs requires FFmpeg executable</p> <p>DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality, and any failure in detection will raise <code>RuntimeError</code> immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation.</p> Additional Python Dependencies for following recipes <p>Following recipes requires additional python dependencies which can be installed easily as below:</p> <ul> <li> <p> OpenCV: OpenCV is required for saving video frames. You can easily install it directly via <code>pip</code>:</p> OpenCV installation from source <p>You can also follow online tutorials for building &amp; installing OpenCV on Windows, Linux, MacOS and Raspberry Pi machines manually from its source. </p> <p> Make sure not to install both pip and source version together. Otherwise installation will fail to work!</p> Other OpenCV binaries <p>OpenCV maintainers also provide additional binaries via pip that contains both main modules and contrib/extra modules <code>opencv-contrib-python</code>, and for server (headless) environments like <code>opencv-python-headless</code> and <code>opencv-contrib-python-headless</code>. You can also install any one of them in similar manner. More information can be found here.</p> <pre><code>pip install opencv-python       </code></pre> </li> <li> <p> Pillow: Pillow is a Imaging Library required for saving frame as Image. You can easily install it directly via <code>pip</code>:</p> <pre><code>pip install Pillow     </code></pre> </li> <li> <p> Matplotlib: Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations, also required for saving frame as Image. You can easily install it directly via <code>pip</code>:</p> <pre><code>pip install matplotlib   </code></pre> </li> <li> <p> Imageio: Imageio is a Library for reading and writing a wide range of image, video, scientific, and volumetric data formats, also required for saving frame as Image. You can easily install it directly via <code>pip</code>:</p> <pre><code>pip install imageio      </code></pre> </li> </ul> <p>Always use FFdecoder API's <code>terminate()</code> method at the end to avoid undesired behavior.</p> Never name your python script <code>deffcode.py</code> <p>When trying out these recipes, never name your python script <code>deffcode.py</code> otherwise it will result in <code>ModuleNotFound</code> error.</p> <p> </p>"},{"location":"recipes/basic/save-keyframe-image/#extracting-key-frames-as-png-image","title":"Extracting Key-frames as PNG image","text":"<p>In this example we will seek to <code>00:00:01.45</code>(or 1045msec) in time and decode one single frame in FFdecoder API, and thereby saving it as PNG image using few prominent Image processing python libraries by providing valid filename (e.g. <code>foo_image.png</code>).</p> Time unit syntax in <code>-ss</code> FFmpeg parameter <p>You can use two different time unit formats with <code>-ss</code> FFmpeg parameter: </p> <ul> <li> Sexagesimal(in seconds): Uses (HOURS:MM:SS.MILLISECONDS) format, such as in <code>01:23:45.678</code>.</li> <li> Fractional: such as in <code>02:30.05</code>. This is interpreted as 2 minutes, 30 and a half a second, which would be the same as using <code>150.5</code> in seconds.</li> </ul> Using PillowUsing OpenCVUsing MatplotlibUsing Imageio <p>In Pillow, the <code>fromarray()</code> function can be used to create an image memory from an RGB frame:</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nfrom PIL import Image\n# define the FFmpeg parameter to seek to 00:00:01.45(or 1s and 45msec)\n# in time and get one single frame\nffparams = {\"-ss\": \"00:00:01.45\", \"-frames:v\": 1}\n# initialize and formulate the decoder with suitable source\ndecoder = FFdecoder(\"foo.mp4\", **ffparams).formulate()\n# grab the RGB24(default) frame from the decoder\nframe = next(decoder.generateFrame(), None)\n# check if frame is None\nif not (frame is None):\n# Convert to Image\nim = Image.fromarray(frame)\n# Save Image as PNG\nim.save(\"foo_image.png\")\nelse:\nraise ValueError(\"Something is wrong!\")\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p>In OpenCV, the <code>imwrite()</code> function can export BGR frame as an image file:</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport cv2\n# define the FFmpeg parameter to seek to 00:00:01.45(or 1s and 45msec) \n# in time and get one single frame\nffparams = {\"-ss\": \"00:00:01.45\", \"-frames:v\":1}\n# initialize and formulate the decoder for BGR24 outputwith suitable source\ndecoder = FFdecoder(\"foo.mp4\", frame_format=\"bgr24\", **ffparams).formulate()\n# grab the BGR24 frame from the decoder\nframe = next(decoder.generateFrame(), None)\n# check if frame is None\nif not(frame is None):\n# Save our image as PNG\ncv2.imwrite('foo_image.png', frame)\nelse:\nraise ValueError(\"Something is wrong!\")\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p>In Matplotlib, the <code>imsave()</code> function can save an RGB frame as an image file:</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport matplotlib.pyplot as plt\n# define the FFmpeg parameter to seek to 00:00:01.45(or 1s and 45msec) \n# in time and get one single frame\nffparams = {\"-ss\": \"00:00:01.45\", \"-frames:v\":1}\n# initialize and formulate the decoder with suitable source\ndecoder = FFdecoder(\"foo.mp4\", **ffparams).formulate()\n# grab the RGB24(default) frame from the decoder\nframe = next(decoder.generateFrame(), None)\n# check if frame is None\nif not(frame is None):\n# Save our image as PNG\nplt.imsave('foo_image.png', frame)\nelse:\nraise ValueError(\"Something is wrong!\")\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p>In Imageio, the <code>imwrite()</code> function can be used to create an image memory from an RGB frame:</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport imageio\n# define the FFmpeg parameter to seek to 00:00:01.45(or 1s and 45msec) \n# in time and get one single frame\nffparams = {\"-ss\": \"00:00:01.45\", \"-frames:v\":1}\n# initialize and formulate the decoder with suitable source\ndecoder = FFdecoder(\"foo.mp4\", **ffparams).formulate()\n# grab the RGB24(default) frame from the decoder\nframe = next(decoder.generateFrame(), None)\n# check if frame is None\nif not(frame is None):\n# Save our output\nimageio.imwrite('foo_image.jpeg', frame)\nelse:\nraise ValueError(\"Something is wrong!\")\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p>"},{"location":"recipes/basic/save-keyframe-image/#generating-thumbnail-with-a-fancy-filter","title":"Generating Thumbnail with a Fancy filter","text":"<code>fancy_thumbnail.jpg</code> (Courtesy - BigBuckBunny) <p>In this example we first apply FFmpeg\u2019s <code>tblend</code> filter  with an <code>hardmix</code> blend mode (cool stuff) and then seek to <code>00:00:25.917</code>(or 25.917sec) in time to retrieve our single frame thumbnail, and thereby save it as JPEG image with valid filename (e.g. <code>fancy_thumbnail.jpg</code>) using Pillow library.</p> Time unit syntax in <code>-ss</code> FFmpeg parameter <p>You can use two different time unit formats with <code>-ss</code> FFmpeg parameter:  - [x] Sexagesimal(in seconds): Uses (HOURS:MM:SS.MILLISECONDS), such as in <code>01:23:45.678</code> - [x] Fractional: such as in <code>02:30.05</code>, this is interpreted as 2 minutes, 30 seconds, and a half a second, which would be the same as using 150.5 in seconds.</p> Available blend mode options <p>Other blend mode options for <code>tblend</code> filter include: <code>addition</code>, <code>addition128</code>, <code>grainmerge</code>, <code>and</code>, <code>average</code>, <code>burn</code>, <code>darken</code>, <code>difference</code>, <code>difference128</code>, <code>grainextract</code>, <code>divide</code>, <code>dodge</code>, <code>freeze</code>, <code>exclusion</code>, <code>extremity</code>, <code>glow</code>, <code>hardlight</code>, <code>hardmix</code>, <code>heat</code>, <code>lighten</code>, <code>linearlight</code>, <code>multiply</code>, <code>multiply128</code>, <code>negation</code>, <code>normal</code>, <code>or</code>, <code>overlay</code>, <code>phoenix</code>, <code>pinlight</code>, <code>reflect</code>, <code>screen</code>, <code>softlight</code>, <code>subtract</code>, <code>vividlight</code>, <code>xor</code></p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nfrom PIL import Image\n# define the FFmpeg parameter to\nffparams = {\n\"-vf\": \"tblend=all_mode='hardmix'\",  # trim and reverse\n\"-ss\": \"00:00:25.917\",  # seek to 00:00:25.917(or 25s 917msec)\n\"-frames:v\": 1,  # get one single frame\n}\n# initialize and formulate the decoder with suitable source\ndecoder = FFdecoder(\"BigBuckBunny.mp4\", **ffparams).formulate()\n# grab the RGB24(default) frame from the decoder\nframe = next(decoder.generateFrame(), None)\n# check if frame is None\nif not (frame is None):\n# Convert to Image\nim = Image.fromarray(frame)\n# Save Image as JPEG\nim.save(\"fancy_thumbnail.jpg\")\nelse:\nraise ValueError(\"Something is wrong!\")\n# terminate the decoder\ndecoder.terminate()\n</code></pre> <p> </p>"},{"location":"recipes/basic/transcode-live-frames-simplegraphs/","title":"Transcoding Live Simple Filtergraphs","text":"What are Simple filtergraphs? <p>Before heading straight into recipes we will talk about Simple filtergraphs: </p> <p>Simple filtergraphs are those filters that have exactly one input and output, both of the same type. </p> <p>They can be processed by simply inserting an additional step between decoding and encoding of video frames:</p> <p></p> <p>Simple filtergraphs are configured with the per-stream <code>-filter</code> option (with <code>-vf</code> for video). </p> <p>DeFFcode's FFdecoder API handles a single chain of filtergraphs (through <code>-vf</code> FFmpeg parameter) to the to real-time frames quite effortlessly. </p> <p>We'll discuss the transcoding of live simple filtergraphs in the following recipes:</p> <p> </p> <p>DeFFcode APIs requires FFmpeg executable</p> <p>DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality, and any failure in detection will raise <code>RuntimeError</code> immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation.</p> Additional Python Dependencies for following recipes <p>Following recipes requires additional python dependencies which can be installed easily as below:</p> <ul> <li> <p> OpenCV: OpenCV is required for previewing and encoding video frames. You can easily install it directly via <code>pip</code>:</p> OpenCV installation from source <p>You can also follow online tutorials for building &amp; installing OpenCV on Windows, Linux, MacOS and Raspberry Pi machines manually from its source. </p> <p> Make sure not to install both pip and source version together. Otherwise installation will fail to work!</p> Other OpenCV binaries <p>OpenCV maintainers also provide additional binaries via pip that contains both main modules and contrib/extra modules <code>opencv-contrib-python</code>, and for server (headless) environments like <code>opencv-python-headless</code> and <code>opencv-contrib-python-headless</code>. You can also install any one of them in similar manner. More information can be found here.</p> <pre><code>pip install opencv-python       </code></pre> </li> </ul> <p>Always use FFdecoder API's <code>terminate()</code> method at the end to avoid undesired behavior.</p> <p>OpenCV's' <code>VideoWriter()</code> class lacks the ability to control output quality, bitrate, compression, and other important features which are only available with VidGear's WriteGear API.</p> <p> </p>"},{"location":"recipes/basic/transcode-live-frames-simplegraphs/#transcoding-trimmed-and-reversed-video","title":"Transcoding Trimmed and Reversed video","text":"Big Buck Bunny Reversed <p>In this example we will take the first 5 seconds of a video clip (using <code>trim</code> filter) and reverse it (by applying <code>reverse</code> filter), and encode them using OpenCV Library's <code>VideoWriter()</code> method in real-time. </p> <p>The <code>reverse</code> filter requires memory to buffer the entire clip, so applying <code>trim</code> filter first is strongly recommended. Otherwise you might probably run Out of Memory.</p> <p>OpenCV's <code>VideoWriter()</code> class requires a valid Output filename (e.g. output_foo.avi), FourCC code, framerate, and resolution as input.</p> <p>You can use FFdecoder's <code>metadata</code> property object that dumps source Video's metadata information (as JSON string) to retrieve output framerate and resolution.</p> <p>By default, OpenCV expects <code>BGR</code> format frames in its <code>write()</code> method.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport json, cv2\n# define the Video Filter definition\n# trim 5 sec from end and reverse\nffparams = {\n\"-vf\": \"trim=end=5,reverse\" \n}\n# initialize and formulate the decoder for BGR24 output with given params\ndecoder = FFdecoder(\n\"foo.mp4\", frame_format=\"bgr24\", verbose=True, **ffparams\n).formulate()\n# retrieve JSON Metadata and convert it to dict\nmetadata_dict = json.loads(decoder.metadata)\n# prepare OpenCV parameters\nFOURCC = cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\")\nFRAMERATE = metadata_dict[\"output_framerate\"]\nFRAMESIZE = tuple(metadata_dict[\"output_frames_resolution\"])\n# Define writer with parameters and suitable output filename for e.g. `output_foo.avi`\nwriter = cv2.VideoWriter(\"output_foo.avi\", FOURCC, FRAMERATE, FRAMESIZE)\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# writing BGR24 frame to writer\nwriter.write(frame)\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.release()\n</code></pre> <p> </p>"},{"location":"recipes/basic/transcode-live-frames-simplegraphs/#transcoding-cropped-video","title":"Transcoding Cropped video","text":"Big Buck Bunny Cropped <p>In this example we will crop real-time video frames by an area with size \u2154 of the input video (say <code>foo.mp4</code>) by applying <code>crop</code> filter in FFdecoder API, all while encoding them using OpenCV Library's <code>VideoWriter()</code> method in real-time. </p> <p>OpenCV's <code>VideoWriter()</code> class requires a valid Output filename (e.g. output_foo.avi), FourCC code, framerate, and resolution as input.</p> <p>You can use FFdecoder's <code>metadata</code> property object that dumps source Video's metadata information (as JSON string) to retrieve output framerate and resolution.</p> <p>More complex examples using <code>crop</code> filter can be found here \u27b6 and can be applied similarly.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport json, cv2\n# define the Video Filter definition\n# cropped the central input area with size 2/3 of the input video\nffparams = {\n\"-vf\": \"crop=2/3*in_w:2/3*in_h\"\n}\n# initialize and formulate the decoder for BGR24 output with given params\ndecoder = FFdecoder(\n\"foo.mp4\", frame_format=\"bgr24\", verbose=True, **ffparams\n).formulate()\n# retrieve JSON Metadata and convert it to dict\nmetadata_dict = json.loads(decoder.metadata)\n# prepare OpenCV parameters\nFOURCC = cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\")\nFRAMERATE = metadata_dict[\"output_framerate\"]\nFRAMESIZE = tuple(metadata_dict[\"output_frames_resolution\"])\n# Define writer with parameters and suitable output filename for e.g. `output_foo.avi`\nwriter = cv2.VideoWriter(\"output_foo.avi\", FOURCC, FRAMERATE, FRAMESIZE)\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# writing BGR24 frame to writer\nwriter.write(frame)\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.release()\n</code></pre> <p> </p>"},{"location":"recipes/basic/transcode-live-frames-simplegraphs/#transcoding-rotated-video-with-rotate-filter","title":"Transcoding Rotated video (with <code>rotate</code> filter)","text":"<p>FFmpeg features Rotate Filter that is used to rotate videos by an arbitrary angle (expressed in radians).</p> <p> </p> Big Buck Bunny Rotated (with <code>rotate</code> filter) <p>In this example we will rotate real-time video frames at an arbitrary angle by applying <code>rotate</code> filter in FFdecoder API and also using green color to fill the output area not covered by the rotated image, all while encoding them using OpenCV Library's <code>VideoWriter()</code> method in real-time. </p> <p>OpenCV's <code>VideoWriter()</code> class requires a valid Output filename (e.g. output_foo.avi), FourCC code, framerate, and resolution as input.</p> <p>You can use FFdecoder's <code>metadata</code> property object that dumps source Video's metadata information (as JSON string) to retrieve output framerate and resolution.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport json, cv2\n# define the Video Filter definition\n# rotate by 0.35 rad and fill green\nffparams = {\n\"-vf\": \"rotate=angle=-20*PI/180:fillcolor=green\" \n}\n# initialize and formulate the decoder for BGR24 output with given params\ndecoder = FFdecoder(\n\"foo.mp4\", frame_format=\"bgr24\", verbose=True, **ffparams\n).formulate()\n# retrieve JSON Metadata and convert it to dict\nmetadata_dict = json.loads(decoder.metadata)\n# prepare OpenCV parameters\nFOURCC = cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\")\nFRAMERATE = metadata_dict[\"output_framerate\"]\nFRAMESIZE = tuple(metadata_dict[\"output_frames_resolution\"])\n# Define writer with parameters and suitable output filename for e.g. `output_foo.avi`\nwriter = cv2.VideoWriter(\"output_foo.avi\", FOURCC, FRAMERATE, FRAMESIZE)\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# writing BGR24 frame to writer\nwriter.write(frame)\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.release()\n</code></pre> <p> </p>"},{"location":"recipes/basic/transcode-live-frames-simplegraphs/#transcoding-rotated-video-with-transpose-filter","title":"Transcoding Rotated video (with <code>transpose</code> filter)","text":"<p>FFmpeg also features Transpose Filter that is used to rotate videos by 90 degrees clockwise and counter-clockwise direction as well as flip them vertically and horizontally.</p> <p> </p> Big Buck Bunny Rotated (with <code>transpose</code> filter) <p>In this example we will rotate real-time video frames by 90 degrees counterclockwise and preserve portrait geometry by applying <code>transpose</code> filter in FFdecoder API, all while encoding them using OpenCV Library's <code>VideoWriter()</code> method in real-time. </p> <p>OpenCV's <code>VideoWriter()</code> class requires a valid Output filename (e.g. output_foo.avi), FourCC code, framerate, and resolution as input.</p> <p>You can use FFdecoder's <code>metadata</code> property object that dumps source Video's metadata information (as JSON string) to retrieve output framerate and resolution.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport json, cv2\n# define the Video Filter definition\n# rotate by 90 degrees counter-clockwise and preserve portrait layout\nffparams = {\n\"-vf\": \"transpose=dir=2:passthrough=portrait\"\n}\n# initialize and formulate the decoder for BGR24 output with given params\ndecoder = FFdecoder(\n\"foo.mp4\", frame_format=\"bgr24\", verbose=True, **ffparams\n).formulate()\n# retrieve JSON Metadata and convert it to dict\nmetadata_dict = json.loads(decoder.metadata)\n# prepare OpenCV parameters\nFOURCC = cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\")\nFRAMERATE = metadata_dict[\"output_framerate\"]\nFRAMESIZE = tuple(metadata_dict[\"output_frames_resolution\"])\n# Define writer with parameters and suitable output filename for e.g. `output_foo.avi`\nwriter = cv2.VideoWriter(\"output_foo.avi\", FOURCC, FRAMERATE, FRAMESIZE)\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# writing BGR24 frame to writer\nwriter.write(frame)\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.release()\n</code></pre> <p> </p>"},{"location":"recipes/basic/transcode-live-frames-simplegraphs/#transcoding-horizontally-flipped-and-scaled-video","title":"Transcoding Horizontally flipped and Scaled video","text":"Big Buck Bunny Horizontally flipped and Scaled <p>In this example we will horizontally flip and scale real-time video frames to half its original size by applying <code>hflip</code> and <code>scale</code> filter one-by-one in FFdecoder API, all while encoding them using OpenCV Library's <code>VideoWriter()</code> method in real-time. </p> <p>OpenCV's <code>VideoWriter()</code> class requires a valid Output filename (e.g. output_foo.avi), FourCC code, framerate, and resolution as input.</p> <p>You can use FFdecoder's <code>metadata</code> property object that dumps source Video's metadata information (as JSON string) to retrieve output framerate and resolution.</p> <p>More complex examples using <code>scale</code> filter can be found here \u27b6 and can be applied similarly.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport json, cv2\n# define the Video Filter definition\n# horizontally flip and scale to half its original size\nffparams = {\n\"-vf\": \"hflip,scale=w=iw/2:h=ih/2\"\n}\n# initialize and formulate the decoder for BGR24 output with given params\ndecoder = FFdecoder(\n\"foo.mp4\", frame_format=\"bgr24\", verbose=True, **ffparams\n).formulate()\n# retrieve JSON Metadata and convert it to dict\nmetadata_dict = json.loads(decoder.metadata)\n# prepare OpenCV parameters\nFOURCC = cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\")\nFRAMERATE = metadata_dict[\"output_framerate\"]\nFRAMESIZE = tuple(metadata_dict[\"output_frames_resolution\"])\n# Define writer with parameters and suitable output filename for e.g. `output_foo.avi`\nwriter = cv2.VideoWriter(\"output_foo.avi\", FOURCC, FRAMERATE, FRAMESIZE)\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# writing BGR24 frame to writer\nwriter.write(frame)\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.release()\n</code></pre> <p> </p>"},{"location":"recipes/basic/transcode-live-frames/","title":"Transcoding Live frames","text":"What exactly is Transcoding? <p>Before heading directly into recipes we have to talk about Transcoding: </p> <p>Transcoding is the technique of transforming one media encoding format into another. </p> <p>This is typically done for compatibility purposes, such as when a media source provides a format that the intended target is not able to process; an in-between adaptation step is required:</p> <ul> <li>Decode media from its originally encoded state into raw, uncompressed information.</li> <li>Encode the raw data back, using a different codec that is supported by end user.</li> </ul> <p>While decoding media into video frames is purely managed by DeFFcode's FFdecoder API, you can easily encode those video frames back into multimedia files using any well-known video processing library such as OpenCV and VidGear. </p> <p>We'll discuss transcoding using both these libraries briefly in the following recipes:</p> <p> </p> <p>DeFFcode APIs requires FFmpeg executable</p> <p>DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality, and any failure in detection will raise <code>RuntimeError</code> immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation.</p> Additional Python Dependencies for following recipes <p>Following recipes requires additional python dependencies which can be installed easily as below:</p> <ul> <li> <p> OpenCV: OpenCV is required for previewing and encoding video frames. You can easily install it directly via <code>pip</code>:</p> OpenCV installation from source <p>You can also follow online tutorials for building &amp; installing OpenCV on Windows, Linux, MacOS and Raspberry Pi machines manually from its source. </p> <p> Make sure not to install both pip and source version together. Otherwise installation will fail to work!</p> Other OpenCV binaries <p>OpenCV maintainers also provide additional binaries via pip that contains both main modules and contrib/extra modules <code>opencv-contrib-python</code>, and for server (headless) environments like <code>opencv-python-headless</code> and <code>opencv-contrib-python-headless</code>. You can also install any one of them in similar manner. More information can be found here.</p> <pre><code>pip install opencv-python       </code></pre> </li> <li> <p> VidGear: VidGear is required for lossless encoding of video frames into file/stream. You can easily install it directly via <code>pip</code>:</p> <pre><code>pip install vidgear[core]       </code></pre> </li> </ul> <p>Always use FFdecoder API's <code>terminate()</code> method at the end to avoid undesired behavior.</p> Never name your python script <code>deffcode.py</code> <p>When trying out these recipes, never name your python script <code>deffcode.py</code> otherwise it will result in <code>ModuleNotFound</code> error.</p> <p> </p>"},{"location":"recipes/basic/transcode-live-frames/#transcoding-video-using-opencv-videowriter-api","title":"Transcoding video using OpenCV VideoWriter API","text":"<p>OpenCV's' <code>VideoWriter()</code> class can be used directly with DeFFcode's FFdecoder API to encode video frames into a multimedia video file but it lacks the ability to control output quality, bitrate, compression, and other important features which are only available with VidGear's WriteGear API.</p> <p>In this example we will decode different pixel formats video frames from a given Video file (say <code>foo.mp4</code>) in FFdecoder API, and encode them using OpenCV Library's <code>VideoWriter()</code> method in real-time. </p> <p>OpenCV's <code>VideoWriter()</code> class requires a valid Output filename (e.g. output_foo.avi), FourCC code, framerate, and resolution as input.</p> <p>You can use FFdecoder's <code>metadata</code> property object that dumps source Video's metadata information (as JSON string) to retrieve output framerate and resolution.</p> BGR framesRGB framesGRAYSCALE framesYUV frames <p>By default, OpenCV expects <code>BGR</code> format frames in its <code>cv2.write()</code> method.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport json, cv2\n# initialize and formulate the decoder for BGR24 pixel format output\ndecoder = FFdecoder(\"foo.mp4\", frame_format=\"bgr24\").formulate()\n# retrieve JSON Metadata and convert it to dict\nmetadata_dict = json.loads(decoder.metadata)\n# prepare OpenCV parameters\nFOURCC = cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\")\nFRAMERATE = metadata_dict[\"output_framerate\"]\nFRAMESIZE = tuple(metadata_dict[\"output_frames_resolution\"])\n# Define writer with parameters and suitable output filename for e.g. `output_foo.avi`\nwriter = cv2.VideoWriter(\"output_foo.avi\", FOURCC, FRAMERATE, FRAMESIZE)\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# writing BGR24 frame to writer\nwriter.write(frame)\n# let's also show output window\ncv2.imshow(\"Output\", frame)\n# check for 'q' key if pressed\nkey = cv2.waitKey(1) &amp; 0xFF\nif key == ord(\"q\"):\nbreak\n# close output window\ncv2.destroyAllWindows()\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.release()\n</code></pre> <p>Since OpenCV expects <code>BGR</code> format frames in its <code>cv2.write()</code> method, therefore we need to convert <code>RGB</code> frames into <code>BGR</code> before encoding as follows:</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport json, cv2\n# initialize and formulate the decoder for RGB24 pixel format output\ndecoder = FFdecoder(\"foo.mp4\").formulate()\n# retrieve JSON Metadata and convert it to dict\nmetadata_dict = json.loads(decoder.metadata)\n# prepare OpenCV parameters\nFOURCC = cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\")\nFRAMERATE = metadata_dict[\"output_framerate\"]\nFRAMESIZE = tuple(metadata_dict[\"output_frames_resolution\"])\n# Define writer with parameters and suitable output filename for e.g. `output_foo.avi`\nwriter = cv2.VideoWriter(\"output_foo.avi\", FOURCC, FRAMERATE, FRAMESIZE)\n# grab the RGB24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# converting RGB24 to BGR24 frame\nframe_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n# writing BGR24 frame to writer\nwriter.write(frame_bgr)\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.release()\n</code></pre> <p>OpenCV also directly consumes <code>GRAYSCALE</code> frames in its <code>cv2.write()</code> method.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport json, cv2\n# initialize and formulate the decoder for GRAYSCALE output\ndecoder = FFdecoder(\"foo.mp4\", frame_format=\"gray\", verbose=True).formulate()\n# retrieve JSON Metadata and convert it to dict\nmetadata_dict = json.loads(decoder.metadata)\n# prepare OpenCV parameters\nFOURCC = cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\")\nFRAMERATE = metadata_dict[\"output_framerate\"]\nFRAMESIZE = tuple(metadata_dict[\"output_frames_resolution\"])\n# Define writer with parameters and suitable output filename for e.g. `output_foo_gray.avi`\nwriter = cv2.VideoWriter(\"output_foo_gray.avi\", FOURCC, FRAMERATE, FRAMESIZE)\n# grab the GRAYSCALE frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# writing GRAYSCALE frame to writer\nwriter.write(frame)\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.release()\n</code></pre> <p>With FFdecoder API, frames extracted with YUV pixel formats (<code>yuv420p</code>, <code>yuv444p</code>, <code>nv12</code>, <code>nv21</code> etc.) are generally incompatible with OpenCV APIs. But you can make them easily compatible by using exclusive <code>-enforce_cv_patch</code> boolean attribute of its <code>ffparam</code> dictionary parameter.</p> <p>Let's try encoding YUV420p pixel-format frames with OpenCV's <code>write()</code> method in following python code:</p> <p>You can also use other YUV pixel-formats such <code>yuv422p</code>(4:2:2 subsampling) or <code>yuv444p</code>(4:4:4 subsampling) etc. instead for more higher dynamic range in the similar manner.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nimport json, cv2\n# enable OpenCV patch for YUV frames\nffparams = {\"-enforce_cv_patch\": True}\n# initialize and formulate the decoder for YUV420p output\ndecoder = FFdecoder(\n\"input_foo.mp4\", frame_format=\"yuv420p\", verbose=True, **ffparams\n).formulate()\n# retrieve JSON Metadata and convert it to dict\nmetadata_dict = json.loads(decoder.metadata)\n# prepare OpenCV parameters\nFOURCC = cv2.VideoWriter_fourcc(\"M\", \"J\", \"P\", \"G\")\nFRAMERATE = metadata_dict[\"output_framerate\"]\nFRAMESIZE = tuple(metadata_dict[\"output_frames_resolution\"])\n# Define writer with parameters and suitable output filename for e.g. `output_foo_gray.avi`\nwriter = cv2.VideoWriter(\"output_foo_gray.avi\", FOURCC, FRAMERATE, FRAMESIZE)\n# grab the yuv420p frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# convert it to `BGR` pixel format,\n# since imshow() method only accepts `BGR` frames\nbgr = cv2.cvtColor(yuv, cv2.COLOR_YUV2BGR_I420)\n# {do something with the BGR frame here}\n# writing BGR frame to writer\nwriter.write(frame)\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.release()\n</code></pre> <p> </p>"},{"location":"recipes/basic/transcode-live-frames/#transcoding-lossless-video-using-writegear-api","title":"Transcoding lossless video using WriteGear API","text":"<p>WriteGear's Compression Mode support for FFdecoder API is currently in beta so you can expect much higher than usual CPU utilization!</p> Lossless transcoding  with FFdecoder and WriteGear API <p>VidGear's WriteGear API implements a complete, flexible, and robust wrapper around FFmpeg in compression mode for encoding real-time video frames to a lossless compressed multimedia output file(s)/stream(s). </p> <p>DeFFcode's FFdecoder API in conjunction with WriteGear API creates a high-level High-performance Lossless FFmpeg Transcoding (Decoding + Encoding) Pipeline  that is able to exploit almost any FFmpeg parameter for achieving anything imaginable with multimedia video data all while allow us to manipulate the real-time video frames with immense flexibility. </p> <p>In this example we will decode different pixel formats video frames from a given Video file (say <code>foo.mp4</code>) in FFdecoder API, and encode them into lossless video file with controlled framerate using WriteGear API in real-time. </p> <p>Additional Parameters in WriteGear API</p> <p>WriteGear API only requires a valid Output filename (e.g. <code>output_foo.mp4</code>) as input, but you can easily control any output specifications (such as bitrate, codec, framerate, resolution, subtitles, etc.) supported by FFmpeg (in use).</p> <p>You can use FFdecoder's <code>metadata</code> property object that dumps source Video's metadata information (as JSON string) to retrieve source framerate.</p> BGR framesRGB framesGRAYSCALE framesYUV frames <p>WriteGear API by default expects <code>BGR</code> format frames in its <code>write()</code> class method.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nfrom vidgear.gears import WriteGear\nimport json\n# initialize and formulate the decoder for BGR24 output\ndecoder = FFdecoder(\"foo.mp4\", frame_format=\"bgr24\", verbose=True).formulate()\n# retrieve framerate from source JSON Metadata and pass it as `-input_framerate` \n# parameter for controlled framerate\noutput_params = {\n\"-input_framerate\": json.loads(decoder.metadata)[\"source_video_framerate\"]\n}\n# Define writer with default parameters and suitable\n# output filename for e.g. `output_foo.mp4`\nwriter = WriteGear(output_filename=\"output_foo.mp4\", **output_params)\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# writing BGR24 frame to writer\nwriter.write(frame)\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.close()\n</code></pre> <p>In WriteGear API, you can use <code>rgb_mode</code> parameter in  <code>write()</code> class method to write <code>RGB</code> format frames instead of default <code>BGR</code> as follows:</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nfrom vidgear.gears import WriteGear\nimport json\n# initialize and formulate the decoder\ndecoder = FFdecoder(\"foo.mp4\", verbose=True).formulate()\n# retrieve framerate from source JSON Metadata and pass it as `-input_framerate` \n# parameter for controlled framerate\noutput_params = {\n\"-input_framerate\": json.loads(decoder.metadata)[\"source_video_framerate\"]\n}\n# Define writer with default parameters and suitable\n# output filename for e.g. `output_foo.mp4`\nwriter = WriteGear(output_filename=\"output_foo.mp4\", **output_params)\n# grab the BGR24 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# writing RGB24 frame to writer\nwriter.write(frame, rgb_mode=True)\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.close()\n</code></pre> <p>WriteGear API also directly consumes <code>GRAYSCALE</code> format frames in its <code>write()</code> class method. </p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nfrom vidgear.gears import WriteGear\nimport json\n# initialize and formulate the decoder for GRAYSCALE output\ndecoder = FFdecoder(\"foo.mp4\", frame_format=\"gray\", verbose=True).formulate()\n# retrieve framerate from source JSON Metadata and pass it as `-input_framerate` parameter\n# for controlled output framerate\noutput_params = {\n\"-input_framerate\": json.loads(decoder.metadata)[\"source_video_framerate\"]\n}\n# Define writer with default parameters and suitable\n# output filename for e.g. `output_foo_gray.mp4`\nwriter = WriteGear(output_filename=\"output_foo_gray.mp4\", **output_params)\n# grab the GRAYSCALE frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# writing GRAYSCALE frame to writer\nwriter.write(frame)\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.close()\n</code></pre> <p>WriteGear API also directly consume <code>YUV</code> (or basically any other supported pixel format) frames in its <code>write()</code> class method with its <code>-input_pixfmt</code> attribute in compression mode. For its  non-compression mode, see above example.</p> <p>You can also use <code>yuv422p</code>(4:2:2 subsampling) or <code>yuv444p</code>(4:4:4 subsampling) instead for more higher dynamic ranges.</p> <p>In WriteGear API, the support for <code>-input_pixfmt</code> attribute in <code>output_params</code> dictionary parameter was added in <code>v0.3.0</code>.</p> <pre><code># import the necessary packages\nfrom deffcode import FFdecoder\nfrom vidgear.gears import WriteGear\nimport json\n# initialize and formulate the decoder for YUV420 output\ndecoder = FFdecoder(\"foo.mp4\", frame_format=\"yuv420p\").formulate()\n# retrieve framerate from source JSON Metadata and pass it as \n# `-input_framerate` parameter for controlled framerate\n# and add input pixfmt as yuv420p also\noutput_params = {\n\"-input_framerate\": json.loads(decoder.metadata)[\"output_framerate\"],\n\"-input_pixfmt\": \"yuv420p\"\n}\n# Define writer with default parameters and suitable\n# output filename for e.g. `output_foo_yuv.mp4`\nwriter = WriteGear(output_filename=\"output_foo_yuv.mp4\", logging=True, **output_params)\n# grab the YUV420 frame from the decoder\nfor frame in decoder.generateFrame():\n# check if frame is None\nif frame is None:\nbreak\n# {do something with the frame here}\n# writing YUV420 frame to writer\nwriter.write(frame)\n# terminate the decoder\ndecoder.terminate()\n# safely close writer\nwriter.close()\n</code></pre> <p> </p>"},{"location":"reference/ffhelper/","title":"deffcode.ffhelper","text":"<p>Following methods are exclusively design to handle FFmpeg related tasks. These tasks includes validation of installed FFmpeg binaries, downloading of FFmpeg binaries(on Windows), and parsing of FFmpeg metadata into useful information using various pattern matching methods.</p> <p>For usage examples, kindly refer our Basic Recipes  and Advanced Recipes </p> <p> </p>"},{"location":"reference/ffhelper/#deffcode.ffhelper.get_valid_ffmpeg_path--get_valid_ffmpeg_path","title":"get_valid_ffmpeg_path","text":"<p>Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path.</p> <p>Parameters:</p> Name Type Description Default <code>custom_ffmpeg</code> <code>string</code> <p>path to custom FFmpeg executables</p> <code>''</code> <code>is_windows</code> <code>boolean</code> <p>is running on Windows OS?</p> <code>False</code> <code>ffmpeg_download_path</code> <code>string</code> <p>FFmpeg static binaries download location (Windows only)</p> <code>''</code> <code>verbose</code> <code>bool</code> <p>enables verbose for its operations</p> <code>False</code> <p>Returns: A valid FFmpeg executable path string.</p> Source code in <code>deffcode/ffhelper.py</code> <pre><code>def get_valid_ffmpeg_path(\ncustom_ffmpeg=\"\", is_windows=False, ffmpeg_download_path=\"\", verbose=False\n):\n\"\"\"\n    ## get_valid_ffmpeg_path\n    Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path.\n    Parameters:\n        custom_ffmpeg (string): path to custom FFmpeg executables\n        is_windows (boolean): is running on Windows OS?\n        ffmpeg_download_path (string): FFmpeg static binaries download location _(Windows only)_\n        verbose (bool): enables verbose for its operations\n    **Returns:** A valid FFmpeg executable path string.\n    \"\"\"\nfinal_path = \"\"\nif is_windows:\n# checks if current os is windows\nif custom_ffmpeg:\n# if custom FFmpeg path is given assign to local variable\nfinal_path += custom_ffmpeg\nelse:\n# otherwise auto-download them\ntry:\nif not (ffmpeg_download_path):\n# otherwise save to Temp Directory\nimport tempfile\nffmpeg_download_path = tempfile.gettempdir()\nverbose and logger.debug(\n\"FFmpeg Windows Download Path: {}\".format(ffmpeg_download_path)\n)\n# download Binaries\nos_bit = (\n(\"win64\" if platform.machine().endswith(\"64\") else \"win32\")\nif is_windows\nelse \"\"\n)\n_path = download_ffmpeg_binaries(\npath=ffmpeg_download_path, os_windows=is_windows, os_bit=os_bit\n)\n# assign to local variable\nfinal_path += _path\nexcept Exception as e:\n# log if any error occurred\nlogger.exception(str(e))\nlogger.error(\n\"Error in downloading FFmpeg binaries, Check your network and Try again!\"\n)\nreturn False\nif os.path.isfile(final_path):\n# check if valid FFmpeg file exist\npass\nelif os.path.isfile(os.path.join(final_path, \"ffmpeg.exe\")):\n# check if FFmpeg directory exists, if does, then check for valid file\nfinal_path = os.path.join(final_path, \"ffmpeg.exe\")\nelse:\n# else return False\nverbose and logger.debug(\n\"No valid FFmpeg executables found at Custom FFmpeg path!\"\n)\nreturn False\nelse:\n# otherwise perform test for Unix\nif custom_ffmpeg:\n# if custom FFmpeg path is given assign to local variable\nif os.path.isfile(custom_ffmpeg):\n# check if valid FFmpeg file exist\nfinal_path += custom_ffmpeg\nelif os.path.isfile(os.path.join(custom_ffmpeg, \"ffmpeg\")):\n# check if FFmpeg directory exists, if does, then check for valid file\nfinal_path = os.path.join(custom_ffmpeg, \"ffmpeg\")\nelse:\n# else return False\nverbose and logger.debug(\n\"No valid FFmpeg executables found at Custom FFmpeg path!\"\n)\nreturn False\nelse:\n# otherwise assign ffmpeg binaries from system\nfinal_path += \"ffmpeg\"\nverbose and logger.debug(\"Final FFmpeg Path: {}\".format(final_path))\n# Final Auto-Validation for FFmeg Binaries. returns final path if test is passed\nreturn final_path if validate_ffmpeg(final_path, verbose=verbose) else False\n</code></pre> <p> </p>"},{"location":"reference/ffhelper/#deffcode.ffhelper.get_valid_ffmpeg_path--get_valid_ffmpeg_path","title":"get_valid_ffmpeg_path","text":"<p>Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path.</p> <p>Parameters:</p> Name Type Description Default <code>custom_ffmpeg</code> <code>string</code> <p>path to custom FFmpeg executables</p> <code>''</code> <code>is_windows</code> <code>boolean</code> <p>is running on Windows OS?</p> <code>False</code> <code>ffmpeg_download_path</code> <code>string</code> <p>FFmpeg static binaries download location (Windows only)</p> <code>''</code> <code>verbose</code> <code>bool</code> <p>enables verbose for its operations</p> <code>False</code> <p>Returns: A valid FFmpeg executable path string.</p> Source code in <code>deffcode/ffhelper.py</code> <pre><code>def get_valid_ffmpeg_path(\ncustom_ffmpeg=\"\", is_windows=False, ffmpeg_download_path=\"\", verbose=False\n):\n\"\"\"\n    ## get_valid_ffmpeg_path\n    Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path.\n    Parameters:\n        custom_ffmpeg (string): path to custom FFmpeg executables\n        is_windows (boolean): is running on Windows OS?\n        ffmpeg_download_path (string): FFmpeg static binaries download location _(Windows only)_\n        verbose (bool): enables verbose for its operations\n    **Returns:** A valid FFmpeg executable path string.\n    \"\"\"\nfinal_path = \"\"\nif is_windows:\n# checks if current os is windows\nif custom_ffmpeg:\n# if custom FFmpeg path is given assign to local variable\nfinal_path += custom_ffmpeg\nelse:\n# otherwise auto-download them\ntry:\nif not (ffmpeg_download_path):\n# otherwise save to Temp Directory\nimport tempfile\nffmpeg_download_path = tempfile.gettempdir()\nverbose and logger.debug(\n\"FFmpeg Windows Download Path: {}\".format(ffmpeg_download_path)\n)\n# download Binaries\nos_bit = (\n(\"win64\" if platform.machine().endswith(\"64\") else \"win32\")\nif is_windows\nelse \"\"\n)\n_path = download_ffmpeg_binaries(\npath=ffmpeg_download_path, os_windows=is_windows, os_bit=os_bit\n)\n# assign to local variable\nfinal_path += _path\nexcept Exception as e:\n# log if any error occurred\nlogger.exception(str(e))\nlogger.error(\n\"Error in downloading FFmpeg binaries, Check your network and Try again!\"\n)\nreturn False\nif os.path.isfile(final_path):\n# check if valid FFmpeg file exist\npass\nelif os.path.isfile(os.path.join(final_path, \"ffmpeg.exe\")):\n# check if FFmpeg directory exists, if does, then check for valid file\nfinal_path = os.path.join(final_path, \"ffmpeg.exe\")\nelse:\n# else return False\nverbose and logger.debug(\n\"No valid FFmpeg executables found at Custom FFmpeg path!\"\n)\nreturn False\nelse:\n# otherwise perform test for Unix\nif custom_ffmpeg:\n# if custom FFmpeg path is given assign to local variable\nif os.path.isfile(custom_ffmpeg):\n# check if valid FFmpeg file exist\nfinal_path += custom_ffmpeg\nelif os.path.isfile(os.path.join(custom_ffmpeg, \"ffmpeg\")):\n# check if FFmpeg directory exists, if does, then check for valid file\nfinal_path = os.path.join(custom_ffmpeg, \"ffmpeg\")\nelse:\n# else return False\nverbose and logger.debug(\n\"No valid FFmpeg executables found at Custom FFmpeg path!\"\n)\nreturn False\nelse:\n# otherwise assign ffmpeg binaries from system\nfinal_path += \"ffmpeg\"\nverbose and logger.debug(\"Final FFmpeg Path: {}\".format(final_path))\n# Final Auto-Validation for FFmeg Binaries. returns final path if test is passed\nreturn final_path if validate_ffmpeg(final_path, verbose=verbose) else False\n</code></pre> <p> </p>"},{"location":"reference/ffhelper/#deffcode.ffhelper.download_ffmpeg_binaries--download_ffmpeg_binaries","title":"download_ffmpeg_binaries","text":"<p>Generates FFmpeg Static Binaries for windows(if not available)</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>path for downloading custom FFmpeg executables</p> required <code>os_windows</code> <code>boolean</code> <p>is running on Windows OS?</p> <code>False</code> <code>os_bit</code> <code>string</code> <p>32-bit or 64-bit OS?</p> <code>''</code> <p>Returns: A valid FFmpeg executable path string.</p> Source code in <code>deffcode/ffhelper.py</code> <pre><code>def download_ffmpeg_binaries(path, os_windows=False, os_bit=\"\"):\n\"\"\"\n    ## download_ffmpeg_binaries\n    Generates FFmpeg Static Binaries for windows(if not available)\n    Parameters:\n        path (string): path for downloading custom FFmpeg executables\n        os_windows (boolean): is running on Windows OS?\n        os_bit (string): 32-bit or 64-bit OS?\n    **Returns:** A valid FFmpeg executable path string.\n    \"\"\"\nfinal_path = \"\"\nif os_windows and os_bit:\n# initialize with available FFmpeg Static Binaries GitHub Server\nfile_url = \"https://github.com/abhiTronix/FFmpeg-Builds/releases/latest/download/ffmpeg-static-{}-gpl.zip\".format(\nos_bit\n)\nfile_name = os.path.join(\nos.path.abspath(path), \"ffmpeg-static-{}-gpl.zip\".format(os_bit)\n)\nfile_path = os.path.join(\nos.path.abspath(path),\n\"ffmpeg-static-{}-gpl/bin/ffmpeg.exe\".format(os_bit),\n)\nbase_path, _ = os.path.split(file_name)  # extract file base path\n# check if file already exists\nif os.path.isfile(file_path):\nfinal_path += file_path  # skip download if does\nelse:\n# import libs\nimport zipfile\n# check if given path has write access\nassert os.access(path, os.W_OK), (\n\"[Helper:ERROR] :: Permission Denied, Cannot write binaries to directory = \"\n+ path\n)\n# remove leftovers if exists\nos.path.isfile(file_name) and delete_file_safe(file_name)\n# download and write file to the given path\nwith open(file_name, \"wb\") as f:\nlogger.debug(\n\"No Custom FFmpeg path provided. Auto-Installing FFmpeg static binaries from GitHub Mirror now. Please wait...\"\n)\n# create session\nwith requests.Session() as http:\n# setup retry strategy\nretries = Retry(\ntotal=3,\nbackoff_factor=1,\nstatus_forcelist=[429, 500, 502, 503, 504],\n)\n# Mount it for https usage\nadapter = TimeoutHTTPAdapter(timeout=2.0, max_retries=retries)\nhttp.mount(\"https://\", adapter)\nresponse = http.get(file_url, stream=True)\nresponse.raise_for_status()\ntotal_length = (\nresponse.headers.get(\"content-length\")\nif \"content-length\" in response.headers\nelse len(response.content)\n)\nassert not (\ntotal_length is None\n), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\"\nbar = tqdm(total=int(total_length), unit=\"B\", unit_scale=True)\nfor data in response.iter_content(chunk_size=4096):\nf.write(data)\nlen(data) &gt; 0 and bar.update(len(data))\nbar.close()\nlogger.debug(\"Extracting executables.\")\nwith zipfile.ZipFile(file_name, \"r\") as zip_ref:\nzip_fname, _ = os.path.split(zip_ref.infolist()[0].filename)\nzip_ref.extractall(base_path)\n# perform cleaning\ndelete_file_safe(file_name)\nlogger.debug(\"FFmpeg binaries for Windows configured successfully!\")\nfinal_path += file_path\n# return final path\nreturn final_path\n</code></pre> <p> </p>"},{"location":"reference/ffhelper/#deffcode.ffhelper.validate_ffmpeg--validate_ffmpeg","title":"validate_ffmpeg","text":"<p>Validate FFmpeg Binaries. Returns <code>True</code> if validity test passes successfully.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of FFmpeg binaries</p> required <code>verbose</code> <code>bool</code> <p>enables verbose for its operations</p> <code>False</code> <p>Returns: A boolean value, confirming whether tests passed, or not?.</p> Source code in <code>deffcode/ffhelper.py</code> <pre><code>def validate_ffmpeg(path, verbose=False):\n\"\"\"\n    ## validate_ffmpeg\n    Validate FFmpeg Binaries. Returns `True` if validity test passes successfully.\n    Parameters:\n        path (string): absolute path of FFmpeg binaries\n        verbose (bool): enables verbose for its operations\n    **Returns:** A boolean value, confirming whether tests passed, or not?.\n    \"\"\"\ntry:\n# get the FFmpeg version\nversion = check_sp_output([path, \"-version\"])\nfirstline = version.split(b\"\\n\")[0]\nversion = firstline.split(b\" \")[2].strip()\nif verbose:  # log if test are passed\nlogger.debug(\"FFmpeg validity Test Passed!\")\nlogger.debug(\n\"Found valid FFmpeg Version: `{}` installed on this system\".format(\nversion\n)\n)\nexcept Exception as e:\n# log if test are failed\nif verbose:\nlogger.exception(str(e))\nlogger.warning(\"FFmpeg validity Test Failed!\")\nreturn False\nreturn True\n</code></pre> <p> </p>"},{"location":"reference/ffhelper/#deffcode.ffhelper.get_supported_pixfmts--get_supported_pixfmts","title":"get_supported_pixfmts","text":"<p>Find and returns all FFmpeg's supported pixel formats.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of FFmpeg binaries</p> required <p>Returns: List of supported pixel formats as (PIXEL FORMAT, NB_COMPONENTS, BITS_PER_PIXEL).</p> Source code in <code>deffcode/ffhelper.py</code> <pre><code>def get_supported_pixfmts(path):\n\"\"\"\n    ## get_supported_pixfmts\n    Find and returns all FFmpeg's supported pixel formats.\n    Parameters:\n        path (string): absolute path of FFmpeg binaries\n    **Returns:** List of supported pixel formats as (PIXEL FORMAT, NB_COMPONENTS, BITS_PER_PIXEL).\n    \"\"\"\npxfmts = check_sp_output([path, \"-hide_banner\", \"-pix_fmts\"])\nsplitted = pxfmts.split(b\"\\n\")\nsrtindex = [i for i, s in enumerate(splitted) if b\"-----\" in s]\n# extract video encoders\nsupported_pxfmts = [\nx.decode(\"utf-8\").strip()\nfor x in splitted[srtindex[0] + 1 :]\nif x.decode(\"utf-8\").strip()\n]\n# compile regex\nfinder = re.compile(r\"([A-Z]*[\\.]+[A-Z]*\\s[a-z0-9_-]*)(\\s+[0-4])(\\s+[0-9]+)\")\n# find all outputs\noutputs = finder.findall(\"\\n\".join(supported_pxfmts))\n# return output findings\nreturn [\n([s for s in o[0].split(\" \")][-1], o[1].strip(), o[2].strip())\nfor o in outputs\nif len(o) == 3\n]\n</code></pre> <p> </p>"},{"location":"reference/ffhelper/#deffcode.ffhelper.get_supported_vdecoders--get_supported_vdecoders","title":"get_supported_vdecoders","text":"<p>Find and returns all FFmpeg's supported video decoders.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of FFmpeg binaries</p> required <p>Returns: List of supported decoders.</p> Source code in <code>deffcode/ffhelper.py</code> <pre><code>def get_supported_vdecoders(path):\n\"\"\"\n    ## get_supported_vdecoders\n    Find and returns all FFmpeg's supported video decoders.\n    Parameters:\n        path (string): absolute path of FFmpeg binaries\n    **Returns:** List of supported decoders.\n    \"\"\"\ndecoders = check_sp_output([path, \"-hide_banner\", \"-decoders\"])\nsplitted = decoders.split(b\"\\n\")\n# extract video encoders\nsupported_vdecoders = [\nx.decode(\"utf-8\").strip()\nfor x in splitted[2 : len(splitted) - 1]\nif x.decode(\"utf-8\").strip().startswith(\"V\")\n]\n# compile regex\nfinder = re.compile(r\"[A-Z]*[\\.]+[A-Z]*\\s[a-z0-9_-]*\")\n# find all outputs\noutputs = finder.findall(\"\\n\".join(supported_vdecoders))\n# return output findings\nreturn [[s for s in o.split(\" \")][-1] for o in outputs]\n</code></pre> <p> </p>"},{"location":"reference/ffhelper/#deffcode.ffhelper.get_supported_demuxers--get_supported_demuxers","title":"get_supported_demuxers","text":"<p>Find and returns all FFmpeg's supported demuxers.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of FFmpeg binaries</p> required <p>Returns: List of supported demuxers.</p> Source code in <code>deffcode/ffhelper.py</code> <pre><code>def get_supported_demuxers(path):\n\"\"\"\n    ## get_supported_demuxers\n    Find and returns all FFmpeg's supported demuxers.\n    Parameters:\n        path (string): absolute path of FFmpeg binaries\n    **Returns:** List of supported demuxers.\n    \"\"\"\ndemuxers = check_sp_output([path, \"-hide_banner\", \"-demuxers\"])\nsplitted = [x.decode(\"utf-8\").strip() for x in demuxers.split(b\"\\n\")]\nsupported_demuxers = splitted[splitted.index(\"--\") + 1 : len(splitted) - 1]\n# compile regex\nfinder = re.compile(r\"\\s\\s[a-z0-9_,-]+\\s+\")\n# find all outputs\noutputs = finder.findall(\"\\n\".join(supported_demuxers))\n# return output findings\nreturn [o.strip() if not (\",\" in o) else o.split(\",\")[-1].strip() for o in outputs]\n</code></pre> <p> </p>"},{"location":"reference/ffhelper/#deffcode.ffhelper.validate_imgseqdir--validate_imgseqdir","title":"validate_imgseqdir","text":"<p>Validates Image Sequence by counting number of Image files.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>string</code> <p>video source to be validated</p> required <code>extension</code> <code>string</code> <p>extension of image sequence.</p> <code>'jpg'</code> <p>Returns: A boolean value, confirming whether tests passed, or not?.</p> Source code in <code>deffcode/ffhelper.py</code> <pre><code>def validate_imgseqdir(source, extension=\"jpg\", verbose=False):\n\"\"\"\n    ## validate_imgseqdir\n    Validates Image Sequence by counting number of Image files.\n    Parameters:\n        source (string): video source to be validated\n        extension (string): extension of image sequence.\n    **Returns:** A boolean value, confirming whether tests passed, or not?.\n    \"\"\"\n# check if path exists\ndirpath = Path(source).parent\ntry:\nif not (dirpath.exists() and dirpath.is_dir()):\nverbose and logger.warning(\n\"Specified path `{}` doesn't exists or valid.\".format(dirpath)\n)\nreturn False\nelse:\nreturn (\nTrue if len(list(dirpath.glob(\"*.{}\".format(extension)))) &gt; 2 else False\n)\nexcept:\nreturn False\n</code></pre> <p> </p>"},{"location":"reference/ffhelper/#deffcode.ffhelper.is_valid_image_seq--is_valid_image_seq","title":"is_valid_image_seq","text":"<p>Checks Image sequence validity by testing its extension against FFmpeg's supported pipe formats and number of Image files.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of FFmpeg binaries</p> required <code>source</code> <code>string</code> <p>video source to be validated</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>enables verbose for its operations</p> <code>False</code> <p>Returns: A boolean value, confirming whether tests passed, or not?.</p> Source code in <code>deffcode/ffhelper.py</code> <pre><code>def is_valid_image_seq(path, source=None, verbose=False):\n\"\"\"\n    ## is_valid_image_seq\n    Checks Image sequence validity by testing its extension against\n    FFmpeg's supported pipe formats and number of Image files.\n    Parameters:\n        path (string): absolute path of FFmpeg binaries\n        source (string): video source to be validated\n        verbose (bool): enables verbose for its operations\n    **Returns:** A boolean value, confirming whether tests passed, or not?.\n    \"\"\"\nif source is None or not (source):\nlogger.error(\"Source is empty!\")\nreturn False\n# extract all FFmpeg supported protocols\nformats = check_sp_output([path, \"-hide_banner\", \"-formats\"])\nextract_formats = re.findall(r\"\\w+_pipe\", formats.decode(\"utf-8\").strip())\nsupported_image_formats = [\nx.split(\"_\")[0] for x in extract_formats if x.endswith(\"_pipe\")\n]\nfilename, extension = os.path.splitext(source)\n# Test and return result whether scheme is supported\nif extension and source.endswith(tuple(supported_image_formats)):\nif validate_imgseqdir(source, extension=extension[1:], verbose=verbose):\nverbose and logger.debug(\n\"A valid Image Sequence source of format `{}` found.\".format(extension)\n)\nreturn True\nelse:\nValueError(\n\"Given Image Sequence source of format `{}` contains insignificant(invalid) sample size, Check the `source` parameter value again!\".format(\nsource.split(\".\")[1]\n)\n)\nelse:\nverbose and logger.warning(\"Source isn't a valid Image Sequence\")\nreturn False\n</code></pre> <p> </p>"},{"location":"reference/ffhelper/#deffcode.ffhelper.is_valid_url--is_valid_url","title":"is_valid_url","text":"<p>Checks URL validity by testing its scheme against FFmpeg's supported protocols.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>string</code> <p>absolute path of FFmpeg binaries</p> required <code>url</code> <code>string</code> <p>URL to be validated</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>enables verbose for its operations</p> <code>False</code> <p>Returns: A boolean value, confirming whether tests passed, or not?.</p> Source code in <code>deffcode/ffhelper.py</code> <pre><code>def is_valid_url(path, url=None, verbose=False):\n\"\"\"\n    ## is_valid_url\n    Checks URL validity by testing its scheme against\n    FFmpeg's supported protocols.\n    Parameters:\n        path (string): absolute path of FFmpeg binaries\n        url (string): URL to be validated\n        verbose (bool): enables verbose for its operations\n    **Returns:** A boolean value, confirming whether tests passed, or not?.\n    \"\"\"\nif url is None or not (url):\nlogger.warning(\"URL is empty!\")\nreturn False\n# extract URL scheme\nextracted_scheme_url = url.split(\"://\", 1)[0]\n# extract all FFmpeg supported protocols\nprotocols = check_sp_output([path, \"-hide_banner\", \"-protocols\"])\nsplitted = [x.decode(\"utf-8\").strip() for x in protocols.split(b\"\\n\")]\nsupported_protocols = splitted[splitted.index(\"Output:\") + 1 : len(splitted) - 1]\n# rtsp is a demuxer somehow\nsupported_protocols += [\"rtsp\"] if \"rtsp\" in get_supported_demuxers(path) else []\n# Test and return result whether scheme is supported\nif extracted_scheme_url and extracted_scheme_url in supported_protocols:\nverbose and logger.debug(\n\"URL scheme `{}` is supported by FFmpeg.\".format(extracted_scheme_url)\n)\nreturn True\nelse:\nverbose and logger.warning(\n\"URL scheme `{}` isn't supported by FFmpeg!\".format(extracted_scheme_url)\n)\nreturn False\n</code></pre> <p> </p>"},{"location":"reference/ffhelper/#deffcode.ffhelper.check_sp_output--check_sp_output","title":"check_sp_output","text":"<p>Returns FFmpeg <code>stdout</code> output from subprocess module.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>based on input</code> <p>Non Keyword Arguments</p> <code>()</code> <code>kwargs</code> <code>based on input</code> <p>Keyword Arguments</p> <code>{}</code> <p>Returns: A string value.</p> Source code in <code>deffcode/ffhelper.py</code> <pre><code>def check_sp_output(*args, **kwargs):\n\"\"\"\n    ## check_sp_output\n    Returns FFmpeg `stdout` output from subprocess module.\n    Parameters:\n        args (based on input): Non Keyword Arguments\n        kwargs (based on input): Keyword Arguments\n    **Returns:** A string value.\n    \"\"\"\n# workaround for python bug: https://bugs.python.org/issue37380\nif platform.system() == \"Windows\":\n# see comment https://bugs.python.org/msg370334\nsp._cleanup = lambda: None\n# handle additional params\nretrieve_stderr = kwargs.pop(\"force_retrieve_stderr\", False)\n# execute command in subprocess\nprocess = sp.Popen(\nstdout=sp.PIPE,\nstderr=sp.DEVNULL if not (retrieve_stderr) else sp.PIPE,\n*args,\n**kwargs,\n)\n# communicate and poll process\noutput, stderr = process.communicate()\nretcode = process.poll()\n# handle return code\nif retcode and not (retrieve_stderr):\nlogger.error(\"[Pipline-Error] :: {}\".format(output.decode(\"utf-8\")))\ncmd = kwargs.get(\"args\")\nif cmd is None:\ncmd = args[0]\nerror = sp.CalledProcessError(retcode, cmd)\nerror.output = output\nraise error\n# raise error if no output\nbool(output) or bool(stderr) or logger.error(\n\"[Pipline-Error] :: Pipline failed to exact any data from command: {}!\".format(\nargs[0] if args else []\n)\n)\n# return output otherwise\nreturn stderr if retrieve_stderr and stderr else output\n</code></pre> <p> </p>"},{"location":"reference/utils/","title":"deffcode.utils","text":"<p>Following are the helper methods required by the DeFFcode APIs.</p> <p>For usage examples, kindly refer our Basic Recipes  and Advanced Recipes </p> <p> </p>"},{"location":"reference/utils/#deffcode.utils.logger_handler--logger_handler","title":"logger_handler","text":"<p>Returns the logger handler</p> <p>Returns: A logger handler</p> Source code in <code>deffcode/utils.py</code> <pre><code>def logger_handler():\n\"\"\"\n    ## logger_handler\n    Returns the logger handler\n    **Returns:** A logger handler\n    \"\"\"\n# logging formatter\nformatter = ColoredFormatter(\n\"{green}{asctime}{reset} :: {bold_purple}{name:^13}{reset} :: {log_color}{levelname:^8}{reset} :: {bold_white}{message}\",\ndatefmt=\"%H:%M:%S\",\nreset=True,\nlog_colors={\n\"INFO\": \"bold_cyan\",\n\"DEBUG\": \"bold_yellow\",\n\"WARNING\": \"bold_red,fg_thin_yellow\",\n\"ERROR\": \"bold_red\",\n\"CRITICAL\": \"bold_red,bg_white\",\n},\nstyle=\"{\",\n)\n# check if FFdecoder_LOGFILE defined\nfile_mode = os.environ.get(\"DEFFCODE_LOGFILE\", False)\n# define handler\nhandler = logging.StreamHandler()\nif file_mode and isinstance(file_mode, str):\nfile_path = os.path.abspath(file_mode)\nif (os.name == \"nt\" or os.access in os.supports_effective_ids) and os.access(\nos.path.dirname(file_path), os.W_OK\n):\nfile_path = (\nos.path.join(file_path, \"deffcode.log\")\nif os.path.isdir(file_path)\nelse file_path\n)\nhandler = logging.FileHandler(file_path, mode=\"a\")\nformatter = logging.Formatter(\n\"{asctime} :: {name} :: {levelname} :: {message}\",\ndatefmt=\"%H:%M:%S\",\nstyle=\"{\",\n)\nhandler.setFormatter(formatter)\nreturn handler\n</code></pre> <p> </p>"},{"location":"reference/utils/#deffcode.utils.dict2Args--dict2args","title":"dict2Args","text":"<p>Converts dictionary attributes to list(args)</p> <p>Parameters:</p> Name Type Description Default <code>param_dict</code> <code>dict</code> <p>Parameters dictionary</p> required <p>Returns: Arguments list</p> Source code in <code>deffcode/utils.py</code> <pre><code>def dict2Args(param_dict):\n\"\"\"\n    ## dict2Args\n    Converts dictionary attributes to list(args)\n    Parameters:\n        param_dict (dict): Parameters dictionary\n    **Returns:** Arguments list\n    \"\"\"\nargs = []\nfor key in param_dict.keys():\nif key in [\"-clones\"] or key.startswith(\"-core\"):\nif isinstance(param_dict[key], list):\nargs.extend(param_dict[key])\nelse:\nlogger.warning(\n\"{} with invalid datatype:`{}`, Skipped!\".format(\n\"Core parameter\" if key.startswith(\"-core\") else \"Clone\",\nparam_dict[key],\n)\n)\nelse:\nargs.append(key)\nargs.append(str(param_dict[key]))\nreturn args\n</code></pre> <p> </p>"},{"location":"reference/utils/#deffcode.utils.delete_file_safe--delete_ext_safe","title":"delete_ext_safe","text":"<p>Safely deletes files at given path.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>string</code> <p>path to the file</p> required Source code in <code>deffcode/utils.py</code> <pre><code>def delete_file_safe(file_path):\n\"\"\"\n    ## delete_ext_safe\n    Safely deletes files at given path.\n    Parameters:\n        file_path (string): path to the file\n    \"\"\"\ntry:\ndfile = Path(file_path)\nif sys.version_info &gt;= (3, 8, 0):\ndfile.unlink(missing_ok=True)\nelse:\ndfile.exists() and dfile.unlink()\nexcept Exception as e:\nlogger.exception(str(e))\n</code></pre> <p> </p>"},{"location":"reference/ffdecoder/","title":"FFdecoder API","text":"<p>FFdecoder API compiles and executes the FFmpeg pipeline inside a subprocess pipe for generating real-time, low-overhead, lightning fast video frames with robust error-handling in python \ud83c\udf9e\ufe0f\u26a1</p> <p>FFdecoder API implements a standalone highly-extensible wrapper around FFmpeg multimedia framework that provides complete control over the underline pipeline including access to almost any FFmpeg specification thinkable such as framerate, resolution, hardware decoder(s), complex filter(s), and pixel format(s) that are readily supported by all well known Computer Vision libraries.</p> <p>FFdecoder API compiles its FFmpeg pipeline by processing input Video Source metadata and User-defined options, and runs it inside a <code>subprocess</code> pipe concurrently with the main thread, while extracting output dataframes(1D arrays) into a Numpy buffer. These dataframes are consecutively grabbed from the buffer and decoded into 24-bit RGB (default) <code>ndarray</code> 3D frames that are readily available through its <code>generateFrame()</code> method.</p> <p>FFdecoder API employs Sourcer API at its backend for gathering, processing, and validating metadata of all multimedia streams available in the given source for formulating/compiling its default FFmpeg pipeline. This metadata information is also available as a JSON string with its <code>metadata</code> property object and can be updated as desired.</p> <p>FFdecoder API supports a wide-ranging media stream as input source such as USB/Virtual/IP Camera Feed, Multimedia video file, Screen Capture, Image Sequence, Network protocols (such as HTTP(s), RTP/RSTP, etc.), so on and so forth.</p> <p>Furthermore, FFdecoder API maintains the standard OpenCV-Python (Python API for OpenCV) coding syntax, thereby making it even easier to integrate this API in any Computer Vision application.</p> <p>For usage examples, kindly refer our Basic Recipes  and Advanced Recipes </p> <p>FFdecoder API parameters are explained here \u27b6</p> Source code in <code>deffcode/ffdecoder.py</code> <pre><code>class FFdecoder:\n\"\"\"\n    &gt; FFdecoder API compiles and executes the FFmpeg pipeline inside a subprocess pipe for generating real-time, low-overhead, lightning fast video frames\n    with robust error-handling in python \ud83c\udf9e\ufe0f\u26a1\n    FFdecoder API implements a **standalone highly-extensible wrapper around [FFmpeg](https://ffmpeg.org/)** multimedia framework that provides complete\n    control over the underline pipeline including **access to almost any FFmpeg specification thinkable** such as framerate, resolution, hardware decoder(s),\n    complex filter(s), and pixel format(s) that are readily supported by all well known Computer Vision libraries.\n    FFdecoder API **compiles its FFmpeg pipeline** by processing input Video Source metadata and User-defined options, and **runs it inside a\n    [`subprocess`](https://docs.python.org/3/library/subprocess.html) pipe** concurrently with the main thread, while extracting output dataframes(1D arrays)\n    into a Numpy buffer. These dataframes are consecutively grabbed from the buffer and decoded into ==[24-bit RGB](https://en.wikipedia.org/wiki/List_of_monochrome_and_RGB_color_formats#24-bit_RGB) _(default)_\n    [`ndarray`](https://numpy.org/doc/stable/reference/arrays.ndarray.html#the-n-dimensional-array-ndarray) 3D frames== that are readily available\n    through its [`generateFrame()`](#deffcode.ffdecoder.FFdecoder.generateFrame) method.\n    FFdecoder API **employs [Sourcer API](../../reference/sourcer) at its backend** for gathering, processing, and validating metadata of all\n    multimedia streams available in the given source for formulating/compiling its default FFmpeg pipeline. This metadata information is also\n    available as a JSON string with its [`metadata`](#deffcode.ffdecoder.FFdecoder.metadata) property object and can be updated as desired.\n    FFdecoder API **supports a wide-ranging media stream** as input source such as USB/Virtual/IP Camera Feed, Multimedia video file,\n    Screen Capture, Image Sequence, Network protocols _(such as HTTP(s), RTP/RSTP, etc.)_, so on and so forth.\n    Furthermore, FFdecoder API maintains the **standard [OpenCV-Python](https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html) _(Python API for OpenCV)_ coding syntax**, thereby making it even easier to\n    integrate this API in any Computer Vision application.\n    !!! example \"For usage examples, kindly refer our **[Basic Recipes :cake:](../../recipes/basic)** and **[Advanced Recipes :croissant:](../../recipes/advanced)**\"\n    !!! info \"FFdecoder API parameters are explained [here \u27b6](params/)\"\n    \"\"\"\ndef __init__(\nself,\nsource,\nsource_demuxer=None,\nframe_format=None,\ncustom_ffmpeg=\"\",\nverbose=False,\n**ffparams\n):\n\"\"\"\n        This constructor method initializes the object state and attributes of the FFdecoder Class.\n        Parameters:\n            source (str): defines the input(`-i`) source filename/URL/device-name/device-path.\n            source_demuxer (str): specifies the demuxer(`-f`) for the input source.\n            frame_format (str): sets pixel format(`-pix_fmt`) of the decoded frames.\n            custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executable.\n            verbose (bool): enables/disables verbose.\n            ffparams (dict): provides the flexibility to control supported internal and FFmpeg parameters.\n        \"\"\"\n# enable verbose if specified\nself.__verbose_logs = (\nverbose if (verbose and isinstance(verbose, bool)) else False\n)\n# define whether initializing\nself.__initializing = True\n# define frame pixel-format for decoded frames\nself.__frame_format = (\nframe_format.lower().strip() if isinstance(frame_format, str) else None\n)\n# handles user-defined parameters\nself.__extra_params = {}\n# handle process to be frames written\nself.__process = None\n# handle exclusive metadata\nself.__ff_pixfmt_metadata = None  # metadata\nself.__raw_frame_num = None  # raw-frame number\nself.__raw_frame_pixfmt = None  # raw-frame pixformat\nself.__raw_frame_dtype = None  # raw-frame dtype\nself.__raw_frame_depth = None  # raw-frame depth\nself.__raw_frame_resolution = None  # raw-frame resolution/dimension\n# define supported mode of operation\nself.__supported_opmodes = {\n\"av\": \"Audio-Video\",  # audio is only for pass-through, not really for audio decoding yet.\n\"vo\": \"Video-Only\",\n\"imgseq\": \"Image-Sequence\",\n# \"ao\":\"Audio-Only\", # reserved for future\n}\n# operation mode variable\nself.__opmode = None\n# handle termination\nself.__terminate_stream = False\n# cleans and reformat user-defined parameters\nself.__extra_params = {\nstr(k).strip(): str(v).strip()\nif not (v is None) and not isinstance(v, (dict, list, int, float, tuple))\nelse v\nfor k, v in ffparams.items()\n}\n# handle custom Sourcer API params\nsourcer_params = self.__extra_params.pop(\"-custom_sourcer_params\", {})\n# reset improper values\nsourcer_params = {} if not isinstance(sourcer_params, dict) else sourcer_params\n# handle user ffmpeg pre-headers(parameters such as `-re`) parameters (must be a list)\nself.__ffmpeg_prefixes = self.__extra_params.pop(\"-ffprefixes\", [])\n# check if not valid type\nif not isinstance(self.__ffmpeg_prefixes, list):\n# log it\nlogger.warning(\n\"Discarding invalid `-ffprefixes` value of wrong type: `{}`!\".format(\ntype(self.__ffmpeg_prefixes).__name__\n)\n)\n# reset improper values\nself.__ffmpeg_prefixes = []\nelse:\n# also pass valid ffmpeg pre-headers to Sourcer API\nsourcer_params[\"-ffprefixes\"] = self.__ffmpeg_prefixes\n# pass parameter(if specified) to Sourcer API, specifying where to save the downloaded FFmpeg Static\n# assets on Windows(if specified)\nsourcer_params[\"-ffmpeg_download_path\"] = self.__extra_params.pop(\n\"-ffmpeg_download_path\", \"\"\n)\n# handle video and audio stream indexes in case of multiple ones.\ndefault_stream_indexes = self.__extra_params.pop(\n\"-default_stream_indexes\", (0, 0)\n)\n# reset improper values\ndefault_stream_indexes = (\n(0, 0)\nif not isinstance(default_stream_indexes, (list, tuple))\nelse default_stream_indexes\n)\n# pass FFmpeg filter to Sourcer API params for processing\nif set([\"-vf\", \"-filter_complex\"]).intersection(self.__extra_params.keys()):\nkey = \"-vf\" if \"-vf\" in self.__extra_params else \"-filter_complex\"\nsourcer_params[key] = self.__extra_params[key]\n# define dict to store user-defined parameters\nself.__user_metadata = {}\n# extract and assign source metadata as dict\n(self.__sourcer_metadata, self.__missing_prop) = (\nSourcer(\nsource=source,\nsource_demuxer=source_demuxer,\nverbose=verbose,\ncustom_ffmpeg=custom_ffmpeg if isinstance(custom_ffmpeg, str) else \"\",\n**sourcer_params\n)\n.probe_stream(default_stream_indexes=default_stream_indexes)\n.retrieve_metadata(force_retrieve_missing=True)\n)\n# handle valid FFmpeg assets location\nself.__ffmpeg = self.__sourcer_metadata[\"ffmpeg_binary_path\"]\n# handle YUV pixel formats(such as `yuv420p`, `yuv444p`, `nv12`, `nv21` etc.)\n# patch for compatibility with OpenCV APIs.\nself.__cv_patch = self.__extra_params.pop(\"-enforce_cv_patch\", False)\nif not (isinstance(self.__cv_patch, bool)):\nself.__cv_patch = False\nself.__verbose_logs and logger.critical(\n\"Enforcing OpenCV compatibility patch for YUV/NV frames.\"\n)\n# handle pass-through audio mode works in conjunction with WriteGear [TODO]\nself.__passthrough_mode = self.__extra_params.pop(\"-passthrough_audio\", False)\nif not (isinstance(self.__passthrough_mode, bool)):\nself.__passthrough_mode = False\n# handle mode of operation\nif self.__sourcer_metadata[\"source_has_image_sequence\"]:\n# image-sequence mode\nself.__opmode = \"imgseq\"\nelif (\nself.__sourcer_metadata[\n\"source_has_video\"\n]  # audio is only for pass-through, not really for audio decoding yet.\nand self.__sourcer_metadata[\"source_has_audio\"]\nand self.__passthrough_mode  # [TODO]\n):\nself.__opmode = \"av\"\n# elif __defop_mode == \"ao\" and self.__sourcer_metadata.contains_audio: # [TODO]\n#    self.__opmode = \"ao\"\nelif self.__sourcer_metadata[\"source_has_video\"]:\n# video-only mode\nself.__opmode = \"vo\"\nelse:\n# raise if unknown mode\nraise ValueError(\n\"Unable to find any usable video stream in the given source!\"\n)\n# store as metadata\nself.__missing_prop[\"ffdecoder_operational_mode\"] = self.__supported_opmodes[\nself.__opmode\n]\n# handle user-defined output framerate\n__framerate = self.__extra_params.pop(\"-framerate\", None)\nif (\nisinstance(__framerate, str)\nand __framerate\n== \"null\"  # special mode to discard `-framerate/-r` parameter\n):\nself.__inputframerate = __framerate\nelif isinstance(__framerate, (float, int)):\nself.__inputframerate = float(__framerate) if __framerate &gt; 0.0 else 0.0\nelse:\n# warn if wrong type\nnot (__framerate is None) and logger.warning(\n\"Discarding invalid `-framerate` value of wrong type `{}`!\".format(\ntype(__framerate).__name__\n)\n)\n# reset to default\nself.__inputframerate = 0.0\n# handle user defined decoded frame resolution\nself.__custom_resolution = self.__extra_params.pop(\"-custom_resolution\", None)\nif (\nisinstance(self.__custom_resolution, str)\nand self.__custom_resolution\n== \"null\"  # special mode to discard `-size/-s` parameter\n) or (\nisinstance(self.__custom_resolution, (list, tuple))\nand len(self.__custom_resolution)\n== 2  # valid resolution(must be a tuple or list)\n):\n# log it\nself.__verbose_logs and not isinstance(\nself.__custom_resolution, str\n) and logger.debug(\n\"Setting raw frames size: `{}`.\".format(self.__custom_resolution)\n)\nelse:\n# log it\nnot (self.__custom_resolution is None) and logger.warning(\n\"Discarding invalid `-custom_resolution` value: `{}`!\".format(\nself.__custom_resolution\n)\n)\n# reset improper values\nself.__custom_resolution = None\ndef formulate(self):\n\"\"\"\n        This method formulates all necessary FFmpeg pipeline arguments and executes it inside the FFmpeg `subprocess` pipe.\n        **Returns:** A reference to the FFdecoder class object.\n        \"\"\"\n# assign values to class variables on first run\nif self.__initializing:\n# prepare parameter dict\ninput_params = OrderedDict()\noutput_params = OrderedDict()\n# dynamically pre-assign a default video-decoder (if not assigned by user).\nsupported_vdecodecs = get_supported_vdecoders(self.__ffmpeg)\ndefault_vdecodec = (\nself.__sourcer_metadata[\"source_video_decoder\"]\nif self.__sourcer_metadata[\"source_video_decoder\"]\nin supported_vdecodecs\nelse \"unknown\"\n)\nif \"-c:v\" in self.__extra_params:\nself.__extra_params[\"-vcodec\"] = self.__extra_params.pop(\n\"-c:v\", default_vdecodec\n)\n# handle image sequence separately\nif self.__opmode == \"imgseq\":\n# -vcodec is discarded by default\n# (This is correct or maybe -vcodec required in some unknown case) [TODO]\nself.__extra_params.pop(\"-vcodec\", None)\nelif (\n\"-vcodec\" in self.__extra_params\nand self.__extra_params[\"-vcodec\"] is None\n):\n# special case when -vcodec is not needed intentionally\nself.__extra_params.pop(\"-vcodec\", None)\nelse:\n# assign video decoder selected here.\nif not \"-vcodec\" in self.__extra_params:\ninput_params[\"-vcodec\"] = default_vdecodec\nelse:\ninput_params[\"-vcodec\"] = self.__extra_params.pop(\n\"-vcodec\", default_vdecodec\n)\nif (\ndefault_vdecodec != \"unknown\"\nand not input_params[\"-vcodec\"] in supported_vdecodecs\n):\n# reset to default if not supported\nlogger.warning(\n\"Provided FFmpeg does not support `{}` video decoder. Switching to default supported `{}` decoder!\".format(\ninput_params[\"-vcodec\"], default_vdecodec\n)\n)\ninput_params[\"-vcodec\"] = default_vdecodec\n# raise error if not valid decoder found\nif not input_params[\"-vcodec\"] in supported_vdecodecs:\nraise RuntimeError(\n\"Provided FFmpeg does not support any known usable video-decoders.\"\n\" Either define your own manually or switch to another FFmpeg binaries(if available).\"\n)\n# handle user-defined number of frames.\nif \"-vframes\" in self.__extra_params:\nself.__extra_params[\"-frames:v\"] = self.__extra_params.pop(\n\"-vframes\", None\n)\nif \"-frames:v\" in self.__extra_params:\nvalue = self.__extra_params.pop(\"-frames:v\", None)\nif not (value is None) and value &gt; 0:\noutput_params[\"-frames:v\"] = value\n# dynamically calculate default raw-frames pixel format(if not assigned by user).\n# notify FFmpeg `-pix_fmt` parameter cannot be assigned directly\nif \"-pix_fmt\" in self.__extra_params:\nlogger.warning(\n\"Discarding user-defined `-pix_fmt` value as it can only be assigned with `frame_format` parameter!\"\n)\nself.__extra_params.pop(\"-pix_fmt\", None)\n# get supported FFmpeg pixfmt data with depth and bpp(bits-per-pixel)\nself.__ff_pixfmt_metadata = get_supported_pixfmts(self.__ffmpeg)\nsupported_pixfmts = [fmts[0] for fmts in self.__ff_pixfmt_metadata]\n# calculate default pixel-format\n# Check special case  - `frame_format`(or `-pix_fmt`) parameter discarded from pipeline\nself.__frame_format == \"null\" and logger.critical(\n\"Manually discarding `frame_format`(or `-pix_fmt`) parameter from this pipeline.\"\n)\n# choose between rgb24(if available) or source pixel-format\n# otherwise, only source pixel-format for special case\ndefault_pixfmt = (\n\"rgb24\"\nif \"rgb24\" in supported_pixfmts and self.__frame_format != \"null\"\nelse self.__sourcer_metadata[\"source_video_pixfmt\"]\n)\n# assign output raw-frames pixel format\nrawframe_pixfmt = None\nif (\nnot (self.__frame_format is None)\nand self.__frame_format in supported_pixfmts\n):\n# check if valid and supported `frame_format` parameter assigned\nrawframe_pixfmt = self.__frame_format.strip()\nself.__verbose_logs and logger.info(\n\"User-defined `{}` frame pixel-format will be used for this pipeline.\".format(\nrawframe_pixfmt\n)\n)\nelif (\n\"output_frames_pixfmt\"\nin self.__sourcer_metadata  # means `format` filter is defined\nand self.__sourcer_metadata[\"output_frames_pixfmt\"] in supported_pixfmts\n):\n# assign if valid and supported\nrawframe_pixfmt = self.__sourcer_metadata[\n\"output_frames_pixfmt\"\n].strip()\nself.__verbose_logs and logger.info(\n\"FFmpeg filter values will be used for this pipeline for defining output pixel-format.\"\n)\nelse:\n# reset to default if not supported\nrawframe_pixfmt = default_pixfmt\n# log it accordingly\nif self.__frame_format is None:\nlogger.info(\n\"Using default `{}` pixel-format for this pipeline.\".format(\ndefault_pixfmt\n)\n)\nelse:\nlogger.warning(\n\"{} Switching to default `{}` pixel-format!\".format(\n\"Provided FFmpeg does not supports `{}` pixel-format.\".format(\nself.__sourcer_metadata[\"output_frames_pixfmt\"]\nif \"output_frames_pixfmt\" in self.__sourcer_metadata\nelse self.__frame_format\n)\nif self.__frame_format != \"null\"\nelse \"No usable pixel-format defined.\",\ndefault_pixfmt,\n)\n)\n# dynamically calculate raw-frame datatype based on pixel-format selected\n(self.__raw_frame_depth, rawframesbpp) = [\n(int(x[1]), int(x[2]))\nfor x in self.__ff_pixfmt_metadata\nif x[0] == rawframe_pixfmt\n][0]\nraw_bit_per_component = (\nrawframesbpp // self.__raw_frame_depth if self.__raw_frame_depth else 0\n)\nif 4 &lt;= raw_bit_per_component &lt;= 8:\nself.__raw_frame_dtype = np.dtype(\"u1\")\nelif 8 &lt; raw_bit_per_component &lt;= 16 and rawframe_pixfmt.endswith(\n(\"le\", \"be\")\n):\nif rawframe_pixfmt.endswith(\"le\"):\nself.__raw_frame_dtype = np.dtype(\"&lt;u2\")\nelse:\nself.__raw_frame_dtype = np.dtype(\"&gt;u2\")\nelse:\n# reset to both pixel-format and datatype to default if not supported\nnot (self.__frame_format is None) and logger.warning(\n\"Selected pixel-format `{}` dtype is not supported by FFdecoder API. Switching to default `rgb24` pixel-format!\".format(\nrawframe_pixfmt\n)\n)\nrawframe_pixfmt = \"rgb24\"\nself.__raw_frame_dtype = np.dtype(\"u1\")\n# Check if not special case\nif self.__frame_format != \"null\":\n# assign to FFmpeg pipeline otherwise\noutput_params[\"-pix_fmt\"] = rawframe_pixfmt\n# assign to global parameter further usage\nself.__raw_frame_pixfmt = rawframe_pixfmt\n# also override as metadata(if available)\nif \"output_frames_pixfmt\" in self.__sourcer_metadata:\nself.__sourcer_metadata[\n\"output_frames_pixfmt\"\n] = self.__raw_frame_pixfmt\n# handle raw-frame resolution\n# notify FFmpeg `-s` parameter cannot be assigned directly\nif \"-s\" in self.__extra_params:\nlogger.warning(\n\"Discarding user-defined `-s` FFmpeg parameter as it can only be assigned with `-custom_resolution` attribute! Read docs for more details.\"\n)\nself.__extra_params.pop(\"-s\", None)\n# assign output rawframe resolution\nif not (self.__custom_resolution is None) and not isinstance(\nself.__custom_resolution, str\n):\n# assign if assigned by user and not \"null\"(str)\nself.__raw_frame_resolution = self.__custom_resolution\nself.__verbose_logs and logger.info(\n\"User-defined `{}` frame resolution will be used for this pipeline.\".format(\nself.__raw_frame_resolution\n)\n)\nelif (\n\"output_frames_resolution\"\nin self.__sourcer_metadata  # means `scale` filter is defined\nand self.__sourcer_metadata[\"output_frames_resolution\"]\nand len(self.__sourcer_metadata[\"output_frames_resolution\"]) == 2\n):\n# calculate raw-frame resolution/dimensions based on output.\nself.__raw_frame_resolution = self.__sourcer_metadata[\n\"output_frames_resolution\"\n]\nelif (\nself.__sourcer_metadata[\"source_video_resolution\"]\nand len(self.__sourcer_metadata[\"source_video_resolution\"]) == 2\n):\n# calculate raw-frame resolution/dimensions based on source.\nself.__raw_frame_resolution = self.__sourcer_metadata[\n\"source_video_resolution\"\n]\nelse:\n# otherwise raise error\nraise RuntimeError(\n\"Both source and output metadata values found Invalid with {} `-custom_resolution` attribute. Aborting!\".format(\n\"null\"\nif isinstance(self.__inputframerate, str)\nelse \"undefined\"\n)\n)\n# special mode to discard `-size/-s` FFmpeg parameter completely\nif isinstance(self.__custom_resolution, str):\nlogger.critical(\n\"Manually discarding `-size/-s` FFmpeg parameter from this pipeline.\"\n)\nelse:\n# add to pipeline\ndimensions = \"{}x{}\".format(\nself.__raw_frame_resolution[0], self.__raw_frame_resolution[1]\n)\noutput_params[\"-s\"] = str(dimensions)\n# log if filters or default source is used\nself.__verbose_logs and (\nself.__custom_resolution is None\nor isinstance(self.__custom_resolution, str)\n) and logger.info(\n\"{} for this pipeline for defining output resolution.\".format(\n\"FFmpeg filter values will be used\"\nif \"output_frames_resolution\" in self.__sourcer_metadata\nelse \"Default source resolution will be used\"\n)\n)\n# dynamically calculate raw-frame framerate based on source (if not assigned by user).\nif (\nnot isinstance(self.__inputframerate, str)\nand self.__inputframerate &gt; 0.0\n):\n# assign if assigned by user and not \"null\"(str)\noutput_params[\"-framerate\"] = str(self.__inputframerate)\nself.__verbose_logs and logger.info(\n\"User-defined `{}` output framerate will be used for this pipeline.\".format(\nstr(self.__inputframerate)\n)\n)\nelif (\n\"output_framerate\"\nin self.__sourcer_metadata  # means `fps` filter is defined\nand self.__sourcer_metadata[\"output_framerate\"] &gt; 0.0\n):\n# special mode to discard `-framerate/-r` FFmpeg parameter completely\nif self.__inputframerate == \"null\":\nlogger.critical(\n\"Manually discarding `-framerate/-r` FFmpeg parameter from this pipeline.\"\n)\nelse:\n# calculate raw-frame framerate based on output\noutput_params[\"-framerate\"] = str(\nself.__sourcer_metadata[\"output_framerate\"]\n)\nself.__verbose_logs and logger.info(\n\"FFmpeg filter values will be used for this pipeline for defining output framerate.\"\n)\nelif self.__sourcer_metadata[\"source_video_framerate\"] &gt; 0.0:\n# special mode to discard `-framerate/-r` FFmpeg parameter completely\nif self.__inputframerate == \"null\":\nlogger.critical(\n\"Manually disabling `-framerate/-r` FFmpeg parameter for this pipeline.\"\n)\nelse:\n# calculate raw-frame framerate based on source\noutput_params[\"-framerate\"] = str(\nself.__sourcer_metadata[\"source_video_framerate\"]\n)\nself.__verbose_logs and logger.info(\n\"Default source framerate will be used for this pipeline for defining output framerate.\"\n)\nelse:\n# otherwise raise error\nraise RuntimeError(\n\"Both source and output metadata values found Invalid with {} `-framerate` attribute. Aborting!\".format(\n\"null\"\nif isinstance(self.__inputframerate, str)\nelse \"undefined\"\n)\n)\n# add rest to output parameters\noutput_params.update(self.__extra_params)\n# dynamically calculate raw-frame numbers based on source (if not assigned by user).\n# TODO Added support for `-re -stream_loop` and `-loop`\nif \"-frames:v\" in input_params:\nself.__raw_frame_num = input_params[\"-frames:v\"]\nelif (\nnot (self.__sourcer_metadata[\"approx_video_nframes\"] is None)\nand self.__sourcer_metadata[\"approx_video_nframes\"] &gt; 0\n):\nself.__raw_frame_num = self.__sourcer_metadata[\"approx_video_nframes\"]\nelse:\nself.__raw_frame_num = None\n# log that number of frames are unknown\nself.__verbose_logs and logger.info(\n\"Live/Network Stream detected! Number of frames in given source are not known.\"\n)\n# log Mode of Operation\nself.__verbose_logs and logger.critical(\n\"Activating {} Mode of Operation.\".format(\nself.__supported_opmodes[self.__opmode]\n)\n)\n# compose the Pipeline using formulated FFmpeg parameters\nself.__launch_FFdecoderline(input_params, output_params)\n# inform the initialization is completed\nself.__initializing = False\nelse:\n# warn if pipeline is recreated\nlogger.error(\"This pipeline is already created and running!\")\nreturn self\ndef __fetchNextfromPipeline(self):\n\"\"\"\n        This Internal method to fetch next dataframes(1D arrays) from `subprocess` pipe's standard output(`stdout`) into a Numpy buffer.\n        \"\"\"\nassert not (\nself.__process is None\n), \"Pipeline is not running! You must call `formulate()` method first.\"\n# formulated raw frame size and apply YUV pixel formats patch(if applicable)\nraw_frame_size = (\n(self.__raw_frame_resolution[0] * (self.__raw_frame_resolution[1] * 3 // 2))\nif self.__raw_frame_pixfmt.startswith((\"yuv\", \"nv\")) and self.__cv_patch\nelse (\nself.__raw_frame_depth\n* self.__raw_frame_resolution[0]\n* self.__raw_frame_resolution[1]\n)\n)\n# next dataframe as numpy ndarray\nnparray = None\ntry:\n# read bytes frames from buffer\nnparray = np.frombuffer(\nself.__process.stdout.read(\nraw_frame_size * self.__raw_frame_dtype.itemsize\n),\ndtype=self.__raw_frame_dtype,\n)\nexcept Exception as e:\nraise RuntimeError(\"Frame buffering failed with error: {}\".format(str(e)))\nreturn (\nnparray\nif not (nparray is None) and len(nparray) == raw_frame_size\nelse None\n)\ndef __fetchNextFrame(self):\n\"\"\"\n        This Internal method grabs and decodes next 3D `ndarray` video-frame from the buffer.\n        \"\"\"\n# Read next and reconstruct as numpy array\nframe = self.__fetchNextfromPipeline()\n# check if empty\nif frame is None:\nreturn frame\nelif self.__raw_frame_pixfmt.startswith(\"gray\"):\n# reconstruct exclusive `gray` frames\nframe = frame.reshape(\n(\nself.__raw_frame_resolution[1],\nself.__raw_frame_resolution[0],\nself.__raw_frame_depth,\n)\n)[:, :, 0]\nelif self.__raw_frame_pixfmt.startswith((\"yuv\", \"nv\")) and self.__cv_patch:\n# reconstruct exclusive YUV formats frames for OpenCV APIs\nframe = frame.reshape(\nself.__raw_frame_resolution[1] * 3 // 2,\nself.__raw_frame_resolution[0],\n)\nelse:\n# reconstruct default frames\nframe = frame.reshape(\n(\nself.__raw_frame_resolution[1],\nself.__raw_frame_resolution[0],\nself.__raw_frame_depth,\n)\n)\n# return frame\nreturn frame\ndef generateFrame(self):\n\"\"\"\n        This method returns a [Generator function](https://wiki.python.org/moin/Generators)\n        _(also an Iterator using `next()`)_ of video frames, grabbed continuously from the buffer.\n        \"\"\"\nif self.__raw_frame_num is None or not self.__raw_frame_num:\nwhile not self.__terminate_stream:  # infinite raw frames\nframe = self.__fetchNextFrame()\nif frame is None:\nself.__terminate_stream = True\nbreak\nyield frame\nelse:\nfor _ in range(self.__raw_frame_num):  # finite raw frames\nframe = self.__fetchNextFrame()\nif frame is None:\nself.__terminate_stream = True\nbreak\nyield frame\ndef __enter__(self):\n\"\"\"\n        Handles entry with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n        **Returns:** Output of `formulate()` method.\n        \"\"\"\nreturn self.formulate()\ndef __exit__(self, exc_type, exc_val, exc_tb):\n\"\"\"\n        Handles exit with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n        \"\"\"\nself.terminate()\n@property\ndef metadata(self):\n\"\"\"\n        A property object that dumps metadata information as JSON string.\n        **Returns:** Metadata as JSON string.\n        \"\"\"\n# import dependency\nimport json\n# return complete metadata information as JSON string\nreturn json.dumps(\n{\n**self.__sourcer_metadata,  # source video\n**self.__missing_prop,  # missing properties\n**self.__user_metadata,  # user-defined\n},\nindent=2,\n)\n@metadata.setter\ndef metadata(self, value):\n\"\"\"\n        A property object that updates metadata information with user-defined dictionary.\n        Parameters:\n            value (dict): User-defined dictionary.\n        \"\"\"\n# check if value dict type\nif value and isinstance(value, dict):\n# log it\nself.__verbose_logs and logger.info(\"Updating Metadata...\")\n# extract any source and output internal metadata keys\ndefault_keys = set(value).intersection(\n{**self.__sourcer_metadata, **self.__missing_prop}\n)\n# counterpart source properties for each output properties\ncounterpart_prop = {\n\"output_frames_resolution\": \"source_video_resolution\",\n\"output_frames_pixfmt\": \"source_video_pixfmt\",\n\"output_framerate\": \"source_video_framerate\",\n}\n# iterate over source metadata keys and sanitize it\nfor key in default_keys or []:\nif key == \"source\":\n# metadata properties that cannot be altered\nlogger.warning(\n\"`{}` metadata property value cannot be altered. Discarding!\".format(\nkey\n)\n)\nelif key in self.__missing_prop:\n# missing metadata properties are unavailable and read-only\n# notify user about alternative counterpart property (if available)\nlogger.warning(\n\"`{}` metadata property is read-only\".format(key)\n+ (\n\". Try updating `{}` property instead!\".format(\ncounterpart_prop[key]\n)\nif key in counterpart_prop.keys()\nelse \" and cannot be updated!\"\n)\n)\nelif isinstance(value[key], type(self.__sourcer_metadata[key])):\n# check if correct datatype as original\nself.__verbose_logs and logger.info(\n\"Updating `{}`{} metadata property to `{}`.\".format(\nkey,\n\" and its counterpart\"\nif key in counterpart_prop.values()\nelse \"\",\nvalue[key],\n)\n)\n# update source metadata if valid\nself.__sourcer_metadata[key] = value[key]\n# also update missing counterpart property (if available)\ncounter_key = next(\n(k for k, v in counterpart_prop.items() if v == key), \"\"\n)\nif counter_key:\nself.__missing_prop[counter_key] = value[key]\nelse:\n# otherwise discard and log it\nlogger.warning(\n\"Manually assigned `{}` metadata property value is of invalid type. Discarding!\"\n).format(key)\n# delete invalid key\ndel value[key]\n# There is no concept of a tuple in the JSON format.\n# Python's `json` module converts Python tuples to JSON lists\n# because that's the closest thing in JSON to a tuple.\nany(isinstance(value[x], tuple) for x in value) and logger.warning(\n\"All TUPLE metadata properties will be converted to LIST datatype. Read docs for more details.\"\n)\n# update user-defined metadata\nself.__user_metadata.update(value)\nelse:\n# otherwise raise error\nraise ValueError(\"Invalid datatype metadata assigned. Aborting!\")\ndef __launch_FFdecoderline(self, input_params, output_params):\n\"\"\"\n        This Internal method executes FFmpeg pipeline arguments inside a `subprocess` pipe in a new process.\n        Parameters:\n            input_params (dict): Input FFmpeg parameters\n            output_params (dict): Output FFmpeg parameters\n        \"\"\"\n# convert input parameters to list\ninput_parameters = dict2Args(input_params)\n# convert output parameters to list\noutput_parameters = dict2Args(output_params)\n# format command\ncmd = (\n[self.__ffmpeg]\n+ ([\"-hide_banner\"] if not self.__verbose_logs else [])\n+ self.__ffmpeg_prefixes\n+ input_parameters\n+ (\n[\"-f\", self.__sourcer_metadata[\"source_demuxer\"]]\nif (\"source_demuxer\" in self.__sourcer_metadata.keys())\nelse []\n)\n+ [\"-i\", self.__sourcer_metadata[\"source\"]]\n+ output_parameters\n+ [\"-f\", \"rawvideo\", \"-\"]\n)\n# compose the FFmpeg process\nif self.__verbose_logs:\nlogger.debug(\"Executing FFmpeg command: `{}`\".format(\" \".join(cmd)))\n# In debugging mode\nself.__process = sp.Popen(\ncmd, stdin=sp.DEVNULL, stdout=sp.PIPE, stderr=None\n)\nelse:\n# In silent mode\nself.__process = sp.Popen(\ncmd, stdin=sp.DEVNULL, stdout=sp.PIPE, stderr=sp.DEVNULL\n)\ndef terminate(self):\n\"\"\"\n        Safely terminates all processes.\n        \"\"\"\n# signal we are closing\nself.__verbose_logs and logger.debug(\"Terminating FFdecoder Pipeline...\")\nself.__terminate_stream = True\n# check if no process was initiated at first place\nif self.__process is None or not (self.__process.poll() is None):\nlogger.info(\"Pipeline already terminated.\")\nreturn\n# Attempt to close pipeline.\n# close `stdin` output\nself.__process.stdin and self.__process.stdin.close()\n# close `stdout` output\nself.__process.stdout and self.__process.stdout.close()\n# terminate/kill process if still processing\nif self.__process.poll() is None:\n# demuxers prefer kill\nself.__process.kill()\n# wait if not exiting\nself.__process.wait()\nself.__process = None\nlogger.info(\"Pipeline terminated successfully.\")\n</code></pre> <p> </p>"},{"location":"reference/ffdecoder/#deffcode.ffdecoder.FFdecoder.metadata","title":"<code>metadata</code>  <code>property</code> <code>writable</code>","text":"<p>A property object that dumps metadata information as JSON string.</p> <p>Returns: Metadata as JSON string.</p>"},{"location":"reference/ffdecoder/#deffcode.ffdecoder.FFdecoder.__enter__","title":"<code>__enter__(self)</code>  <code>special</code>","text":"<p>Handles entry with the <code>with</code> statement. See PEP343 -- The 'with' statement'.</p> <p>Returns: Output of <code>formulate()</code> method.</p> Source code in <code>deffcode/ffdecoder.py</code> <pre><code>def __enter__(self):\n\"\"\"\n    Handles entry with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n    **Returns:** Output of `formulate()` method.\n    \"\"\"\nreturn self.formulate()\n</code></pre>"},{"location":"reference/ffdecoder/#deffcode.ffdecoder.FFdecoder.__exit__","title":"<code>__exit__(self, exc_type, exc_val, exc_tb)</code>  <code>special</code>","text":"<p>Handles exit with the <code>with</code> statement. See PEP343 -- The 'with' statement'.</p> Source code in <code>deffcode/ffdecoder.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n\"\"\"\n    Handles exit with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/).\n    \"\"\"\nself.terminate()\n</code></pre>"},{"location":"reference/ffdecoder/#deffcode.ffdecoder.FFdecoder.__init__","title":"<code>__init__(self, source, source_demuxer=None, frame_format=None, custom_ffmpeg='', verbose=False, **ffparams)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the FFdecoder Class.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>defines the input(<code>-i</code>) source filename/URL/device-name/device-path.</p> required <code>source_demuxer</code> <code>str</code> <p>specifies the demuxer(<code>-f</code>) for the input source.</p> <code>None</code> <code>frame_format</code> <code>str</code> <p>sets pixel format(<code>-pix_fmt</code>) of the decoded frames.</p> <code>None</code> <code>custom_ffmpeg</code> <code>str</code> <p>assigns the location of custom path/directory for custom FFmpeg executable.</p> <code>''</code> <code>verbose</code> <code>bool</code> <p>enables/disables verbose.</p> <code>False</code> <code>ffparams</code> <code>dict</code> <p>provides the flexibility to control supported internal and FFmpeg parameters.</p> <code>{}</code> Source code in <code>deffcode/ffdecoder.py</code> <pre><code>def __init__(\nself,\nsource,\nsource_demuxer=None,\nframe_format=None,\ncustom_ffmpeg=\"\",\nverbose=False,\n**ffparams\n):\n\"\"\"\n    This constructor method initializes the object state and attributes of the FFdecoder Class.\n    Parameters:\n        source (str): defines the input(`-i`) source filename/URL/device-name/device-path.\n        source_demuxer (str): specifies the demuxer(`-f`) for the input source.\n        frame_format (str): sets pixel format(`-pix_fmt`) of the decoded frames.\n        custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executable.\n        verbose (bool): enables/disables verbose.\n        ffparams (dict): provides the flexibility to control supported internal and FFmpeg parameters.\n    \"\"\"\n# enable verbose if specified\nself.__verbose_logs = (\nverbose if (verbose and isinstance(verbose, bool)) else False\n)\n# define whether initializing\nself.__initializing = True\n# define frame pixel-format for decoded frames\nself.__frame_format = (\nframe_format.lower().strip() if isinstance(frame_format, str) else None\n)\n# handles user-defined parameters\nself.__extra_params = {}\n# handle process to be frames written\nself.__process = None\n# handle exclusive metadata\nself.__ff_pixfmt_metadata = None  # metadata\nself.__raw_frame_num = None  # raw-frame number\nself.__raw_frame_pixfmt = None  # raw-frame pixformat\nself.__raw_frame_dtype = None  # raw-frame dtype\nself.__raw_frame_depth = None  # raw-frame depth\nself.__raw_frame_resolution = None  # raw-frame resolution/dimension\n# define supported mode of operation\nself.__supported_opmodes = {\n\"av\": \"Audio-Video\",  # audio is only for pass-through, not really for audio decoding yet.\n\"vo\": \"Video-Only\",\n\"imgseq\": \"Image-Sequence\",\n# \"ao\":\"Audio-Only\", # reserved for future\n}\n# operation mode variable\nself.__opmode = None\n# handle termination\nself.__terminate_stream = False\n# cleans and reformat user-defined parameters\nself.__extra_params = {\nstr(k).strip(): str(v).strip()\nif not (v is None) and not isinstance(v, (dict, list, int, float, tuple))\nelse v\nfor k, v in ffparams.items()\n}\n# handle custom Sourcer API params\nsourcer_params = self.__extra_params.pop(\"-custom_sourcer_params\", {})\n# reset improper values\nsourcer_params = {} if not isinstance(sourcer_params, dict) else sourcer_params\n# handle user ffmpeg pre-headers(parameters such as `-re`) parameters (must be a list)\nself.__ffmpeg_prefixes = self.__extra_params.pop(\"-ffprefixes\", [])\n# check if not valid type\nif not isinstance(self.__ffmpeg_prefixes, list):\n# log it\nlogger.warning(\n\"Discarding invalid `-ffprefixes` value of wrong type: `{}`!\".format(\ntype(self.__ffmpeg_prefixes).__name__\n)\n)\n# reset improper values\nself.__ffmpeg_prefixes = []\nelse:\n# also pass valid ffmpeg pre-headers to Sourcer API\nsourcer_params[\"-ffprefixes\"] = self.__ffmpeg_prefixes\n# pass parameter(if specified) to Sourcer API, specifying where to save the downloaded FFmpeg Static\n# assets on Windows(if specified)\nsourcer_params[\"-ffmpeg_download_path\"] = self.__extra_params.pop(\n\"-ffmpeg_download_path\", \"\"\n)\n# handle video and audio stream indexes in case of multiple ones.\ndefault_stream_indexes = self.__extra_params.pop(\n\"-default_stream_indexes\", (0, 0)\n)\n# reset improper values\ndefault_stream_indexes = (\n(0, 0)\nif not isinstance(default_stream_indexes, (list, tuple))\nelse default_stream_indexes\n)\n# pass FFmpeg filter to Sourcer API params for processing\nif set([\"-vf\", \"-filter_complex\"]).intersection(self.__extra_params.keys()):\nkey = \"-vf\" if \"-vf\" in self.__extra_params else \"-filter_complex\"\nsourcer_params[key] = self.__extra_params[key]\n# define dict to store user-defined parameters\nself.__user_metadata = {}\n# extract and assign source metadata as dict\n(self.__sourcer_metadata, self.__missing_prop) = (\nSourcer(\nsource=source,\nsource_demuxer=source_demuxer,\nverbose=verbose,\ncustom_ffmpeg=custom_ffmpeg if isinstance(custom_ffmpeg, str) else \"\",\n**sourcer_params\n)\n.probe_stream(default_stream_indexes=default_stream_indexes)\n.retrieve_metadata(force_retrieve_missing=True)\n)\n# handle valid FFmpeg assets location\nself.__ffmpeg = self.__sourcer_metadata[\"ffmpeg_binary_path\"]\n# handle YUV pixel formats(such as `yuv420p`, `yuv444p`, `nv12`, `nv21` etc.)\n# patch for compatibility with OpenCV APIs.\nself.__cv_patch = self.__extra_params.pop(\"-enforce_cv_patch\", False)\nif not (isinstance(self.__cv_patch, bool)):\nself.__cv_patch = False\nself.__verbose_logs and logger.critical(\n\"Enforcing OpenCV compatibility patch for YUV/NV frames.\"\n)\n# handle pass-through audio mode works in conjunction with WriteGear [TODO]\nself.__passthrough_mode = self.__extra_params.pop(\"-passthrough_audio\", False)\nif not (isinstance(self.__passthrough_mode, bool)):\nself.__passthrough_mode = False\n# handle mode of operation\nif self.__sourcer_metadata[\"source_has_image_sequence\"]:\n# image-sequence mode\nself.__opmode = \"imgseq\"\nelif (\nself.__sourcer_metadata[\n\"source_has_video\"\n]  # audio is only for pass-through, not really for audio decoding yet.\nand self.__sourcer_metadata[\"source_has_audio\"]\nand self.__passthrough_mode  # [TODO]\n):\nself.__opmode = \"av\"\n# elif __defop_mode == \"ao\" and self.__sourcer_metadata.contains_audio: # [TODO]\n#    self.__opmode = \"ao\"\nelif self.__sourcer_metadata[\"source_has_video\"]:\n# video-only mode\nself.__opmode = \"vo\"\nelse:\n# raise if unknown mode\nraise ValueError(\n\"Unable to find any usable video stream in the given source!\"\n)\n# store as metadata\nself.__missing_prop[\"ffdecoder_operational_mode\"] = self.__supported_opmodes[\nself.__opmode\n]\n# handle user-defined output framerate\n__framerate = self.__extra_params.pop(\"-framerate\", None)\nif (\nisinstance(__framerate, str)\nand __framerate\n== \"null\"  # special mode to discard `-framerate/-r` parameter\n):\nself.__inputframerate = __framerate\nelif isinstance(__framerate, (float, int)):\nself.__inputframerate = float(__framerate) if __framerate &gt; 0.0 else 0.0\nelse:\n# warn if wrong type\nnot (__framerate is None) and logger.warning(\n\"Discarding invalid `-framerate` value of wrong type `{}`!\".format(\ntype(__framerate).__name__\n)\n)\n# reset to default\nself.__inputframerate = 0.0\n# handle user defined decoded frame resolution\nself.__custom_resolution = self.__extra_params.pop(\"-custom_resolution\", None)\nif (\nisinstance(self.__custom_resolution, str)\nand self.__custom_resolution\n== \"null\"  # special mode to discard `-size/-s` parameter\n) or (\nisinstance(self.__custom_resolution, (list, tuple))\nand len(self.__custom_resolution)\n== 2  # valid resolution(must be a tuple or list)\n):\n# log it\nself.__verbose_logs and not isinstance(\nself.__custom_resolution, str\n) and logger.debug(\n\"Setting raw frames size: `{}`.\".format(self.__custom_resolution)\n)\nelse:\n# log it\nnot (self.__custom_resolution is None) and logger.warning(\n\"Discarding invalid `-custom_resolution` value: `{}`!\".format(\nself.__custom_resolution\n)\n)\n# reset improper values\nself.__custom_resolution = None\n</code></pre>"},{"location":"reference/ffdecoder/#deffcode.ffdecoder.FFdecoder.formulate","title":"<code>formulate(self)</code>","text":"<p>This method formulates all necessary FFmpeg pipeline arguments and executes it inside the FFmpeg <code>subprocess</code> pipe.</p> <p>Returns: A reference to the FFdecoder class object.</p> Source code in <code>deffcode/ffdecoder.py</code> <pre><code>def formulate(self):\n\"\"\"\n    This method formulates all necessary FFmpeg pipeline arguments and executes it inside the FFmpeg `subprocess` pipe.\n    **Returns:** A reference to the FFdecoder class object.\n    \"\"\"\n# assign values to class variables on first run\nif self.__initializing:\n# prepare parameter dict\ninput_params = OrderedDict()\noutput_params = OrderedDict()\n# dynamically pre-assign a default video-decoder (if not assigned by user).\nsupported_vdecodecs = get_supported_vdecoders(self.__ffmpeg)\ndefault_vdecodec = (\nself.__sourcer_metadata[\"source_video_decoder\"]\nif self.__sourcer_metadata[\"source_video_decoder\"]\nin supported_vdecodecs\nelse \"unknown\"\n)\nif \"-c:v\" in self.__extra_params:\nself.__extra_params[\"-vcodec\"] = self.__extra_params.pop(\n\"-c:v\", default_vdecodec\n)\n# handle image sequence separately\nif self.__opmode == \"imgseq\":\n# -vcodec is discarded by default\n# (This is correct or maybe -vcodec required in some unknown case) [TODO]\nself.__extra_params.pop(\"-vcodec\", None)\nelif (\n\"-vcodec\" in self.__extra_params\nand self.__extra_params[\"-vcodec\"] is None\n):\n# special case when -vcodec is not needed intentionally\nself.__extra_params.pop(\"-vcodec\", None)\nelse:\n# assign video decoder selected here.\nif not \"-vcodec\" in self.__extra_params:\ninput_params[\"-vcodec\"] = default_vdecodec\nelse:\ninput_params[\"-vcodec\"] = self.__extra_params.pop(\n\"-vcodec\", default_vdecodec\n)\nif (\ndefault_vdecodec != \"unknown\"\nand not input_params[\"-vcodec\"] in supported_vdecodecs\n):\n# reset to default if not supported\nlogger.warning(\n\"Provided FFmpeg does not support `{}` video decoder. Switching to default supported `{}` decoder!\".format(\ninput_params[\"-vcodec\"], default_vdecodec\n)\n)\ninput_params[\"-vcodec\"] = default_vdecodec\n# raise error if not valid decoder found\nif not input_params[\"-vcodec\"] in supported_vdecodecs:\nraise RuntimeError(\n\"Provided FFmpeg does not support any known usable video-decoders.\"\n\" Either define your own manually or switch to another FFmpeg binaries(if available).\"\n)\n# handle user-defined number of frames.\nif \"-vframes\" in self.__extra_params:\nself.__extra_params[\"-frames:v\"] = self.__extra_params.pop(\n\"-vframes\", None\n)\nif \"-frames:v\" in self.__extra_params:\nvalue = self.__extra_params.pop(\"-frames:v\", None)\nif not (value is None) and value &gt; 0:\noutput_params[\"-frames:v\"] = value\n# dynamically calculate default raw-frames pixel format(if not assigned by user).\n# notify FFmpeg `-pix_fmt` parameter cannot be assigned directly\nif \"-pix_fmt\" in self.__extra_params:\nlogger.warning(\n\"Discarding user-defined `-pix_fmt` value as it can only be assigned with `frame_format` parameter!\"\n)\nself.__extra_params.pop(\"-pix_fmt\", None)\n# get supported FFmpeg pixfmt data with depth and bpp(bits-per-pixel)\nself.__ff_pixfmt_metadata = get_supported_pixfmts(self.__ffmpeg)\nsupported_pixfmts = [fmts[0] for fmts in self.__ff_pixfmt_metadata]\n# calculate default pixel-format\n# Check special case  - `frame_format`(or `-pix_fmt`) parameter discarded from pipeline\nself.__frame_format == \"null\" and logger.critical(\n\"Manually discarding `frame_format`(or `-pix_fmt`) parameter from this pipeline.\"\n)\n# choose between rgb24(if available) or source pixel-format\n# otherwise, only source pixel-format for special case\ndefault_pixfmt = (\n\"rgb24\"\nif \"rgb24\" in supported_pixfmts and self.__frame_format != \"null\"\nelse self.__sourcer_metadata[\"source_video_pixfmt\"]\n)\n# assign output raw-frames pixel format\nrawframe_pixfmt = None\nif (\nnot (self.__frame_format is None)\nand self.__frame_format in supported_pixfmts\n):\n# check if valid and supported `frame_format` parameter assigned\nrawframe_pixfmt = self.__frame_format.strip()\nself.__verbose_logs and logger.info(\n\"User-defined `{}` frame pixel-format will be used for this pipeline.\".format(\nrawframe_pixfmt\n)\n)\nelif (\n\"output_frames_pixfmt\"\nin self.__sourcer_metadata  # means `format` filter is defined\nand self.__sourcer_metadata[\"output_frames_pixfmt\"] in supported_pixfmts\n):\n# assign if valid and supported\nrawframe_pixfmt = self.__sourcer_metadata[\n\"output_frames_pixfmt\"\n].strip()\nself.__verbose_logs and logger.info(\n\"FFmpeg filter values will be used for this pipeline for defining output pixel-format.\"\n)\nelse:\n# reset to default if not supported\nrawframe_pixfmt = default_pixfmt\n# log it accordingly\nif self.__frame_format is None:\nlogger.info(\n\"Using default `{}` pixel-format for this pipeline.\".format(\ndefault_pixfmt\n)\n)\nelse:\nlogger.warning(\n\"{} Switching to default `{}` pixel-format!\".format(\n\"Provided FFmpeg does not supports `{}` pixel-format.\".format(\nself.__sourcer_metadata[\"output_frames_pixfmt\"]\nif \"output_frames_pixfmt\" in self.__sourcer_metadata\nelse self.__frame_format\n)\nif self.__frame_format != \"null\"\nelse \"No usable pixel-format defined.\",\ndefault_pixfmt,\n)\n)\n# dynamically calculate raw-frame datatype based on pixel-format selected\n(self.__raw_frame_depth, rawframesbpp) = [\n(int(x[1]), int(x[2]))\nfor x in self.__ff_pixfmt_metadata\nif x[0] == rawframe_pixfmt\n][0]\nraw_bit_per_component = (\nrawframesbpp // self.__raw_frame_depth if self.__raw_frame_depth else 0\n)\nif 4 &lt;= raw_bit_per_component &lt;= 8:\nself.__raw_frame_dtype = np.dtype(\"u1\")\nelif 8 &lt; raw_bit_per_component &lt;= 16 and rawframe_pixfmt.endswith(\n(\"le\", \"be\")\n):\nif rawframe_pixfmt.endswith(\"le\"):\nself.__raw_frame_dtype = np.dtype(\"&lt;u2\")\nelse:\nself.__raw_frame_dtype = np.dtype(\"&gt;u2\")\nelse:\n# reset to both pixel-format and datatype to default if not supported\nnot (self.__frame_format is None) and logger.warning(\n\"Selected pixel-format `{}` dtype is not supported by FFdecoder API. Switching to default `rgb24` pixel-format!\".format(\nrawframe_pixfmt\n)\n)\nrawframe_pixfmt = \"rgb24\"\nself.__raw_frame_dtype = np.dtype(\"u1\")\n# Check if not special case\nif self.__frame_format != \"null\":\n# assign to FFmpeg pipeline otherwise\noutput_params[\"-pix_fmt\"] = rawframe_pixfmt\n# assign to global parameter further usage\nself.__raw_frame_pixfmt = rawframe_pixfmt\n# also override as metadata(if available)\nif \"output_frames_pixfmt\" in self.__sourcer_metadata:\nself.__sourcer_metadata[\n\"output_frames_pixfmt\"\n] = self.__raw_frame_pixfmt\n# handle raw-frame resolution\n# notify FFmpeg `-s` parameter cannot be assigned directly\nif \"-s\" in self.__extra_params:\nlogger.warning(\n\"Discarding user-defined `-s` FFmpeg parameter as it can only be assigned with `-custom_resolution` attribute! Read docs for more details.\"\n)\nself.__extra_params.pop(\"-s\", None)\n# assign output rawframe resolution\nif not (self.__custom_resolution is None) and not isinstance(\nself.__custom_resolution, str\n):\n# assign if assigned by user and not \"null\"(str)\nself.__raw_frame_resolution = self.__custom_resolution\nself.__verbose_logs and logger.info(\n\"User-defined `{}` frame resolution will be used for this pipeline.\".format(\nself.__raw_frame_resolution\n)\n)\nelif (\n\"output_frames_resolution\"\nin self.__sourcer_metadata  # means `scale` filter is defined\nand self.__sourcer_metadata[\"output_frames_resolution\"]\nand len(self.__sourcer_metadata[\"output_frames_resolution\"]) == 2\n):\n# calculate raw-frame resolution/dimensions based on output.\nself.__raw_frame_resolution = self.__sourcer_metadata[\n\"output_frames_resolution\"\n]\nelif (\nself.__sourcer_metadata[\"source_video_resolution\"]\nand len(self.__sourcer_metadata[\"source_video_resolution\"]) == 2\n):\n# calculate raw-frame resolution/dimensions based on source.\nself.__raw_frame_resolution = self.__sourcer_metadata[\n\"source_video_resolution\"\n]\nelse:\n# otherwise raise error\nraise RuntimeError(\n\"Both source and output metadata values found Invalid with {} `-custom_resolution` attribute. Aborting!\".format(\n\"null\"\nif isinstance(self.__inputframerate, str)\nelse \"undefined\"\n)\n)\n# special mode to discard `-size/-s` FFmpeg parameter completely\nif isinstance(self.__custom_resolution, str):\nlogger.critical(\n\"Manually discarding `-size/-s` FFmpeg parameter from this pipeline.\"\n)\nelse:\n# add to pipeline\ndimensions = \"{}x{}\".format(\nself.__raw_frame_resolution[0], self.__raw_frame_resolution[1]\n)\noutput_params[\"-s\"] = str(dimensions)\n# log if filters or default source is used\nself.__verbose_logs and (\nself.__custom_resolution is None\nor isinstance(self.__custom_resolution, str)\n) and logger.info(\n\"{} for this pipeline for defining output resolution.\".format(\n\"FFmpeg filter values will be used\"\nif \"output_frames_resolution\" in self.__sourcer_metadata\nelse \"Default source resolution will be used\"\n)\n)\n# dynamically calculate raw-frame framerate based on source (if not assigned by user).\nif (\nnot isinstance(self.__inputframerate, str)\nand self.__inputframerate &gt; 0.0\n):\n# assign if assigned by user and not \"null\"(str)\noutput_params[\"-framerate\"] = str(self.__inputframerate)\nself.__verbose_logs and logger.info(\n\"User-defined `{}` output framerate will be used for this pipeline.\".format(\nstr(self.__inputframerate)\n)\n)\nelif (\n\"output_framerate\"\nin self.__sourcer_metadata  # means `fps` filter is defined\nand self.__sourcer_metadata[\"output_framerate\"] &gt; 0.0\n):\n# special mode to discard `-framerate/-r` FFmpeg parameter completely\nif self.__inputframerate == \"null\":\nlogger.critical(\n\"Manually discarding `-framerate/-r` FFmpeg parameter from this pipeline.\"\n)\nelse:\n# calculate raw-frame framerate based on output\noutput_params[\"-framerate\"] = str(\nself.__sourcer_metadata[\"output_framerate\"]\n)\nself.__verbose_logs and logger.info(\n\"FFmpeg filter values will be used for this pipeline for defining output framerate.\"\n)\nelif self.__sourcer_metadata[\"source_video_framerate\"] &gt; 0.0:\n# special mode to discard `-framerate/-r` FFmpeg parameter completely\nif self.__inputframerate == \"null\":\nlogger.critical(\n\"Manually disabling `-framerate/-r` FFmpeg parameter for this pipeline.\"\n)\nelse:\n# calculate raw-frame framerate based on source\noutput_params[\"-framerate\"] = str(\nself.__sourcer_metadata[\"source_video_framerate\"]\n)\nself.__verbose_logs and logger.info(\n\"Default source framerate will be used for this pipeline for defining output framerate.\"\n)\nelse:\n# otherwise raise error\nraise RuntimeError(\n\"Both source and output metadata values found Invalid with {} `-framerate` attribute. Aborting!\".format(\n\"null\"\nif isinstance(self.__inputframerate, str)\nelse \"undefined\"\n)\n)\n# add rest to output parameters\noutput_params.update(self.__extra_params)\n# dynamically calculate raw-frame numbers based on source (if not assigned by user).\n# TODO Added support for `-re -stream_loop` and `-loop`\nif \"-frames:v\" in input_params:\nself.__raw_frame_num = input_params[\"-frames:v\"]\nelif (\nnot (self.__sourcer_metadata[\"approx_video_nframes\"] is None)\nand self.__sourcer_metadata[\"approx_video_nframes\"] &gt; 0\n):\nself.__raw_frame_num = self.__sourcer_metadata[\"approx_video_nframes\"]\nelse:\nself.__raw_frame_num = None\n# log that number of frames are unknown\nself.__verbose_logs and logger.info(\n\"Live/Network Stream detected! Number of frames in given source are not known.\"\n)\n# log Mode of Operation\nself.__verbose_logs and logger.critical(\n\"Activating {} Mode of Operation.\".format(\nself.__supported_opmodes[self.__opmode]\n)\n)\n# compose the Pipeline using formulated FFmpeg parameters\nself.__launch_FFdecoderline(input_params, output_params)\n# inform the initialization is completed\nself.__initializing = False\nelse:\n# warn if pipeline is recreated\nlogger.error(\"This pipeline is already created and running!\")\nreturn self\n</code></pre>"},{"location":"reference/ffdecoder/#deffcode.ffdecoder.FFdecoder.generateFrame","title":"<code>generateFrame(self)</code>","text":"<p>This method returns a Generator function (also an Iterator using <code>next()</code>) of video frames, grabbed continuously from the buffer.</p> Source code in <code>deffcode/ffdecoder.py</code> <pre><code>def generateFrame(self):\n\"\"\"\n    This method returns a [Generator function](https://wiki.python.org/moin/Generators)\n    _(also an Iterator using `next()`)_ of video frames, grabbed continuously from the buffer.\n    \"\"\"\nif self.__raw_frame_num is None or not self.__raw_frame_num:\nwhile not self.__terminate_stream:  # infinite raw frames\nframe = self.__fetchNextFrame()\nif frame is None:\nself.__terminate_stream = True\nbreak\nyield frame\nelse:\nfor _ in range(self.__raw_frame_num):  # finite raw frames\nframe = self.__fetchNextFrame()\nif frame is None:\nself.__terminate_stream = True\nbreak\nyield frame\n</code></pre>"},{"location":"reference/ffdecoder/#deffcode.ffdecoder.FFdecoder.terminate","title":"<code>terminate(self)</code>","text":"<p>Safely terminates all processes.</p> Source code in <code>deffcode/ffdecoder.py</code> <pre><code>def terminate(self):\n\"\"\"\n    Safely terminates all processes.\n    \"\"\"\n# signal we are closing\nself.__verbose_logs and logger.debug(\"Terminating FFdecoder Pipeline...\")\nself.__terminate_stream = True\n# check if no process was initiated at first place\nif self.__process is None or not (self.__process.poll() is None):\nlogger.info(\"Pipeline already terminated.\")\nreturn\n# Attempt to close pipeline.\n# close `stdin` output\nself.__process.stdin and self.__process.stdin.close()\n# close `stdout` output\nself.__process.stdout and self.__process.stdout.close()\n# terminate/kill process if still processing\nif self.__process.poll() is None:\n# demuxers prefer kill\nself.__process.kill()\n# wait if not exiting\nself.__process.wait()\nself.__process = None\nlogger.info(\"Pipeline terminated successfully.\")\n</code></pre>"},{"location":"reference/ffdecoder/params/","title":"FFdecoder API Parameters","text":""},{"location":"reference/ffdecoder/params/#source","title":"<code>source</code>","text":"<p>This parameter defines the input source (<code>-i</code>) for decoding real-time frames.</p> <p>FFdecoder API will throw <code>Assertion</code> if <code>source</code> provided is invalid or missing.</p> <p>FFdecoder API checks for <code>video bitrate</code> or <code>frame-size</code> and <code>framerate</code> in video's metadata to ensure given input <code>source</code> has usable video stream available. Thereby, it will throw <code>ValueError</code> if it fails to find those parameters.</p> <p>Multiple video inputs are not yet supported!</p> <p>Data-Type: String.</p> <p>Its valid input can be one of the following: </p> <ul> <li> <p> Filepath: Valid path of the video file, for e.g <code>\"/home/foo.mp4\"</code> as follows:</p> <pre><code># initialize and formulate the decoder with `foo.mp4` source\ndecoder = FFdecoder('/home/foo.mp4').formulate()\n</code></pre> <p>Related usage recipes  can found here \u27b6</p> </li> <li> <p> Image Sequence: Valid image sequence such as sequential(<code>'img%03d.png'</code>) or glob pattern(<code>'*.png'</code>) or single (looping) image as input:</p> SequentialGlob patternSingle (loop) image How to start with specific number image? <p>You can use <code>-start_number</code> FFmpeg parameter if you want to start with specific number image:</p> <pre><code># define `-start_number` such as `5`\nffparams = {\"-ffprefixes\":[\"-start_number\", \"5\"]}\n# initialize and formulate the decoder with define parameters\ndecoder = FFdecoder('img%03d.png', verbose=True, **ffparams).formulate()\n</code></pre> <pre><code># initialize and formulate the decoder\ndecoder = FFdecoder('img%03d.png').formulate()\n</code></pre> <p>Bash-style globbing (<code>*</code> represents any number of any characters) is useful if your images are sequential but not necessarily in a numerically sequential order.</p> <p>The glob pattern is not available on Windows builds.</p> <pre><code># define `-pattern_type glob` for accepting glob pattern\nsourcer_params = {\"-ffprefixes\":[\"-pattern_type\", \"glob\"]}\n# initialize and formulate the decoder with define parameters\ndecoder = FFdecoder('img*.png', verbose=True, **sourcer_params).formulate()\n</code></pre> <pre><code># define `-loop 1` for looping\nffparams = {\"-ffprefixes\":[\"-loop\", \"1\"]}\n# initialize and formulate the decoder with define parameters\ndecoder = FFdecoder('img.jpg', verbose=True, **ffparams).formulate()\n</code></pre> <p>Related usage recipes  can found here \u27b6</p> </li> <li> <p> Network Address: Valid (<code>http(s)</code>, <code>rtp</code>, <code>rstp</code>, <code>rtmp</code>, <code>mms</code>, etc.) incoming network stream address such as <code>'rtsp://xx:yy@192.168.1.ee:fd/av0_0'</code> as input:</p> <pre><code># define `rtsp_transport` or necessary parameters \nffparams = {\"-ffprefixes\":[\"-rtsp_transport\", \"tcp\"]}\n# initialize and formulate the decoder with define parameters\ndecoder = FFdecoder('rtsp://xx:yy@192.168.1.ee:fd/av0_0', verbose=True, **ffparams).formulate()\n</code></pre> <p>Related usage recipes  can found here \u27b6</p> </li> <li> <p> Camera Device Index: Valid \"device index\" or \"camera index\" of the connected Camera Device. One can easily Capture desired Camera Device in FFdecoder API by specifying its matching index value (use Sourcer API's <code>enumerate_devices</code> to list them) either as integer or string of integer type to its <code>source</code> parameter. For example, for capturing <code>\"0\"</code> index device on  Windows, we can do as follows in FFdecoder API: </p> Requirement for Index based Camera Device Capturing in FFdecoder API <ul> <li> <p> MUST have appropriate FFmpeg binaries, Drivers, and Softwares installed:</p> <p>Internally, DeFFcode APIs achieves Index based Camera Device Capturing by employing some specific FFmpeg demuxers on different platforms(OSes). These platform specific demuxers are as follows:</p> Platform(OS) Demuxer  Windows OS <code>dshow</code> (or DirectShow)  Linux OS <code>video4linux2</code> (or its alias <code>v4l2</code>)  Mac OS <code>avfoundation</code> <p> Important: Kindly make sure your FFmpeg binaries support these platform specific demuxers as well as system have the appropriate video drivers and related softwares installed.</p> </li> <li> <p> The <code>source</code> parameter value MUST be exactly the probed Camera Device index (use Sourcer API's <code>enumerate_devices</code> to list them).</p> </li> <li> The <code>source_demuxer</code> parameter value  MUST be either <code>None</code>(also means empty) or <code>\"auto\"</code>. </li> </ul> Important Facts related to Camera Device Indexing <ul> <li> Camera Device indexes are 0-indexed. So the first device is at <code>0</code>, second is at <code>1</code>, so on. So if the there are <code>n</code> devices, the last device is at <code>n-1</code>.</li> <li> Camera Device indexes can be of either integer (e.g. <code>0</code>,<code>1</code>, etc.) or string of integer (e.g. <code>\"0\"</code>,<code>\"1\"</code>, etc.) type.</li> <li> Camera Device indexes can be negative (e.g. <code>-1</code>,<code>-2</code>, etc.), this means you can also start indexing from the end.<ul> <li>For example, If there are three devices:      <pre><code>{0: 'Integrated Camera', 1: 'USB2.0 Camera', 2: 'DroidCam Source'}\n</code></pre></li> <li> <p>Then, You can specify Positive Indexes and its Equivalent Negative Indexes as follows:</p> Positive Indexes Equivalent Negative Indexes <code>FFdecoder(\"0\").formulate()</code> <code>FFdecoder(\"-3\").formulate()</code> <code>FFdecoder(\"1\").formulate()</code> <code>FFdecoder(\"-2\").formulate()</code> <code>FFdecoder(\"2\").formulate()</code> <code>FFdecoder(\"-1\").formulate()</code> </li> </ul> </li> </ul> <p>Out of Index Camera Device index values will raise <code>ValueError</code> in FFdecoder API</p> <pre><code># initialize and formulate the decoder with \"0\" index source for BGR24 output\ndecoder = FFdecoder(\"0\", frame_format=\"bgr24\", verbose=True).formulate()\n</code></pre> <p>Related usage recipes  can found here \u27b6</p> </li> <li> <p> Video Capture Device Name/Path: Valid video capture device's name (e.g. <code>\"USB2.0 Camera\"</code>) or its path (e.g. <code>\"/dev/video0\"</code> on linux) or its index (e.g. <code>\"0\"</code>) as input  w.r.t <code>source_demuxer</code> parameter value in use. For example, for capturing <code>\"USB2.0 Camera\"</code> named device with <code>dshow</code> source demuxer on  Windows, we can do as follows in FFdecoder API: </p> Identifying and Specifying Device name/path/index and suitable Demuxer on different OSes  Windows Linux MacOS <p>Windows OS users can use the dshow (DirectShow) to list video input device which is the preferred option for Windows users. You can refer following steps to identify and specify your input video device's name:</p> <ul> <li> <p> Identify Video Devices: You can locate your video device's name (already connected to your system) using <code>dshow</code> as follows:</p> <pre><code>c:\\&gt; ffmpeg.exe -list_devices true -f dshow -i dummy\n\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[dshow @ 03ACF580] DirectShow video devices\n[dshow @ 03ACF580]  \"Integrated Camera\"\n[dshow @ 03ACF580]  \"USB2.0 Camera\"\n[dshow @ 03ACF580] DirectShow audio devices\n[dshow @ 03ACF580]  \"Microphone (Realtek High Definition Audio)\"\n[dshow @ 03ACF580]  \"Microphone (USB2.0 Camera)\"\ndummy: Immediate exit requested\n</code></pre> </li> <li> <p> Specify Video Device's name: Then, you can specify and initialize your located Video device's name in FFdecoder API as follows:</p> <pre><code># initialize and formulate the decoder with \"USB2.0 Camera\" source for BGR24 output\ndecoder = FFdecoder(\"USB2.0 Camera\", source_demuxer=\"dshow\", frame_format=\"bgr24\", verbose=True).formulate()\n</code></pre> </li> <li> <p> [OPTIONAL] Specify Video Device's index along with name: If there are multiple Video devices with similar name, then you can use <code>-video_device_number</code> parameter to specify the arbitrary index of the particular device. For instance, to open second video device with name <code>\"Camera\"</code> you can do as follows:</p> <pre><code># define video_device_number as 1 (numbering start from 0)\nffparams = {\"-ffprefixes\":[\"-video_device_number\", \"1\"]}\n# initialize and formulate the decoder with \"Camera\" source for BGR24 output\ndecoder = FFdecoder(\"Camera\", source_demuxer=\"dshow\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n</code></pre> </li> </ul> <p>Linux OS users can use the <code>video4linux2</code> (or its alias <code>v4l2</code>) to list to all capture video devices such as from an USB webcam. You can refer following steps to identify and specify your capture video device's path:</p> <ul> <li> <p> Identify Video Devices: Linux systems tend to automatically create file device node/path when the device (e.g. an USB webcam) is plugged into the system, and has a name of the kind <code>'/dev/videoN'</code>, where <code>N</code> is a index associated to the device. To get the list of all available file device node/path on your Linux machine, you can use the <code>v4l-ctl</code> command.</p> <p>You can use <code>sudo apt install v4l-utils</code> APT command to install <code>v4l-ctl</code> tool on Debian-based Linux distros.</p> <pre><code>$ v4l2-ctl --list-devices\n\nUSB2.0 PC CAMERA (usb-0000:00:1d.7-1):\n        /dev/video1\n\nUVC Camera (046d:0819) (usb-0000:00:1d.7-2):\n        /dev/video0\n</code></pre> </li> <li> <p> Specify Video Device's path: Then, you can specify and initialize your located Video device's path in FFdecoder API as follows:</p> <pre><code># initialize and formulate the decoder with \"/dev/video0\" source for BGR24 output\ndecoder = FFdecoder(\"/dev/video0\", source_demuxer=\"v4l2\", frame_format=\"bgr24\", verbose=True).formulate()\n</code></pre> </li> <li> <p> [OPTIONAL] Specify Video Device's additional specifications: You can also specify additional specifications (such as pixel format(s), video format(s), framerate, and frame dimensions) supported by your Video Device as follows:</p> <p>You can use <code>ffmpeg -f v4l2 -list_formats all -i /dev/video0</code> terminal command to list available specifications.</p> <pre><code># define video device specifications\nffparams = {\"-ffprefixes\":[\"-framerate\", \"25\", \"-video_size\", \"640x480\"]}\n# initialize and formulate the decoder with \"/dev/video0\" source for BGR24 output\ndecoder = FFdecoder(\"/dev/video0\", source_demuxer=\"v4l2\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n</code></pre> </li> </ul> <p>MacOS users can use the AVFoundation to list input devices and is the currently recommended framework by Apple for streamgrabbing on Mac OSX-10.7 (Lion) and later as well as on iOS. You can refer following steps to identify and specify your capture video device's name or index on MacOS/OSX machines:</p> <p>QTKit is also available for streamgrabbing on Mac OS X 10.4 (Tiger) and later, but has been marked deprecated since OS X 10.7 (Lion) and may not be available on future releases.</p> <ul> <li> <p> Identify Video Devices: Then, You can locate your Video device's name and index using <code>avfoundation</code> as follows:</p> <pre><code>$ ffmpeg -f avfoundation -list_devices true -i \"\"\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation video devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] FaceTime HD camera (built-in)\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Capture screen 0\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation audio devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] Blackmagic Audio\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Built-in Microphone\n</code></pre> </li> <li> <p> Specify Video Device's name or index: Then, you can specify and initialize your located Video device in FFdecoder API using its either the name or the index shown in the device listing:</p> Using device's indexUsing device's name <pre><code># initialize and formulate the decoder with `1` index source for BGR24 output\ndecoder = FFdecoder(\"1\", source_demuxer=\"avfoundation\", frame_format=\"bgr24\", verbose=True).formulate()\n</code></pre> <p>When specifying device's name, abbreviations using just the beginning of the device name are possible. Thus, to capture from a device named \"Integrated iSight-camera\" just \"Integrated\" is sufficient:</p> <pre><code># initialize and formulate the decoder with \"Integrated iSight-camera\" source for BGR24 output\ndecoder = FFdecoder(\"Integrated\", source_demuxer=\"avfoundation\", frame_format=\"bgr24\", verbose=True).formulate()\n</code></pre> </li> <li> <p> [OPTIONAL] Specify Default Video device: You can also use the default device which is usually the first device in the listing by using \"default\" as source:</p> <pre><code># initialize and formulate the decoder with \"default\" source for BGR24 output\ndecoder = FFdecoder(\"default\", source_demuxer=\"avfoundation\", frame_format=\"bgr24\", verbose=True).formulate()\n</code></pre> </li> </ul> <p>If these steps doesn't work for you then reach us out on Gitter \u27b6 Community channel</p> <pre><code># initialize and formulate the decoder with \"USB2.0 Camera\" source for BGR24 output\ndecoder = FFdecoder(\"USB2.0 Camera\", source_demuxer=\"dshow\", frame_format=\"bgr24\", verbose=True).formulate()\n</code></pre> <p>Related usage recipe  can found here \u27b6</p> </li> <li> <p> Screen Capturing/Recording: Valid screen capture device's name (e.g. <code>\"desktop\"</code>) or its index (e.g. <code>\":0.0\"</code>) as input w.r.t <code>source_demuxer</code> parameter value in use. You can also specify additional specifications (such as limiting capture area to a region, setting capturing coordinates, whether to capture mouse pointer and clicks etc.). For example, for capturing <code>\"0:\"</code> indexed device with <code>avfoundation</code> source demuxer on  MacOS along with mouse pointer and clicks, we can do as follows in FFdecoder API: </p> Specifying suitable Parameter(s) and Demuxer for Capturing your Desktop on different OSes  Windows Linux MacOS <p>Windows OS users can use the gdigrab to grab video from the Windows screen. You can refer following steps to specify source for capturing different regions of your display:</p> <p>For Windows OS users <code>dshow</code> is also available for grabbing frames from your desktop. But it is highly unreliable and don't works most of the times.</p> <ul> <li> <p> Capturing entire desktop: For capturing all your displays as one big contiguous display, you can specify source, suitable parameters and demuxers in FFdecoder API as follows:</p> <pre><code># define framerate\nffparams = {\"-framerate\": \"30\"}\n# initialize and formulate the decoder with \"desktop\" source for BGR24 output\ndecoder = FFdecoder(\"desktop\", source_demuxer=\"gdigrab\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n</code></pre> </li> <li> <p> Capturing a region: If you want to limit capturing to a region, and show the area being grabbed, you can specify source and suitable parameters in FFdecoder API as follows:</p> <p><code>x_offset</code> and <code>y_offset</code> specify the offsets of the grabbed area with respect to the top-left border of the desktop screen. They default to <code>0</code>. </p> <pre><code># define suitable parameters\nffparams = {\n\"-framerate\": \"30\", # input framerate\n\"-ffprefixes\": [\n\"-offset_x\", \"10\", \"-offset_y\", \"20\", # grab at position 10,20\n\"-video_size\", \"640x480\", # frame size\n\"-show_region\", \"1\", # show only region\n],\n}\n# initialize and formulate the decoder with \"desktop\" source for BGR24 output\ndecoder = FFdecoder(\"desktop\", source_demuxer=\"gdigrab\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n</code></pre> </li> </ul> <p>Linux OS users can use the x11grab to capture an X11 display. You can refer following steps to specify source for capturing different regions of your display:</p> <p>For X11 display, the source input has the syntax: <code>\"display_number.screen_number[+x_offset,y_offset]\"</code>.</p> <ul> <li> <p> Capturing entire desktop: For capturing all your displays as one big contiguous display, you can specify source, suitable parameters and demuxers in FFdecoder API as follows:</p> <pre><code># define framerate\nffparams = {\"-framerate\": \"30\"}\n# initialize and formulate the decoder with \":0.0\" desktop source for BGR24 output\ndecoder = FFdecoder(\":0.0\", source_demuxer=\"x11grab\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n</code></pre> </li> <li> <p> Capturing a region: If you want to limit capturing to a region, and show the area being grabbed, you can specify source and suitable parameters in FFdecoder API as follows:</p> <p><code>x_offset</code> and <code>y_offset</code> specify the offsets of the grabbed area with respect to the top-left border of the X11 screen. They default to <code>0</code>. </p> <pre><code># define suitable parameters\nffparams = {\n\"-framerate\": \"30\", # input framerate\n\"-ffprefixes\": [\n\"-video_size\", \"1024x768\", # frame size\n],\n}\n# initialize and formulate the decoder with \":0.0\" desktop source(starting with the upper-left corner at x=10, y=20) \n# for BGR24 output\ndecoder = FFdecoder(\":0.0+10,20\", source_demuxer=\"x11grab\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n</code></pre> </li> </ul> <p>MacOS users can use the AVFoundation to list input devices and is the currently recommended framework by Apple for stream capturing on Mac OSX-10.7 (Lion) and later as well as on iOS. You can refer following steps to identify and specify your capture video device's name or index on MacOS/OSX machines:</p> <p>QTKit is also available for stream capturing on Mac OS X 10.4 (Tiger) and later, but has been marked deprecated since OS X 10.7 (Lion) and may not be available on future releases.</p> <ul> <li> <p> Identify Video Devices:  You can enumerate all the available input devices including screens ready to be captured using <code>avfoundation</code> as follows:</p> <pre><code>$ ffmpeg -f avfoundation -list_devices true -i \"\"\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation video devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] FaceTime HD camera (built-in)\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Capture screen 0\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation audio devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] Blackmagic Audio\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Built-in Microphone\n</code></pre> </li> <li> <p> Capturing entire desktop: Then, you can specify and initialize your located screens in FFdecoder API using its index shown:</p> <pre><code># initialize and formulate the decoder with `0:` index desktop screen for BGR24 output\ndecoder = FFdecoder(\"0:\", source_demuxer=\"avfoundation\", frame_format=\"bgr24\", verbose=True).formulate()\n</code></pre> </li> <li> <p> [OPTIONAL] Capturing mouse: You can also specify additional specifications to capture the mouse pointer and screen mouse clicks as follows:</p> <pre><code># define specifications\nffparams = {\"-ffprefixes\":[\"-capture_cursor\", \"1\", \"-capture_mouse_clicks\", \"0\"]}\n# initialize and formulate the decoder with \"0:\" source for BGR24 output\ndecoder = FFdecoder(\"0:\", source_demuxer=\"avfoundation\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n</code></pre> </li> </ul> <p>If these steps doesn't work for you then reach us out on Gitter \u27b6 Community channel</p> <pre><code># define specifications\nffparams = {\"-ffprefixes\":[\"-capture_cursor\", \"1\", \"-capture_mouse_clicks\", \"0\"]}\n# initialize and formulate the decoder with \"0:\" source for BGR24 output\ndecoder = FFdecoder(\"0:\", source_demuxer=\"avfoundation\", frame_format=\"bgr24\", verbose=True, **ffparams).formulate()\n</code></pre> <p>Related usage recipe  can found here \u27b6</p> </li> <li> <p> Virtual Sources: Valid filtergraph to use as input with <code>lavfi</code> (Libavfilter input virtual device) source that reads data from the open output pads of a libavfilter filtergraph. For example, for generating and decoding Mandelbrot graph of <code>1280x720</code> frame size and <code>30</code> framerate using <code>lavfi</code> input virtual device, we can do as follows in FFdecoder API: </p> <pre><code># initialize and formulate the decoder with \"mandelbrot\" source of\n# `1280x720` frame size and `30` framerate for BGR24 output\ndecoder = FFdecoder(\n\"mandelbrot=size=1280x720:rate=30\",\nsource_demuxer=\"lavfi\",\nframe_format=\"bgr24\",\n).formulate()\n</code></pre> <p>Related usage recipes  can found here \u27b6</p> </li> </ul> <p> </p>"},{"location":"reference/ffdecoder/params/#source_demuxer","title":"<code>source_demuxer</code>","text":"<p>This parameter specifies the demuxer(<code>-f</code>) for the input source (such as <code>dshow</code>, <code>v4l2</code>, <code>gdigrab</code> etc.) to support Live Feed Devices, <code>lavfi</code> (Libavfilter input virtual device) that reads data from the open output pads of a libavfilter filtergraph, and  </p> <p>Any invalid or unsupported value to <code>source_demuxer</code> parameter value will raise <code>Assertion</code> error!</p> <p>Use <code>ffmpeg -demuxers</code> terminal command to lists all FFmpeg supported demuxers.</p> Specifying <code>source_demuxer</code> for Index based Camera Device Capturing in FFdecoder API <p>For enabling Index based Camera Device Capturing in FFdecoder API, the <code>source_demuxer</code> parameter value  MUST be either <code>None</code>(also means empty) or <code>\"auto\"</code>:</p> <code>source_demuxer=None</code> (Default and Recommended)<code>source_demuxer=\"auto\"</code> <pre><code># initialize and formulate the decoder with \"0\" index source for BGR24 output\ndecoder = FFdecoder(\"0\", frame_format=\"bgr24\").formulate()\n</code></pre> <pre><code># initialize and formulate the decoder with \"0\" index source for BGR24 output\ndecoder = FFdecoder(\"0\", source_demuxer=\"auto, frame_format=\"bgr24\").formulate()\n</code></pre> <p>Related usage recipes  can found here \u27b6</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>.</p> <p>Usage:</p> <pre><code># initialize and formulate the decoder with `dshow` demuxer\ndecoder = FFdecoder(\"foo.mp4\", source_demuxer=\"dshow\").formulate()\n</code></pre> <p> </p>"},{"location":"reference/ffdecoder/params/#frame_format","title":"<code>frame_format</code>","text":"<p>This parameter select the pixel format for output video frames (such as <code>gray</code> for grayscale output).</p> Any invalid or unsupported value to <code>frame_format</code> parameter will discarded! <p>Any improper <code>frame_format</code> parameter value (i.e. either <code>null</code>(special-case), undefined, or invalid type) , then <code>-pix_fmt</code> FFmpeg parameter value in Decoding pipeline uses <code>output_frames_pixfmt</code> metadata property extracted from Output Stream. Thereby, in case if no valid <code>output_frames_resolution</code>  metadata property is found, then API finally defaults to Default pixel-format1 (calculated variably).</p> Use <code>frame_format=\"null\"</code> to manually discard <code>-pix_fmt</code> FFmpeg parameter entirely from Decoding pipeline. <p>This feature allows users to manually skip <code>-pix_fmt</code> FFmpeg parameter in Decoding pipeline, essentially for using only <code>format</code> ffmpeg filter values instead, or even better let FFmpeg itself choose the best available output frame pixel-format for the given source.</p> <p>Data-Type: String</p> <p>Default Value: Its default value is Default pixel-format1 (calculated variably).</p> <p>Usage:</p> <pre><code># initialize and formulate the decoder for grayscale frames\ndecoder = FFdecoder(\"foo.mp4\", frame_format=\"gray\").formulate()\n</code></pre> <p>Use <code>ffmpeg -pix_fmts</code> terminal command to lists all FFmpeg supported pixel formats.</p> <p>Various Pixel formats related usage recipes  can found here \u27b6</p> <p> </p>"},{"location":"reference/ffdecoder/params/#custom_ffmpeg","title":"<code>custom_ffmpeg</code>","text":"<p>This parameter can be used to manually assigns the system file-path/directory where the custom or downloaded FFmpeg executable is located.</p> Behavior on Windows  <p>If custom FFmpeg executable binary file-path/directory is not assigned through <code>custom_ffmpeg</code> parameter on Windows machine, then FFdecoder API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine. More information can be found here \u27b6.</p> How to change FFmpeg Static Binaries download directory? <p>You can use <code>-ffmpeg_download_path</code> (via. <code>-custom_sourcer_params</code>) exclusive parameter in FFdecoder API to set the custom directory for downloading FFmpeg Static Binaries during the Auto-Installation step on Windows Machines. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. <code>C:/User/temp</code>) on your windows machine. It can be used as follows in FFdecoder API:</p> <pre><code># # define suitable parameter to download at \"C:/User/foo/foo1\"\nffparams = {\"-custom_sourcer_params\": {\"-ffmpeg_download_path\": \"C:/User/foo/foo1\"}}\n# initialize and formulate the decoder\nFFdecoder(\"foo.mp4\", verbose=True, **ffparams).formulate()\n</code></pre> <p>If binaries were not found at the manually specified path, DeFFcode APIs will throw RuntimeError!</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>.</p> <p>Usage:</p> <pre><code># If ffmpeg executables are located at \"/foo/foo1/ffmpeg\"\nFFdecoder(\"foo.mp4\", custom_ffmpeg=\"/foo/foo1/ffmpeg\").formulate()\n</code></pre> <p> </p>"},{"location":"reference/ffdecoder/params/#verbose","title":"<code>verbose</code>","text":"<p>This parameter enables verbose logs (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code># initialize and formulate decoder with verbose logs\nFFdecoder(\"foo.mp4\", verbose=True).formulate()\n</code></pre> <p> </p>"},{"location":"reference/ffdecoder/params/#ffparams","title":"<code>ffparams</code>","text":"<p>This dictionary parameter accepts all supported parameters formatted as its attributes:</p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code>.</p>"},{"location":"reference/ffdecoder/params/#supported-parameters","title":"Supported Parameters","text":""},{"location":"reference/ffdecoder/params/#a-ffmpeg-parameters","title":"A. FFmpeg Parameters","text":"<p>Almost any FFmpeg parameter (supported by installed FFmpeg)  can be passed as dictionary attributes in <code>ffparams</code> parameter.</p> <p>Let's assume we want to <code>00:00:01.45</code>(or 1045msec) in time and decode one single frame from given source (say <code>foo.mp4</code>) in FFdecoder API, then we can assign required FFmpeg parameters as dictionary attributes as follows:</p> <p>Kindly read FFmpeg Docs carefully before passing any additional values to <code>ffparams</code> parameter. Wrong invalid values may result in undesired errors or no output at all.</p> <p>All FFmpeg parameters are case-sensitive. Remember to double check every parameter if any error(s) occurred.</p> <pre><code># define the FFmpeg parameter to seek to 00:00:01.45(or 1s and 45msec)\n# in time and get one single frame\nffparams = {\"-ss\": \"00:00:01.45\", \"-frames:v\": 1}\n# initialize and formulate decoder with suitable source and FFmpeg params\ndecoder = FFdecoder(\"foo.mp4\", verbose=True, **ffparams).formulate()\n</code></pre> <p> </p>"},{"location":"reference/ffdecoder/params/#b-exclusive-parameters","title":"B. Exclusive Parameters","text":"<p>In addition to FFmpeg parameters, FFdecoder API also supports few Exclusive Parameters to allow users to flexibly change its internal pipeline, properties, and handle some special FFmpeg parameters (such as repeated <code>map</code>) that cannot be assigned via. python dictionary. </p> <p>These parameters are discussed below:</p> <ul> <li> <p><code>-vcodec</code> (str) : This attribute works similar to <code>-vcodec</code> FFmpeg parameter for specifying supported decoders that are compiled with FFmpeg in use. If not specified, it's value is derived from source video metadata. Its usage is as follows: </p> <p>Use <code>ffmpeg -decoders</code> terminal command to lists all FFmpeg supported decoders.</p> Use <code>{\"-vcodec\":None}</code> in ffparams to discard <code>-vcodec</code> FFmpeg parameter entirely from Decoding pipeline. <p>This feature allows users to manually skip <code>-vcodec</code> FFmpeg parameter in Decoding pipeline, for letting FFmpeg itself choose the best available video decoder for the given source.</p> <pre><code># define suitable parameter\nffparams = {\"-vcodec\": \"h264\"} # set decoder to `h264`\n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-framerate</code> (float/int) : This attribute works similar to <code>-framerate</code> FFmpeg parameter for generating video-frames at specified framerate. If not specified, it calculated from video metadata. Its usage is as follows: </p> Any invalid or unsupported value to <code>-framerate</code> attribute will discarded! <p>The <code>output_frames_framerate</code> metadata property is only available when FFmpeg filters via. <code>-vf</code> or <code>-filter_complex</code> are manually defined.</p> <p>Any improper <code>-framerate</code> parameter value (i.e. either <code>null</code>(special-case), undefined, or invalid type) , then <code>-framerate/-r</code> FFmpeg parameter value in Decoding pipeline uses <code>output_frames_framerate</code> metadata property extracted from Output Stream. Thereby, in case if no valid <code>output_framerate</code>  metadata property is found, then API finally defaults to <code>source_video_framerate</code> metadata property extracted from Input Source Stream.</p> <p>In case neither <code>output_framerate</code> nor <code>source_video_framerate</code> valid metadata properties are found, then <code>RuntimeError</code> is raised.</p> Use <code>{\"-framerate\":\"null\"}</code> in ffparams to discard <code>-framerate/-r</code> FFmpeg parameter entirely from Decoding pipeline. <p>This feature allows users to manually skip <code>-framerate/-r</code> FFmpeg parameter in Decoding pipeline, essentially for using only <code>fps</code> filter values, or even better, let FFmpeg itself choose the best available output framerate for the given source.</p> <pre><code># define suitable parameter\nffparams = {\"-framerate\": 60.0} # set input video source framerate to 60fps\n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-custom_resolution</code> (tuple/list) : This attribute sets the custom resolution/size of the output frames. Its value can either be a tuple (<code>(width,height)</code>) or a list (<code>[width, height]</code>). If not specified, it calculated from video metadata. Its usage is as follows: </p> Any invalid or unsupported value to <code>-custom_resolution</code> attribute will discarded! <p>The <code>output_frames_resolution</code> metadata property is only available when FFmpeg filters via. <code>-vf</code> or <code>-filter_complex</code> are manually defined.</p> <p>Any improper <code>-custom_resolution</code> parameter value (i.e. either <code>null</code>(special-case), undefined, or invalid type) , then <code>-s/-size</code> FFmpeg parameter value in Decoding pipeline uses <code>output_frames_resolution</code> metadata property extracted from Output Stream. Thereby, in case if no valid <code>output_frames_resolution</code>  metadata property is found, then API finally defaults to <code>source_video_resolution</code> metadata property extracted from Input Source Stream.</p> <p>In case neither <code>output_frames_resolution</code> nor <code>source_video_resolution</code> valid metadata properties are found, then <code>RuntimeError</code> is raised.</p> Use <code>{\"-custom_resolution\":\"null\"}</code> in ffparams to discard <code>-size/-s</code> FFmpeg parameter entirely from Decoding pipeline. <p>This feature allows users to manually skip <code>-size/-s</code> FFmpeg parameter in Decoding pipeline, essentially for using only <code>fps</code> filter values, or even better, let FFmpeg itself choose the best available output frames resolution for the given source.</p> <pre><code># define suitable parameter\nffparams = {\"-output_dimensions\": (1280,720)} # to produce a 1280x720 resolution/scale output video\n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-ffprefixes</code> (list): This attribute sets the special FFmpeg parameters that generally occurs at the very beginning (such as <code>-re</code>) before input (<code>-i</code>) source. The FFmpeg parameters defined with this attribute can repeated more than once and maintains its original order in the FFmpeg command. Its value can be of datatype <code>list</code> only and its usage is as follows: </p> Difference from  <code>-clones</code> parameter <p>The <code>-clones</code> and <code>-ffprefixes</code> parameters even tho fundamentally work the same, they're meant to serve at different positions in the FFmpeg command. Normally, FFdecoder API pipeline looks something like following with these parameters in place:</p> <pre><code>ffmpeg {{-ffprefixes FFmpeg params}} -vcodec h264 -i foo.mp4 -pix_fmt rgb24 -s 1280x720 -framerate 25.0 {{-clones FFmpeg params}} -f rawvideo -\n</code></pre> <p>Turn on <code>verbose</code> parameter (<code>verbose = True</code>) to see the FFmpeg command that is being executed in FFdecoder's pipeline. This helps you debug/address any issues and make adjustments accordingly.</p> <pre><code># define suitable parameter\nffparams = {\"-ffprefixes\": ['-re']} # executes as `ffmpeg -re &lt;rest of command&gt;`\n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-clones</code> (list):  This attribute sets the special FFmpeg parameters after that are repeated more than once or occurs in a specific order (that cannot be altered) in the FFmpeg command. Its value can be of datatype <code>list</code> only and its usage is as follows: </p> <p>Turn on <code>verbose</code> parameter (<code>verbose = True</code>) to see the FFmpeg command that is being executed in FFdecoder's pipeline. This helps you debug/address any issues and make adjustments accordingly.</p> <pre><code># define suitable parameter\nffparams = {\"-clones\": ['-map', '0:v:0', '-map', '1:a?']} \n# NOTE: Will be format as `ffmpeg -vcodec -i foo.mp4 -pix_fmt rgb24 -s 1280x720 -framerate 25.0 -map 0:v:0 -map 1:a -f rawvideo -`\n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-custom_sourcer_params</code> (dict) :  This attribute assigns all Exclusive Parameter meant for Sourcer API's <code>sourcer_params</code> dictionary parameter directly through FFdecoder API. Its usage is as follows: </p> <pre><code># define suitable parameter meant for `sourcer_params`\nffparams = {\"-custom_sourcer_params\": {\"-ffmpeg_download_path\": \"C:/User/foo/foo1\"}}\n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-default_stream_indexes</code> (list/tuple) : This attribute assign value directly to <code>default_stream_indexes</code> parameter in Sourcer API's <code>probe_stream()</code> method for selecting specific video and audio stream index in case of multiple ones. Value can be of format: <code>(int,int)</code> or <code>[int,int]</code> as follows:</p> <pre><code># define suitable parameter meant for `probe_stream()` method\nffparams = {\"-default_stream_indexes\": (0,1)} # (\"0th video stream\", \"1st audio stream\")\n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-enforce_cv_patch</code> (bool) : This attribute can be enabled(<code>True</code>) for patching YUV pixel-formats (such as <code>YUV420p</code>, <code>yuv444p</code>, <code>NV12</code>, <code>NV21</code> etc.) frames to be seamless compatibility with OpenCV APIs such as <code>imshow()</code>, <code>write()</code> etc. It can be used as follows:</p> <p>As of now, YUV pixel-formats starting with <code>YUV</code> and <code>NV</code> are only supported.</p> <pre><code># define suitable parameter\nffparams = {\"-enforce_cv_patch\": True} # enables OpenCV patch for YUV frames\n</code></pre> <p>YUV pixel-formats usage recipe  can found here \u27b6</p> </li> </ul> <p> </p> <ul> <li><code>-passthrough_audio</code> (bool/list) : (Yet to be supported)</li> </ul> <p> </p> <ol> <li> <p>Default pixel-format is calculated variably in FFdecoder API:</p> <ul> <li> If <code>frame_format != \"null\"</code>: <ul> <li>If <code>frame_format</code> parameter is valid and supported: Default pixel-format is <code>frame_format</code> parameter value.</li> <li>If <code>frame_format</code> parameter is NOT valid or supported:<ul> <li>If <code>output_frame_pixfmt</code> metadata is available: Default pixel-format is <code>output_frame_pixfmt</code> metadata value.</li> <li>If <code>output_frame_pixfmt</code> metadata is NOT available: Default pixel-format is <code>rgb24</code> if supported otherwise <code>source_video_pixfmt</code> metadata value.</li> </ul> </li> </ul> </li> <li> If <code>frame_format == \"null\"</code>: Default pixel-format is <code>source_video_pixfmt</code> metadata value</li> </ul> <p>\u21a9\u21a9</p> </li> </ol>"},{"location":"reference/sourcer/","title":"Sourcer API","text":"<p>Sourcer API acts as Source Probing Utility that unlike other FFmpeg Wrappers which mostly uses <code>ffprobe</code> module, attempts to open the given Input Source directly with FFmpeg inside a <code>subprocess</code> pipe, and parses/probes the standard output(stdout) employing various pattern matching methods in order to recognize all the properties(metadata) of each media stream contained in it.</p> <p>Sourcer API primarily acts as a backend for FFdecoder API for gathering, processing, and validating all multimedia streams metadata available in the given Input Source. Sourcer shares this information with FFdecoder API which helps in formulating its default FFmpeg pipeline parameters for real-time video-frames generation.</p> <p>Sourcer API is design as a standalone Metadata Extraction API for easily parsing information from multimedia streams available in the given Input Source and returns it in either Human-readable (JSON string) or Machine-readable (Dictionary object) type with its <code>retrieve_metadata()</code> method.</p> <p>All metadata attributes available with Sourcer API(On  Windows) are discussed here \u27b6.</p> <p>Furthermore, Sourcer's <code>sourcer_params</code> dictionary parameter can be used to define almost any FFmpeg parameter as well as alter internal API settings.</p> <p>For usage examples, kindly refer our Basic Recipes  and Advanced Recipes </p> <p>Sourcer API parameters are explained here \u27b6</p> Source code in <code>deffcode/sourcer.py</code> <pre><code>class Sourcer:\n\"\"\"\n    &gt; Sourcer API acts as **Source Probing Utility** that unlike other FFmpeg Wrappers which mostly uses [`ffprobe`](https://ffmpeg.org/ffprobe.html) module,\n    attempts to open the given Input Source directly with [**FFmpeg**](https://ffmpeg.org/) inside a [`subprocess`](https://docs.python.org/3/library/subprocess.html) pipe,\n    and parses/probes the standard output(stdout) employing various pattern matching methods in order to recognize all the properties(metadata) of each\n    media stream contained in it.\n    Sourcer API primarily acts as a **backend for [FFdecoder API](../../reference/ffdecoder)** for gathering, processing, and validating\n    all multimedia streams metadata available in the given Input Source. Sourcer shares this information with FFdecoder API which helps in\n    formulating its default FFmpeg pipeline parameters for real-time video-frames generation.\n    Sourcer API is design as a standalone **Metadata Extraction API** for easily parsing information from multimedia streams available in the\n    given Input Source and returns it in either Human-readable _(JSON string)_ or Machine-readable _(Dictionary object)_ type with its\n    [`retrieve_metadata()`](#deffcode.sourcer.Sourcer.retrieve_metadata) method.\n    !!! info \"All metadata attributes available with Sourcer API(On :fontawesome-brands-windows: Windows) are discussed [here \u27b6](../../recipes/basic/#display-source-video-metadata).\"\n    Furthermore, Sourcer's [`sourcer_params`](params/#sourcer_params) dictionary parameter can be used to define almost any FFmpeg parameter as well as alter internal API settings.\n    !!! example \"For usage examples, kindly refer our **[Basic Recipes :cake:](../../recipes/basic)** and **[Advanced Recipes :croissant:](../../recipes/advanced)**\"\n    !!! info \"Sourcer API parameters are explained [here \u27b6](params/)\"\n    \"\"\"\ndef __init__(\nself,\nsource,\nsource_demuxer=None,\ncustom_ffmpeg=\"\",\nverbose=False,\n**sourcer_params,\n):\n\"\"\"\n        This constructor method initializes the object state and attributes of the Sourcer Class.\n        Parameters:\n            source (str): defines the input(`-i`) source filename/URL/device-name/device-path.\n            source_demuxer (str): specifies the demuxer(`-f`) for the input source.\n            custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executable.\n            verbose (bool): enables/disables verbose.\n            sourcer_params (dict): provides the flexibility to control supported internal and FFmpeg parameters.\n        \"\"\"\n# checks if machine in-use is running windows os or not\nself.__machine_OS = platform.system()\n# define internal parameters\nself.__verbose_logs = (  # enable verbose if specified\nverbose if (verbose and isinstance(verbose, bool)) else False\n)\n# handle metadata received\nself.__ffsp_output = None\n# sanitize sourcer_params\nself.__sourcer_params = {\nstr(k).strip(): str(v).strip()\nif not isinstance(v, (dict, list, int, float, tuple))\nelse v\nfor k, v in sourcer_params.items()\n}\n# handle whether to force validate source\nself.__forcevalidatesource = self.__sourcer_params.pop(\n\"-force_validate_source\", False\n)\nif not isinstance(self.__forcevalidatesource, bool):\n# reset improper values\nself.__forcevalidatesource = False\n# handle user defined ffmpeg pre-headers(parameters such as `-re`) parameters (must be a list)\nself.__ffmpeg_prefixes = self.__sourcer_params.pop(\"-ffprefixes\", [])\nif not isinstance(self.__ffmpeg_prefixes, list):\n# log it\nlogger.warning(\n\"Discarding invalid `-ffprefixes` value of wrong type `{}`!\".format(\ntype(self.__ffmpeg_prefixes).__name__\n)\n)\n# reset improper values\nself.__ffmpeg_prefixes = []\n# handle where to save the downloaded FFmpeg Static assets on Windows(if specified)\n__ffmpeg_download_path = self.__sourcer_params.pop(\"-ffmpeg_download_path\", \"\")\nif not isinstance(__ffmpeg_download_path, str):\n# reset improper values\n__ffmpeg_download_path = \"\"\n# validate the FFmpeg assets and return location (also downloads static assets on windows)\nself.__ffmpeg = get_valid_ffmpeg_path(\nstr(custom_ffmpeg),\nTrue if self.__machine_OS == \"Windows\" else False,\nffmpeg_download_path=__ffmpeg_download_path,\nverbose=self.__verbose_logs,\n)\n# check if valid FFmpeg path returned\nif self.__ffmpeg:\nself.__verbose_logs and logger.debug(\n\"Found valid FFmpeg executable: `{}`.\".format(self.__ffmpeg)\n)\nelse:\n# else raise error\nraise RuntimeError(\n\"[DeFFcode:ERROR] :: Failed to find FFmpeg assets on this system. Kindly compile/install FFmpeg or provide a valid custom FFmpeg binary path!\"\n)\n# sanitize externally accessible parameters and assign them\n# handles source demuxer\nif source is None:\n# first check if source value is empty\n# raise error if true\nraise ValueError(\"Input `source` parameter is empty!\")\nelif isinstance(source_demuxer, str):\n# assign if valid demuxer value\nself.__source_demuxer = source_demuxer.strip().lower()\n# assign if valid demuxer value\nassert self.__source_demuxer != \"auto\" or validate_device_index(\nsource\n), \"Invalid `source_demuxer='auto'` value detected with source: `{}`. Aborting!\".format(\nsource\n)\nelse:\n# otherwise find valid default source demuxer value\n# enforce \"auto\" if valid index device\nself.__source_demuxer = \"auto\" if validate_device_index(source) else None\n# log if not valid index device and invalid type\nself.__verbose_logs and not self.__source_demuxer in [\n\"auto\",\nNone,\n] and logger.warning(\n\"Discarding invalid `source_demuxer` parameter value of wrong type: `{}`\".format(\ntype(source_demuxer).__name__\n)\n)\n# log if not valid index device and invalid type\nself.__verbose_logs and self.__source_demuxer == \"auto\" and logger.critical(\n\"Given source `{}` is a valid device index. Enforcing 'auto' demuxer.\".format(\nsource\n)\n)\n# handles source stream\nself.__source = source\n# creates shallow copy for further usage #TODO\nself.__source_org = copy.copy(self.__source)\nself.__source_demuxer_org = copy.copy(self.__source_demuxer)\n# handles all extracted devices names/paths list\n# when source_demuxer = \"auto\"\nself.__extracted_devices_list = []\n# various source stream params\nself.__default_video_resolution = \"\"  # handles stream resolution\nself.__default_video_framerate = \"\"  # handles stream framerate\nself.__default_video_bitrate = \"\"  # handles stream's video bitrate\nself.__default_video_pixfmt = \"\"  # handles stream's video pixfmt\nself.__default_video_decoder = \"\"  # handles stream's video decoder\nself.__default_source_duration = \"\"  # handles stream's video duration\nself.__approx_video_nframes = \"\"  # handles approx stream frame number\nself.__default_audio_bitrate = \"\"  # handles stream's audio bitrate\nself.__default_audio_samplerate = \"\"  # handles stream's audio samplerate\n# handle various stream flags\nself.__contains_video = False  # contains video\nself.__contains_audio = False  # contains audio\nself.__contains_images = False  # contains image-sequence\n# handles output parameters through filters\nself.__metadata_output = None  # handles output stream metadata\nself.__output_frames_resolution = \"\"  # handles output stream resolution\nself.__output_framerate = \"\"  # handles output stream framerate\nself.__output_frames_pixfmt = \"\"  # handles output frame pixel format\n# check whether metadata probed or not?\nself.__metadata_probed = False\ndef probe_stream(self, default_stream_indexes=(0, 0)):\n\"\"\"\n        This method Parses/Probes FFmpeg `subprocess` pipe's Standard Output for given input source and Populates the information in private class variables.\n        Parameters:\n            default_stream_indexes (list, tuple): selects specific video and audio stream index in case of multiple ones. Value can be of format: `(int,int)`. For example `(0,1)` is (\"0th video stream\", \"1st audio stream\").\n        **Returns:** Reference to the instance object.\n        \"\"\"\nassert (\nisinstance(default_stream_indexes, (list, tuple))\nand len(default_stream_indexes) == 2\nand all(isinstance(x, int) for x in default_stream_indexes)\n), \"Invalid default_stream_indexes value!\"\n# validate source and extract metadata\nself.__ffsp_output = self.__validate_source(\nself.__source,\nsource_demuxer=self.__source_demuxer,\nforced_validate=(\nself.__forcevalidatesource if self.__source_demuxer is None else True\n),\n)\n# parse resolution and framerate\nvideo_rfparams = self.__extract_resolution_framerate(\ndefault_stream=default_stream_indexes[0]\n)\nif video_rfparams:\nself.__default_video_resolution = video_rfparams[\"resolution\"]\nself.__default_video_framerate = video_rfparams[\"framerate\"]\n# parse output parameters through filters (if available)\nif not (self.__metadata_output is None):\n# parse output resolution and framerate\nout_video_rfparams = self.__extract_resolution_framerate(\ndefault_stream=default_stream_indexes[0], extract_output=True\n)\nif out_video_rfparams:\nself.__output_frames_resolution = out_video_rfparams[\"resolution\"]\nself.__output_framerate = out_video_rfparams[\"framerate\"]\n# parse output pixel-format\nself.__output_frames_pixfmt = self.__extract_video_pixfmt(\ndefault_stream=default_stream_indexes[0], extract_output=True\n)\n# parse pixel-format\nself.__default_video_pixfmt = self.__extract_video_pixfmt(\ndefault_stream=default_stream_indexes[0]\n)\n# parse video decoder\nself.__default_video_decoder = self.__extract_video_decoder(\ndefault_stream=default_stream_indexes[0]\n)\n# parse rest of metadata\nif not self.__contains_images:\n# parse video bitrate\nself.__default_video_bitrate = self.__extract_video_bitrate(\ndefault_stream=default_stream_indexes[0]\n)\n# parse audio bitrate and samplerate\naudio_params = self.__extract_audio_bitrate_nd_samplerate(\ndefault_stream=default_stream_indexes[1]\n)\nif audio_params:\nself.__default_audio_bitrate = audio_params[\"bitrate\"]\nself.__default_audio_samplerate = audio_params[\"samplerate\"]\n# parse video duration\nself.__default_source_duration = self.__extract_duration()\n# calculate all flags\nif (\nself.__default_video_bitrate\nor (self.__default_video_framerate and self.__default_video_resolution)\n) and (self.__default_audio_bitrate or self.__default_audio_samplerate):\nself.__contains_video = True\nself.__contains_audio = True\nelif self.__default_video_bitrate or (\nself.__default_video_framerate and self.__default_video_resolution\n):\nself.__contains_video = True\nelif self.__default_audio_bitrate or self.__default_audio_samplerate:\nself.__contains_audio = True\nelse:\nraise ValueError(\n\"Invalid source with no decodable audio or video stream provided. Aborting!\"\n)\n# calculate approximate number of video frame\nif self.__default_video_framerate and self.__default_source_duration:\nself.__approx_video_nframes = np.rint(\nself.__default_video_framerate * self.__default_source_duration\n).astype(int, casting=\"unsafe\")\n# signal metadata has been probed\nself.__metadata_probed = True\n# return reference to the instance object.\nreturn self\ndef retrieve_metadata(self, pretty_json=False, force_retrieve_missing=False):\n\"\"\"\n        This method returns Parsed/Probed Metadata of the given source.\n        Parameters:\n            pretty_json (bool): whether to return metadata as JSON string(if `True`) or Dictionary(if `False`) type?\n            force_retrieve_output (bool): whether to also return metadata missing in current Pipeline. This method returns `(metadata, metadata_missing)` tuple if `force_retrieve_output=True` instead of `metadata`.\n        **Returns:** `metadata` or `(metadata, metadata_missing)`, formatted as JSON string or python dictionary.\n        \"\"\"\n# check if metadata has been probed or not\nassert (\nself.__metadata_probed\n), \"Source Metadata not been probed yet! Check if you called `probe_stream()` method.\"\n# log it\nself.__verbose_logs and logger.debug(\"Extracting Metadata...\")\n# create metadata dictionary from information populated in private class variables\nmetadata = {\n\"ffmpeg_binary_path\": self.__ffmpeg,\n\"source\": self.__source,\n}\nmetadata_missing = {}\n# Only either `source_demuxer` or `source_extension` attribute can be\n# present in metadata.\nif self.__source_demuxer is None:\nmetadata.update({\"source_extension\": os.path.splitext(self.__source)[-1]})\n# update missing\nforce_retrieve_missing and metadata_missing.update({\"source_demuxer\": \"\"})\nelse:\nmetadata.update({\"source_demuxer\": self.__source_demuxer})\n# update missing\nforce_retrieve_missing and metadata_missing.update({\"source_extension\": \"\"})\n# add source video metadata properties\nmetadata.update(\n{\n\"source_video_resolution\": self.__default_video_resolution,\n\"source_video_pixfmt\": self.__default_video_pixfmt,\n\"source_video_framerate\": self.__default_video_framerate,\n\"source_video_decoder\": self.__default_video_decoder,\n\"source_duration_sec\": self.__default_source_duration,\n\"approx_video_nframes\": (\nint(self.__approx_video_nframes)\nif self.__approx_video_nframes\nelse None\n),\n\"source_video_bitrate\": self.__default_video_bitrate,\n\"source_audio_bitrate\": self.__default_audio_bitrate,\n\"source_audio_samplerate\": self.__default_audio_samplerate,\n\"source_has_video\": self.__contains_video,\n\"source_has_audio\": self.__contains_audio,\n\"source_has_image_sequence\": self.__contains_images,\n}\n)\n# add output metadata properties (if available)\nif not (self.__metadata_output is None):\nmetadata.update(\n{\n\"output_frames_resolution\": self.__output_frames_resolution,\n\"output_frames_pixfmt\": self.__output_frames_pixfmt,\n\"output_framerate\": self.__output_framerate,\n}\n)\nelse:\n# since output stream metadata properties are only available when additional\n# FFmpeg parameters(such as filters) are defined manually, thereby missing\n# output stream properties are handled by assigning them counterpart source\n# stream metadata property values\nforce_retrieve_missing and metadata_missing.update(\n{\n\"output_frames_resolution\": self.__default_video_resolution,\n\"output_frames_pixfmt\": self.__default_video_pixfmt,\n\"output_framerate\": self.__default_video_framerate,\n}\n)\n# log it\nself.__verbose_logs and logger.debug(\n\"Metadata Extraction completed successfully!\"\n)\n# parse as JSON string(`json.dumps`), if defined\nmetadata = json.dumps(metadata, indent=2) if pretty_json else metadata\nmetadata_missing = (\njson.dumps(metadata_missing, indent=2) if pretty_json else metadata_missing\n)\n# return `metadata` or `(metadata, metadata_missing)`\nreturn metadata if not force_retrieve_missing else (metadata, metadata_missing)\n@property\ndef enumerate_devices(self):\n\"\"\"\n        A property object that enumerate all probed Camera Devices connected to your system names\n        along with their respective \"device indexes\" or \"camera indexes\" as python dictionary.\n        **Returns:** Probed Camera Devices as python dictionary.\n        \"\"\"\n# check if metadata has been probed or not\nassert (\nself.__metadata_probed\n), \"Source Metadata not been probed yet! Check if you called `probe_stream()` method.\"\n# log if specified\nself.__verbose_logs and logger.debug(\"Enumerating all probed Camera Devices.\")\n# return probed Camera Devices as python dictionary.\nreturn {\ndev_idx: dev for dev_idx, dev in enumerate(self.__extracted_devices_list)\n}\ndef __validate_source(self, source, source_demuxer=None, forced_validate=False):\n\"\"\"\n        This Internal method validates source and extracts its metadata.\n        Parameters:\n            source_demuxer(str): specifies the demuxer(`-f`) for the input source.\n            forced_validate (bool): whether to skip validation tests or not?\n        **Returns:** `True` if passed tests else `False`.\n        \"\"\"\n# validate source demuxer(if defined)\nif not (source_demuxer is None):\n# check if \"auto\" demuxer is specified\nif source_demuxer == \"auto\":\n# integerise source to get index\nindex = int(source)\n# extract devices list and actual demuxer value\n(\nself.__extracted_devices_list,\nsource_demuxer,\n) = extract_device_n_demuxer(\nself.__ffmpeg,\nmachine_OS=self.__machine_OS,\nverbose=self.__verbose_logs,\n)\n# valid indexes range\nvalid_indexes = [\nx\nfor x in range(\n-len(self.__extracted_devices_list),\nlen(self.__extracted_devices_list),\n)\n]\n# check index is within valid range\nif self.__extracted_devices_list and index in valid_indexes:\n# overwrite actual source device name/path/index\nif self.__machine_OS == \"Windows\":\n# Windows OS requires \"video=\" suffix\nself.__source = source = \"video={}\".format(\nself.__extracted_devices_list[index]\n)\nelif self.__machine_OS == \"Darwin\":\n# Darwin OS requires only device indexes\nself.__source = source = (\nstr(index)\nif index &gt;= 0\nelse str(len(self.__extracted_devices_list) + index)\n)\nelse:\n# Linux OS require /dev/video format\nself.__source = source = next(\niter(self.__extracted_devices_list[index].keys())\n)\n# overwrite source_demuxer global variable\nself.__source_demuxer = source_demuxer\nself.__verbose_logs and logger.debug(\n\"Successfully configured device `{}` at index `{}` with demuxer `{}`.\".format(\nself.__extracted_devices_list[index]\nif self.__machine_OS != \"Linux\"\nelse next(\niter(self.__extracted_devices_list[index].values())\n)[0],\nindex\nif index &gt;= 0\nelse len(self.__extracted_devices_list) + index,\nself.__source_demuxer,\n)\n)\nelse:\n# raise error otherwise\nraise ValueError(\n\"Given source `{}` is not a valid device index. Possible values index values can be: {}\".format(\nsource,\n\",\".join(f\"{x}\" for x in valid_indexes),\n)\n)\n# otherwise validate against supported demuxers\nelif not (source_demuxer in get_supported_demuxers(self.__ffmpeg)):\n# raise if fails\nraise ValueError(\n\"Installed FFmpeg failed to recognize `{}` demuxer. Check `source_demuxer` parameter value again!\".format(\nsource_demuxer\n)\n)\nelse:\npass\n# assert if valid source\nassert source and isinstance(\nsource, str\n), \"Input `source` parameter is of invalid type!\"\n# Differentiate input\nif forced_validate:\nsource_demuxer is None and logger.critical(\n\"Forcefully passing validation test for given source!\"\n)\nself.__source = source\nelif os.path.isfile(source):\nself.__source = os.path.abspath(source)\nelif is_valid_image_seq(\nself.__ffmpeg, source=source, verbose=self.__verbose_logs\n):\nself.__source = source\nself.__contains_images = True\nelif is_valid_url(self.__ffmpeg, url=source, verbose=self.__verbose_logs):\nself.__source = source\nelse:\nlogger.error(\"`source` value is unusable or unsupported!\")\n# discard the value otherwise\nraise ValueError(\"Input source is invalid. Aborting!\")\n# format command\nif self.__sourcer_params:\n# handle additional params separately\nmeta_cmd = (\n[self.__ffmpeg]\n+ ([\"-hide_banner\"] if not self.__verbose_logs else [])\n+ [\"-t\", \"0.0001\"]\n+ self.__ffmpeg_prefixes\n+ ([\"-f\", source_demuxer] if source_demuxer else [])\n+ [\"-i\", source]\n+ dict2Args(self.__sourcer_params)\n+ [\"-f\", \"null\", \"-\"]\n)\nelse:\nmeta_cmd = (\n[self.__ffmpeg]\n+ ([\"-hide_banner\"] if not self.__verbose_logs else [])\n+ self.__ffmpeg_prefixes\n+ ([\"-f\", source_demuxer] if source_demuxer else [])\n+ [\"-i\", source]\n)\n# extract metadata, decode, and filter\nmetadata = (\ncheck_sp_output(\nmeta_cmd,\nforce_retrieve_stderr=True,\n)\n.decode(\"utf-8\")\n.strip()\n)\n# separate input and output metadata (if available)\nif \"Output #\" in metadata:\n(metadata, self.__metadata_output) = metadata.split(\"Output #\")\n# return metadata based on params\nreturn metadata\ndef __extract_video_bitrate(self, default_stream=0):\n\"\"\"\n        This Internal method parses default video-stream bitrate from metadata.\n        Parameters:\n            default_stream (int): selects specific video-stream in case of multiple ones.\n        **Returns:** Default Video bitrate as string value.\n        \"\"\"\nidentifiers = [\"Video:\", \"Stream #\"]\nvideo_bitrate_text = [\nline.strip()\nfor line in self.__ffsp_output.split(\"\\n\")\nif all(x in line for x in identifiers)\n]\nif video_bitrate_text:\nselected_stream = video_bitrate_text[\ndefault_stream\nif default_stream &gt; 0 and default_stream &lt; len(video_bitrate_text)\nelse 0\n]\nfiltered_bitrate = re.findall(\nr\",\\s[0-9]+\\s\\w\\w[\\/]s\", selected_stream.strip()\n)\nif len(filtered_bitrate):\ndefault_video_bitrate = filtered_bitrate[0].split(\" \")[1:3]\nfinal_bitrate = \"{}{}\".format(\nint(default_video_bitrate[0].strip()),\n\"k\" if (default_video_bitrate[1].strip().startswith(\"k\")) else \"M\",\n)\nreturn final_bitrate\nreturn \"\"\ndef __extract_video_decoder(self, default_stream=0):\n\"\"\"\n        This Internal method parses default video-stream decoder from metadata.\n        Parameters:\n            default_stream (int): selects specific video-stream in case of multiple ones.\n        **Returns:** Default Video decoder as string value.\n        \"\"\"\nassert isinstance(default_stream, int), \"Invalid input!\"\nidentifiers = [\"Video:\", \"Stream #\"]\nmeta_text = [\nline.strip()\nfor line in self.__ffsp_output.split(\"\\n\")\nif all(x in line for x in identifiers)\n]\nif meta_text:\nselected_stream = meta_text[\ndefault_stream\nif default_stream &gt; 0 and default_stream &lt; len(meta_text)\nelse 0\n]\nfiltered_pixfmt = re.findall(\nr\"Video:\\s[a-z0-9_-]*\", selected_stream.strip()\n)\nif filtered_pixfmt:\nreturn filtered_pixfmt[0].split(\" \")[-1]\nreturn \"\"\ndef __extract_video_pixfmt(self, default_stream=0, extract_output=False):\n\"\"\"\n        This Internal method parses default video-stream pixel-format from metadata.\n        Parameters:\n            default_stream (int): selects specific video-stream in case of multiple ones.\n        **Returns:** Default Video pixel-format as string value.\n        \"\"\"\nidentifiers = [\"Video:\", \"Stream #\"]\nmeta_text = (\n[\nline.strip()\nfor line in self.__ffsp_output.split(\"\\n\")\nif all(x in line for x in identifiers)\n]\nif not extract_output\nelse [\nline.strip()\nfor line in self.__metadata_output.split(\"\\n\")\nif all(x in line for x in identifiers)\n]\n)\nif meta_text:\nselected_stream = meta_text[\ndefault_stream\nif default_stream &gt; 0 and default_stream &lt; len(meta_text)\nelse 0\n]\nfiltered_pixfmt = re.findall(\nr\",\\s[a-z][a-z0-9_-]*\", selected_stream.strip()\n)\nif filtered_pixfmt:\nreturn filtered_pixfmt[0].split(\" \")[-1]\nreturn \"\"\ndef __extract_audio_bitrate_nd_samplerate(self, default_stream=0):\n\"\"\"\n        This Internal method parses default audio-stream bitrate and sample-rate from metadata.\n        Parameters:\n            default_stream (int): selects specific audio-stream in case of multiple ones.\n        **Returns:** Default Audio-stream bitrate and sample-rate as string value.\n        \"\"\"\nidentifiers = [\"Audio:\", \"Stream #\"]\nmeta_text = [\nline.strip()\nfor line in self.__ffsp_output.split(\"\\n\")\nif all(x in line for x in identifiers)\n]\nresult = {}\nif meta_text:\nselected_stream = meta_text[\ndefault_stream\nif default_stream &gt; 0 and default_stream &lt; len(meta_text)\nelse 0\n]\n# filter data\nfiltered_audio_bitrate = re.findall(\nr\"fltp,\\s[0-9]+\\s\\w\\w[\\/]s\", selected_stream.strip()\n)\nfiltered_audio_samplerate = re.findall(\nr\",\\s[0-9]+\\sHz\", selected_stream.strip()\n)\n# get audio bitrate metadata\nif filtered_audio_bitrate:\nfiltered = filtered_audio_bitrate[0].split(\" \")[1:3]\nresult[\"bitrate\"] = \"{}{}\".format(\nint(filtered[0].strip()),\n\"k\" if (filtered[1].strip().startswith(\"k\")) else \"M\",\n)\nelse:\nresult[\"bitrate\"] = \"\"\n# get audio samplerate metadata\nresult[\"samplerate\"] = (\nfiltered_audio_samplerate[0].split(\", \")[1]\nif filtered_audio_samplerate\nelse \"\"\n)\nreturn result if result and (len(result) == 2) else {}\ndef __extract_resolution_framerate(self, default_stream=0, extract_output=False):\n\"\"\"\n        This Internal method parses default video-stream resolution and framerate from metadata.\n        Parameters:\n            default_stream (int): selects specific audio-stream in case of multiple ones.\n            extract_output (bool): Whether to extract from output(if true) or input(if false) stream?\n        **Returns:** Default Video resolution and framerate as dictionary value.\n        \"\"\"\nidentifiers = [\"Video:\", \"Stream #\"]\n# use output metadata if available\nmeta_text = (\n[\nline.strip()\nfor line in self.__ffsp_output.split(\"\\n\")\nif all(x in line for x in identifiers)\n]\nif not extract_output\nelse [\nline.strip()\nfor line in self.__metadata_output.split(\"\\n\")\nif all(x in line for x in identifiers)\n]\n)\nresult = {}\nif meta_text:\nselected_stream = meta_text[\ndefault_stream\nif default_stream &gt; 0 and default_stream &lt; len(meta_text)\nelse 0\n]\n# filter data\nfiltered_resolution = re.findall(\nr\"([1-9]\\d+)x([1-9]\\d+)\", selected_stream.strip()\n)\nfiltered_framerate = re.findall(\nr\"\\d+(?:\\.\\d+)?\\sfps\", selected_stream.strip()\n)\nfiltered_tbr = re.findall(r\"\\d+(?:\\.\\d+)?\\stbr\", selected_stream.strip())\n# extract framerate metadata\nif filtered_framerate:\n# calculate actual framerate\nresult[\"framerate\"] = float(\nre.findall(r\"[\\d\\.\\d]+\", filtered_framerate[0])[0]\n)\nelif filtered_tbr:\n# guess from TBR(if fps unavailable)\nresult[\"framerate\"] = float(\nre.findall(r\"[\\d\\.\\d]+\", filtered_tbr[0])[0]\n)\n# extract resolution metadata\nif filtered_resolution:\nresult[\"resolution\"] = [int(x) for x in filtered_resolution[0]]\nreturn result if result and (len(result) == 2) else {}\ndef __extract_duration(self, inseconds=True):\n\"\"\"\n        This Internal method parses stream duration from metadata.\n        Parameters:\n            inseconds (bool): whether to parse time in second(s) or `HH::mm::ss`?\n        **Returns:** Default Stream duration as string value.\n        \"\"\"\nidentifiers = [\"Duration:\"]\nstripped_data = [\nline.strip()\nfor line in self.__ffsp_output.split(\"\\n\")\nif all(x in line for x in identifiers)\n]\nif stripped_data:\nt_duration = re.findall(\nr\"(?:[01]\\d|2[0123]):(?:[012345]\\d):(?:[012345]\\d+(?:\\.\\d+)?)\",\nstripped_data[0],\n)\nif t_duration:\nreturn (\nsum(\nfloat(x) * 60**i\nfor i, x in enumerate(reversed(t_duration[0].split(\":\")))\n)\nif inseconds\nelse t_duration\n)\nreturn 0\n</code></pre> <p> </p>"},{"location":"reference/sourcer/#deffcode.sourcer.Sourcer.enumerate_devices","title":"<code>enumerate_devices</code>  <code>property</code> <code>readonly</code>","text":"<p>A property object that enumerate all probed Camera Devices connected to your system names along with their respective \"device indexes\" or \"camera indexes\" as python dictionary.</p> <p>Returns: Probed Camera Devices as python dictionary.</p>"},{"location":"reference/sourcer/#deffcode.sourcer.Sourcer.__init__","title":"<code>__init__(self, source, source_demuxer=None, custom_ffmpeg='', verbose=False, **sourcer_params)</code>  <code>special</code>","text":"<p>This constructor method initializes the object state and attributes of the Sourcer Class.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>defines the input(<code>-i</code>) source filename/URL/device-name/device-path.</p> required <code>source_demuxer</code> <code>str</code> <p>specifies the demuxer(<code>-f</code>) for the input source.</p> <code>None</code> <code>custom_ffmpeg</code> <code>str</code> <p>assigns the location of custom path/directory for custom FFmpeg executable.</p> <code>''</code> <code>verbose</code> <code>bool</code> <p>enables/disables verbose.</p> <code>False</code> <code>sourcer_params</code> <code>dict</code> <p>provides the flexibility to control supported internal and FFmpeg parameters.</p> <code>{}</code> Source code in <code>deffcode/sourcer.py</code> <pre><code>def __init__(\nself,\nsource,\nsource_demuxer=None,\ncustom_ffmpeg=\"\",\nverbose=False,\n**sourcer_params,\n):\n\"\"\"\n    This constructor method initializes the object state and attributes of the Sourcer Class.\n    Parameters:\n        source (str): defines the input(`-i`) source filename/URL/device-name/device-path.\n        source_demuxer (str): specifies the demuxer(`-f`) for the input source.\n        custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executable.\n        verbose (bool): enables/disables verbose.\n        sourcer_params (dict): provides the flexibility to control supported internal and FFmpeg parameters.\n    \"\"\"\n# checks if machine in-use is running windows os or not\nself.__machine_OS = platform.system()\n# define internal parameters\nself.__verbose_logs = (  # enable verbose if specified\nverbose if (verbose and isinstance(verbose, bool)) else False\n)\n# handle metadata received\nself.__ffsp_output = None\n# sanitize sourcer_params\nself.__sourcer_params = {\nstr(k).strip(): str(v).strip()\nif not isinstance(v, (dict, list, int, float, tuple))\nelse v\nfor k, v in sourcer_params.items()\n}\n# handle whether to force validate source\nself.__forcevalidatesource = self.__sourcer_params.pop(\n\"-force_validate_source\", False\n)\nif not isinstance(self.__forcevalidatesource, bool):\n# reset improper values\nself.__forcevalidatesource = False\n# handle user defined ffmpeg pre-headers(parameters such as `-re`) parameters (must be a list)\nself.__ffmpeg_prefixes = self.__sourcer_params.pop(\"-ffprefixes\", [])\nif not isinstance(self.__ffmpeg_prefixes, list):\n# log it\nlogger.warning(\n\"Discarding invalid `-ffprefixes` value of wrong type `{}`!\".format(\ntype(self.__ffmpeg_prefixes).__name__\n)\n)\n# reset improper values\nself.__ffmpeg_prefixes = []\n# handle where to save the downloaded FFmpeg Static assets on Windows(if specified)\n__ffmpeg_download_path = self.__sourcer_params.pop(\"-ffmpeg_download_path\", \"\")\nif not isinstance(__ffmpeg_download_path, str):\n# reset improper values\n__ffmpeg_download_path = \"\"\n# validate the FFmpeg assets and return location (also downloads static assets on windows)\nself.__ffmpeg = get_valid_ffmpeg_path(\nstr(custom_ffmpeg),\nTrue if self.__machine_OS == \"Windows\" else False,\nffmpeg_download_path=__ffmpeg_download_path,\nverbose=self.__verbose_logs,\n)\n# check if valid FFmpeg path returned\nif self.__ffmpeg:\nself.__verbose_logs and logger.debug(\n\"Found valid FFmpeg executable: `{}`.\".format(self.__ffmpeg)\n)\nelse:\n# else raise error\nraise RuntimeError(\n\"[DeFFcode:ERROR] :: Failed to find FFmpeg assets on this system. Kindly compile/install FFmpeg or provide a valid custom FFmpeg binary path!\"\n)\n# sanitize externally accessible parameters and assign them\n# handles source demuxer\nif source is None:\n# first check if source value is empty\n# raise error if true\nraise ValueError(\"Input `source` parameter is empty!\")\nelif isinstance(source_demuxer, str):\n# assign if valid demuxer value\nself.__source_demuxer = source_demuxer.strip().lower()\n# assign if valid demuxer value\nassert self.__source_demuxer != \"auto\" or validate_device_index(\nsource\n), \"Invalid `source_demuxer='auto'` value detected with source: `{}`. Aborting!\".format(\nsource\n)\nelse:\n# otherwise find valid default source demuxer value\n# enforce \"auto\" if valid index device\nself.__source_demuxer = \"auto\" if validate_device_index(source) else None\n# log if not valid index device and invalid type\nself.__verbose_logs and not self.__source_demuxer in [\n\"auto\",\nNone,\n] and logger.warning(\n\"Discarding invalid `source_demuxer` parameter value of wrong type: `{}`\".format(\ntype(source_demuxer).__name__\n)\n)\n# log if not valid index device and invalid type\nself.__verbose_logs and self.__source_demuxer == \"auto\" and logger.critical(\n\"Given source `{}` is a valid device index. Enforcing 'auto' demuxer.\".format(\nsource\n)\n)\n# handles source stream\nself.__source = source\n# creates shallow copy for further usage #TODO\nself.__source_org = copy.copy(self.__source)\nself.__source_demuxer_org = copy.copy(self.__source_demuxer)\n# handles all extracted devices names/paths list\n# when source_demuxer = \"auto\"\nself.__extracted_devices_list = []\n# various source stream params\nself.__default_video_resolution = \"\"  # handles stream resolution\nself.__default_video_framerate = \"\"  # handles stream framerate\nself.__default_video_bitrate = \"\"  # handles stream's video bitrate\nself.__default_video_pixfmt = \"\"  # handles stream's video pixfmt\nself.__default_video_decoder = \"\"  # handles stream's video decoder\nself.__default_source_duration = \"\"  # handles stream's video duration\nself.__approx_video_nframes = \"\"  # handles approx stream frame number\nself.__default_audio_bitrate = \"\"  # handles stream's audio bitrate\nself.__default_audio_samplerate = \"\"  # handles stream's audio samplerate\n# handle various stream flags\nself.__contains_video = False  # contains video\nself.__contains_audio = False  # contains audio\nself.__contains_images = False  # contains image-sequence\n# handles output parameters through filters\nself.__metadata_output = None  # handles output stream metadata\nself.__output_frames_resolution = \"\"  # handles output stream resolution\nself.__output_framerate = \"\"  # handles output stream framerate\nself.__output_frames_pixfmt = \"\"  # handles output frame pixel format\n# check whether metadata probed or not?\nself.__metadata_probed = False\n</code></pre>"},{"location":"reference/sourcer/#deffcode.sourcer.Sourcer.probe_stream","title":"<code>probe_stream(self, default_stream_indexes=(0, 0))</code>","text":"<p>This method Parses/Probes FFmpeg <code>subprocess</code> pipe's Standard Output for given input source and Populates the information in private class variables.</p> <p>Parameters:</p> Name Type Description Default <code>default_stream_indexes</code> <code>list, tuple</code> <p>selects specific video and audio stream index in case of multiple ones. Value can be of format: <code>(int,int)</code>. For example <code>(0,1)</code> is (\"0th video stream\", \"1st audio stream\").</p> <code>(0, 0)</code> <p>Returns: Reference to the instance object.</p> Source code in <code>deffcode/sourcer.py</code> <pre><code>def probe_stream(self, default_stream_indexes=(0, 0)):\n\"\"\"\n    This method Parses/Probes FFmpeg `subprocess` pipe's Standard Output for given input source and Populates the information in private class variables.\n    Parameters:\n        default_stream_indexes (list, tuple): selects specific video and audio stream index in case of multiple ones. Value can be of format: `(int,int)`. For example `(0,1)` is (\"0th video stream\", \"1st audio stream\").\n    **Returns:** Reference to the instance object.\n    \"\"\"\nassert (\nisinstance(default_stream_indexes, (list, tuple))\nand len(default_stream_indexes) == 2\nand all(isinstance(x, int) for x in default_stream_indexes)\n), \"Invalid default_stream_indexes value!\"\n# validate source and extract metadata\nself.__ffsp_output = self.__validate_source(\nself.__source,\nsource_demuxer=self.__source_demuxer,\nforced_validate=(\nself.__forcevalidatesource if self.__source_demuxer is None else True\n),\n)\n# parse resolution and framerate\nvideo_rfparams = self.__extract_resolution_framerate(\ndefault_stream=default_stream_indexes[0]\n)\nif video_rfparams:\nself.__default_video_resolution = video_rfparams[\"resolution\"]\nself.__default_video_framerate = video_rfparams[\"framerate\"]\n# parse output parameters through filters (if available)\nif not (self.__metadata_output is None):\n# parse output resolution and framerate\nout_video_rfparams = self.__extract_resolution_framerate(\ndefault_stream=default_stream_indexes[0], extract_output=True\n)\nif out_video_rfparams:\nself.__output_frames_resolution = out_video_rfparams[\"resolution\"]\nself.__output_framerate = out_video_rfparams[\"framerate\"]\n# parse output pixel-format\nself.__output_frames_pixfmt = self.__extract_video_pixfmt(\ndefault_stream=default_stream_indexes[0], extract_output=True\n)\n# parse pixel-format\nself.__default_video_pixfmt = self.__extract_video_pixfmt(\ndefault_stream=default_stream_indexes[0]\n)\n# parse video decoder\nself.__default_video_decoder = self.__extract_video_decoder(\ndefault_stream=default_stream_indexes[0]\n)\n# parse rest of metadata\nif not self.__contains_images:\n# parse video bitrate\nself.__default_video_bitrate = self.__extract_video_bitrate(\ndefault_stream=default_stream_indexes[0]\n)\n# parse audio bitrate and samplerate\naudio_params = self.__extract_audio_bitrate_nd_samplerate(\ndefault_stream=default_stream_indexes[1]\n)\nif audio_params:\nself.__default_audio_bitrate = audio_params[\"bitrate\"]\nself.__default_audio_samplerate = audio_params[\"samplerate\"]\n# parse video duration\nself.__default_source_duration = self.__extract_duration()\n# calculate all flags\nif (\nself.__default_video_bitrate\nor (self.__default_video_framerate and self.__default_video_resolution)\n) and (self.__default_audio_bitrate or self.__default_audio_samplerate):\nself.__contains_video = True\nself.__contains_audio = True\nelif self.__default_video_bitrate or (\nself.__default_video_framerate and self.__default_video_resolution\n):\nself.__contains_video = True\nelif self.__default_audio_bitrate or self.__default_audio_samplerate:\nself.__contains_audio = True\nelse:\nraise ValueError(\n\"Invalid source with no decodable audio or video stream provided. Aborting!\"\n)\n# calculate approximate number of video frame\nif self.__default_video_framerate and self.__default_source_duration:\nself.__approx_video_nframes = np.rint(\nself.__default_video_framerate * self.__default_source_duration\n).astype(int, casting=\"unsafe\")\n# signal metadata has been probed\nself.__metadata_probed = True\n# return reference to the instance object.\nreturn self\n</code></pre>"},{"location":"reference/sourcer/#deffcode.sourcer.Sourcer.retrieve_metadata","title":"<code>retrieve_metadata(self, pretty_json=False, force_retrieve_missing=False)</code>","text":"<p>This method returns Parsed/Probed Metadata of the given source.</p> <p>Parameters:</p> Name Type Description Default <code>pretty_json</code> <code>bool</code> <p>whether to return metadata as JSON string(if <code>True</code>) or Dictionary(if <code>False</code>) type?</p> <code>False</code> <code>force_retrieve_output</code> <code>bool</code> <p>whether to also return metadata missing in current Pipeline. This method returns <code>(metadata, metadata_missing)</code> tuple if <code>force_retrieve_output=True</code> instead of <code>metadata</code>.</p> required <p>Returns: <code>metadata</code> or <code>(metadata, metadata_missing)</code>, formatted as JSON string or python dictionary.</p> Source code in <code>deffcode/sourcer.py</code> <pre><code>def retrieve_metadata(self, pretty_json=False, force_retrieve_missing=False):\n\"\"\"\n    This method returns Parsed/Probed Metadata of the given source.\n    Parameters:\n        pretty_json (bool): whether to return metadata as JSON string(if `True`) or Dictionary(if `False`) type?\n        force_retrieve_output (bool): whether to also return metadata missing in current Pipeline. This method returns `(metadata, metadata_missing)` tuple if `force_retrieve_output=True` instead of `metadata`.\n    **Returns:** `metadata` or `(metadata, metadata_missing)`, formatted as JSON string or python dictionary.\n    \"\"\"\n# check if metadata has been probed or not\nassert (\nself.__metadata_probed\n), \"Source Metadata not been probed yet! Check if you called `probe_stream()` method.\"\n# log it\nself.__verbose_logs and logger.debug(\"Extracting Metadata...\")\n# create metadata dictionary from information populated in private class variables\nmetadata = {\n\"ffmpeg_binary_path\": self.__ffmpeg,\n\"source\": self.__source,\n}\nmetadata_missing = {}\n# Only either `source_demuxer` or `source_extension` attribute can be\n# present in metadata.\nif self.__source_demuxer is None:\nmetadata.update({\"source_extension\": os.path.splitext(self.__source)[-1]})\n# update missing\nforce_retrieve_missing and metadata_missing.update({\"source_demuxer\": \"\"})\nelse:\nmetadata.update({\"source_demuxer\": self.__source_demuxer})\n# update missing\nforce_retrieve_missing and metadata_missing.update({\"source_extension\": \"\"})\n# add source video metadata properties\nmetadata.update(\n{\n\"source_video_resolution\": self.__default_video_resolution,\n\"source_video_pixfmt\": self.__default_video_pixfmt,\n\"source_video_framerate\": self.__default_video_framerate,\n\"source_video_decoder\": self.__default_video_decoder,\n\"source_duration_sec\": self.__default_source_duration,\n\"approx_video_nframes\": (\nint(self.__approx_video_nframes)\nif self.__approx_video_nframes\nelse None\n),\n\"source_video_bitrate\": self.__default_video_bitrate,\n\"source_audio_bitrate\": self.__default_audio_bitrate,\n\"source_audio_samplerate\": self.__default_audio_samplerate,\n\"source_has_video\": self.__contains_video,\n\"source_has_audio\": self.__contains_audio,\n\"source_has_image_sequence\": self.__contains_images,\n}\n)\n# add output metadata properties (if available)\nif not (self.__metadata_output is None):\nmetadata.update(\n{\n\"output_frames_resolution\": self.__output_frames_resolution,\n\"output_frames_pixfmt\": self.__output_frames_pixfmt,\n\"output_framerate\": self.__output_framerate,\n}\n)\nelse:\n# since output stream metadata properties are only available when additional\n# FFmpeg parameters(such as filters) are defined manually, thereby missing\n# output stream properties are handled by assigning them counterpart source\n# stream metadata property values\nforce_retrieve_missing and metadata_missing.update(\n{\n\"output_frames_resolution\": self.__default_video_resolution,\n\"output_frames_pixfmt\": self.__default_video_pixfmt,\n\"output_framerate\": self.__default_video_framerate,\n}\n)\n# log it\nself.__verbose_logs and logger.debug(\n\"Metadata Extraction completed successfully!\"\n)\n# parse as JSON string(`json.dumps`), if defined\nmetadata = json.dumps(metadata, indent=2) if pretty_json else metadata\nmetadata_missing = (\njson.dumps(metadata_missing, indent=2) if pretty_json else metadata_missing\n)\n# return `metadata` or `(metadata, metadata_missing)`\nreturn metadata if not force_retrieve_missing else (metadata, metadata_missing)\n</code></pre>"},{"location":"reference/sourcer/params/","title":"Sourcer API Parameters","text":""},{"location":"reference/sourcer/params/#source","title":"<code>source</code>","text":"<p>This parameter defines the input source (<code>-i</code>) for probing.</p> <p>Sourcer API will throw <code>AssertionError</code> if <code>source</code> provided is invalid or missing.</p> <p>Sourcer API checks for <code>video bitrate</code> or <code>frame-size</code> and <code>framerate</code> in video's metadata to ensure given input <code>source</code> has usable video stream available. Thereby, it will throw <code>ValueError</code> if it fails to find those parameters.</p> <p>Multiple video inputs are not yet supported!</p> <p>Data-Type: String.</p> <p>Its valid input can be one of the following: </p> <ul> <li> <p> Filepath: Valid path of the video file, for e.g <code>\"/home/foo.mp4\"</code> as follows:</p> <pre><code># initialize the sourcer and probe it\nsourcer = Sourcer('/home/foo.mp4').probe_stream()\n</code></pre> </li> <li> <p> Image Sequence: Valid image sequence such as sequential(<code>'img%03d.png'</code>) or glob pattern(<code>'*.png'</code>) or single (looping) image as input:</p> SequentialGlob patternSingle (loop) image How to start with specific number image? <p>You can use <code>-start_number</code> FFmpeg parameter if you want to start with specific number image:</p> <pre><code># define `-start_number` such as `5`\nsourcer_params = {\"-ffprefixes\":[\"-start_number\", \"5\"]}\n# initialize the sourcer with define parameters\nsourcer = Sourcer('img%03d.png', verbose=True, **sourcer_params).probe_stream()\n</code></pre> <pre><code># initialize the sourcer and probe it\nsourcer = Sourcer('img%03d.png', verbose=True).probe_stream()\n</code></pre> <p>Bash-style globbing (<code>*</code> represents any number of any characters) is useful if your images are sequential but not necessarily in a numerically sequential order.</p> <p>The glob pattern is not available on Windows builds.</p> <pre><code># define `-pattern_type glob` for accepting glob pattern\nsourcer_params = {\"-ffprefixes\":[\"-pattern_type\", \"glob\"]}\n# initialize the sourcer with define parameters and probe it\nsourcer = Sourcer('img*.png', verbose=True, **sourcer_params).probe_stream()\n</code></pre> <pre><code># define `-loop 1` for looping\nsourcer_params = {\"-ffprefixes\":[\"-loop\", \"1\"]}\n# initialize the sourcer with define parameters and probe it\nsourcer = Sourcer('img.jpg', verbose=True, **sourcer_params).probe_stream()\n</code></pre> </li> <li> <p> Network Address: Valid (<code>http(s)</code>, <code>rtp</code>, <code>rstp</code>, <code>rtmp</code>, <code>mms</code>, etc.) incoming network stream address such as <code>'rtsp://xx:yy@192.168.1.ee:fd/av0_0'</code> as input:</p> <pre><code># define `rtsp_transport` or necessary parameters \nsourcer_params = {\"-ffprefixes\":[\"-rtsp_transport\", \"tcp\"]}\n# initialize the sourcer with define parameters and probe it\nsourcer = Sourcer('rtsp://xx:yy@192.168.1.ee:fd/av0_0', verbose=True, **sourcer_params).probe_stream()\n</code></pre> </li> <li> <p> Camera Device Index: Valid \"device index\" or \"camera index\" of the connected Camera Device. For example, for using <code>\"0\"</code> index device as source on  Windows, we can do as follows in Sourcer API: </p> Requirement for using Camera Device as source in Sourcer API <ul> <li> <p> MUST have appropriate FFmpeg binaries, Drivers, and Softwares installed:</p> <p>Internally, DeFFcode APIs achieves Index based Camera Device Capturing by employing some specific FFmpeg demuxers on different platforms(OSes). These platform specific demuxers are as follows:</p> Platform(OS) Demuxer  Windows OS <code>dshow</code> (or DirectShow)  Linux OS <code>video4linux2</code> (or its alias <code>v4l2</code>)  Mac OS <code>avfoundation</code> <p> Important: Kindly make sure your FFmpeg binaries support these platform specific demuxers as well as system have the appropriate video drivers and related softwares installed.</p> </li> <li> <p> The <code>source</code> parameter value MUST be any Camera Device index that can be of either integer (e.g. <code>-1</code>,<code>0</code>,<code>1</code>, etc.) or string of integer (e.g. <code>\"-1\"</code>,<code>\"0\"</code>,<code>\"1\"</code>, etc.) type.</p> </li> <li> <p> The <code>source_demuxer</code> parameter value  MUST be either <code>None</code>(also means empty) or <code>\"auto\"</code>. </p> </li> </ul> <pre><code># initialize the sourcer with \"0\" index source and probe it\nsourcer = Sourcer(\"0\", verbose=True).probe_stream()\n</code></pre> </li> <li> <p> Video Capture Devices: Valid video probe device's name (e.g. <code>\"USB2.0 Camera\"</code>) or its path (e.g. <code>\"/dev/video0\"</code> on linux) or its index (e.g. <code>\"0\"</code>) as input  w.r.t <code>source_demuxer</code> parameter value in use. For example, for probing <code>\"USB2.0 Camera\"</code> named device with <code>dshow</code> source demuxer on  Windows, we can do as follows in Sourcer API: </p> Identifying and Specifying Device name/path/index and suitable Demuxer on different OSes  Windows Linux MacOS <p>Windows OS users can use the dshow (DirectShow) to list video input device which is the preferred option for Windows users. You can refer following steps to identify and specify your input video device's name:</p> <ul> <li> <p> Identify Video Devices: You can locate your video device's name (already connected to your system) using <code>dshow</code> as follows:</p> <pre><code>c:\\&gt; ffmpeg.exe -list_devices true -f dshow -i dummy\n\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[dshow @ 03ACF580] DirectShow video devices\n[dshow @ 03ACF580]  \"Integrated Camera\"\n[dshow @ 03ACF580]  \"USB2.0 Camera\"\n[dshow @ 03ACF580] DirectShow audio devices\n[dshow @ 03ACF580]  \"Microphone (Realtek High Definition Audio)\"\n[dshow @ 03ACF580]  \"Microphone (USB2.0 Camera)\"\ndummy: Immediate exit requested\n</code></pre> </li> <li> <p> Specify Video Device's name: Then, you can specify and initialize your located Video device's name in Sourcer API as follows:</p> <pre><code># initialize the sourcer with \"USB2.0 Camera\" source and probe it\nsourcer = Sourcer(\"USB2.0 Camera\", source_demuxer=\"dshow\", verbose=True).probe_stream()\n</code></pre> </li> <li> <p> [OPTIONAL] Specify Video Device's index along with name: If there are multiple Video devices with similar name, then you can use <code>-video_device_number</code> parameter to specify the arbitrary index of the particular device. For instance, to open second video device with name <code>\"Camera\"</code> you can do as follows:</p> <pre><code># define video_device_number as 1 (numbering start from 0)\nsourcer_params = {\"-ffprefixes\":[\"-video_device_number\", \"1\"]}\n# initialize the sourcer with \"Camera\" source and probe it\nsourcer = Sourcer(\"Camera\", source_demuxer=\"dshow\", verbose=True, **sourcer_params).probe_stream()\n</code></pre> </li> </ul> <p>Linux OS users can use the <code>video4linux2</code> (or its alias <code>v4l2</code>) to list to all video capture devices such as from an USB webcam. You can refer following steps to identify and specify your probe video device's path:</p> <ul> <li> <p> Identify Video Devices: Linux systems tend to automatically create file device node/path when the device (e.g. an USB webcam) is plugged into the system, and has a name of the kind <code>'/dev/videoN'</code>, where <code>N</code> is a index associated to the device. To get the list of all available file device node/path on your Linux machine, you can use the <code>v4l-ctl</code> command.</p> <p>You can use <code>sudo apt install v4l-utils</code> APT command to install <code>v4l-ctl</code> tool on Debian-based Linux distros.</p> <pre><code>$ v4l2-ctl --list-devices\n\nUSB2.0 PC CAMERA (usb-0000:00:1d.7-1):\n        /dev/video1\n\nUVC Camera (046d:0819) (usb-0000:00:1d.7-2):\n        /dev/video0\n</code></pre> </li> <li> <p> Specify Video Device's path: Then, you can specify and initialize your located Video device's path in Sourcer API as follows:</p> <pre><code># initialize the sourcer with \"/dev/video0\" source and probe it\nsourcer = Sourcer(\"/dev/video0\", source_demuxer=\"v4l2\", verbose=True).probe_stream()\n</code></pre> </li> </ul> <p>MacOS users can use the AVFoundation to list input devices and is the currently recommended framework by Apple for streamgrabbing on Mac OSX-10.7 (Lion) and later as well as on iOS. You can refer following steps to identify and specify your probe video device's name or index on MacOS/OSX machines:</p> <p>QTKit is also available for streamgrabbing on Mac OS X 10.4 (Tiger) and later, but has been marked deprecated since OS X 10.7 (Lion) and may not be available on future releases.</p> <ul> <li> <p> Identify Video Devices: Then, You can locate your Video device's name and index using <code>avfoundation</code> as follows:</p> <pre><code>$ ffmpeg -f avfoundation -list_devices true -i \"\"\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation video devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] FaceTime HD camera (built-in)\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Capture screen 0\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation audio devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] Blackmagic Audio\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Built-in Microphone\n</code></pre> </li> <li> <p> Specify Video Device's name or index: Then, you can specify and initialize your located Video device in Sourcer API using its either the name or the index shown in the device listing:</p> Using device's indexUsing device's name <pre><code># initialize the sourcer with `1` index source and probe it\nsourcer = Sourcer(\"1\", source_demuxer=\"avfoundation\", verbose=True).probe_stream()\n</code></pre> <p>When specifying device's name, abbreviations using just the beginning of the device name are possible. Thus, to probe from a device named \"Integrated iSight-camera\" just \"Integrated\" is sufficient:</p> <pre><code># initialize the sourcer with \"Integrated iSight-camera\" source \nsourcer = Sourcer(\"Integrated\", source_demuxer=\"avfoundation\", verbose=True).probe_stream()\n</code></pre> </li> </ul> <p>If these steps doesn't work for you then reach us out on Gitter \u27b6 Community channel</p> <pre><code># initialize the sourcer with \"USB2.0 Camera\" source \nsourcer = Sourcer(\"USB2.0 Camera\", source_demuxer=\"dshow\", verbose=True).probe_stream()\n</code></pre> </li> <li> <p> Screen Capturing/Recording: Valid screen probe device's name (e.g. <code>\"desktop\"</code>) or its index (e.g. <code>\":0.0\"</code>) as input w.r.t <code>source_demuxer</code> parameter value in use. For example, for probing <code>\"0:\"</code> indexed device with <code>avfoundation</code> source demuxer on  MacOS, we can do as follows in Sourcer API: </p> Specifying suitable Parameter(s) and Demuxer for Capturing your Desktop on different OSes  Windows Linux MacOS <p>Windows OS users can use the gdigrab to grab video from the Windows screen. You can refer following steps to specify source for probing:</p> <p>For Windows OS users <code>dshow</code> is also available for grabbing frames from your desktop. But it is highly unreliable and don't works most of the times.</p> <pre><code># define framerate\nsourcer_params = {\"-framerate\": \"30\"}\n# initialize the sourcer with \"desktop\" source and probe it\nsourcer = Sourcer(\"desktop\", source_demuxer=\"gdigrab\", verbose=True, **sourcer_params).probe_stream()\n</code></pre> <p>Linux OS users can use the x11grab to probe an X11 display. You can refer following steps to specify source for probing:</p> <pre><code># initialize the sourcer with \":0.0\" desktop source and probe it\nsourcer = Sourcer(\":0.0\", source_demuxer=\"x11grab\", verbose=True).probe_stream()\n</code></pre> <p>MacOS users can use the AVFoundation to list input devices and is the currently recommended framework by Apple for streamgrabbing on Mac OSX-10.7 (Lion) and later as well as on iOS. You can refer following steps to identify and specify your probe video device's name or index in Sourcer API:</p> <p>QTKit is also available for streamgrabbing on Mac OS X 10.4 (Tiger) and later, but has been marked deprecated since OS X 10.7 (Lion) and may not be available on future releases.</p> <p>You can enumerate all the available input devices including screens ready to be probed using <code>avfoundation</code> as follows:</p> <pre><code>$ ffmpeg -f avfoundation -list_devices true -i \"\"\nffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect\n  libavutil      51. 74.100 / 51. 74.100\n  libavcodec     54. 65.100 / 54. 65.100\n  libavformat    54. 31.100 / 54. 31.100\n  libavdevice    54.  3.100 / 54.  3.100\n  libavfilter     3. 19.102 /  3. 19.102\n  libswscale      2.  1.101 /  2.  1.101\n  libswresample   0. 16.100 /  0. 16.100\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation video devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] FaceTime HD camera (built-in)\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Capture screen 0\n[AVFoundation input device @ 0x7f8e2540ef20] AVFoundation audio devices:\n[AVFoundation input device @ 0x7f8e2540ef20] [0] Blackmagic Audio\n[AVFoundation input device @ 0x7f8e2540ef20] [1] Built-in Microphone\n</code></pre> <p>Then, you can specify and initialize your located screens in Sourcer API using its index shown:</p> <pre><code># initialize the sourcer with `0:` index desktop screen and probe it\nsourcer = Sourcer(\"0:\", source_demuxer=\"avfoundation\", verbose=True).probe_stream()\n</code></pre> <p>If these steps doesn't work for you then reach us out on Gitter \u27b6 Community channel</p> <pre><code># initialize the sourcer with \"0:\" source and probe it\nsourcer = Sourcer(\"0:\", source_demuxer=\"avfoundation\", verbose=True).probe_stream()\n</code></pre> </li> <li> <p> Virtual Sources: Valid filtergraph to use as input with <code>lavfi</code> (Libavfilter input virtual device) source that reads data from the open output pads of a libavfilter filtergraph. For example, for generating and probing Mandelbrot graph of <code>1280x720</code> frame size and <code>30</code> framerate using <code>lavfi</code> input virtual device, we can do as follows in Sourcer API: </p> <pre><code># initialize the sourcer with \"mandelbrot\" source of\n# `1280x720` frame size and `30` framerate and probe it\nsourcer = Sourcer(\n\"mandelbrot=size=1280x720:rate=30\",\nsource_demuxer=\"lavfi\",\nframe_format=\"bgr24\",\n).probe_stream()\n</code></pre> </li> </ul> <p> </p>"},{"location":"reference/sourcer/params/#source_demuxer","title":"<code>source_demuxer</code>","text":"<p>This parameter specifies the demuxer(<code>-f</code>) for the input source (such as <code>dshow</code>, <code>v4l2</code>, <code>gdigrab</code> etc.) to support Live Feed Devices, as well as <code>lavfi</code> (Libavfilter input virtual device) that reads data from the open output pads of a libavfilter filtergraph. </p> <p>Any invalid or unsupported value to <code>source_demuxer</code> parameter value will raise <code>Assertion</code> error!</p> <p>Use <code>ffmpeg -demuxers</code> terminal command to lists all FFmpeg supported demuxers.</p> Specifying <code>source_demuxer</code> for using Camera Device Index as source in Sourcer API <p>For using Camera Device Index as source in Sourcer API, the <code>source_demuxer</code> parameter value  MUST be either <code>None</code>(also means empty) or <code>\"auto\"</code>:</p> <code>source_demuxer=None</code> (Default and Recommended)<code>source_demuxer=\"auto\"</code> <pre><code># initialize the sourcer with \"0\" index source and probe it\nsourcer = Sourcer(\"0\").probe_stream()\n</code></pre> <pre><code># initialize the sourcer with \"0\" index source and probe it\nsourcer = Sourcer(\"0\", source_demuxer=\"auto).probe_stream()\n</code></pre> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>.</p> <p>Usage:</p> <pre><code># initialize the sourcer with `dshow` demuxer and probe it\nsourcer = Sourcer(\"foo.mp4\", source_demuxer=\"dshow\").probe_stream()\n</code></pre> <p> </p>"},{"location":"reference/sourcer/params/#custom_ffmpeg","title":"<code>custom_ffmpeg</code>","text":"<p>This parameter can be used to manually assigns the system file-path/directory where the custom or downloaded FFmpeg executable is located.</p> Behavior on Windows  <p>If custom FFmpeg executable binary file-path/directory is not assigned through <code>custom_ffmpeg</code> parameter on Windows machine, then Sourcer API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine. More information can be found here \u27b6.</p> How to change FFmpeg Static Binaries download directory? <p>You can use <code>-ffmpeg_download_path</code> exclusive parameter in Sourcer API to set the custom directory for downloading FFmpeg Static Binaries during the Auto-Installation step on Windows Machines. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. <code>C:/User/temp</code>) on your windows machine. It can be used as follows in Sourcer API:</p> <pre><code># # define suitable parameter to download at \"C:/User/foo/foo1\"\nsourcer_params = {\"-ffmpeg_download_path\": \"C:/User/foo/foo1\"}\n# initialize the sourcer\nSourcer(\"foo.mp4\", verbose=True, **sourcer_params).probe_stream()\n</code></pre> <p>If binaries were not found at the manually specified path, DeFFcode APIs will throw RuntimeError!</p> <p>Data-Type: String</p> <p>Default Value: Its default value is <code>None</code>.</p> <p>Usage:</p> <pre><code># If ffmpeg executables are located at \"/foo/foo1/ffmpeg\"\nSourcer(\"foo.mp4\", custom_ffmpeg=\"/foo/foo1/ffmpeg\").probe_stream()\n</code></pre> <p> </p>"},{"location":"reference/sourcer/params/#verbose","title":"<code>verbose</code>","text":"<p>This parameter enables verbose logs (if <code>True</code>), essential for debugging. </p> <p>Data-Type: Boolean</p> <p>Default Value: Its default value is <code>False</code>.</p> <p>Usage:</p> <pre><code># initialize the sourcer with verbose logs\nSourcer(\"foo.mp4\", verbose=True).probe_stream()\n</code></pre> <p> </p>"},{"location":"reference/sourcer/params/#sourcer_params","title":"<code>sourcer_params</code>","text":"<p>This dictionary parameter accepts all Exclusive Parameters formatted as its attributes:</p> Additional FFmpeg parameters <p>In addition to Exclusive Parameters, Sourcer API supports almost any FFmpeg parameter (supported by installed FFmpeg), and thereby can be passed as dictionary attributes in <code>sourcer_params</code> parameter.</p> <p>Kindly read FFmpeg Docs carefully before passing any additional values to <code>sourcer_params</code> parameter. Wrong invalid values may result in undesired errors or no output at all.</p> <p>All FFmpeg parameters are case-sensitive. Remember to double check every parameter if any error(s) occurred.</p> <p>Data-Type: Dictionary</p> <p>Default Value: Its default value is <code>{}</code>.</p>"},{"location":"reference/sourcer/params/#exclusive-parameters","title":"Exclusive Parameters","text":"<p>Sourcer API supports few Exclusive Parameters to allow users to flexibly change its probing properties and handle some special FFmpeg parameters.</p> <p>These parameters are discussed below:</p> <ul> <li> <p><code>-ffprefixes</code> (list): This attribute sets the special FFmpeg parameters that generally occurs at the very beginning (such as <code>-re</code>) before input (<code>-i</code>) source. The FFmpeg parameters defined with this attribute can repeated more than once and maintains its original order in the FFmpeg command. Its value can be of datatype <code>list</code> only and its usage is as follows: </p> <p>Turn on <code>verbose</code> parameter (<code>verbose = True</code>) to see the FFmpeg command that is being executed in Sourcer's pipeline. This helps you debug/address any issues and make adjustments accordingly.</p> <pre><code># define suitable parameter\nsourcer_params = {\"-ffprefixes\": ['-re']} # executes as `ffmpeg -re &lt;rest of command&gt;`\n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-ffmpeg_download_path</code> (string): sets the custom directory for downloading FFmpeg Static Binaries in Compression Mode, during the Auto-Installation on Windows Machines Only. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. <code>C:/User/temp</code>) on your windows machine. It can be used as follows: </p> <pre><code>sourcer_params = {\"-ffmpeg_download_path\": \"C:/User/foo/foo1\"} # will be saved to \"C:/User/foo/foo1\"\n</code></pre> </li> </ul> <p> </p> <ul> <li> <p><code>-force_validate_source</code> (bool): forcefully passes validation test for given <code>source</code> which is required for some special cases with unusual input. It can be used as follows: </p> <p><pre><code>sourcer_params = {\"-force_validate_source\": True} # will pass validation test forcefully\n</code></pre> </p> </li> </ul>"}]}