{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 A cross-platform High-performance Video Frames Decoder that flexibly executes FFmpeg pipeline inside a subprocess pipe for generating real-time, low-overhead, lightning fast video frames with robust error-handling in just a few lines of python code Highly Adaptive - DeFFcode APIs implements a standalone highly-extensible wrapper around FFmpeg multimedia framework. These APIs supports a wide-ranging media streams as input source such as live USB/Virtual/IP camera feeds, regular multimedia files, screen recordings, image sequences, network protocols (such as HTTP(s), RTP/RSTP, etc.) , so on and so forth. Highly Flexible - DeFFcode APIs gains an edge over other Wrappers by providing complete control over the underline pipeline including access to almost any FFmpeg specification thinkable such as specifying framerate, resolution, hardware decoder(s), filtergraph(s), and pixel-format(s) that are readily supported by all well known Computer Vision libraries . Highly Convenient - FFmpeg has a steep learning curve especially for users unfamiliar with a command line interface. DeFFcode helps users by keeping the same OpenCV-Python (Python API for OpenCV) coding syntax for its APIs , thereby making it even easier to learn, create, and develop FFmpeg based apps in Python. \u2009 Key features of DeFFcode \u00b6 Here are some key features that stand out: High-performance, low-overhead video frames decoding with robust error-handling. Flexible API with access to almost any FFmpeg specification thinkable. Supports a wide-range of media streams/devices/protocols as input source. Curated list of well-documented recipes ranging from Basic to Advanced skill levels. Memory efficient Live Simple & Complex Filtergraphs . (Yes, You read it correctly \"Live\"!) Lightning fast dedicated GPU-Accelerated Video Decoding & Transcoding . Enables precise FFmpeg Frame Seeking with pinpoint accuracy. Effortless Metadata Extraction from all streams available in the source. Maintains the standard easy to learn OpenCV-Python coding syntax. Out-of-the-box support for all prominent Computer Vision libraries. Cross-platform, runs on Python 3.7+, and easy to install. Still missing a key feature in DeFFcode? Please review DeFFcode's Roadmap . If you still can't find the desired feature there, then you can request one simply by Commenting or Upvoting an existing comment on that issue . Getting Started \u00b6 In case you're run into any problems, consult our Help section . Installation Notes \u00b6 If this is your first time using DeFFcode, head straight to the Installation Notes to install DeFFcode on your machine . Recipes a.k.a Examples \u00b6 Once you have DeFFcode installed, checkout our Well-Documented Recipes for usage examples : How to Begin? If you\u2019re just starting, check out the Beginner Basic Recipes and as your confidence grows, move up to Advanced Recipes . Basic Recipes : Recipes for beginners of any skill level to get started. Advanced Recipes : Recipes to take your skills to the next level. API in a nutshell \u00b6 As a user, you just have to remember only two DeFFcode APIs, namely: See API Reference for more in-depth information. A. FFdecoder API \u00b6 The primary function of FFdecoder API is to decode 24-bit RGB video frames from the given source: # import the necessary packages from deffcode import FFdecoder # formulate the decoder with suitable source decoder = FFdecoder ( \"https://abhitronix.github.io/html/Big_Buck_Bunny_1080_10s_1MB.mp4\" ) . formulate () # grab RGB24(default) 3D frames from decoder for frame in decoder . generateFrame (): # lets print its shape print ( frame . shape ) # (1080, 1920, 3) # terminate the decoder decoder . terminate () B. Sourcer API \u00b6 The primary function of Sourcer API is to gather information from all multimedia streams available in the given source: # import the necessary packages from deffcode import Sourcer # initialize and formulate the decoder using suitable source sourcer = Sourcer ( \"https://abhitronix.github.io/html/Big_Buck_Bunny_1080_10s_1MB.mp4\" ) . probe_stream () # print metadata as `json.dump` print ( sourcer . retrieve_metadata ( pretty_json = True )) The resultant Terminal Output will look something as following on Windows machine: { \"ffmpeg_binary_path\" : \"C:\\\\Users\\\\foo\\\\AppData\\\\Local\\\\Temp\\\\ffmpeg-static-win64-gpl/bin/ffmpeg.exe\" , \"source\" : \"https://abhitronix.github.io/html/Big_Buck_Bunny_1080_10s_1MB.mp4\" , \"source_extension\" : \".mp4\" , \"source_video_resolution\" : [ 1920 , 1080 ], \"source_video_framerate\" : 60.0 , \"source_video_pixfmt\" : \"yuv420p\" , \"source_video_decoder\" : \"h264\" , \"source_duration_sec\" : 10.0 , \"approx_video_nframes\" : 600 , \"source_video_bitrate\" : \"832k\" , \"source_audio_bitrate\" : \"\" , \"source_audio_samplerate\" : \"\" , \"source_has_video\" : true , \"source_has_audio\" : false , \"source_has_image_sequence\" : false } Contribution Guidelines \u00b6 Contributions are welcome, and greatly appreciated! Please read our Contribution Guidelines for more details. Community Channel \u00b6 If you've come up with some new idea, or looking for the fastest way troubleshoot your problems. Please checkout our Gitter community channel \u27b6 Become a Stargazer \u00b6 You can be a Stargazer by starring us on Github, it helps us a lot and you're making it easier for others to find & trust this library. Thanks! Donations \u00b6 DeFFcode is free and open source and will always remain so. It is something I am doing with my own free time. But so much more needs to be done, and I need your help to do this. For just the price of a cup of coffee, you can make a difference kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw(); Citation \u00b6 Here is a Bibtex entry you can use to cite this project in a publication: @software { deffcode , author = {Abhishek Thakur} , title = {abhiTronix/deffcode: v0.2.3} , month = aug , year = 2022 , publisher = {Zenodo} , version = {v0.2.3} , doi = {10.5281/zenodo.6984364} , url = {https://doi.org/10.5281/zenodo.6984364} }","title":"Introduction"},{"location":"#introduction","text":"A cross-platform High-performance Video Frames Decoder that flexibly executes FFmpeg pipeline inside a subprocess pipe for generating real-time, low-overhead, lightning fast video frames with robust error-handling in just a few lines of python code Highly Adaptive - DeFFcode APIs implements a standalone highly-extensible wrapper around FFmpeg multimedia framework. These APIs supports a wide-ranging media streams as input source such as live USB/Virtual/IP camera feeds, regular multimedia files, screen recordings, image sequences, network protocols (such as HTTP(s), RTP/RSTP, etc.) , so on and so forth. Highly Flexible - DeFFcode APIs gains an edge over other Wrappers by providing complete control over the underline pipeline including access to almost any FFmpeg specification thinkable such as specifying framerate, resolution, hardware decoder(s), filtergraph(s), and pixel-format(s) that are readily supported by all well known Computer Vision libraries . Highly Convenient - FFmpeg has a steep learning curve especially for users unfamiliar with a command line interface. DeFFcode helps users by keeping the same OpenCV-Python (Python API for OpenCV) coding syntax for its APIs , thereby making it even easier to learn, create, and develop FFmpeg based apps in Python.","title":"Introduction"},{"location":"#key-features-of-deffcode","text":"Here are some key features that stand out: High-performance, low-overhead video frames decoding with robust error-handling. Flexible API with access to almost any FFmpeg specification thinkable. Supports a wide-range of media streams/devices/protocols as input source. Curated list of well-documented recipes ranging from Basic to Advanced skill levels. Memory efficient Live Simple & Complex Filtergraphs . (Yes, You read it correctly \"Live\"!) Lightning fast dedicated GPU-Accelerated Video Decoding & Transcoding . Enables precise FFmpeg Frame Seeking with pinpoint accuracy. Effortless Metadata Extraction from all streams available in the source. Maintains the standard easy to learn OpenCV-Python coding syntax. Out-of-the-box support for all prominent Computer Vision libraries. Cross-platform, runs on Python 3.7+, and easy to install. Still missing a key feature in DeFFcode? Please review DeFFcode's Roadmap . If you still can't find the desired feature there, then you can request one simply by Commenting or Upvoting an existing comment on that issue .","title":"Key features of DeFFcode"},{"location":"#getting-started","text":"In case you're run into any problems, consult our Help section .","title":"Getting Started"},{"location":"#installation-notes","text":"If this is your first time using DeFFcode, head straight to the Installation Notes to install DeFFcode on your machine .","title":" Installation Notes"},{"location":"#recipes-aka-examples","text":"Once you have DeFFcode installed, checkout our Well-Documented Recipes for usage examples : How to Begin? If you\u2019re just starting, check out the Beginner Basic Recipes and as your confidence grows, move up to Advanced Recipes . Basic Recipes : Recipes for beginners of any skill level to get started. Advanced Recipes : Recipes to take your skills to the next level.","title":" Recipes a.k.a Examples"},{"location":"#api-in-a-nutshell","text":"As a user, you just have to remember only two DeFFcode APIs, namely: See API Reference for more in-depth information.","title":" API in a nutshell"},{"location":"#a-ffdecoder-api","text":"The primary function of FFdecoder API is to decode 24-bit RGB video frames from the given source: # import the necessary packages from deffcode import FFdecoder # formulate the decoder with suitable source decoder = FFdecoder ( \"https://abhitronix.github.io/html/Big_Buck_Bunny_1080_10s_1MB.mp4\" ) . formulate () # grab RGB24(default) 3D frames from decoder for frame in decoder . generateFrame (): # lets print its shape print ( frame . shape ) # (1080, 1920, 3) # terminate the decoder decoder . terminate ()","title":"A. FFdecoder API"},{"location":"#b-sourcer-api","text":"The primary function of Sourcer API is to gather information from all multimedia streams available in the given source: # import the necessary packages from deffcode import Sourcer # initialize and formulate the decoder using suitable source sourcer = Sourcer ( \"https://abhitronix.github.io/html/Big_Buck_Bunny_1080_10s_1MB.mp4\" ) . probe_stream () # print metadata as `json.dump` print ( sourcer . retrieve_metadata ( pretty_json = True )) The resultant Terminal Output will look something as following on Windows machine: { \"ffmpeg_binary_path\" : \"C:\\\\Users\\\\foo\\\\AppData\\\\Local\\\\Temp\\\\ffmpeg-static-win64-gpl/bin/ffmpeg.exe\" , \"source\" : \"https://abhitronix.github.io/html/Big_Buck_Bunny_1080_10s_1MB.mp4\" , \"source_extension\" : \".mp4\" , \"source_video_resolution\" : [ 1920 , 1080 ], \"source_video_framerate\" : 60.0 , \"source_video_pixfmt\" : \"yuv420p\" , \"source_video_decoder\" : \"h264\" , \"source_duration_sec\" : 10.0 , \"approx_video_nframes\" : 600 , \"source_video_bitrate\" : \"832k\" , \"source_audio_bitrate\" : \"\" , \"source_audio_samplerate\" : \"\" , \"source_has_video\" : true , \"source_has_audio\" : false , \"source_has_image_sequence\" : false }","title":"B. Sourcer API"},{"location":"#contribution-guidelines","text":"Contributions are welcome, and greatly appreciated! Please read our Contribution Guidelines for more details.","title":"Contribution Guidelines"},{"location":"#community-channel","text":"If you've come up with some new idea, or looking for the fastest way troubleshoot your problems. Please checkout our Gitter community channel \u27b6","title":"Community Channel"},{"location":"#become-a-stargazer","text":"You can be a Stargazer by starring us on Github, it helps us a lot and you're making it easier for others to find & trust this library. Thanks!","title":"Become a Stargazer"},{"location":"#donations","text":"DeFFcode is free and open source and will always remain so. It is something I am doing with my own free time. But so much more needs to be done, and I need your help to do this. For just the price of a cup of coffee, you can make a difference kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw();","title":"Donations"},{"location":"#citation","text":"Here is a Bibtex entry you can use to cite this project in a publication: @software { deffcode , author = {Abhishek Thakur} , title = {abhiTronix/deffcode: v0.2.3} , month = aug , year = 2022 , publisher = {Zenodo} , version = {v0.2.3} , doi = {10.5281/zenodo.6984364} , url = {https://doi.org/10.5281/zenodo.6984364} }","title":"Citation"},{"location":"changelog/","text":"Release Notes \u00b6 v0.2.3 (2022-08-11) \u00b6 New Features Docs: Added Zenodo Bibtex entry and badge in docs for easy citation. Added new <div> tag bounding-box style to the Static FFmpeg binary download links in FFmpeg Installation Doc for better accessibility. Maintenance: Switched to new Issue GitHub's form schema using YAML: Added new bug_report.yaml Issue GitHub's form schema for Bug Reports. Added new idea.yaml Issue GitHub's form schema for new Ideas. Added new question.yaml Issue GitHub's form schema for Questions. Deleted old depreciated markdown( .md ) files. Polished forms. Updates/Improvements Maintenance: Added new patterns to .gitignore to ignore vim files. CI: Updated test_FFdecoder_params unittest to include with statement access method. Setup: Added new patches for using README.md text as long_description metadata. Implemented new patch to remove GitHub README UI specific text. Simplified multiple str.replace to chained str.replace of better readability. Bumped version to 0.2.3 . Docs: Updated recipes to include with statement access method. Updated existing recipes to include with statement access method in FFdecoder APIs. Included new example code of accessing RGB frames using with statement access method. Updated Recipe title to \"Accessing RGB frames from a video file\" across docs. Included warning admonition for advising users to always use trim with reverse filter. Updated docs text font to Libre Franklin . Updated method description texts and logging messages. Update icons and admonition messages. Updated code comments. Updated changelog.md . Bug-fixes FFdecoder API: Fixed Context Manager methods. Fixed __enter__ method returning class instance instead of formulating pipeline. Fixed __exit__ method calling wrong non-existent method. Setup: Fixed missing comma(,) in keywords metadata. Fixed bug in patch string. Docs: Fixed typos in code comments. Fixed several typos in docs. Pull Requests PR #26 v0.2.2 (2022-08-09) \u00b6 New Features Sourcer API: Added support for -ffprefixes attribute through Sourcer API's sourcer_param dictionary parameter (similar to FFdecoder API) . FFdecoder API: Added new output_frames_pixfmt metadata property to preview and handle output frames pixel-format. Docs: Added separate \"Basic\" and \"Advanced\" Recipes markdowns files with self-explanatory text, related usage code, asset (such as images, diagrams, GIFs, etc.) , and UI upgrades for bringing standard quality to visual design. Added separate index.md for Basic and Advanced Recipes with introductory text and curated hyperlinks for quick references to various recipes (separated with sub-categories \"Decoding\", \"Transcoding\", and \"Extracting Video Metadata\") . Added related admonitions to specify python dependencies as well as other requirements and relevant information required for each of these recipes. Added new Basic Decoding Recipes: Added Decoding Video files with various pixel formats recipes. Added Decoding Live Feed Devices recipes with source_demuxer FFdecoder API parameter. Added Decoding Image sequences recipes supporting Sequential, Glob pattern , Single (looping) image. Added Decoding Network Streams recipes. Added new Basic Transcoding Recipes: Added Transcoding Live frames recipes with OpenCV and WriteGear. Added Transcoding Live Simple Filtergraphs recipes with OpenCV. Added Saving Key-frames as Image recipes with different image processing libraries. Added new Basic Extracting Video Metadata Recipes: Added Extracting Video Metadata recipes with FFdecoder and Sourcer APIs. Added new Advanced Decoding Recipes: Added Hardware-Accelerated Video Decoding recipe using NVIDIA's H.264 CUVID Video-decoder( h264_cuvid ). Added Decoding Live Virtual Sources recipes with many test patterns using lavfi input virtual device. Added new Advanced Decoding Recipes: Added lossless Hardware-Accelerated Video Transcoding recipe with WriteGear API. Added Transcoding Live Complex Filtergraphs recipes with WriteGear API. Added Transcoding Video Art with Filtergraphs recipes with WriteGear API for creating real-time artistic generative video art using simple and complex filtergraphs. Added new Advanced Updating Video Metadata Recipes: Added Updating Video Metadata recipes with user-defined as well as source metadata in FFdecoder API. Added new dark and light theme logo support. Added new recipes GIF assets to gifs folder. Added new dark logo deffcode-dark.png asset to images folder. Added new ffdecoder.png and sourcer.png Image assets to images folder. Added new navigation.tabs feature. Added Material Announcement-Bar notifying recent changes. Updates/Improvements Sourcer API: Implemented new validation checks to ensure given source has usable video stream available by checking availability of either video bitrate or both frame-size and framerate _ properties in the source metadata. Improved extract_resolution_framerate method for making framerate extraction more robust by falling back to extracting TBR value when no framerate value available in the source metadata. FFdecoder API: Updated metadata property object to validate and override source metadata properties directly by overloading same property object before formulating Frames Decoder Pipeline: Implemented validation checks to verify each validate manually assigned source metadata property against specific datatype before overriding. Updated logging to notify invalid datatype values when assigned through metadata property object. Added support for overriding source_video_resolution source metadata property to control frame-size directly through metadata. Added support for overriding output_frames_pixfmt metadata attribute to be used as default pixel-format, when frame_format parameter value is None-type. Improved handling of source metadata keys in metadata property object. Updated metadata property object to handle and assign User-defined metadata directly by overloading the same property object: Added new internal user_metadata class variable to handle all User-defined metadata information separately. FFdecoder API's metadata property object now returns User-defined metadata information merged with Source Video metadata. Added tuple value warning log to notify users json module converts Python tuples to JSON lists . Improved logic to test validity of -custom_resolution attribute value through ffparams dictionary parameter. Improved handling of FFmpeg pipeline framerate with both user-defined and metadata defined values. Added tuple to exception in datatype check for ffparams dictionary parameter. Added datatype validation check for frame_format parameter. Improved handling of -framerate parameter. Maintenance: Reformatted all Core class and methods text descriptions: Rewritten introductory each API class description. Moved reference block from index.md to class description. Fixed missing class and methods parameter description. Fixed typos and context in texts. Reformatted code comments. Simplified for loop with if condition checking in metadata property object. Updated logging comments. Setup: Updated project description in metadata. Bumped version to 0.2.2 . Docs: Updated Introduction doc: Added new text sections such as \"Getting Started\", \"Installation Notes\", \"Recipes a.k.a Examples\" and \"API in a nutshell\". Rewritten Introduction( index.md ) with recent Information, redefined context, UI changes, updated recipe codes, curated hyperlinks to various recipes(separated with categories), and relatable GIFs. Updated spacing in index.md using spacer class within <div> tag and &nbsp; . Reformatted and centered DeFFcode Introductory description. Reformatted FFmpeg Installation doc and Issue & PR guidelines. Updated static FFmpeg binaries download URLs in FFmpeg Installation doc. Refashioned text contexts, icons, and recipes codes. Updated Key Features section with reflecting new features. Updated README.md: Updated README.md w.r.t recent changes in Introduction( index.md ) doc. Simplified and Reformatted text sections similar to Introduction doc. Imported new \"Contributions\" and \"Donations\" sections from VidGear docs. Added collapsible text and output section using <summary> and <detail> tags. Added experimental note GitHub blockquote to simulate admonition in README.md. Removed tag-line from README.md and related image asset. Simplified and Grouped README URL hyperlinks. Removed Roadmap section. Updated Recipes docs: Revamped DeFFcode Introduction index.md with new Information, Context and UI changes, Updated example codes and hyperlinks. Updated Announcement Bar to fix announcement_link variable and text. Updated footer note to notify users regarding tuple value warning in FFdecoder API. Rewritten recipes w.r.t breaking changes in APIs. Updated Reference docs: Completely revamped API's parameter reference docs. Added new Functional Block Diagrams to FFdecoder and Sourcer API References. Rewritten and Reformatted FFdecoder and Sourcer API's parameter reference docs with new information w.r.t recent changes. Implemented new admonitions explaining new changes, related warnings/errors, usage examples etc. Removed redundant advanced.md and basic.md docs. Added new abstracts to FFhelper and Utils docs. Updated docs site navigation and titles: Reformatted index.md and installation/index.md . Renamed help/index.md to help/help.md . Moved basic and advanced recipes from example to recipes folder. Imported \"Donations\" sections from VidGear docs to help.md . Added updated page-title and navigation hyperlinks in mkdocs.yml to new markdown files incorporated recently. Updated internal navigation hyperlinks in docs and removed old redundant file links. Updated docs UI: Added custom spacer class in CSS for custom vertical spacing. Imported new \"New\", \"Advance\", \"Alert\", \"Danger\" and \"Bug\" admonitions custom CSS UI patches from vidgear. Updated all admonitions icons with new custom icon SVG+XML URLs. Reformatted custom.css and added missing comments. Updated docs fonts: Updated text font to Heebo . Updated code font to JetBrains Mono . Updated primary and accent colors: Updated primary light color to light green . Updated primary dark color to amber . Updated accent light color to green . Updated accent dark color to lime . Replaced admonitions with appropriate ones. Changed Color palette toggle icons. Updated icons in title headings. Updated admonitions messages. Updated changelog.md . CI: Pinned jinja2 version to <3.1.0 , since jinja2>=3.1.0 breaks mkdocs ( mkdocs/mkdocs#2799 ). Updated unittests w.r.t recent changes in APIs: Updated test_frame_format unittest to include manually assign output pixel-format via metadata property object. Updated test_metadata unittest to include new checks parameter to decide whether to perform Assertion test on assigned metadata properties in FFdecoder API. Added new parametrize attributes in test_metadata and test_seek_n_save unittests to cover every use-cases. Replaced IOError with ValueError in Sourcer API unittests. Updated test_metadata unittest to verify tuple value warning. Updated unittests to increase code coverage significantly. Breaking Updates/Changes Sourcer API: Sourcer API's retrieve_metadata() method now returns parsed metadata either as JSON string or dictionary type. Added new pretty_json boolean parameter to retrieve_metadata() , that is when True , returns metadata formatted as JSON string instead of default python dictionary. Changed IOError to ValueError in Sourcer API, raised when source with no decodable audio or video stream is provided. FFdecoder API: Rename extraparams dictionary parameter to ffparams in FFdecoder API. The source metadata value cannot be altered through metadata property object in FFdecoder API. Removed -ffpostfixes attribute support from ffparams dictionary parameter in FFdecoder API, since totally redundant in favor of similar -ffprefixes and -clones attributes. Bug-fixes FFdecoder API: Fixed metadata property object unable to process user-defined keys when any source metadata keys are defined. Fixed TypeError bug with string type -framerate parameter values. Sourcer API: Fixed Sourcer API throws IOError for videos containing streams without both source bitrate and framerate defined (such as from lavfi input virtual device) . Fixed AttributeError bug due to typo in variable name. CI: Fixed support for newer mkdocstring version in DeFFcode Docs Deployer workflow. Added new mkdocstrings-python-legacy dependency. Replaced rendering variable with options . Removed pinned mkdocstrings==0.17.0 version. Removed redundant variables. Updated test_metadata unittest to fix AssertionError Bug. Docs: Fixed some admonitions icons not showing bug using !important rule in CSS. Fixed 404.html static page not showing up. Fixed invalid internal navigation hyperlinks and asset paths. Removed quote/cite/summary admonition custom UI patches. Removed redundant information texts. Fixed typos in code comments. Fixed typos in example code. Pull Requests PR #23 v0.2.1 (2022-07-14) \u00b6 New Features Sourcer API: Implemented support for extracting metadata from live input devices/sources. Added new source_demuxer and forced_validate parameters to validate_source internal method. Implemented logic to validate source_demuxer value against FFmpeg supported demuxers. Rearranged metadata dict. Updated Code comments. FFdecoder API: Implemented functionality to supported live devices by allowing device path and respective demuxer into pipeline. Included -f FFmpeg parameter into pipeline to specify source device demuxer. Added special case for discarding -framerate value with Nonetype. CI: Added new unittest test_camera_capture() to test support for live Virtual Camera devices. Added new v4l2loopback-dkms , v4l2loopback-utils and kernel related APT dependencies. Bash Script: Added new FFmpeg command to extract image datasets from given video on Linux envs. Created live Virtual Camera devices through v4l2loopback library on Github Actions Linux envs. Added v4l2loopback modprobe command to setup Virtual Camera named VCamera dynamically at /dev/video2 . Added v4l2-ctl --list-devices command for debugging. Implemented FFmpeg command through nohup (no hangup) to feed video loop input to Virtual Camera in the background. Updates/Improvements Sourcer API: Only either source_demuxer or source_extension attribute can be present in metadata. Enforced forced_validate for live input devices/sources in validate_source internal method. FFdecoder API: Rearranged FFmpeg parameters in pipeline. Removed redundant code. Updated Code comments. FFhelper API: Logged error message on metadata extraction failure. CI: Restricted test_camera_capture() unittest to Linux envs only. Removed return_generated_frames_path() method support for Linux envs. Pinned jinja2 3.1.0 or above breaking mkdocs. jinja2>=3.1.0 breaks mkdocs ( mkdocs/mkdocs#2799 ), therefore pinned jinja2 version to <3.1.0 . Bash Script: Updated to latest FFmpeg Static Binaries links. Updated download links to abhiTronix/ffmpeg-static-builds * hosting latest available versions. Updated date/version tag to 12-07-2022 . Removed depreciated binaries download links and code. Setup: Bumped version to 0.2.1 . Docs: Updated changelog.md . Breaking Updates/Changes Implement support for live input devices/sources. source parameter now accepts device name or path. Added source_demuxer parameter to specify demuxer for live input devices/sources. Implemented Automated inserting of -f FFmpeg parameter whenever source_demuxer is specified by the user. Bug-fixes Sourcer API: Fixed Nonetype value bug in source_demuxer assertion logic. Fixed typos in parameter names. Added missing import. FFhelper API: Logged error message on metadata extraction failure. Fixed bug with get_supported_demuxers not detecting name patterns with commas. Removed redundant logging. CI: Fixed critical permission bug causing v4l2loopback to fail on Github Actions Linux envs. Elevated privileges to root by adding sudo to all commands(including bash scripts and python commands). Updated vidgear dependency to pip install from its git testing branch with recent bug fixes. Replaced relative paths with absolute paths in unit tests. Fixed WriteGear API unable to write frames due to permission errors. Fixed test_source_playback() test failing on Darwin envs with OLD FFmpeg binaries. Removed custom_ffmpeg value for Darwin envs. Fixed various naming typos. Fixed missing APT dependencies. Pull Requests PR #17 v0.2.0 (2022-03-21) \u00b6 New Features Sourcer API: Added a new source_audio_samplerate metadata parameter: Re-implemented __extract_audio_bitrate internal function from scratch as __extract_audio_bitrate_nd_samplerate . Implemented new algorithm to extract both extract both audio bitrate and samplerate from given source. Updated regex patterns according to changes. Updated __contains_video and __contains_audio logic to support new changes. Added metadata extraction support: Added retrieve_metadata class method to Sourcer API for extracting source metadata as python dictionary. Populated private source member values in dictionary with distinct keys. Added new -force_validate_source attribute to Sourcer API's sourcer_params dict parameter for special cases. Implemented check whether probe_stream() called or not in Sourcer API. FFdecoder API: Added metadata extraction and updation support: Added metadata property object function to FFdecoder API for retrieving source metadata form Sourcer API as dict and return it as JSON dump for pretty printing. Added Operational Mode as read-only property in metadata. Added metadata property object with setter() method for updating source metadata with user-defined dictionary. Implemented way to manually alter metadata keys and values for custom results. Docs: Added new comprehensive documentation with Mkdocs: Added new image assets: Added new Deffcode banner image, logo and tagline Added new icon ICO file with each layer of the favicon holds a different size of the image. Added new png images for best compatibility with different web browsers. Added new docs files: Added new index.md with introduction to project. Added new changelog.md. Added license.md Added new index.md with instructions for contributing in DeFFcode. Added issue.md with Issue Contribution Guidelines. Added PR.md with PR Contribution Guidelines. Added new custom.js to add gitter sidecard support. Added new custom.css that brings standard and quality visual design experience to DeFFcode docs. Added new admonitions new and alert . Added separate LICENSE(under CC creative commons) and REAME.md for assets. Added new main.html extending base.html for defining custom site metadata. Added deFFcode banner image to metadata. Added twitter card and metadata. Added version warning for displaying a warning when the user visits any other version. Added footer sponsorship block. Added gitter card official JS script dist. Added new custom 404.html to handle HTTP status code 404 Not Found. Implemented custom theming with new CSS style. Added custom 404 image asset. Added new index.md with DeFFcode Installation notes. Added info about Supported Systems, Supported Python legacies, Prerequisites, Installation instructions. Added Pip and Source Installation instructions. Added new ffmpeg_install.md with machine-specific instructions for FFmpeg installation. Added new index.md with different ways to help DeFFcode, other users, and the author. Added info about Starring and Watching DeFFcode on GitHub, Helping with open issues etc. Added Tweeter intent used for tweeting #deffode hastags easily. Added Kofi Donation link button. Added author contact links and left align avatar image. Added new get_help.md to get help with DeFFcode. Added DeFFcode gitter community link. Added other helpful links. Added new assets folders. Added Basic Recipes with basic.md Added Advanced Recipes with advanced.md Added all API References. Added mkdocstrings automatic documentation from sources. Added new index.md for FFdecoder API with its description and explaining its API. Added new index.md for Sourcer API with its description and explaining its API. Added ffhelper methods API references. Added utils methods API references. Added all API Parameters. Added new params.md for FFdecoder API explaining all its parameters. Added new params.md for Sourcer API explaining all its parameters. Added Mkdocs support with mkdocs.yml Implemented new mkdocs.yml with relevant parameters. Added extended material theme with overridden parts. Added site metadata with site_name, site_url, site_author, site_description, repo_name, repo_url, edit_uri, copyright etc. Added navigation under sections for easily accessing each document. Implemented Page tree for DeFFcode docs. Added features like navigation.tracking, navigation.indexes, navigation.top, search.suggest, search.highlight, search.share, content.code.annotate. Added separate palette [default]light(with primary:green accent: dark green) and [slate]dark(with primary:teal accent: light green) mode. Added Color palette toggle switch with icon material/home-lightning-bolt . Added support for all pymarkdown-extensions. Added google fonts for text: Quicksand and code: Fira Code . Added custom logo and icon for DeFFcode. Added support for plugins like search, git-revision-date-localized, minify. Added support for mkdocstrings plugin for auto-built API references. Added python handler for parsing python source-code to mkdocstrings . Improved source-code docs for compatibility with mkdocstrings . Added support for extensions like admonition , attr_list , codehilite , def_list , footnotes , meta , and toc . Added social icons and links. Added custom extra_css and extra_javascript . Added support for en (English) language. Added new badges to README.md for displaying current status of CI jobs and coverage. Added Roadmap to README.md CI: Automated CI support for different environments: Implemented auto-handling of dependencies installation, unit testing, and coverage report uploading. Added GitHub Action workflow for Linux envs: Added and configured CIlinux.yml to enable GitHub Action workflow for Linux-based Testing Envs. Added 3.7+ python-versions to build matrix. Added code coverage through codecov/codecov-action@v2 workflow for measuring unit-tests effectiveness. Implemented behavior to about coverage upload on timeout(error code 124 ) in pytests. Added Appveyor workflow for Windows envs: Add and configured appveyor.yml to enable Appveyor workflow for Windows-based Testing Envs. Added 3.7+ 64-bit python-versions to build matrix. Enabled fast_finish to exit immediately on error. Added Azure-Pipelines workflow for MacOS envs: Add and configured azure-pipelines.yml to enable Azure-Pipelines workflow for MacOS-based Testing Envs. Added code coverage through codecov workflow for measuring unit-tests effectiveness. Added online auto validation of codecov bash script using SH256SUM and sig files as recommended. Implemented behavior to about coverage upload on timeout(error code 124 ) in pytests. Added 3.7+ python-versions to build matrix. Added automated flake8 testing to discover any anomalies in code. Added master branches for triggering CI. Implement new automated Docs Building and Deployment on gh-pages through GitHub Actions workflow: Added new workflow yaml docs_deployer.yml for automated docs deployment. Added different jobs with ubuntu-latest environement to build matrix. Added actions/checkout@v2 for repo checkout and actions/setup-python@v2 for python environment. Pinned python version to 3.8 for python environment in docs building. Added GIT_TOKEN , GIT_NAME , GIT_EMAIL environment variables through secrets. Added Mkdocs Material theme related python dependencies and environments. Added push on master and dev branch release with published as triggers. Pinned mkdocstrings==0.17.0 . Added new Automated Docs Versioning: Implemented Docs versioning through mike . Separate new workflow steps to handle different versions. Added step to auto-create RELEASE_NAME environment variable from DeFFcode version file. Update docs deploy workflow to support latest , release and dev builds. Added automatic release version extraction from GitHub events. Added Skip Duplicate Actions Workflow to DeFFcode Docs Deployer: Added Skip Duplicate Actions( fkirc/skip-duplicate-actions@master ) Workflow to DeFFcode Docs Deployer to prevent redundant duplicate workflow-runs. Maintenance: New DeFFcode project issue and PR templates: Added PR template: Added a pull request template( PULL_REQUEST_TEMPLATE.md ) for project contributors to automatically see the template's contents in the pull request body. Added Brief Description, Requirements / Checklist, Related Issue, Context, Types of changes blocks. Added Proposal, Bug-Report and Question templates: Created an ISSUE_TEMPLATE subdirectory to contain multiple issue templates. Add manually-created Proposal( proposal.md ) and Question( question.md ) issue template for project contributors to automatically see the template's contents in the issue body. Added Brief Description, Acknowledgment, Context, Current Environment, Any Other Information like blocks. Add an manually-created Bug Report( bug_report.md ) issue template to ISSUE_TEMPLATE subdirectory for project contributors to automatically see the template's contents in the issue body. Added Brief Description, Acknowledgment, Context, Current Environment, Expected Behavior, Actual Behavior, Possible Fix, Steps to reproduce, Miscellaneous like blocks. Added YAML frontmatter to each issue template to pre-fill the issue title, automatically add labels and assignees, and give the template a name and description. Added a config.yml file to the .github/ISSUE_TEMPLATE folder to customize the issue template chooser that people see when creating a new issue. Set blank_issues_enabled parameter to false to encourage contributors to use issue templates. Added contact_links parameter with gitter community link to receive regular issues outside of GitHub. Added new FUNDING.yml with ko-fi donation link. Added .gitattributes for DeFFcode, that set the default behavior, in case people don't have core.autocrlf set. Imported Codecov config( codecov.yml ) from vidgear to modify coverage parameters. Tests: Added DeFFcode unit tests with pytest : Added essential.py for defining all essential functions necessary for DeFFcode unit tests. Added return_static_ffmpeg , remove_file_safe , return_testvideo_path , return_generated_frames_path, actual_frame_count_n_frame_size essential functions. Added is_windows global variable. Added related imports and logging. Added __init__.py . Moved all files to test folder. Added DeFFcode's utils unit tests with pytest. Added new test_loggerhandler and test_dict2Args tests. Added DeFFcode's ffhelper unit tests with pytest. Added new test_ffmpeg_binaries_download , test_validate_ffmpeg , test_get_valid_ffmpeg_path , test_check_sp_output , test_is_valid_url , test_is_valid_image_seq , and test_validate_imgseqdir parametrize tests. Added DeFFcode's Sourcer API unit tests with pytest. Added new test_source and test_probe_stream_n_retrieve_metadata parametrize tests. Added DeFFcode's FFdecoder API unit tests with pytest. Added new test_source_playback , test_frame_format , test_metadata , test_seek_n_save , and test_FFdecoder_params parametrize unit tests. Added related imports and logging. Added unit test for delete_file_safe utils function. Bash: \ud83d\udd27 Imported prepare_dataset.sh from vidgear for downloading pytest datasets to temp dir. Updates/Improvements FFdecoder API: Removed redundant forcing -r FFmpeg parameter for image sequences as source. Removed redundant checks on -vf FFmpeg parameter. FFmpeg parameter -s will be discarded in favor of -custom_resolution attribute. Replaced -constant_framerate with FFmpeg -framerate attribute. Replaced -custom_source_params with correct -custom_sourcer_params attribute. Renamed operational_mode metadata parameter to ffdecoder_operational_mode . Sourcer API: Converted all Sourcer APIs public available variables into private ones for stability. All Sourcer's publicly accessed variable metadata values in FFdecoder, therefore replaced with dictionary counterparts. Moved FFmpeg path validation and handling to Sourcer from FFdecoder API. Moved -ffmpeg_download_path dictionary attribute to Sourcer API's sourcer_params parameter. Moved dependencies and related functions. CI: Excluded dev branch from triggering workflow on any environment. Updated yaml files to exclude beta dev branch from triggering workflow on any environment. Restricted codecov to use only master branch. Re-implemented fkirc/skip-duplicate-actions@master to Skip individual deploy steps instead of Skip entire jobs Docs: Updated PR.md Added instructions to download prepare_dataset.sh using curl. Updated dependencies for pytest . Updated advanced.md Updated generating Video from Image sequence to save video using OpenCV writer instead of WriteGear API. Added frame_format=\"bgr24\" and additional instructions regarding OpenCV writer. Updated example codes with new changes. Rearranged examples placement. Updates to custom.css Added donation sponsor link in page footer with heart animation. Added bouncing heart animation through pure CSS. Added Bold property to currently highlighted link in Navigation Bar. Updated Navigation Bar title font size. Updated version list text to uppercase and bold. Updated icon for task list unchecked. Added more top-padding to docs heading. Updated Block quote symbol and theming. Updated Custom Button theming to match docs. Added new custom classes to create shadow effect in dark mode for better visibility. Updated dark mode theme \"slate\" hue to 285. Updated admonitions colors. Updated gitter sidecard UI colors and properties. Reflected recent changes in Sourcer and FFdecoder API's metadata. Updated sample code formatting from sh to json . Added missing docs for delete_file_safe utils function. Updated Download Test Datasets instructions. Updated contribution guidelines and installation docs with related changes. Updated License Notice. Updated code comments. Updated logging messages. Updated Deffcode Logo and Tagline to be dark-mode friendly. Adjusted asset alignment. Updated example code. Updated Installation instructions, Requirements and Roadmap. Corrected links to documents. Updated project description. Updated LICENSE. Updated indentation and code comments Re-aligned text and images in README.md Adjusted image classes and width. Maintenance: Updated LICENSE notice to add vidgear notice. Bumped version to 0.2.0 Added useful comments for convenience. Breaking Updates/Changes Sourcer API will now raises Assertion error if probe_stream() not called before calling retrieve_metadata() . Only -framerate values greater than 0.0 are now valid. Renamed decode_stream to probe_stream in Sourcer API. Any of video bitrate or video framerate are sufficient to validate if source contains valid video stream(s). Any of audio bitrate or audio samplerate are sufficient to validate if source contains valid audio stream(s). Bug-fixes APIs: Added missing delete_file_safe function in utils. Imported delete_file_safe from vidgear to safely deletes files at given path. Fixed forward slash bugs in regex patterns. Fixed IndexError when no bitrate was discovered in given source. Fixed FFmpeg subprocess pipeline not terminating gracefully in FFdecoder API. Fixed __version__ not defined in DeFFcode's __init__.py that throws AttributeError: module 'deffcode' has no attribute '__version__' on query. Added necessary import in __init__.py . Docs: Fixed missing \"-vcodec\": \"h264_cuvid\" value in example code. Fixed typos in filenames in utils.py Fixed internal missing or invalid hyperlinks. Fixed improper docs context and typos. Fixed \"year\" in license notice. Fixed content spacing. Fixed Gitter Community Link in Mkdocs. Fixed typos in README.md. Fixed typos in license notices. Fixed typos in code comments. Fixed typos in example code. CI: Fixed missing FFmpeg dependency bug in GitHub Actions. Fixes typo in Docs Deployer yaml. Fixed if condition skipping when need is skipping Maintenance: Added missing imports. Fixed redundant conditional logics. Removed or Replaced redundant conditions and definitions. Fixed minor typos in templates. Pull Requests PR #5 PR #6 PR #8 PR #9 PR #11 PR #12 PR #13 PR #14 v0.1.0 (2022-03-07) \u00b6 New Features Open-Sourced DeFFcode under the Apache 2.0 License. Added new Classes(APIs): FFdecoder: Performant Real-time Video frames Generator for generating blazingly fast video frames(RGB ndarray by default). Sourcer: Extracts source video metadata (bitrate, resolution, framerate, nframes etc.) using its subprocess FFmpeg output. Added new Helper functions: ffhelper: Backend FFmpeg Wrapper that handles all subprocess transactions and gather data. utils: Handles all additional Utilizes required for functioning of DeFFcode. First PyPi Release: Released DeFFcode to Python Package Index (PyPI) Added setup.py and related metadata. Added version.py Docs: Added abstract and related information in README.md Added installation instructions. Added preliminary usage examples. Maintenance: Added LICENSE. Added .gitignore Updates/Improvements Maintenance: Bumped version to 0.1.0 Updated LICENSE notice to add vidgear code usage notice. Breaking Updates/Changes Fixed support for Python-3.7 and above legacies only. Bug-fixes Docs: Fixed hyperlinks in README. Fixed indentation and spacing. Fixed typos and updated context. Removed dead code.","title":"Changelog"},{"location":"changelog/#release-notes","text":"","title":"Release Notes"},{"location":"changelog/#v023-2022-08-11","text":"New Features Docs: Added Zenodo Bibtex entry and badge in docs for easy citation. Added new <div> tag bounding-box style to the Static FFmpeg binary download links in FFmpeg Installation Doc for better accessibility. Maintenance: Switched to new Issue GitHub's form schema using YAML: Added new bug_report.yaml Issue GitHub's form schema for Bug Reports. Added new idea.yaml Issue GitHub's form schema for new Ideas. Added new question.yaml Issue GitHub's form schema for Questions. Deleted old depreciated markdown( .md ) files. Polished forms. Updates/Improvements Maintenance: Added new patterns to .gitignore to ignore vim files. CI: Updated test_FFdecoder_params unittest to include with statement access method. Setup: Added new patches for using README.md text as long_description metadata. Implemented new patch to remove GitHub README UI specific text. Simplified multiple str.replace to chained str.replace of better readability. Bumped version to 0.2.3 . Docs: Updated recipes to include with statement access method. Updated existing recipes to include with statement access method in FFdecoder APIs. Included new example code of accessing RGB frames using with statement access method. Updated Recipe title to \"Accessing RGB frames from a video file\" across docs. Included warning admonition for advising users to always use trim with reverse filter. Updated docs text font to Libre Franklin . Updated method description texts and logging messages. Update icons and admonition messages. Updated code comments. Updated changelog.md . Bug-fixes FFdecoder API: Fixed Context Manager methods. Fixed __enter__ method returning class instance instead of formulating pipeline. Fixed __exit__ method calling wrong non-existent method. Setup: Fixed missing comma(,) in keywords metadata. Fixed bug in patch string. Docs: Fixed typos in code comments. Fixed several typos in docs. Pull Requests PR #26","title":"v0.2.3 (2022-08-11) "},{"location":"changelog/#v022-2022-08-09","text":"New Features Sourcer API: Added support for -ffprefixes attribute through Sourcer API's sourcer_param dictionary parameter (similar to FFdecoder API) . FFdecoder API: Added new output_frames_pixfmt metadata property to preview and handle output frames pixel-format. Docs: Added separate \"Basic\" and \"Advanced\" Recipes markdowns files with self-explanatory text, related usage code, asset (such as images, diagrams, GIFs, etc.) , and UI upgrades for bringing standard quality to visual design. Added separate index.md for Basic and Advanced Recipes with introductory text and curated hyperlinks for quick references to various recipes (separated with sub-categories \"Decoding\", \"Transcoding\", and \"Extracting Video Metadata\") . Added related admonitions to specify python dependencies as well as other requirements and relevant information required for each of these recipes. Added new Basic Decoding Recipes: Added Decoding Video files with various pixel formats recipes. Added Decoding Live Feed Devices recipes with source_demuxer FFdecoder API parameter. Added Decoding Image sequences recipes supporting Sequential, Glob pattern , Single (looping) image. Added Decoding Network Streams recipes. Added new Basic Transcoding Recipes: Added Transcoding Live frames recipes with OpenCV and WriteGear. Added Transcoding Live Simple Filtergraphs recipes with OpenCV. Added Saving Key-frames as Image recipes with different image processing libraries. Added new Basic Extracting Video Metadata Recipes: Added Extracting Video Metadata recipes with FFdecoder and Sourcer APIs. Added new Advanced Decoding Recipes: Added Hardware-Accelerated Video Decoding recipe using NVIDIA's H.264 CUVID Video-decoder( h264_cuvid ). Added Decoding Live Virtual Sources recipes with many test patterns using lavfi input virtual device. Added new Advanced Decoding Recipes: Added lossless Hardware-Accelerated Video Transcoding recipe with WriteGear API. Added Transcoding Live Complex Filtergraphs recipes with WriteGear API. Added Transcoding Video Art with Filtergraphs recipes with WriteGear API for creating real-time artistic generative video art using simple and complex filtergraphs. Added new Advanced Updating Video Metadata Recipes: Added Updating Video Metadata recipes with user-defined as well as source metadata in FFdecoder API. Added new dark and light theme logo support. Added new recipes GIF assets to gifs folder. Added new dark logo deffcode-dark.png asset to images folder. Added new ffdecoder.png and sourcer.png Image assets to images folder. Added new navigation.tabs feature. Added Material Announcement-Bar notifying recent changes. Updates/Improvements Sourcer API: Implemented new validation checks to ensure given source has usable video stream available by checking availability of either video bitrate or both frame-size and framerate _ properties in the source metadata. Improved extract_resolution_framerate method for making framerate extraction more robust by falling back to extracting TBR value when no framerate value available in the source metadata. FFdecoder API: Updated metadata property object to validate and override source metadata properties directly by overloading same property object before formulating Frames Decoder Pipeline: Implemented validation checks to verify each validate manually assigned source metadata property against specific datatype before overriding. Updated logging to notify invalid datatype values when assigned through metadata property object. Added support for overriding source_video_resolution source metadata property to control frame-size directly through metadata. Added support for overriding output_frames_pixfmt metadata attribute to be used as default pixel-format, when frame_format parameter value is None-type. Improved handling of source metadata keys in metadata property object. Updated metadata property object to handle and assign User-defined metadata directly by overloading the same property object: Added new internal user_metadata class variable to handle all User-defined metadata information separately. FFdecoder API's metadata property object now returns User-defined metadata information merged with Source Video metadata. Added tuple value warning log to notify users json module converts Python tuples to JSON lists . Improved logic to test validity of -custom_resolution attribute value through ffparams dictionary parameter. Improved handling of FFmpeg pipeline framerate with both user-defined and metadata defined values. Added tuple to exception in datatype check for ffparams dictionary parameter. Added datatype validation check for frame_format parameter. Improved handling of -framerate parameter. Maintenance: Reformatted all Core class and methods text descriptions: Rewritten introductory each API class description. Moved reference block from index.md to class description. Fixed missing class and methods parameter description. Fixed typos and context in texts. Reformatted code comments. Simplified for loop with if condition checking in metadata property object. Updated logging comments. Setup: Updated project description in metadata. Bumped version to 0.2.2 . Docs: Updated Introduction doc: Added new text sections such as \"Getting Started\", \"Installation Notes\", \"Recipes a.k.a Examples\" and \"API in a nutshell\". Rewritten Introduction( index.md ) with recent Information, redefined context, UI changes, updated recipe codes, curated hyperlinks to various recipes(separated with categories), and relatable GIFs. Updated spacing in index.md using spacer class within <div> tag and &nbsp; . Reformatted and centered DeFFcode Introductory description. Reformatted FFmpeg Installation doc and Issue & PR guidelines. Updated static FFmpeg binaries download URLs in FFmpeg Installation doc. Refashioned text contexts, icons, and recipes codes. Updated Key Features section with reflecting new features. Updated README.md: Updated README.md w.r.t recent changes in Introduction( index.md ) doc. Simplified and Reformatted text sections similar to Introduction doc. Imported new \"Contributions\" and \"Donations\" sections from VidGear docs. Added collapsible text and output section using <summary> and <detail> tags. Added experimental note GitHub blockquote to simulate admonition in README.md. Removed tag-line from README.md and related image asset. Simplified and Grouped README URL hyperlinks. Removed Roadmap section. Updated Recipes docs: Revamped DeFFcode Introduction index.md with new Information, Context and UI changes, Updated example codes and hyperlinks. Updated Announcement Bar to fix announcement_link variable and text. Updated footer note to notify users regarding tuple value warning in FFdecoder API. Rewritten recipes w.r.t breaking changes in APIs. Updated Reference docs: Completely revamped API's parameter reference docs. Added new Functional Block Diagrams to FFdecoder and Sourcer API References. Rewritten and Reformatted FFdecoder and Sourcer API's parameter reference docs with new information w.r.t recent changes. Implemented new admonitions explaining new changes, related warnings/errors, usage examples etc. Removed redundant advanced.md and basic.md docs. Added new abstracts to FFhelper and Utils docs. Updated docs site navigation and titles: Reformatted index.md and installation/index.md . Renamed help/index.md to help/help.md . Moved basic and advanced recipes from example to recipes folder. Imported \"Donations\" sections from VidGear docs to help.md . Added updated page-title and navigation hyperlinks in mkdocs.yml to new markdown files incorporated recently. Updated internal navigation hyperlinks in docs and removed old redundant file links. Updated docs UI: Added custom spacer class in CSS for custom vertical spacing. Imported new \"New\", \"Advance\", \"Alert\", \"Danger\" and \"Bug\" admonitions custom CSS UI patches from vidgear. Updated all admonitions icons with new custom icon SVG+XML URLs. Reformatted custom.css and added missing comments. Updated docs fonts: Updated text font to Heebo . Updated code font to JetBrains Mono . Updated primary and accent colors: Updated primary light color to light green . Updated primary dark color to amber . Updated accent light color to green . Updated accent dark color to lime . Replaced admonitions with appropriate ones. Changed Color palette toggle icons. Updated icons in title headings. Updated admonitions messages. Updated changelog.md . CI: Pinned jinja2 version to <3.1.0 , since jinja2>=3.1.0 breaks mkdocs ( mkdocs/mkdocs#2799 ). Updated unittests w.r.t recent changes in APIs: Updated test_frame_format unittest to include manually assign output pixel-format via metadata property object. Updated test_metadata unittest to include new checks parameter to decide whether to perform Assertion test on assigned metadata properties in FFdecoder API. Added new parametrize attributes in test_metadata and test_seek_n_save unittests to cover every use-cases. Replaced IOError with ValueError in Sourcer API unittests. Updated test_metadata unittest to verify tuple value warning. Updated unittests to increase code coverage significantly. Breaking Updates/Changes Sourcer API: Sourcer API's retrieve_metadata() method now returns parsed metadata either as JSON string or dictionary type. Added new pretty_json boolean parameter to retrieve_metadata() , that is when True , returns metadata formatted as JSON string instead of default python dictionary. Changed IOError to ValueError in Sourcer API, raised when source with no decodable audio or video stream is provided. FFdecoder API: Rename extraparams dictionary parameter to ffparams in FFdecoder API. The source metadata value cannot be altered through metadata property object in FFdecoder API. Removed -ffpostfixes attribute support from ffparams dictionary parameter in FFdecoder API, since totally redundant in favor of similar -ffprefixes and -clones attributes. Bug-fixes FFdecoder API: Fixed metadata property object unable to process user-defined keys when any source metadata keys are defined. Fixed TypeError bug with string type -framerate parameter values. Sourcer API: Fixed Sourcer API throws IOError for videos containing streams without both source bitrate and framerate defined (such as from lavfi input virtual device) . Fixed AttributeError bug due to typo in variable name. CI: Fixed support for newer mkdocstring version in DeFFcode Docs Deployer workflow. Added new mkdocstrings-python-legacy dependency. Replaced rendering variable with options . Removed pinned mkdocstrings==0.17.0 version. Removed redundant variables. Updated test_metadata unittest to fix AssertionError Bug. Docs: Fixed some admonitions icons not showing bug using !important rule in CSS. Fixed 404.html static page not showing up. Fixed invalid internal navigation hyperlinks and asset paths. Removed quote/cite/summary admonition custom UI patches. Removed redundant information texts. Fixed typos in code comments. Fixed typos in example code. Pull Requests PR #23","title":"v0.2.2 (2022-08-09)"},{"location":"changelog/#v021-2022-07-14","text":"New Features Sourcer API: Implemented support for extracting metadata from live input devices/sources. Added new source_demuxer and forced_validate parameters to validate_source internal method. Implemented logic to validate source_demuxer value against FFmpeg supported demuxers. Rearranged metadata dict. Updated Code comments. FFdecoder API: Implemented functionality to supported live devices by allowing device path and respective demuxer into pipeline. Included -f FFmpeg parameter into pipeline to specify source device demuxer. Added special case for discarding -framerate value with Nonetype. CI: Added new unittest test_camera_capture() to test support for live Virtual Camera devices. Added new v4l2loopback-dkms , v4l2loopback-utils and kernel related APT dependencies. Bash Script: Added new FFmpeg command to extract image datasets from given video on Linux envs. Created live Virtual Camera devices through v4l2loopback library on Github Actions Linux envs. Added v4l2loopback modprobe command to setup Virtual Camera named VCamera dynamically at /dev/video2 . Added v4l2-ctl --list-devices command for debugging. Implemented FFmpeg command through nohup (no hangup) to feed video loop input to Virtual Camera in the background. Updates/Improvements Sourcer API: Only either source_demuxer or source_extension attribute can be present in metadata. Enforced forced_validate for live input devices/sources in validate_source internal method. FFdecoder API: Rearranged FFmpeg parameters in pipeline. Removed redundant code. Updated Code comments. FFhelper API: Logged error message on metadata extraction failure. CI: Restricted test_camera_capture() unittest to Linux envs only. Removed return_generated_frames_path() method support for Linux envs. Pinned jinja2 3.1.0 or above breaking mkdocs. jinja2>=3.1.0 breaks mkdocs ( mkdocs/mkdocs#2799 ), therefore pinned jinja2 version to <3.1.0 . Bash Script: Updated to latest FFmpeg Static Binaries links. Updated download links to abhiTronix/ffmpeg-static-builds * hosting latest available versions. Updated date/version tag to 12-07-2022 . Removed depreciated binaries download links and code. Setup: Bumped version to 0.2.1 . Docs: Updated changelog.md . Breaking Updates/Changes Implement support for live input devices/sources. source parameter now accepts device name or path. Added source_demuxer parameter to specify demuxer for live input devices/sources. Implemented Automated inserting of -f FFmpeg parameter whenever source_demuxer is specified by the user. Bug-fixes Sourcer API: Fixed Nonetype value bug in source_demuxer assertion logic. Fixed typos in parameter names. Added missing import. FFhelper API: Logged error message on metadata extraction failure. Fixed bug with get_supported_demuxers not detecting name patterns with commas. Removed redundant logging. CI: Fixed critical permission bug causing v4l2loopback to fail on Github Actions Linux envs. Elevated privileges to root by adding sudo to all commands(including bash scripts and python commands). Updated vidgear dependency to pip install from its git testing branch with recent bug fixes. Replaced relative paths with absolute paths in unit tests. Fixed WriteGear API unable to write frames due to permission errors. Fixed test_source_playback() test failing on Darwin envs with OLD FFmpeg binaries. Removed custom_ffmpeg value for Darwin envs. Fixed various naming typos. Fixed missing APT dependencies. Pull Requests PR #17","title":"v0.2.1 (2022-07-14)"},{"location":"changelog/#v020-2022-03-21","text":"New Features Sourcer API: Added a new source_audio_samplerate metadata parameter: Re-implemented __extract_audio_bitrate internal function from scratch as __extract_audio_bitrate_nd_samplerate . Implemented new algorithm to extract both extract both audio bitrate and samplerate from given source. Updated regex patterns according to changes. Updated __contains_video and __contains_audio logic to support new changes. Added metadata extraction support: Added retrieve_metadata class method to Sourcer API for extracting source metadata as python dictionary. Populated private source member values in dictionary with distinct keys. Added new -force_validate_source attribute to Sourcer API's sourcer_params dict parameter for special cases. Implemented check whether probe_stream() called or not in Sourcer API. FFdecoder API: Added metadata extraction and updation support: Added metadata property object function to FFdecoder API for retrieving source metadata form Sourcer API as dict and return it as JSON dump for pretty printing. Added Operational Mode as read-only property in metadata. Added metadata property object with setter() method for updating source metadata with user-defined dictionary. Implemented way to manually alter metadata keys and values for custom results. Docs: Added new comprehensive documentation with Mkdocs: Added new image assets: Added new Deffcode banner image, logo and tagline Added new icon ICO file with each layer of the favicon holds a different size of the image. Added new png images for best compatibility with different web browsers. Added new docs files: Added new index.md with introduction to project. Added new changelog.md. Added license.md Added new index.md with instructions for contributing in DeFFcode. Added issue.md with Issue Contribution Guidelines. Added PR.md with PR Contribution Guidelines. Added new custom.js to add gitter sidecard support. Added new custom.css that brings standard and quality visual design experience to DeFFcode docs. Added new admonitions new and alert . Added separate LICENSE(under CC creative commons) and REAME.md for assets. Added new main.html extending base.html for defining custom site metadata. Added deFFcode banner image to metadata. Added twitter card and metadata. Added version warning for displaying a warning when the user visits any other version. Added footer sponsorship block. Added gitter card official JS script dist. Added new custom 404.html to handle HTTP status code 404 Not Found. Implemented custom theming with new CSS style. Added custom 404 image asset. Added new index.md with DeFFcode Installation notes. Added info about Supported Systems, Supported Python legacies, Prerequisites, Installation instructions. Added Pip and Source Installation instructions. Added new ffmpeg_install.md with machine-specific instructions for FFmpeg installation. Added new index.md with different ways to help DeFFcode, other users, and the author. Added info about Starring and Watching DeFFcode on GitHub, Helping with open issues etc. Added Tweeter intent used for tweeting #deffode hastags easily. Added Kofi Donation link button. Added author contact links and left align avatar image. Added new get_help.md to get help with DeFFcode. Added DeFFcode gitter community link. Added other helpful links. Added new assets folders. Added Basic Recipes with basic.md Added Advanced Recipes with advanced.md Added all API References. Added mkdocstrings automatic documentation from sources. Added new index.md for FFdecoder API with its description and explaining its API. Added new index.md for Sourcer API with its description and explaining its API. Added ffhelper methods API references. Added utils methods API references. Added all API Parameters. Added new params.md for FFdecoder API explaining all its parameters. Added new params.md for Sourcer API explaining all its parameters. Added Mkdocs support with mkdocs.yml Implemented new mkdocs.yml with relevant parameters. Added extended material theme with overridden parts. Added site metadata with site_name, site_url, site_author, site_description, repo_name, repo_url, edit_uri, copyright etc. Added navigation under sections for easily accessing each document. Implemented Page tree for DeFFcode docs. Added features like navigation.tracking, navigation.indexes, navigation.top, search.suggest, search.highlight, search.share, content.code.annotate. Added separate palette [default]light(with primary:green accent: dark green) and [slate]dark(with primary:teal accent: light green) mode. Added Color palette toggle switch with icon material/home-lightning-bolt . Added support for all pymarkdown-extensions. Added google fonts for text: Quicksand and code: Fira Code . Added custom logo and icon for DeFFcode. Added support for plugins like search, git-revision-date-localized, minify. Added support for mkdocstrings plugin for auto-built API references. Added python handler for parsing python source-code to mkdocstrings . Improved source-code docs for compatibility with mkdocstrings . Added support for extensions like admonition , attr_list , codehilite , def_list , footnotes , meta , and toc . Added social icons and links. Added custom extra_css and extra_javascript . Added support for en (English) language. Added new badges to README.md for displaying current status of CI jobs and coverage. Added Roadmap to README.md CI: Automated CI support for different environments: Implemented auto-handling of dependencies installation, unit testing, and coverage report uploading. Added GitHub Action workflow for Linux envs: Added and configured CIlinux.yml to enable GitHub Action workflow for Linux-based Testing Envs. Added 3.7+ python-versions to build matrix. Added code coverage through codecov/codecov-action@v2 workflow for measuring unit-tests effectiveness. Implemented behavior to about coverage upload on timeout(error code 124 ) in pytests. Added Appveyor workflow for Windows envs: Add and configured appveyor.yml to enable Appveyor workflow for Windows-based Testing Envs. Added 3.7+ 64-bit python-versions to build matrix. Enabled fast_finish to exit immediately on error. Added Azure-Pipelines workflow for MacOS envs: Add and configured azure-pipelines.yml to enable Azure-Pipelines workflow for MacOS-based Testing Envs. Added code coverage through codecov workflow for measuring unit-tests effectiveness. Added online auto validation of codecov bash script using SH256SUM and sig files as recommended. Implemented behavior to about coverage upload on timeout(error code 124 ) in pytests. Added 3.7+ python-versions to build matrix. Added automated flake8 testing to discover any anomalies in code. Added master branches for triggering CI. Implement new automated Docs Building and Deployment on gh-pages through GitHub Actions workflow: Added new workflow yaml docs_deployer.yml for automated docs deployment. Added different jobs with ubuntu-latest environement to build matrix. Added actions/checkout@v2 for repo checkout and actions/setup-python@v2 for python environment. Pinned python version to 3.8 for python environment in docs building. Added GIT_TOKEN , GIT_NAME , GIT_EMAIL environment variables through secrets. Added Mkdocs Material theme related python dependencies and environments. Added push on master and dev branch release with published as triggers. Pinned mkdocstrings==0.17.0 . Added new Automated Docs Versioning: Implemented Docs versioning through mike . Separate new workflow steps to handle different versions. Added step to auto-create RELEASE_NAME environment variable from DeFFcode version file. Update docs deploy workflow to support latest , release and dev builds. Added automatic release version extraction from GitHub events. Added Skip Duplicate Actions Workflow to DeFFcode Docs Deployer: Added Skip Duplicate Actions( fkirc/skip-duplicate-actions@master ) Workflow to DeFFcode Docs Deployer to prevent redundant duplicate workflow-runs. Maintenance: New DeFFcode project issue and PR templates: Added PR template: Added a pull request template( PULL_REQUEST_TEMPLATE.md ) for project contributors to automatically see the template's contents in the pull request body. Added Brief Description, Requirements / Checklist, Related Issue, Context, Types of changes blocks. Added Proposal, Bug-Report and Question templates: Created an ISSUE_TEMPLATE subdirectory to contain multiple issue templates. Add manually-created Proposal( proposal.md ) and Question( question.md ) issue template for project contributors to automatically see the template's contents in the issue body. Added Brief Description, Acknowledgment, Context, Current Environment, Any Other Information like blocks. Add an manually-created Bug Report( bug_report.md ) issue template to ISSUE_TEMPLATE subdirectory for project contributors to automatically see the template's contents in the issue body. Added Brief Description, Acknowledgment, Context, Current Environment, Expected Behavior, Actual Behavior, Possible Fix, Steps to reproduce, Miscellaneous like blocks. Added YAML frontmatter to each issue template to pre-fill the issue title, automatically add labels and assignees, and give the template a name and description. Added a config.yml file to the .github/ISSUE_TEMPLATE folder to customize the issue template chooser that people see when creating a new issue. Set blank_issues_enabled parameter to false to encourage contributors to use issue templates. Added contact_links parameter with gitter community link to receive regular issues outside of GitHub. Added new FUNDING.yml with ko-fi donation link. Added .gitattributes for DeFFcode, that set the default behavior, in case people don't have core.autocrlf set. Imported Codecov config( codecov.yml ) from vidgear to modify coverage parameters. Tests: Added DeFFcode unit tests with pytest : Added essential.py for defining all essential functions necessary for DeFFcode unit tests. Added return_static_ffmpeg , remove_file_safe , return_testvideo_path , return_generated_frames_path, actual_frame_count_n_frame_size essential functions. Added is_windows global variable. Added related imports and logging. Added __init__.py . Moved all files to test folder. Added DeFFcode's utils unit tests with pytest. Added new test_loggerhandler and test_dict2Args tests. Added DeFFcode's ffhelper unit tests with pytest. Added new test_ffmpeg_binaries_download , test_validate_ffmpeg , test_get_valid_ffmpeg_path , test_check_sp_output , test_is_valid_url , test_is_valid_image_seq , and test_validate_imgseqdir parametrize tests. Added DeFFcode's Sourcer API unit tests with pytest. Added new test_source and test_probe_stream_n_retrieve_metadata parametrize tests. Added DeFFcode's FFdecoder API unit tests with pytest. Added new test_source_playback , test_frame_format , test_metadata , test_seek_n_save , and test_FFdecoder_params parametrize unit tests. Added related imports and logging. Added unit test for delete_file_safe utils function. Bash: \ud83d\udd27 Imported prepare_dataset.sh from vidgear for downloading pytest datasets to temp dir. Updates/Improvements FFdecoder API: Removed redundant forcing -r FFmpeg parameter for image sequences as source. Removed redundant checks on -vf FFmpeg parameter. FFmpeg parameter -s will be discarded in favor of -custom_resolution attribute. Replaced -constant_framerate with FFmpeg -framerate attribute. Replaced -custom_source_params with correct -custom_sourcer_params attribute. Renamed operational_mode metadata parameter to ffdecoder_operational_mode . Sourcer API: Converted all Sourcer APIs public available variables into private ones for stability. All Sourcer's publicly accessed variable metadata values in FFdecoder, therefore replaced with dictionary counterparts. Moved FFmpeg path validation and handling to Sourcer from FFdecoder API. Moved -ffmpeg_download_path dictionary attribute to Sourcer API's sourcer_params parameter. Moved dependencies and related functions. CI: Excluded dev branch from triggering workflow on any environment. Updated yaml files to exclude beta dev branch from triggering workflow on any environment. Restricted codecov to use only master branch. Re-implemented fkirc/skip-duplicate-actions@master to Skip individual deploy steps instead of Skip entire jobs Docs: Updated PR.md Added instructions to download prepare_dataset.sh using curl. Updated dependencies for pytest . Updated advanced.md Updated generating Video from Image sequence to save video using OpenCV writer instead of WriteGear API. Added frame_format=\"bgr24\" and additional instructions regarding OpenCV writer. Updated example codes with new changes. Rearranged examples placement. Updates to custom.css Added donation sponsor link in page footer with heart animation. Added bouncing heart animation through pure CSS. Added Bold property to currently highlighted link in Navigation Bar. Updated Navigation Bar title font size. Updated version list text to uppercase and bold. Updated icon for task list unchecked. Added more top-padding to docs heading. Updated Block quote symbol and theming. Updated Custom Button theming to match docs. Added new custom classes to create shadow effect in dark mode for better visibility. Updated dark mode theme \"slate\" hue to 285. Updated admonitions colors. Updated gitter sidecard UI colors and properties. Reflected recent changes in Sourcer and FFdecoder API's metadata. Updated sample code formatting from sh to json . Added missing docs for delete_file_safe utils function. Updated Download Test Datasets instructions. Updated contribution guidelines and installation docs with related changes. Updated License Notice. Updated code comments. Updated logging messages. Updated Deffcode Logo and Tagline to be dark-mode friendly. Adjusted asset alignment. Updated example code. Updated Installation instructions, Requirements and Roadmap. Corrected links to documents. Updated project description. Updated LICENSE. Updated indentation and code comments Re-aligned text and images in README.md Adjusted image classes and width. Maintenance: Updated LICENSE notice to add vidgear notice. Bumped version to 0.2.0 Added useful comments for convenience. Breaking Updates/Changes Sourcer API will now raises Assertion error if probe_stream() not called before calling retrieve_metadata() . Only -framerate values greater than 0.0 are now valid. Renamed decode_stream to probe_stream in Sourcer API. Any of video bitrate or video framerate are sufficient to validate if source contains valid video stream(s). Any of audio bitrate or audio samplerate are sufficient to validate if source contains valid audio stream(s). Bug-fixes APIs: Added missing delete_file_safe function in utils. Imported delete_file_safe from vidgear to safely deletes files at given path. Fixed forward slash bugs in regex patterns. Fixed IndexError when no bitrate was discovered in given source. Fixed FFmpeg subprocess pipeline not terminating gracefully in FFdecoder API. Fixed __version__ not defined in DeFFcode's __init__.py that throws AttributeError: module 'deffcode' has no attribute '__version__' on query. Added necessary import in __init__.py . Docs: Fixed missing \"-vcodec\": \"h264_cuvid\" value in example code. Fixed typos in filenames in utils.py Fixed internal missing or invalid hyperlinks. Fixed improper docs context and typos. Fixed \"year\" in license notice. Fixed content spacing. Fixed Gitter Community Link in Mkdocs. Fixed typos in README.md. Fixed typos in license notices. Fixed typos in code comments. Fixed typos in example code. CI: Fixed missing FFmpeg dependency bug in GitHub Actions. Fixes typo in Docs Deployer yaml. Fixed if condition skipping when need is skipping Maintenance: Added missing imports. Fixed redundant conditional logics. Removed or Replaced redundant conditions and definitions. Fixed minor typos in templates. Pull Requests PR #5 PR #6 PR #8 PR #9 PR #11 PR #12 PR #13 PR #14","title":"v0.2.0 (2022-03-21)"},{"location":"changelog/#v010-2022-03-07","text":"New Features Open-Sourced DeFFcode under the Apache 2.0 License. Added new Classes(APIs): FFdecoder: Performant Real-time Video frames Generator for generating blazingly fast video frames(RGB ndarray by default). Sourcer: Extracts source video metadata (bitrate, resolution, framerate, nframes etc.) using its subprocess FFmpeg output. Added new Helper functions: ffhelper: Backend FFmpeg Wrapper that handles all subprocess transactions and gather data. utils: Handles all additional Utilizes required for functioning of DeFFcode. First PyPi Release: Released DeFFcode to Python Package Index (PyPI) Added setup.py and related metadata. Added version.py Docs: Added abstract and related information in README.md Added installation instructions. Added preliminary usage examples. Maintenance: Added LICENSE. Added .gitignore Updates/Improvements Maintenance: Bumped version to 0.1.0 Updated LICENSE notice to add vidgear code usage notice. Breaking Updates/Changes Fixed support for Python-3.7 and above legacies only. Bug-fixes Docs: Fixed hyperlinks in README. Fixed indentation and spacing. Fixed typos and updated context. Removed dead code.","title":"v0.1.0 (2022-03-07)"},{"location":"help/","text":"Helping Us \u00b6 Liked DeFFcode? Would you like to help DeFFcode, other users, and the author? There are many simple ways to help us: Star DeFFcode on GitHub \u00b6 You can star DeFFcode on GitHub: It helps us a lot by making it easier for others to find & trust this library. Thanks! \u2009 Help others with issues on GitHub \u00b6 You can see through any opened or pinned existing issues on our GitHub repository, and try helping others, wherever possible: \u2009 Watch the GitHub repository \u00b6 You can watch \ud83d\udc40 DeFFcode Activities on GitHub: When you watch a repository, you will be notified of all conversations for that repository, including when someone creates a new issue, or pushes a new pull request. You can try helping solving those issues, or give valuable feedback/review on new Pull Requests. \u2009 Tweet about DeFFcode \u00b6 Tweet about DeFFcode and Spread the word \ud83d\udde3: Tweet #deffcode Let others know how you are using DeFFcode and why you like it! \u2009 Helping Author \u00b6 Donations help keep DeFFcode's development alive and motivate me (as author) . It is something I am doing with my own free time. But so much more needs to be done, and I need your help to do this. For just the price of a cup of coffee, you can make a difference kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw(); Thanks a million! \u2009 Connect with Author \u00b6 You can connect with me, the author \ud83d\udc4b: Follow author on GitHub: Follow author on Twitter: Follow @abhi_una12 Get in touch with author on Linkedin:","title":"Help Us"},{"location":"help/#helping-us","text":"Liked DeFFcode? Would you like to help DeFFcode, other users, and the author? There are many simple ways to help us:","title":"Helping Us"},{"location":"help/#star-deffcode-on-github","text":"You can star DeFFcode on GitHub: It helps us a lot by making it easier for others to find & trust this library. Thanks!","title":" Star DeFFcode on GitHub"},{"location":"help/#help-others-with-issues-on-github","text":"You can see through any opened or pinned existing issues on our GitHub repository, and try helping others, wherever possible:","title":" Help others with issues on GitHub"},{"location":"help/#watch-the-github-repository","text":"You can watch \ud83d\udc40 DeFFcode Activities on GitHub: When you watch a repository, you will be notified of all conversations for that repository, including when someone creates a new issue, or pushes a new pull request. You can try helping solving those issues, or give valuable feedback/review on new Pull Requests.","title":" Watch the GitHub repository"},{"location":"help/#tweet-about-deffcode","text":"Tweet about DeFFcode and Spread the word \ud83d\udde3: Tweet #deffcode Let others know how you are using DeFFcode and why you like it!","title":" Tweet about DeFFcode"},{"location":"help/#helping-author","text":"Donations help keep DeFFcode's development alive and motivate me (as author) . It is something I am doing with my own free time. But so much more needs to be done, and I need your help to do this. For just the price of a cup of coffee, you can make a difference kofiwidget2.init('Support Me on Ko-fi', '#eba100', 'W7W8WTYO');kofiwidget2.draw(); Thanks a million!","title":" Helping Author"},{"location":"help/#connect-with-author","text":"You can connect with me, the author \ud83d\udc4b: Follow author on GitHub: Follow author on Twitter: Follow @abhi_una12 Get in touch with author on Linkedin:","title":" Connect with Author"},{"location":"license/","text":"License \u00b6 This library is released under the Apache 2.0 License . Copyright Notice \u00b6 Copyright (c) 2021 Abhishek Thakur(@abhiTronix) <abhi.una12@gmail.com> Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"License"},{"location":"license/#license","text":"This library is released under the Apache 2.0 License .","title":"License"},{"location":"license/#copyright-notice","text":"Copyright (c) 2021 Abhishek Thakur(@abhiTronix) <abhi.una12@gmail.com> Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.","title":"Copyright Notice"},{"location":"contribution/","text":"Contribution Overview \u00b6 Contributions are always welcomed We'd love your contribution to DeFFcode in order to fix bugs or to implement new features! Submission Guidelines \u00b6 Submitting an Issue Guidelines \u27b6 Submitting Pull Request(PR) Guidelines \u27b6 Submission Contexts \u00b6 Got a question or problem? \u00b6 For quick questions, please refrain from opening an issue, instead you can reach us on Gitter community channel. Found a typo? \u00b6 There's no need to contribute for some typos. Just reach us on Gitter \u27b6 community channel, We will correct them in (less than) no time. Found a bug? \u00b6 If you encountered a bug, you can help us by submitting an issue in our GitHub repository. Even better, you can submit a Pull Request(PR) with a fix, but make sure to read the guidelines \u27b6 . Request for a feature/improvement? \u00b6 Subscribe to Github Repository You can subscribe our GitHub Repository to receive notifications through email for new pull requests, commits and issues that are created in DeFFcode. Learn more about it here \u27b6 You can request our GitHub Repository for a new feature/improvement based on the type of request: Please submit an issue with a proposal template for your request to explain how it benefits everyone in the community. Major Feature Requests: If you require a major feature for DeFFcode, then first open an issue and outline your proposal so that it can be discussed. This will also allow us to better coordinate our efforts, prevent duplication of work, and help you to craft the change so that it is successfully accepted into the project. The purposed feature, if accepted, may take time based on its complexity and availability/time-schedule of our maintainers, but once it's completed, you will be notified right away. Please be patient! Minor Feature Requests: Small features and bugs resolved on priority. You just have to submit an issue to our GitHub Repository.","title":"Overview"},{"location":"contribution/#contribution-overview","text":"Contributions are always welcomed We'd love your contribution to DeFFcode in order to fix bugs or to implement new features!","title":"Contribution Overview"},{"location":"contribution/#submission-guidelines","text":"Submitting an Issue Guidelines \u27b6 Submitting Pull Request(PR) Guidelines \u27b6","title":"Submission Guidelines"},{"location":"contribution/#submission-contexts","text":"","title":"Submission Contexts"},{"location":"contribution/#got-a-question-or-problem","text":"For quick questions, please refrain from opening an issue, instead you can reach us on Gitter community channel.","title":"Got a question or problem?"},{"location":"contribution/#found-a-typo","text":"There's no need to contribute for some typos. Just reach us on Gitter \u27b6 community channel, We will correct them in (less than) no time.","title":"Found a typo?"},{"location":"contribution/#found-a-bug","text":"If you encountered a bug, you can help us by submitting an issue in our GitHub repository. Even better, you can submit a Pull Request(PR) with a fix, but make sure to read the guidelines \u27b6 .","title":"Found a bug?"},{"location":"contribution/#request-for-a-featureimprovement","text":"Subscribe to Github Repository You can subscribe our GitHub Repository to receive notifications through email for new pull requests, commits and issues that are created in DeFFcode. Learn more about it here \u27b6 You can request our GitHub Repository for a new feature/improvement based on the type of request: Please submit an issue with a proposal template for your request to explain how it benefits everyone in the community. Major Feature Requests: If you require a major feature for DeFFcode, then first open an issue and outline your proposal so that it can be discussed. This will also allow us to better coordinate our efforts, prevent duplication of work, and help you to craft the change so that it is successfully accepted into the project. The purposed feature, if accepted, may take time based on its complexity and availability/time-schedule of our maintainers, but once it's completed, you will be notified right away. Please be patient! Minor Feature Requests: Small features and bugs resolved on priority. You just have to submit an issue to our GitHub Repository.","title":"Request for a feature/improvement?"},{"location":"contribution/PR/","text":"Submitting Pull Request(PR) Guidelines: \u00b6 The following guidelines tells you how to submit a valid PR for DeFFcode: Working on your first Pull Request for DeFFcode? You can learn about \" How to contribute to an Open Source Project on GitHub \" from this doc \u27b6 If you're stuck at something, please join our Gitter community channel . We will help you get started! Clone branch for PR \u00b6 You can clone your Forked remote git to local and create your PR working branch as a sub-branch of latest master branch as follows: Make sure the master branch of your Forked repository is up-to-date with DeFFcode, before starting working on a Pull Request. # clone your forked repository(change with your username) and get inside git clone https://github.com/ { YOUR USERNAME } /DeFFcode.git && cd DeFFcode # pull any recent updates git pull # Now create your new branch with suitable name(such as \"subbranch_of_master\") git checkout -b subbranch_of_master Now after working with this newly created branch for your Pull Request, you can commit and push or merge it locally or remotely as usual. PR Submission Checklist \u00b6 There are some important checks you need to perform while submitting your Pull Request(s) for DeFFcode library: Submit a Related Issue: The first thing you do is submit an issue with a proposal template for your work first and then work on your Pull Request. Submit a Draft Pull Request: Submit the draft pull request from the first day of your development. Add a brief but descriptive title for your PR. Explain what the PR adds, fixes, or improves. In case of bug fixes, add a new unit test case that would fail against your bug fix. Provide output or screenshots, if you can. Make sure your pull request passed all the CI checks (triggers automatically on pushing commits against master branch) . If it's somehow failing, then ask the maintainer for a review. Click \" ready for review \" when finished. Test, Format & lint code locally: Make sure to test, format, and lint the modified code locally before every commit. The details are discussed below \u27b6 Make sensible commit messages: If your pull request fixes a separate issue number, remember to include \"resolves #issue_number\" in the commit message. Learn more about it here \u27b6 . Keep the commit message concisely as much as possible at every submit. You can make a supplement to the previous commit with git commit --amend command. Perform Integrity Checks: Any duplicate pull request will be Rejected! Search GitHub if there's a similar open or closed PR that relates to your submission. Check if your purpose code matches the overall direction of the DeFFcode APIs and improves it. Retain copyright for your contributions, but also agree to license them for usage by the project and author(s) under the Apache 2.0 license \u27b6 . Link your Issues: For more information on Linking a pull request to an issue, See this doc\u27b6 Finally, when you're confident enough, make your pull request public. You can link an issue to a pull request manually or using a supported keyword in the pull request description. It helps collaborators see that someone is working on the issue. For more information, see this doc\u27b6 Testing, Formatting & Linting \u00b6 All Pull Request(s) must be tested, formatted & linted against our library standards as discussed below: Requirements \u00b6 Testing DeFFcode requires additional test dependencies and dataset, which can be handled manually as follows: Install additional python libraries: You can easily install these dependencies via pip: # Install opencv(only if not installed previously) $ pip install opencv-python # install rest of dependencies $ pip install --upgrade flake8 black pytest vidgear [ core ] Download Tests Dataset: To perform tests, you also need to download additional dataset (to your temp dir) by running prepare_dataset.sh bash script as follows: On Linux/MacOS On Windows $ chmod +x scripts/bash/prepare_dataset.sh $ ./scripts/bash/prepare_dataset.sh $ sh scripts/bash/prepare_dataset.sh Running Tests \u00b6 All tests can be run with pytest ( in DeFFcode's root folder ) as follows: $ pytest -sv #-sv for verbose output. Formatting & Linting \u00b6 For formatting and linting, following libraries are used: Flake8: You must run flake8 linting for checking the code base against the coding style (PEP8), programming errors and other cyclomatic complexity: $ flake8 { source_file_or_directory } --count --select = E9,F63,F7,F82 --show-source --statistics Black: DeFFcode follows black formatting to make code review faster by producing the smallest diffs possible. You must run it with sensible defaults as follows: $ black { source_file_or_directory } Frequently Asked Questions \u00b6 Q1. Why do my changes taking so long to be Reviewed and/or Merged? Submission Aftermaths After your PR is merged, you can safely delete your branch and pull the changes from the main (upstream) repository. The changes will remain in dev branch until next DeFFcode version is released, then it will be merged into master branch. After a successful Merge, your newer contributions will be given priority over others. Pull requests will be reviewed by the maintainers and the rationale behind the maintainer\u2019s decision to accept or deny the changes will be posted in the pull request. Please wait for our code review and approval, possibly enhancing your change on request. Q2. Would you accept a huge Pull Request with Lots of Changes? First, make sure that the changes are somewhat related. Otherwise, please create separate pull requests. Anyway, before submitting a huge change, it's probably a good idea to open an issue in the DeFFcode Github repository to ask the maintainers if they agree with your proposed changes. Otherwise, they could refuse your proposal after you put all that hard work into making the changes. We definitely don't want you to waste your time!","title":"Pull Request(PR) Guidelines"},{"location":"contribution/PR/#submitting-pull-requestpr-guidelines","text":"The following guidelines tells you how to submit a valid PR for DeFFcode: Working on your first Pull Request for DeFFcode? You can learn about \" How to contribute to an Open Source Project on GitHub \" from this doc \u27b6 If you're stuck at something, please join our Gitter community channel . We will help you get started!","title":"Submitting Pull Request(PR) Guidelines:"},{"location":"contribution/PR/#clone-branch-for-pr","text":"You can clone your Forked remote git to local and create your PR working branch as a sub-branch of latest master branch as follows: Make sure the master branch of your Forked repository is up-to-date with DeFFcode, before starting working on a Pull Request. # clone your forked repository(change with your username) and get inside git clone https://github.com/ { YOUR USERNAME } /DeFFcode.git && cd DeFFcode # pull any recent updates git pull # Now create your new branch with suitable name(such as \"subbranch_of_master\") git checkout -b subbranch_of_master Now after working with this newly created branch for your Pull Request, you can commit and push or merge it locally or remotely as usual.","title":"Clone branch for PR"},{"location":"contribution/PR/#pr-submission-checklist","text":"There are some important checks you need to perform while submitting your Pull Request(s) for DeFFcode library: Submit a Related Issue: The first thing you do is submit an issue with a proposal template for your work first and then work on your Pull Request. Submit a Draft Pull Request: Submit the draft pull request from the first day of your development. Add a brief but descriptive title for your PR. Explain what the PR adds, fixes, or improves. In case of bug fixes, add a new unit test case that would fail against your bug fix. Provide output or screenshots, if you can. Make sure your pull request passed all the CI checks (triggers automatically on pushing commits against master branch) . If it's somehow failing, then ask the maintainer for a review. Click \" ready for review \" when finished. Test, Format & lint code locally: Make sure to test, format, and lint the modified code locally before every commit. The details are discussed below \u27b6 Make sensible commit messages: If your pull request fixes a separate issue number, remember to include \"resolves #issue_number\" in the commit message. Learn more about it here \u27b6 . Keep the commit message concisely as much as possible at every submit. You can make a supplement to the previous commit with git commit --amend command. Perform Integrity Checks: Any duplicate pull request will be Rejected! Search GitHub if there's a similar open or closed PR that relates to your submission. Check if your purpose code matches the overall direction of the DeFFcode APIs and improves it. Retain copyright for your contributions, but also agree to license them for usage by the project and author(s) under the Apache 2.0 license \u27b6 . Link your Issues: For more information on Linking a pull request to an issue, See this doc\u27b6 Finally, when you're confident enough, make your pull request public. You can link an issue to a pull request manually or using a supported keyword in the pull request description. It helps collaborators see that someone is working on the issue. For more information, see this doc\u27b6","title":"PR Submission Checklist"},{"location":"contribution/PR/#testing-formatting-linting","text":"All Pull Request(s) must be tested, formatted & linted against our library standards as discussed below:","title":"Testing, Formatting &amp; Linting"},{"location":"contribution/PR/#requirements","text":"Testing DeFFcode requires additional test dependencies and dataset, which can be handled manually as follows: Install additional python libraries: You can easily install these dependencies via pip: # Install opencv(only if not installed previously) $ pip install opencv-python # install rest of dependencies $ pip install --upgrade flake8 black pytest vidgear [ core ] Download Tests Dataset: To perform tests, you also need to download additional dataset (to your temp dir) by running prepare_dataset.sh bash script as follows: On Linux/MacOS On Windows $ chmod +x scripts/bash/prepare_dataset.sh $ ./scripts/bash/prepare_dataset.sh $ sh scripts/bash/prepare_dataset.sh","title":"Requirements"},{"location":"contribution/PR/#running-tests","text":"All tests can be run with pytest ( in DeFFcode's root folder ) as follows: $ pytest -sv #-sv for verbose output.","title":"Running Tests"},{"location":"contribution/PR/#formatting-linting","text":"For formatting and linting, following libraries are used: Flake8: You must run flake8 linting for checking the code base against the coding style (PEP8), programming errors and other cyclomatic complexity: $ flake8 { source_file_or_directory } --count --select = E9,F63,F7,F82 --show-source --statistics Black: DeFFcode follows black formatting to make code review faster by producing the smallest diffs possible. You must run it with sensible defaults as follows: $ black { source_file_or_directory }","title":"Formatting &amp; Linting"},{"location":"contribution/PR/#frequently-asked-questions","text":"Q1. Why do my changes taking so long to be Reviewed and/or Merged? Submission Aftermaths After your PR is merged, you can safely delete your branch and pull the changes from the main (upstream) repository. The changes will remain in dev branch until next DeFFcode version is released, then it will be merged into master branch. After a successful Merge, your newer contributions will be given priority over others. Pull requests will be reviewed by the maintainers and the rationale behind the maintainer\u2019s decision to accept or deny the changes will be posted in the pull request. Please wait for our code review and approval, possibly enhancing your change on request. Q2. Would you accept a huge Pull Request with Lots of Changes? First, make sure that the changes are somewhat related. Otherwise, please create separate pull requests. Anyway, before submitting a huge change, it's probably a good idea to open an issue in the DeFFcode Github repository to ask the maintainers if they agree with your proposed changes. Otherwise, they could refuse your proposal after you put all that hard work into making the changes. We definitely don't want you to waste your time!","title":"Frequently Asked Questions"},{"location":"contribution/issue/","text":"Submitting an Issue Guidelines \u00b6 If you've found a new bug or you've come up with some new feature which can improve the quality of the DeFFcode, then related issues are welcomed! But, Before you do, please read the following guidelines: First Issue on GitHub? You can easily learn about it from creating an issue wiki. Info Please note that your issue will be fixed much faster if you spend about half an hour preparing it, including the exact reproduction steps and a demo. If you're in a hurry or don't feel confident, it's fine to report issues with less details, but this makes it less likely they'll get fixed soon. Search the Docs and Previous Issues \u00b6 Remember to first search GitHub for a open or closed issue that relates to your submission or already been reported. You may find related information and the discussion might inform you of workarounds that may help to resolve the issue. For quick questions, please refrain from opening an issue, as you can reach us on Gitter community channel. Also, go comprehensively through our dedicated FAQ & Troubleshooting section . Gather Required Information \u00b6 All DeFFcode APIs provides a verbose boolean flag in parameters, to log debugged output to terminal. Kindly turn this parameter True in the respective API for getting debug output, and paste it with your Issue. In order to reproduce bugs we will systematically ask you to provide a minimal reproduction code for your report. Check and paste, exact DeFFcode version by running command python - c \"import deffcode; print(deffcode.__version__)\" . Follow the Issue Template \u00b6 Please format your issue by choosing the appropriate template. Any improper/insufficient reports will be marked Invalid \u26d4 , and if we don't hear back from you we may close the issue. Raise the Issue \u00b6 Add a brief but descriptive title for your issue. Keep the issue phrasing in context of the problem. Attach source-code/screenshots if you have one. Finally, raise it by choosing the appropriate Issue Template: Bug report \ud83d\udc1e , Idea \ud83d\udca1 , Question \u2754 .","title":"Issue Guidelines"},{"location":"contribution/issue/#submitting-an-issue-guidelines","text":"If you've found a new bug or you've come up with some new feature which can improve the quality of the DeFFcode, then related issues are welcomed! But, Before you do, please read the following guidelines: First Issue on GitHub? You can easily learn about it from creating an issue wiki. Info Please note that your issue will be fixed much faster if you spend about half an hour preparing it, including the exact reproduction steps and a demo. If you're in a hurry or don't feel confident, it's fine to report issues with less details, but this makes it less likely they'll get fixed soon.","title":"Submitting an Issue Guidelines"},{"location":"contribution/issue/#search-the-docs-and-previous-issues","text":"Remember to first search GitHub for a open or closed issue that relates to your submission or already been reported. You may find related information and the discussion might inform you of workarounds that may help to resolve the issue. For quick questions, please refrain from opening an issue, as you can reach us on Gitter community channel. Also, go comprehensively through our dedicated FAQ & Troubleshooting section .","title":"Search the Docs and Previous Issues"},{"location":"contribution/issue/#gather-required-information","text":"All DeFFcode APIs provides a verbose boolean flag in parameters, to log debugged output to terminal. Kindly turn this parameter True in the respective API for getting debug output, and paste it with your Issue. In order to reproduce bugs we will systematically ask you to provide a minimal reproduction code for your report. Check and paste, exact DeFFcode version by running command python - c \"import deffcode; print(deffcode.__version__)\" .","title":"Gather Required Information"},{"location":"contribution/issue/#follow-the-issue-template","text":"Please format your issue by choosing the appropriate template. Any improper/insufficient reports will be marked Invalid \u26d4 , and if we don't hear back from you we may close the issue.","title":"Follow the Issue Template"},{"location":"contribution/issue/#raise-the-issue","text":"Add a brief but descriptive title for your issue. Keep the issue phrasing in context of the problem. Attach source-code/screenshots if you have one. Finally, raise it by choosing the appropriate Issue Template: Bug report \ud83d\udc1e , Idea \ud83d\udca1 , Question \u2754 .","title":"Raise the Issue"},{"location":"help/get_help/","text":"Getting Help \u00b6 Courtesy - tenor Would you like to get help with DeFFcode? There are several ways to get help with DeFFcode: Join our Gitter Community channel \u00b6 Have you come up with some new idea \ud83d\udca1 or looking for the fastest way troubleshoot your problems Join and chat on our Gitter Community channel: There you can ask quick questions, swiftly troubleshoot your problems, help others, share ideas & information, etc. \u2009 This is what you do when... \u00b6 Got a question or problem? Found a typo? Found a bug? Missing a feature/improvement? \u2009 Reporting an issues \u00b6 Want to report a bug? Suggest a new feature? Before you do, please read our guidelines \u27b6 \u2009 Preparing a Pull Request \u00b6 Interested in contributing to DeFFcode? Before you do, please read our guidelines \u27b6","title":"Get Help"},{"location":"help/get_help/#getting-help","text":"Courtesy - tenor Would you like to get help with DeFFcode? There are several ways to get help with DeFFcode:","title":"Getting Help"},{"location":"help/get_help/#join-our-gitter-community-channel","text":"Have you come up with some new idea \ud83d\udca1 or looking for the fastest way troubleshoot your problems Join and chat on our Gitter Community channel: There you can ask quick questions, swiftly troubleshoot your problems, help others, share ideas & information, etc.","title":" Join our Gitter Community channel"},{"location":"help/get_help/#this-is-what-you-do-when","text":"Got a question or problem? Found a typo? Found a bug? Missing a feature/improvement?","title":" This is what you do when..."},{"location":"help/get_help/#reporting-an-issues","text":"Want to report a bug? Suggest a new feature? Before you do, please read our guidelines \u27b6","title":" Reporting an issues"},{"location":"help/get_help/#preparing-a-pull-request","text":"Interested in contributing to DeFFcode? Before you do, please read our guidelines \u27b6","title":" Preparing a Pull Request"},{"location":"installation/","text":"Installation Notes \u00b6 Supported Systems \u00b6 DeFFcode is well-tested and supported on the following systems(but not limited to), with python 3.7+ and pip installed: Upgrade your pip It strongly advised to upgrade to latest pip before installing deffcode to avoid any undesired installation error(s). There are two mechanisms to upgrade pip : pip ensurepip You can use existing pip to upgrade itself: Install pip if not present Download the script, from https://bootstrap.pypa.io/get-pip.py . Open a terminal/command prompt, cd to the folder containing the get-pip.py file and run: Linux/MacOS Windows python get-pip.py py get-pip.py More details about this script can be found in pypa/get-pip\u2019s README . Linux/MacOS Windows python -m pip install pip --upgrade py -m pip install pip --upgrade Python also comes with an ensurepip module 1 , which can easily upgrade/install pip in any Python environment. Linux/MacOS Windows python -m ensurepip --upgrade py -m ensurepip --upgrade Any Linux distro released in 2016 or later Windows 7 or later MacOS 10.12.6 (Sierra) or later \u2009 Supported Python legacies \u00b6 Python 3.7+ are only supported legacies for installing DeFFcode v0.1.0 and above. \u2009 Prerequisites \u00b6 DeFFcode APIs requires FFmpeg binaries to be installed for all of its core functionality. FFmpeg \u00b6 When installing DeFFcode, FFmpeg is the only prerequisites you need to configure/install manually. You could easily do it by referring FFmpeg Installation doc . Installation \u00b6 A. Installation using pip (Recommended) \u00b6 Best option for easily getting stable DeFFcode installed. Installation is as simple as: Windows Installation If you are using Windows, some of the commands given below, may not work out-of-the-box. A quick solution may be to preface every Python command with python -m like this: # Install latest stable release python -m pip install -U deffcode And, If you don't have the privileges to the directory you're installing package. Then use --user flag, that makes pip install packages in your home directory instead: # Install latest stable release python -m pip install --upgrade --user deffcode Or, If you're using py as alias for installed python, then: # Install latest stable release py -m pip install --upgrade --user deffcode # Install latest stable release pip install -U deffcode And you can also download its wheel ( .whl ) package from our repository's releases section, thereby can be installed as follows: # Install latest release pip install deffcode-0.2.0-py3-none-any.whl \u2009 B. Installation from Source \u00b6 Best option for trying latest patches(maybe experimental), forking for Pull Requests, or automatically installing all prerequisites(with a few exceptions). Installation using dev banch If you're looking for latest work-in-progress enhancements or bug-fixes, then you want to checkout our beta dev branch with the following commands: The beta dev branch at times can be very unstable or even unusable, User discretion is advised! # clone the repository and get inside git clone https://github.com/abhiTronix/deffcode.git && cd deffcode # checkout the dev beta branch git checkout dev # Install it pip install -U . Windows Installation If you are using Windows, some of the commands given below, may not work out-of-the-box. A quick solution may be to preface every Python command with python -m like this: # Install latest beta branch python -m pip install -U . And, If you don't have the privileges to the directory you're installing package. Then use --user flag, that makes pip install packages in your home directory instead: # Install latest beta branch python -m pip install --upgrade --user . Or, If you're using py as alias for installed python, then: # Install latest beta branch py -m pip install --upgrade --user . # clone the repository and get inside git clone https://github.com/abhiTronix/deffcode.git && cd deffcode # Install it pip install -U . The ensurepip module is missing/disabled on Ubuntu. Use pip method only. \u21a9","title":"Overview"},{"location":"installation/#installation-notes","text":"","title":"Installation Notes"},{"location":"installation/#supported-systems","text":"DeFFcode is well-tested and supported on the following systems(but not limited to), with python 3.7+ and pip installed: Upgrade your pip It strongly advised to upgrade to latest pip before installing deffcode to avoid any undesired installation error(s). There are two mechanisms to upgrade pip : pip ensurepip You can use existing pip to upgrade itself: Install pip if not present Download the script, from https://bootstrap.pypa.io/get-pip.py . Open a terminal/command prompt, cd to the folder containing the get-pip.py file and run: Linux/MacOS Windows python get-pip.py py get-pip.py More details about this script can be found in pypa/get-pip\u2019s README . Linux/MacOS Windows python -m pip install pip --upgrade py -m pip install pip --upgrade Python also comes with an ensurepip module 1 , which can easily upgrade/install pip in any Python environment. Linux/MacOS Windows python -m ensurepip --upgrade py -m ensurepip --upgrade Any Linux distro released in 2016 or later Windows 7 or later MacOS 10.12.6 (Sierra) or later","title":"Supported Systems"},{"location":"installation/#supported-python-legacies","text":"Python 3.7+ are only supported legacies for installing DeFFcode v0.1.0 and above.","title":"Supported Python legacies"},{"location":"installation/#prerequisites","text":"DeFFcode APIs requires FFmpeg binaries to be installed for all of its core functionality.","title":"Prerequisites"},{"location":"installation/#ffmpeg","text":"When installing DeFFcode, FFmpeg is the only prerequisites you need to configure/install manually. You could easily do it by referring FFmpeg Installation doc .","title":"FFmpeg"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#a-installation-using-pip-recommended","text":"Best option for easily getting stable DeFFcode installed. Installation is as simple as: Windows Installation If you are using Windows, some of the commands given below, may not work out-of-the-box. A quick solution may be to preface every Python command with python -m like this: # Install latest stable release python -m pip install -U deffcode And, If you don't have the privileges to the directory you're installing package. Then use --user flag, that makes pip install packages in your home directory instead: # Install latest stable release python -m pip install --upgrade --user deffcode Or, If you're using py as alias for installed python, then: # Install latest stable release py -m pip install --upgrade --user deffcode # Install latest stable release pip install -U deffcode And you can also download its wheel ( .whl ) package from our repository's releases section, thereby can be installed as follows: # Install latest release pip install deffcode-0.2.0-py3-none-any.whl","title":"A. Installation using pip (Recommended)"},{"location":"installation/#b-installation-from-source","text":"Best option for trying latest patches(maybe experimental), forking for Pull Requests, or automatically installing all prerequisites(with a few exceptions). Installation using dev banch If you're looking for latest work-in-progress enhancements or bug-fixes, then you want to checkout our beta dev branch with the following commands: The beta dev branch at times can be very unstable or even unusable, User discretion is advised! # clone the repository and get inside git clone https://github.com/abhiTronix/deffcode.git && cd deffcode # checkout the dev beta branch git checkout dev # Install it pip install -U . Windows Installation If you are using Windows, some of the commands given below, may not work out-of-the-box. A quick solution may be to preface every Python command with python -m like this: # Install latest beta branch python -m pip install -U . And, If you don't have the privileges to the directory you're installing package. Then use --user flag, that makes pip install packages in your home directory instead: # Install latest beta branch python -m pip install --upgrade --user . Or, If you're using py as alias for installed python, then: # Install latest beta branch py -m pip install --upgrade --user . # clone the repository and get inside git clone https://github.com/abhiTronix/deffcode.git && cd deffcode # Install it pip install -U . The ensurepip module is missing/disabled on Ubuntu. Use pip method only. \u21a9","title":"B. Installation from Source"},{"location":"installation/ffmpeg_install/","text":"FFmpeg Installation Doc \u00b6 \u2009 DeFFcode APIs requires FFmpeg binaries to be installed for all of its core functionality. You can following machine-specific instructions for its configuration/installation: DeFFcode APIs will throw RuntimeError , if they failed to detect valid FFmpeg executables on your system. Enable verbose ( verbose=True ) for debugging FFmpeg validation process. \u2009 Linux FFmpeg Installation \u00b6 DeFFcode APIs supports Auto-Detection and Manual Configuration methods on a Linux OS machines: A. Auto-Detection \u00b6 This is a recommended approach on Linux Machines If DeFFcode APIs do not receive any input from the user on custom_ffmpeg parameter, then they try to auto-detect the required FFmpeg installed binaries through a validation test that employs subprocess python module on the Linux OS systems. You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6 B. Manual Configuration \u00b6 Download: You can also manually download the latest Linux Static Binaries (based on your machine architecture) from the link below: Linux Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the DeFFcode APIs. If binaries were not found at the manually specified path, DeFFcode APIs will throw RuntimeError ! Windows FFmpeg Installation \u00b6 DeFFcode APIs supports Auto-Installation and Manual Configuration methods on Windows OS machines: A. Auto-Installation \u00b6 This is a recommended approach on Windows Machines If DeFFcode APIs do not receive any input from the user on custom_ffmpeg parameter, then they try to auto-generate the required FFmpeg Static Binaries from our dedicated Github Server into the temporary directory(e.g. C:\\Temp ) of your machine on the Windows OS systems. Active Internet connection is required while downloading required FFmpeg Static Binaries from our dedicated Github Server onto your Windows machine. Important Information regarding Auto-Installation The files downloaded to a temporary directory (e.g. C:\\TEMP ), may get erased if your machine shutdowns/restarts in some cases. You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through exclusive -ffmpeg_download_path attribute in Sourcer API. How to use -ffmpeg_download_path attribute in FFdecoder API? -ffmpeg_download_path is also available in FFdecoder API through the -custom_sourcer_params attribute of its ffparams dictionary parameter. If binaries were found at the specified path, DeFFcode APIs automatically skips the Auto-Installation step. If the required FFmpeg static binary fails to download, extract, or validate during Auto-Installation, then DeFFcode APIs will exit with RuntimeError ! B. Manual Configuration \u00b6 Download: You can also manually download the latest Windows Static Binaries (based on your machine arch(x86/x64)) from the link below: Windows Static Binaries: https://ffmpeg.org/download.html#build-windows Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'C:/foo/Downloads/ffmpeg/bin' ) or path of ffmpeg.exe executable itself to the custom_ffmpeg parameter in the DeFFcode APIs. If binaries were not found at the manually specified path, DeFFcode APIs will throw RuntimeError ! MacOS FFmpeg Installation \u00b6 DeFFcode APIs supports Auto-Detection and Manual Configuration methods on MacOS OS machines: A. Auto-Detection \u00b6 This is a recommended approach on MacOS Machines If DeFFcode APIs do not receive any input from the user on custom_ffmpeg parameter, then they try to auto-detect the required FFmpeg installed binaries through a validation test that employs subprocess python module on the MacOS systems. You can easily install FFmpeg on your MacOS machine by following this tutorial \u27b6 B. Manual Configuration \u00b6 Download: You can also manually download the latest MacOS Static Binaries (only x64 Binaries) from the link below: MacOS Static Binaries: https://ffmpeg.org/download.html#build-mac Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the DeFFcode APIs. If binaries were not found at the manually specified path, DeFFcode APIs will throw RuntimeError !","title":"FFmpeg Installation"},{"location":"installation/ffmpeg_install/#ffmpeg-installation-doc","text":"DeFFcode APIs requires FFmpeg binaries to be installed for all of its core functionality. You can following machine-specific instructions for its configuration/installation: DeFFcode APIs will throw RuntimeError , if they failed to detect valid FFmpeg executables on your system. Enable verbose ( verbose=True ) for debugging FFmpeg validation process.","title":"FFmpeg Installation Doc"},{"location":"installation/ffmpeg_install/#linux-ffmpeg-installation","text":"DeFFcode APIs supports Auto-Detection and Manual Configuration methods on a Linux OS machines:","title":" Linux FFmpeg Installation"},{"location":"installation/ffmpeg_install/#a-auto-detection","text":"This is a recommended approach on Linux Machines If DeFFcode APIs do not receive any input from the user on custom_ffmpeg parameter, then they try to auto-detect the required FFmpeg installed binaries through a validation test that employs subprocess python module on the Linux OS systems. You can install easily install official FFmpeg according to your Linux Distro by following this post \u27b6","title":"A. Auto-Detection"},{"location":"installation/ffmpeg_install/#b-manual-configuration","text":"Download: You can also manually download the latest Linux Static Binaries (based on your machine architecture) from the link below: Linux Static Binaries: http://johnvansickle.com/ffmpeg/ Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the DeFFcode APIs. If binaries were not found at the manually specified path, DeFFcode APIs will throw RuntimeError !","title":"B. Manual Configuration"},{"location":"installation/ffmpeg_install/#windows-ffmpeg-installation","text":"DeFFcode APIs supports Auto-Installation and Manual Configuration methods on Windows OS machines:","title":" Windows FFmpeg Installation"},{"location":"installation/ffmpeg_install/#a-auto-installation","text":"This is a recommended approach on Windows Machines If DeFFcode APIs do not receive any input from the user on custom_ffmpeg parameter, then they try to auto-generate the required FFmpeg Static Binaries from our dedicated Github Server into the temporary directory(e.g. C:\\Temp ) of your machine on the Windows OS systems. Active Internet connection is required while downloading required FFmpeg Static Binaries from our dedicated Github Server onto your Windows machine. Important Information regarding Auto-Installation The files downloaded to a temporary directory (e.g. C:\\TEMP ), may get erased if your machine shutdowns/restarts in some cases. You can also provide a custom save path for auto-downloading FFmpeg Static Binaries through exclusive -ffmpeg_download_path attribute in Sourcer API. How to use -ffmpeg_download_path attribute in FFdecoder API? -ffmpeg_download_path is also available in FFdecoder API through the -custom_sourcer_params attribute of its ffparams dictionary parameter. If binaries were found at the specified path, DeFFcode APIs automatically skips the Auto-Installation step. If the required FFmpeg static binary fails to download, extract, or validate during Auto-Installation, then DeFFcode APIs will exit with RuntimeError !","title":"A. Auto-Installation"},{"location":"installation/ffmpeg_install/#b-manual-configuration_1","text":"Download: You can also manually download the latest Windows Static Binaries (based on your machine arch(x86/x64)) from the link below: Windows Static Binaries: https://ffmpeg.org/download.html#build-windows Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'C:/foo/Downloads/ffmpeg/bin' ) or path of ffmpeg.exe executable itself to the custom_ffmpeg parameter in the DeFFcode APIs. If binaries were not found at the manually specified path, DeFFcode APIs will throw RuntimeError !","title":"B. Manual Configuration"},{"location":"installation/ffmpeg_install/#macos-ffmpeg-installation","text":"DeFFcode APIs supports Auto-Detection and Manual Configuration methods on MacOS OS machines:","title":" MacOS FFmpeg Installation"},{"location":"installation/ffmpeg_install/#a-auto-detection_1","text":"This is a recommended approach on MacOS Machines If DeFFcode APIs do not receive any input from the user on custom_ffmpeg parameter, then they try to auto-detect the required FFmpeg installed binaries through a validation test that employs subprocess python module on the MacOS systems. You can easily install FFmpeg on your MacOS machine by following this tutorial \u27b6","title":"A. Auto-Detection"},{"location":"installation/ffmpeg_install/#b-manual-configuration_2","text":"Download: You can also manually download the latest MacOS Static Binaries (only x64 Binaries) from the link below: MacOS Static Binaries: https://ffmpeg.org/download.html#build-mac Assignment: Then, you can easily assign the custom path to the folder containing FFmpeg executables( for e.g 'ffmpeg/bin' ) or path of ffmpeg executable itself to the custom_ffmpeg parameter in the DeFFcode APIs. If binaries were not found at the manually specified path, DeFFcode APIs will throw RuntimeError !","title":"B. Manual Configuration"},{"location":"recipes/advanced/","text":"Advanced Recipes \u00b6 The following challenging recipes will take your skills to the next level and will give access to new DeFFcode techniques, tricky examples, and advanced FFmpeg parameters: Courtesy - tenor Refer Basic Recipes first! If you're just getting started, check out the Beginner's Basic Recipes first before trying these advanced recipes. Any proficiency with OpenCV-Python will be Helpful Any proficiency with OpenCV-Python (Python API for OpenCV) surely help you with these recipes. Wanna suggest any improvements or additional recipes? Please feel free to suggest any improvements or additional recipes on our Gitter community channel \u27b6 \u2009 Advanced Decoding Recipes \u00b6 Decoding Live Virtual Sources Generate and Decode frames from Sierpinski pattern Generate and Decode frames from Test Source pattern Generate and Decode frames from Gradients with custom Text effect Generate and Decode frames from Mandelbrot test pattern with vectorscope & waveforms Generate and Decode frames from Game of Life Visualization Hardware-Accelerated Video Decoding GPU-accelerated Hardware-based Video Decoding Advanced Transcoding Recipes \u00b6 Transcoding Live Complex Filtergraphs Transcoding video with Live Custom watermark image overlay Transcoding video from sequence of Images with additional filtering Transcoding Video Art with Filtergraphs Transcoding video art with YUV Bitplane Visualization Transcoding video art with Jetcolor effect Transcoding video art with Ghosting effect Transcoding video art with Pixelation effect Hardware-Accelerated Video Transcoding GPU-accelerated Hardware-based Video Transcoding with WriteGear API Advanced Metadata Recipes \u00b6 Updating Video Metadata Added new attributes to metadata in FFdecoder API Overriding source video metadata in FFdecoder API","title":"Overview"},{"location":"recipes/advanced/#advanced-recipes","text":"The following challenging recipes will take your skills to the next level and will give access to new DeFFcode techniques, tricky examples, and advanced FFmpeg parameters: Courtesy - tenor Refer Basic Recipes first! If you're just getting started, check out the Beginner's Basic Recipes first before trying these advanced recipes. Any proficiency with OpenCV-Python will be Helpful Any proficiency with OpenCV-Python (Python API for OpenCV) surely help you with these recipes. Wanna suggest any improvements or additional recipes? Please feel free to suggest any improvements or additional recipes on our Gitter community channel \u27b6","title":"Advanced Recipes"},{"location":"recipes/advanced/#advanced-decoding-recipes","text":"Decoding Live Virtual Sources Generate and Decode frames from Sierpinski pattern Generate and Decode frames from Test Source pattern Generate and Decode frames from Gradients with custom Text effect Generate and Decode frames from Mandelbrot test pattern with vectorscope & waveforms Generate and Decode frames from Game of Life Visualization Hardware-Accelerated Video Decoding GPU-accelerated Hardware-based Video Decoding","title":"Advanced  Decoding Recipes"},{"location":"recipes/advanced/#advanced-transcoding-recipes","text":"Transcoding Live Complex Filtergraphs Transcoding video with Live Custom watermark image overlay Transcoding video from sequence of Images with additional filtering Transcoding Video Art with Filtergraphs Transcoding video art with YUV Bitplane Visualization Transcoding video art with Jetcolor effect Transcoding video art with Ghosting effect Transcoding video art with Pixelation effect Hardware-Accelerated Video Transcoding GPU-accelerated Hardware-based Video Transcoding with WriteGear API","title":"Advanced  Transcoding Recipes"},{"location":"recipes/advanced/#advanced-metadata-recipes","text":"Updating Video Metadata Added new attributes to metadata in FFdecoder API Overriding source video metadata in FFdecoder API","title":"Advanced  Metadata Recipes"},{"location":"recipes/advanced/decode-hw-acceleration/","text":"Hardware-Accelerated Video Decoding \u00b6 FFmpeg offer access to dedicated GPU hardware with varying support on different platforms for performing a range of video-related tasks to be completed faster or using less of other resources (particularly CPU). By default, DeFFcode's FFdecoder API uses the Input Source's video-decoder (extracted using Sourcer API) itself for decoding its input. However, you could easily change the video-decoder to your desired specific supported Video-Decoder using the -vcodec FFmpeg option by way of its ffparams dictionary parameter. This means easy access to GPU Accelerated Hardware Decoder to get better playback and accelerated video decoding on GPUs that will generate equivalent output to software decoders, but may use less power and CPU to do so. Use ffmpeg -decoders terminal command to lists all FFmpeg supported decoders. We'll discuss its Hardware-Accelerated Video Decoding capabilities briefly in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error. \u2009 GPU-accelerated Hardware-based Video Decoding \u00b6 Example Assumptions Please note that following recipe explicitly assumes: You're running Windows operating system with a supported NVIDIA GPU . You're using FFmpeg 4.4 or newer, configured with atleast --enable-nonfree --enable-libx264 --enable-cuda --enable-cuvid --enable-cuda-nvcc options during compilation. For manual compilation follow these instructions \u27b6 You already have appropriate Nvidia video drivers and related softwares installed on your machine. These assumptions MAY/MAY NOT suit your current setup. Kindly use suitable parameters based your system platform and hardware settings only. In this example, we will be using Nvidia's H.264 CUVID Video-decoder( h264_cuvid ) in FFdecoder API to achieve fully-accelerated hardware video decoding of BGR24 frames from a given Video file (say foo.mp4 ) on Windows Machine, and preview them using OpenCV Library's cv2.imshow() method. More information on Nvidia's CUVID can be found here \u27b6 Remember to check H.264 CUVID Video-decoder support in FFmpeg To use h264_cuvid decoder, remember to check if your FFmpeg compiled with H.264 CUVID decoder support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows: $ ffmpeg -hide_banner -decoders | grep h264 VFS..D h264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 V....D h264_qsv H264 video ( Intel Quick Sync Video acceleration ) ( codec h264 ) V..... h264_cuvid Nvidia CUVID H264 decoder ( codec h264 ) You can also use optimized HEVC CUVID Video-decoder( hevc_cuvid ) in the similar way, if supported. To learn about exclusive -ffprefixes parameter. See Exclusive Parameters \u27b6 # import the necessary packages from deffcode import FFdecoder import cv2 # define suitable FFmpeg parameter ffparams = { \"-vcodec\" : \"h264_cuvid\" , # CUVID H.264 Video-decoder \"-ffprefixes\" : [ \"-vsync\" , \"0\" ], } # initialize and formulate the decoder with suitable source and params decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # grab the RGB24(default) frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"Hardware-Accelerated Video Decoding"},{"location":"recipes/advanced/decode-hw-acceleration/#hardware-accelerated-video-decoding","text":"FFmpeg offer access to dedicated GPU hardware with varying support on different platforms for performing a range of video-related tasks to be completed faster or using less of other resources (particularly CPU). By default, DeFFcode's FFdecoder API uses the Input Source's video-decoder (extracted using Sourcer API) itself for decoding its input. However, you could easily change the video-decoder to your desired specific supported Video-Decoder using the -vcodec FFmpeg option by way of its ffparams dictionary parameter. This means easy access to GPU Accelerated Hardware Decoder to get better playback and accelerated video decoding on GPUs that will generate equivalent output to software decoders, but may use less power and CPU to do so. Use ffmpeg -decoders terminal command to lists all FFmpeg supported decoders. We'll discuss its Hardware-Accelerated Video Decoding capabilities briefly in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error.","title":" Hardware-Accelerated Video Decoding"},{"location":"recipes/advanced/decode-hw-acceleration/#gpu-accelerated-hardware-based-video-decoding","text":"Example Assumptions Please note that following recipe explicitly assumes: You're running Windows operating system with a supported NVIDIA GPU . You're using FFmpeg 4.4 or newer, configured with atleast --enable-nonfree --enable-libx264 --enable-cuda --enable-cuvid --enable-cuda-nvcc options during compilation. For manual compilation follow these instructions \u27b6 You already have appropriate Nvidia video drivers and related softwares installed on your machine. These assumptions MAY/MAY NOT suit your current setup. Kindly use suitable parameters based your system platform and hardware settings only. In this example, we will be using Nvidia's H.264 CUVID Video-decoder( h264_cuvid ) in FFdecoder API to achieve fully-accelerated hardware video decoding of BGR24 frames from a given Video file (say foo.mp4 ) on Windows Machine, and preview them using OpenCV Library's cv2.imshow() method. More information on Nvidia's CUVID can be found here \u27b6 Remember to check H.264 CUVID Video-decoder support in FFmpeg To use h264_cuvid decoder, remember to check if your FFmpeg compiled with H.264 CUVID decoder support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows: $ ffmpeg -hide_banner -decoders | grep h264 VFS..D h264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 V....D h264_qsv H264 video ( Intel Quick Sync Video acceleration ) ( codec h264 ) V..... h264_cuvid Nvidia CUVID H264 decoder ( codec h264 ) You can also use optimized HEVC CUVID Video-decoder( hevc_cuvid ) in the similar way, if supported. To learn about exclusive -ffprefixes parameter. See Exclusive Parameters \u27b6 # import the necessary packages from deffcode import FFdecoder import cv2 # define suitable FFmpeg parameter ffparams = { \"-vcodec\" : \"h264_cuvid\" , # CUVID H.264 Video-decoder \"-ffprefixes\" : [ \"-vsync\" , \"0\" ], } # initialize and formulate the decoder with suitable source and params decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # grab the RGB24(default) frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"GPU-accelerated Hardware-based Video Decoding"},{"location":"recipes/advanced/decode-live-virtual-sources/","text":"Decoding Live Virtual Sources \u00b6 Instead of using prerecorded video files as streams, DeFFcode's FFdecoder API with the help of powerful lavfi ( Libavfilter input virtual device) source that reads data from the open output pads of a libavfilter filtergraph, is also capable of creating virtual video frames out of thin air in real-time, which you might want to use as input for testing, compositing, and merging with other streams to obtain desired output on-the-fly. We'll discuss the recipies for generating Live Fake Sources briefly below: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error. \u2009 Generate and Decode frames from Sierpinski pattern \u00b6 The sierpinski graph generates a Sierpinski carpet/triangle fractal, and randomly pan around by a single pixel each frame. Sierpinski carpet fractal In this example we will generate and decode 8 seconds of a Sierpinski carpet fractal pattern of 1280x720 frame size and 30 framerate using sierpinski graph source with lavfi input virtual device in FFdecoder API, and preview decoded frames using OpenCV Library's cv2.imshow() method in real-time. By default, OpenCV expects BGR format frames in its cv2.imshow() method. # import the necessary packages from deffcode import FFdecoder import cv2 # playback time of 8 seconds ffparams = { \"-ffprefixes\" : [ \"-t\" , \"8\" ]} # initialize and formulate the decoder with \"sierpinski\" source of # `1280x720` frame size and `30` framerate for BGR24 output decoder = FFdecoder ( \"sierpinski=size=1280x720:rate=30\" , source_demuxer = \"lavfi\" , frame_format = \"bgr24\" , ** ffparams ) . formulate () # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): cv2 . imwrite ( 'foo_image.gif' , frame ) break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () Generate and Decode frames from Test Source pattern \u00b6 The testsrc graph generates a test video pattern showing a color pattern, a scrolling gradient, and a timestamp. This is useful for testing purposes. Test Source pattern In this example we will generate and decode 10 seconds of a Test Source pattern ( 1280x720 frame size & 30 framerate) using testsrc graph source with lavfi input virtual device in FFdecoder API, all while previewing decoded frames using OpenCV Library's cv2.imshow() method in real-time. By default, OpenCV expects BGR format frames in its cv2.imshow() method. # import the necessary packages from deffcode import FFdecoder import cv2 # define parameters ffparams = { \"-ffprefixes\" : [ \"-t\" , \"10\" ], # playback time of 10 seconds } # initialize and formulate the decoder with \"testsrc\" source of # `1280x720` frame size and `30` framerate for BGR24 output decoder = FFdecoder ( \"testsrc=size=1280x720:rate=30\" , source_demuxer = \"lavfi\" , frame_format = \"bgr24\" , ** ffparams ) . formulate () # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () Generate and Decode frames from Gradients with custom Text effect \u00b6 The gradients graph (as name suggests) generates several random gradients. Gradients pattern with real-time text output In this example we will generate and decode 15 seconds of Gradients using gradients graph source with lavfi input virtual device and also draw real-time text output (format HH::MM::SS ) scrolling upward direction on it using drawtext filter in FFdecoder API, all while previewing decoded frames using OpenCV Library's cv2.imshow() method in real-time. This example assumes you're running Windows machine. If not, then change fontfile parameter path in drawtext video filtergraph definition accordingly. By default, OpenCV expects BGR format frames in its cv2.imshow() method. # import the necessary packages from deffcode import FFdecoder import cv2 # define parameters ffparams = { \"-ffprefixes\" : [ \"-t\" , \"15\" ], # playback time of 15 seconds \"-vf\" : \"drawtext=\" # draw text + \"text='%{localtime\\: %X }':\" # real time text (HH::MM::SS) + \"fontfile='c\\:\\/windows\\/fonts\\/arial.ttf':\" # fontfile path (Only Windows) + \"x=(w-text_w)/2:y=h-40*t:\" # scroll upward effect + \"fontsize=50:\" # font size 50 + \"fontcolor=white\" , # font color white } # initialize and formulate the decoder with # \"gradients\" source for BGR24 output decoder = FFdecoder ( \"gradients=n=3\" , source_demuxer = \"lavfi\" , frame_format = \"bgr24\" , ** ffparams ) . formulate () # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () Generate and Decode frames from Mandelbrot test pattern with vectorscope & waveforms \u00b6 The mandelbrot graph generate a Mandelbrot set fractal , that progressively zoom towards a specfic point. Mandelbrot pattern with a Vectorscope & two Waveforms In this example we will generate and decode 20 seconds of a Mandelbrot test pattern ( 1280x720 frame size & 30 framerate) using mandelbrot graph source with lavfi input virtual device with a vectorscope (plots 2 color component values) & two waveforms (plots YUV color component intensity) stacked to it in FFdecoder API, all while previewing decoded frames using OpenCV Library's cv2.imshow() method in real-time. By default, OpenCV expects BGR format frames in its cv2.imshow() method. # import the necessary packages from deffcode import FFdecoder import cv2 # define parameters ffparams = { \"-ffprefixes\" : [ \"-t\" , \"20\" ], # playback time of 20 seconds \"-vf\" : \"format=yuv444p,\" # change input format to yuv444p + \"split=4[a][b][c][d],\" # split input into 4 identical outputs. + \"[a]waveform[aa],\" # apply waveform on first output + \"[b][aa]vstack[V],\" # vertical stack 2nd output with waveform [V] + \"[c]waveform=m=0[cc],\" # apply waveform on 3rd output + \"[d]vectorscope=color4[dd],\" # apply vectorscope on 4th output + \"[cc][dd]vstack[V2],\" # vertical stack waveform and vectorscope [V2] + \"[V][V2]hstack\" , # horizontal stack [V] and [V2] vertical stacks } # initialize and formulate the decoder with \"mandelbrot\" source of # `1280x720` frame size and `30` framerate for BGR24 output decoder = FFdecoder ( \"mandelbrot=size=1280x720:rate=30\" , source_demuxer = \"lavfi\" , frame_format = \"bgr24\" , ** ffparams ) . formulate () # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () Generate and Decode frames from Game of Life Visualization \u00b6 The life graph generates a life pattern based on a generalization of John Conway\u2019s life game. The sourced input represents a life grid, each pixel represents a cell which can be in one of two possible states, alive or dead. Every cell interacts with its eight neighbours, which are the cells that are horizontally, vertically, or diagonally adjacent. At each interaction the grid evolves according to the adopted rule, which specifies the number of neighbor alive cells which will make a cell stay alive or born. Game of Life Visualization In this example we will generate and decode 25 seconds of Game of Life Visualization using life graph source with lavfi input virtual device in FFdecoder API, all while previewing decoded frames using OpenCV Library's cv2.imshow() method in real-time. By default, OpenCV expects BGR format frames in its cv2.imshow() method. # import the necessary packages from deffcode import FFdecoder import cv2 # define parameters ffparams = { \"-ffprefixes\" : [ \"-t\" , \"25\" ], # playback time of 25 seconds } # initialize and formulate the decoder with \"life\" source for BGR24 output decoder = FFdecoder ( \"life=\" # life graph + \"s=640x480:\" # grid size (in pixels) + \"mold=10:\" # cell mold speed + \"r=36:\" # framerate + \"ratio=0.5:\" # random fill ratio for the initial random grid + \"death_color=#39FF14:\" # color of dead cells + \"life_color=#1d1160\" # color of living (or new born) cells + \",scale=640:480:\" # frame size + \"flags=16\" , source_demuxer = \"lavfi\" , frame_format = \"bgr24\" , ** ffparams ) . formulate () # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"Decoding Live Virtual Sources"},{"location":"recipes/advanced/decode-live-virtual-sources/#decoding-live-virtual-sources","text":"Instead of using prerecorded video files as streams, DeFFcode's FFdecoder API with the help of powerful lavfi ( Libavfilter input virtual device) source that reads data from the open output pads of a libavfilter filtergraph, is also capable of creating virtual video frames out of thin air in real-time, which you might want to use as input for testing, compositing, and merging with other streams to obtain desired output on-the-fly. We'll discuss the recipies for generating Live Fake Sources briefly below: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error.","title":" Decoding Live Virtual Sources"},{"location":"recipes/advanced/decode-live-virtual-sources/#generate-and-decode-frames-from-sierpinski-pattern","text":"The sierpinski graph generates a Sierpinski carpet/triangle fractal, and randomly pan around by a single pixel each frame. Sierpinski carpet fractal In this example we will generate and decode 8 seconds of a Sierpinski carpet fractal pattern of 1280x720 frame size and 30 framerate using sierpinski graph source with lavfi input virtual device in FFdecoder API, and preview decoded frames using OpenCV Library's cv2.imshow() method in real-time. By default, OpenCV expects BGR format frames in its cv2.imshow() method. # import the necessary packages from deffcode import FFdecoder import cv2 # playback time of 8 seconds ffparams = { \"-ffprefixes\" : [ \"-t\" , \"8\" ]} # initialize and formulate the decoder with \"sierpinski\" source of # `1280x720` frame size and `30` framerate for BGR24 output decoder = FFdecoder ( \"sierpinski=size=1280x720:rate=30\" , source_demuxer = \"lavfi\" , frame_format = \"bgr24\" , ** ffparams ) . formulate () # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): cv2 . imwrite ( 'foo_image.gif' , frame ) break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"Generate and Decode frames from Sierpinski pattern"},{"location":"recipes/advanced/decode-live-virtual-sources/#generate-and-decode-frames-from-test-source-pattern","text":"The testsrc graph generates a test video pattern showing a color pattern, a scrolling gradient, and a timestamp. This is useful for testing purposes. Test Source pattern In this example we will generate and decode 10 seconds of a Test Source pattern ( 1280x720 frame size & 30 framerate) using testsrc graph source with lavfi input virtual device in FFdecoder API, all while previewing decoded frames using OpenCV Library's cv2.imshow() method in real-time. By default, OpenCV expects BGR format frames in its cv2.imshow() method. # import the necessary packages from deffcode import FFdecoder import cv2 # define parameters ffparams = { \"-ffprefixes\" : [ \"-t\" , \"10\" ], # playback time of 10 seconds } # initialize and formulate the decoder with \"testsrc\" source of # `1280x720` frame size and `30` framerate for BGR24 output decoder = FFdecoder ( \"testsrc=size=1280x720:rate=30\" , source_demuxer = \"lavfi\" , frame_format = \"bgr24\" , ** ffparams ) . formulate () # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"Generate and Decode frames from Test Source pattern"},{"location":"recipes/advanced/decode-live-virtual-sources/#generate-and-decode-frames-from-gradients-with-custom-text-effect","text":"The gradients graph (as name suggests) generates several random gradients. Gradients pattern with real-time text output In this example we will generate and decode 15 seconds of Gradients using gradients graph source with lavfi input virtual device and also draw real-time text output (format HH::MM::SS ) scrolling upward direction on it using drawtext filter in FFdecoder API, all while previewing decoded frames using OpenCV Library's cv2.imshow() method in real-time. This example assumes you're running Windows machine. If not, then change fontfile parameter path in drawtext video filtergraph definition accordingly. By default, OpenCV expects BGR format frames in its cv2.imshow() method. # import the necessary packages from deffcode import FFdecoder import cv2 # define parameters ffparams = { \"-ffprefixes\" : [ \"-t\" , \"15\" ], # playback time of 15 seconds \"-vf\" : \"drawtext=\" # draw text + \"text='%{localtime\\: %X }':\" # real time text (HH::MM::SS) + \"fontfile='c\\:\\/windows\\/fonts\\/arial.ttf':\" # fontfile path (Only Windows) + \"x=(w-text_w)/2:y=h-40*t:\" # scroll upward effect + \"fontsize=50:\" # font size 50 + \"fontcolor=white\" , # font color white } # initialize and formulate the decoder with # \"gradients\" source for BGR24 output decoder = FFdecoder ( \"gradients=n=3\" , source_demuxer = \"lavfi\" , frame_format = \"bgr24\" , ** ffparams ) . formulate () # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"Generate and Decode frames from Gradients with custom Text effect"},{"location":"recipes/advanced/decode-live-virtual-sources/#generate-and-decode-frames-from-mandelbrot-test-pattern-with-vectorscope-waveforms","text":"The mandelbrot graph generate a Mandelbrot set fractal , that progressively zoom towards a specfic point. Mandelbrot pattern with a Vectorscope & two Waveforms In this example we will generate and decode 20 seconds of a Mandelbrot test pattern ( 1280x720 frame size & 30 framerate) using mandelbrot graph source with lavfi input virtual device with a vectorscope (plots 2 color component values) & two waveforms (plots YUV color component intensity) stacked to it in FFdecoder API, all while previewing decoded frames using OpenCV Library's cv2.imshow() method in real-time. By default, OpenCV expects BGR format frames in its cv2.imshow() method. # import the necessary packages from deffcode import FFdecoder import cv2 # define parameters ffparams = { \"-ffprefixes\" : [ \"-t\" , \"20\" ], # playback time of 20 seconds \"-vf\" : \"format=yuv444p,\" # change input format to yuv444p + \"split=4[a][b][c][d],\" # split input into 4 identical outputs. + \"[a]waveform[aa],\" # apply waveform on first output + \"[b][aa]vstack[V],\" # vertical stack 2nd output with waveform [V] + \"[c]waveform=m=0[cc],\" # apply waveform on 3rd output + \"[d]vectorscope=color4[dd],\" # apply vectorscope on 4th output + \"[cc][dd]vstack[V2],\" # vertical stack waveform and vectorscope [V2] + \"[V][V2]hstack\" , # horizontal stack [V] and [V2] vertical stacks } # initialize and formulate the decoder with \"mandelbrot\" source of # `1280x720` frame size and `30` framerate for BGR24 output decoder = FFdecoder ( \"mandelbrot=size=1280x720:rate=30\" , source_demuxer = \"lavfi\" , frame_format = \"bgr24\" , ** ffparams ) . formulate () # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"Generate and Decode frames from Mandelbrot test pattern with vectorscope &amp; waveforms"},{"location":"recipes/advanced/decode-live-virtual-sources/#generate-and-decode-frames-from-game-of-life-visualization","text":"The life graph generates a life pattern based on a generalization of John Conway\u2019s life game. The sourced input represents a life grid, each pixel represents a cell which can be in one of two possible states, alive or dead. Every cell interacts with its eight neighbours, which are the cells that are horizontally, vertically, or diagonally adjacent. At each interaction the grid evolves according to the adopted rule, which specifies the number of neighbor alive cells which will make a cell stay alive or born. Game of Life Visualization In this example we will generate and decode 25 seconds of Game of Life Visualization using life graph source with lavfi input virtual device in FFdecoder API, all while previewing decoded frames using OpenCV Library's cv2.imshow() method in real-time. By default, OpenCV expects BGR format frames in its cv2.imshow() method. # import the necessary packages from deffcode import FFdecoder import cv2 # define parameters ffparams = { \"-ffprefixes\" : [ \"-t\" , \"25\" ], # playback time of 25 seconds } # initialize and formulate the decoder with \"life\" source for BGR24 output decoder = FFdecoder ( \"life=\" # life graph + \"s=640x480:\" # grid size (in pixels) + \"mold=10:\" # cell mold speed + \"r=36:\" # framerate + \"ratio=0.5:\" # random fill ratio for the initial random grid + \"death_color=#39FF14:\" # color of dead cells + \"life_color=#1d1160\" # color of living (or new born) cells + \",scale=640:480:\" # frame size + \"flags=16\" , source_demuxer = \"lavfi\" , frame_format = \"bgr24\" , ** ffparams ) . formulate () # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"Generate and Decode frames from Game of Life Visualization"},{"location":"recipes/advanced/transcode-art-filtergraphs/","text":"Transcoding Video Art with Filtergraphs \u00b6 What are Simple filtergraphs? Before heading straight into recipes we will talk about Simple filtergraphs: Simple filtergraphs are those filters that have exactly one input and output, both of the same type. They can be processed by simply inserting an additional step between decoding and encoding of video frames: Simple filtergraphs are configured with the per-stream -filter option (with -vf for video) . DeFFcode's FFdecoder API unlocks the power of ffmpeg backend for creating real-time artistic generative video art using simple and complex filtergraphs, and decoding them into live video frames. We'll discuss the Transcoding Video Art with Filtergraphs in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing and encoding video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python VidGear: VidGear is required for lossless encoding of video frames into file/stream. You can easily install it directly via pip : pip install vidgear [ core ] Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. WriteGear's Compression Mode support for FFdecoder API is currently in beta so you can expect much higher than usual CPU utilization! \u2009 Transcoding video art with YUV Bitplane Visualization \u00b6 Based on the QCTools bitplane visualization, this video art has numerical values ranging between -1 (no change) and 10 (noisiest) for the Y (luminance) , U and V (chroma or color difference) planes, yielding cool and different results for different values. YUV Bitplane Visualization This Video Art idea credits goes to ffmpeg-artschool - An AMIA workshop featuring scripts, exercises, and activities to make art using FFmpeg. In this example we will generate 8 seconds of Bitplane Visualization by binding the bit position of the Y , U , and V planes of a video file (say foo.mp4 ) by using FFmpeg's lutyuv filter and assigning them random values (between -1 (no change) and 10 (noisiest)) , and decode live BGR24 video frames in FFdecoder API. We'll also be encoding those decoded frames in real-time into lossless video file using WriteGear API with controlled framerate. # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import cv2 , json # define Video Filter definition ffparams = { \"-ffprefixes\" : [ \"-t\" , \"8\" ], # playback time of 8 seconds \"-vf\" : \"format=yuv444p,\" # change input format to yuv444p + \"lutyuv=\" # use lutyuv filter for binding bit position of the Y, U, and V planes + \"y=if(eq( {y} \\,-1)\\,512\\,if(eq( {y} \\,0)\\,val\\,bitand(val\\,pow(2\\,10- {y} ))*pow(2\\, {y} ))):\" . format ( y = 3 # define `Y` (luminance) plane value (b/w -1 and 10) ) + \"u=if(eq( {u} \\,-1)\\,512\\,if(eq( {u} \\,0)\\,val\\,bitand(val\\,pow(2\\,10- {u} ))*pow(2\\, {u} ))):\" . format ( u = 1 # define `U` (chroma or color difference) plane value (b/w -1 and 10) ) + \"v=if(eq( {v} \\,-1)\\,512\\,if(eq( {v} \\,0)\\,val\\,bitand(val\\,pow(2\\,10- {v} ))*pow(2\\, {v} ))),\" . format ( v = 3 # define `V` (chroma or color difference) plane value (b/w -1 and 10) ) + \"format=yuv422p10le\" , # change output format to yuv422p10le } # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve framerate from source JSON Metadata and pass it as `-input_framerate` # parameter for controlled framerate and define other parameters output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"output_framerate\" ], } # Define writer with default parameters and suitable # output filename for e.g. `output_foo.mp4` writer = WriteGear ( output_filename = \"output_foo.mp4\" , ** output_params ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close () Transcoding video art with Jetcolor effect \u00b6 This video art uses FFmpeg's pseudocolor filter to create a Jetcolor effect which is high contrast, high brightness, and high saturation colormap that ranges from blue to red, and passes through the colors cyan, yellow, and orange. The jet colormap is associated with an astrophysical fluid jet simulation from the National Center for Supercomputer Applications. Jetcolor effect This Video Art idea credits goes to ffmpeg-artschool - An AMIA workshop featuring scripts, exercises, and activities to make art using FFmpeg. In this example we will generate 8 seconds of Jetcolor effect by changing frame colors of a video file (say foo.mp4 ) using FFmpeg's pseudocolor filter in different modes (values between 0 (cleaner) [default] and 2 (noisiest)) , and decode live BGR24 video frames in FFdecoder API. We'll also be encoding those decoded frames in real-time into lossless video file using WriteGear API with controlled framerate. # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import cv2 , json # define Video Filter definition ffparams = { \"-ffprefixes\" : [ \"-t\" , \"8\" ], # playback time of 8 seconds \"-vf\" : \"format=yuv444p,\" # change input format to `yuv444p` + \"eq=brightness=0.40:saturation=8,\" # default `brightness = 0.40` and `saturation=8` + \"pseudocolor='\" # dynamically controlled colors through `pseudocolor` filter + \"if(between(val,0,85),lerp(45,159,(val-0)/(85-0)),\" + \"if(between(val,85,170),lerp(159,177,(val-85)/(170-85)),\" + \"if(between(val,170,255),lerp(177,70,(val-170)/(255-170))))):\" # mode 0 (cleaner) [default] + \"if(between(val,0,85),lerp(205,132,(val-0)/(85-0)),\" + \"if(between(val,85,170),lerp(132,59,(val-85)/(170-85)),\" + \"if(between(val,170,255),lerp(59,100,(val-170)/(255-170))))):\" # mode 1 + \"if(between(val,0,85),lerp(110,59,(val-0)/(85-0)),\" + \"if(between(val,85,170),lerp(59,127,(val-85)/(170-85)),\" + \"if(between(val,170,255),lerp(127,202,(val-170)/(255-170))))):\" # mode 2 (noisiest) + \"i= {mode} ',\" . format ( mode = 0 # define mode value (b/w `0` and `2`) to control colors ) + \"format=yuv422p10le\" , # change output format to `yuv422p10le` } # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve framerate from source JSON Metadata and pass it as `-input_framerate` # parameter for controlled framerate and define other parameters output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"output_framerate\" ], } # Define writer with default parameters and suitable # output filename for e.g. `output_foo.mp4` writer = WriteGear ( output_filename = \"output_foo.mp4\" , ** output_params ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close () Transcoding video art with Ghosting effect \u00b6 This video art using FFmpeg\u2019s lagfun filter to create a video echo/ghost/trailing effect. Ghosting effect This Video Art idea credits goes to ffmpeg-artschool - An AMIA workshop featuring scripts, exercises, and activities to make art using FFmpeg. In this example we will generate 8 seconds of Ghosting effect using FFmpeg's lagfun filter on a video file (say foo.mp4 ) , and decode live BGR24 video frames in FFdecoder API. We'll also be encoding those decoded frames in real-time into lossless video file using WriteGear API with controlled framerate. # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import cv2 , json # define Video Filter definition ffparams = { \"-ffprefixes\" : [ \"-t\" , \"8\" ], # playback time of 8 seconds \"-filter_complex\" : \"format=yuv444p[formatted];\" # change video input format to yuv444p + \"[formatted]split[a][b];\" # split input into 2 identical outputs + \"[a]lagfun=decay=.99:planes=1[a];\" # apply lagfun filter on first output + \"[b]lagfun=decay=.98:planes=2[b];\" # apply lagfun filter on 2nd output + \"[a][b]blend=all_mode=screen:c0_opacity=.5:c1_opacity=.5,\" # apply screen blend mode both outputs + \"format=yuv422p10le[out]\" , # change output format to yuv422p10le \"-map\" : \"[out]\" , # map the output } # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve framerate from source JSON Metadata and pass it as `-input_framerate` # parameter for controlled framerate and define other parameters output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"output_framerate\" ], } # Define writer with default parameters and suitable # output filename for e.g. `output_foo.mp4` writer = WriteGear ( output_filename = \"output_foo.mp4\" , ** output_params ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close () Transcoding video art with Pixelation effect \u00b6 This video art uses FFmpeg\u2019s overlay , smartblur and stacks of dilation filters to intentionally Pixelate your video in artistically cool looking ways such that each pixel become visible to the naked eye. Pixelation effect This Video Art idea credits goes to oioiiooixiii blogspot . In this example we will generate 8 seconds of Pixelation effect using FFmpeg\u2019s smartblur and stacks of dilation filters overlayed on a video file (say foo.mp4 ) , and decode live BGR24 video frames in FFdecoder API. We'll also be encoding those decoded frames in real-time into lossless video file using WriteGear API with controlled framerate. # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import cv2 , json # define Video Filter definition ffparams = { \"-ffprefixes\" : [ \"-t\" , \"8\" ], # playback time of 8 seconds \"-vf\" : \"format=yuv444p,\" # change input format to yuv444p + \"split [out1][out2];\" # split input into 2 identical outputs + \"[out1][out2] overlay,smartblur,\" # apply overlay,smartblur filter on both outputs + \"dilation,dilation,dilation,dilation,dilation,\" # apply stacks of dilation filters on both outputs + \"eq=contrast=1.4:brightness=-0.09 [pixels];\" # change brightness and contrast + \"[pixels]format=yuv422p10le[out]\" , # change output format to yuv422p10le \"-mode\" : \"[out]\" , # map the output } # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve framerate from source JSON Metadata and pass it as `-input_framerate` # parameter for controlled framerate and define other parameters output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"output_framerate\" ], } # Define writer with default parameters and suitable # output filename for e.g. `output_foo.mp4` writer = WriteGear ( output_filename = \"output_foo.mp4\" , ** output_params ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close ()","title":"Transcoding Video Art with Filtergraphs"},{"location":"recipes/advanced/transcode-art-filtergraphs/#transcoding-video-art-with-filtergraphs","text":"What are Simple filtergraphs? Before heading straight into recipes we will talk about Simple filtergraphs: Simple filtergraphs are those filters that have exactly one input and output, both of the same type. They can be processed by simply inserting an additional step between decoding and encoding of video frames: Simple filtergraphs are configured with the per-stream -filter option (with -vf for video) . DeFFcode's FFdecoder API unlocks the power of ffmpeg backend for creating real-time artistic generative video art using simple and complex filtergraphs, and decoding them into live video frames. We'll discuss the Transcoding Video Art with Filtergraphs in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing and encoding video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python VidGear: VidGear is required for lossless encoding of video frames into file/stream. You can easily install it directly via pip : pip install vidgear [ core ] Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. WriteGear's Compression Mode support for FFdecoder API is currently in beta so you can expect much higher than usual CPU utilization!","title":" Transcoding Video Art with Filtergraphs"},{"location":"recipes/advanced/transcode-art-filtergraphs/#transcoding-video-art-with-yuv-bitplane-visualization","text":"Based on the QCTools bitplane visualization, this video art has numerical values ranging between -1 (no change) and 10 (noisiest) for the Y (luminance) , U and V (chroma or color difference) planes, yielding cool and different results for different values. YUV Bitplane Visualization This Video Art idea credits goes to ffmpeg-artschool - An AMIA workshop featuring scripts, exercises, and activities to make art using FFmpeg. In this example we will generate 8 seconds of Bitplane Visualization by binding the bit position of the Y , U , and V planes of a video file (say foo.mp4 ) by using FFmpeg's lutyuv filter and assigning them random values (between -1 (no change) and 10 (noisiest)) , and decode live BGR24 video frames in FFdecoder API. We'll also be encoding those decoded frames in real-time into lossless video file using WriteGear API with controlled framerate. # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import cv2 , json # define Video Filter definition ffparams = { \"-ffprefixes\" : [ \"-t\" , \"8\" ], # playback time of 8 seconds \"-vf\" : \"format=yuv444p,\" # change input format to yuv444p + \"lutyuv=\" # use lutyuv filter for binding bit position of the Y, U, and V planes + \"y=if(eq( {y} \\,-1)\\,512\\,if(eq( {y} \\,0)\\,val\\,bitand(val\\,pow(2\\,10- {y} ))*pow(2\\, {y} ))):\" . format ( y = 3 # define `Y` (luminance) plane value (b/w -1 and 10) ) + \"u=if(eq( {u} \\,-1)\\,512\\,if(eq( {u} \\,0)\\,val\\,bitand(val\\,pow(2\\,10- {u} ))*pow(2\\, {u} ))):\" . format ( u = 1 # define `U` (chroma or color difference) plane value (b/w -1 and 10) ) + \"v=if(eq( {v} \\,-1)\\,512\\,if(eq( {v} \\,0)\\,val\\,bitand(val\\,pow(2\\,10- {v} ))*pow(2\\, {v} ))),\" . format ( v = 3 # define `V` (chroma or color difference) plane value (b/w -1 and 10) ) + \"format=yuv422p10le\" , # change output format to yuv422p10le } # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve framerate from source JSON Metadata and pass it as `-input_framerate` # parameter for controlled framerate and define other parameters output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"output_framerate\" ], } # Define writer with default parameters and suitable # output filename for e.g. `output_foo.mp4` writer = WriteGear ( output_filename = \"output_foo.mp4\" , ** output_params ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close ()","title":"Transcoding video art with YUV Bitplane Visualization"},{"location":"recipes/advanced/transcode-art-filtergraphs/#transcoding-video-art-with-jetcolor-effect","text":"This video art uses FFmpeg's pseudocolor filter to create a Jetcolor effect which is high contrast, high brightness, and high saturation colormap that ranges from blue to red, and passes through the colors cyan, yellow, and orange. The jet colormap is associated with an astrophysical fluid jet simulation from the National Center for Supercomputer Applications. Jetcolor effect This Video Art idea credits goes to ffmpeg-artschool - An AMIA workshop featuring scripts, exercises, and activities to make art using FFmpeg. In this example we will generate 8 seconds of Jetcolor effect by changing frame colors of a video file (say foo.mp4 ) using FFmpeg's pseudocolor filter in different modes (values between 0 (cleaner) [default] and 2 (noisiest)) , and decode live BGR24 video frames in FFdecoder API. We'll also be encoding those decoded frames in real-time into lossless video file using WriteGear API with controlled framerate. # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import cv2 , json # define Video Filter definition ffparams = { \"-ffprefixes\" : [ \"-t\" , \"8\" ], # playback time of 8 seconds \"-vf\" : \"format=yuv444p,\" # change input format to `yuv444p` + \"eq=brightness=0.40:saturation=8,\" # default `brightness = 0.40` and `saturation=8` + \"pseudocolor='\" # dynamically controlled colors through `pseudocolor` filter + \"if(between(val,0,85),lerp(45,159,(val-0)/(85-0)),\" + \"if(between(val,85,170),lerp(159,177,(val-85)/(170-85)),\" + \"if(between(val,170,255),lerp(177,70,(val-170)/(255-170))))):\" # mode 0 (cleaner) [default] + \"if(between(val,0,85),lerp(205,132,(val-0)/(85-0)),\" + \"if(between(val,85,170),lerp(132,59,(val-85)/(170-85)),\" + \"if(between(val,170,255),lerp(59,100,(val-170)/(255-170))))):\" # mode 1 + \"if(between(val,0,85),lerp(110,59,(val-0)/(85-0)),\" + \"if(between(val,85,170),lerp(59,127,(val-85)/(170-85)),\" + \"if(between(val,170,255),lerp(127,202,(val-170)/(255-170))))):\" # mode 2 (noisiest) + \"i= {mode} ',\" . format ( mode = 0 # define mode value (b/w `0` and `2`) to control colors ) + \"format=yuv422p10le\" , # change output format to `yuv422p10le` } # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve framerate from source JSON Metadata and pass it as `-input_framerate` # parameter for controlled framerate and define other parameters output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"output_framerate\" ], } # Define writer with default parameters and suitable # output filename for e.g. `output_foo.mp4` writer = WriteGear ( output_filename = \"output_foo.mp4\" , ** output_params ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close ()","title":"Transcoding video art with Jetcolor effect"},{"location":"recipes/advanced/transcode-art-filtergraphs/#transcoding-video-art-with-ghosting-effect","text":"This video art using FFmpeg\u2019s lagfun filter to create a video echo/ghost/trailing effect. Ghosting effect This Video Art idea credits goes to ffmpeg-artschool - An AMIA workshop featuring scripts, exercises, and activities to make art using FFmpeg. In this example we will generate 8 seconds of Ghosting effect using FFmpeg's lagfun filter on a video file (say foo.mp4 ) , and decode live BGR24 video frames in FFdecoder API. We'll also be encoding those decoded frames in real-time into lossless video file using WriteGear API with controlled framerate. # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import cv2 , json # define Video Filter definition ffparams = { \"-ffprefixes\" : [ \"-t\" , \"8\" ], # playback time of 8 seconds \"-filter_complex\" : \"format=yuv444p[formatted];\" # change video input format to yuv444p + \"[formatted]split[a][b];\" # split input into 2 identical outputs + \"[a]lagfun=decay=.99:planes=1[a];\" # apply lagfun filter on first output + \"[b]lagfun=decay=.98:planes=2[b];\" # apply lagfun filter on 2nd output + \"[a][b]blend=all_mode=screen:c0_opacity=.5:c1_opacity=.5,\" # apply screen blend mode both outputs + \"format=yuv422p10le[out]\" , # change output format to yuv422p10le \"-map\" : \"[out]\" , # map the output } # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve framerate from source JSON Metadata and pass it as `-input_framerate` # parameter for controlled framerate and define other parameters output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"output_framerate\" ], } # Define writer with default parameters and suitable # output filename for e.g. `output_foo.mp4` writer = WriteGear ( output_filename = \"output_foo.mp4\" , ** output_params ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close ()","title":"Transcoding video art with Ghosting effect"},{"location":"recipes/advanced/transcode-art-filtergraphs/#transcoding-video-art-with-pixelation-effect","text":"This video art uses FFmpeg\u2019s overlay , smartblur and stacks of dilation filters to intentionally Pixelate your video in artistically cool looking ways such that each pixel become visible to the naked eye. Pixelation effect This Video Art idea credits goes to oioiiooixiii blogspot . In this example we will generate 8 seconds of Pixelation effect using FFmpeg\u2019s smartblur and stacks of dilation filters overlayed on a video file (say foo.mp4 ) , and decode live BGR24 video frames in FFdecoder API. We'll also be encoding those decoded frames in real-time into lossless video file using WriteGear API with controlled framerate. # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import cv2 , json # define Video Filter definition ffparams = { \"-ffprefixes\" : [ \"-t\" , \"8\" ], # playback time of 8 seconds \"-vf\" : \"format=yuv444p,\" # change input format to yuv444p + \"split [out1][out2];\" # split input into 2 identical outputs + \"[out1][out2] overlay,smartblur,\" # apply overlay,smartblur filter on both outputs + \"dilation,dilation,dilation,dilation,dilation,\" # apply stacks of dilation filters on both outputs + \"eq=contrast=1.4:brightness=-0.09 [pixels];\" # change brightness and contrast + \"[pixels]format=yuv422p10le[out]\" , # change output format to yuv422p10le \"-mode\" : \"[out]\" , # map the output } # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve framerate from source JSON Metadata and pass it as `-input_framerate` # parameter for controlled framerate and define other parameters output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"output_framerate\" ], } # Define writer with default parameters and suitable # output filename for e.g. `output_foo.mp4` writer = WriteGear ( output_filename = \"output_foo.mp4\" , ** output_params ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close ()","title":"Transcoding video art with Pixelation effect"},{"location":"recipes/advanced/transcode-hw-acceleration/","text":"Hardware-Accelerated Video Transcoding \u00b6 What exactly is Transcoding? Before heading directly into recipes we have to talk about Transcoding: Transcoding is the technique of transforming one media encoding format into another. This is typically done for compatibility purposes, such as when a media source provides a format that the intended target is not able to process; an in-between adaptation step is required: Decode media from its originally encoded state into raw, uncompressed information. Encode the raw data back, using a different codec that is supported by end user. DeFFcode's FFdecoder API in conjunction with VidGear's WriteGear API creates a high-level High-performance Lossless FFmpeg Transcoding (Decoding & Encoding respectively) Pipeline that is able to exploit almost any FFmpeg parameter for achieving anything imaginable with multimedia video data all while allow us to manipulate the real-time video frames with immense flexibility. Both these APIs are capable of utilizing the potential of GPU supported fully-accelerated Hardware based video Decoding(FFdecoder API with hardware decoder) and Encoding (WriteGear API with hardware encoder) , thus dramatically improving the performance of the end-to-end transcoding. We'll discuss its Hardware-Accelerated Video Transcoding capabilities using these APIs briefly in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing and encoding video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python VidGear: VidGear is required for lossless encoding of video frames into file/stream. You can easily install it directly via pip : pip install vidgear [ core ] Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. WriteGear's Compression Mode support for FFdecoder API is currently in beta so you can expect much higher than usual CPU utilization! \u2009 GPU-accelerated Hardware-based Video Transcoding with WriteGear API \u00b6 Example Assumptions Please note that following recipe explicitly assumes: You're running Windows operating system with a supported NVIDIA GPU . You're using FFmpeg 4.4 or newer, configured with atleast --enable-nonfree --enable-libx264 --enable-cuda --enable-nvenc --enable-nvdec --enable-cuda-nvcc --enable-libnpp options during compilation. For manual compilation follow these instructions \u27b6 You already have appropriate Nvidia video drivers and related softwares installed on your machine. These assumptions MAY/MAY NOT suit your current setup. Kindly use suitable parameters based your system platform and hardware settings only. Limitation: Bottleneck in Hardware-Accelerated Video Transcoding Performance Generally, adding the \u2013hwaccel cuvid / \u2013hwaccel cuda -hwaccel_output_format cuda options means the raw decoded frames will not be copied between system and GPU memory (via the PCIe bus) , and the transcoding will be faster and use less system resources, and may even result in up to 2x the throughput compared to the unoptimized calls: General Memory Flow with Hardware Acceleration But unfortunately, for processing real-time frames in our python script with FFdecoder and WriteGear APIs, we're bound to sacrifice this performance gained by explicitly copying raw decoded frames between System and GPU memory via the PCIe bus, thereby creating self-made latency in transfer time and increasing PCIe bandwidth occupancy due to overheads in communication over the bus. Also, given PCIe bandwidth limits, copying uncompressed image data would quickly saturate the PCIe bus. Memory Flow with Hardware Acceleration and Real-time Processing On the bright side however, GPU supported hardware based encoding/decoding is inherently faster and more efficient (do not use much CPU resources) thus freeing up the CPU for other tasks, as compared to software based encoding/decoding that is generally known to be quite CPU intensive. Plus scaling, deinterlacing, filtering, and other post-processing tasks will be faster than usual using these hardware based decoders/encoders with same equivalent output to software ones, and will use less power and CPU to do so. On the whole, You don't have to worry about it as you're getting to manipulate the real-time video frames with immense speed and flexibility which is impossible to do otherwise. In this example, we will be using Nvidia's H.264 CUVID Video-decoder( h264_cuvid ) with \u2013hwaccel cuvid accelerator in FFdecoder API to decode and keep decoded BGR24 frames from a given Video file (say foo.mp4 ) within GPU, all while rescaling (with nvcuvid's resize ) as well as encoding them in real-time with WriteGear API using Nvidia's hardware accelerated H.264 NVENC Video-encoder( h264_nvenc ) into lossless video file within GPU. Remember to check H.264 CUVID decoder and H.264 NVENC encoder support in FFmpeg Using h264_cuvid decoder : Remember to check if your FFmpeg compiled with H.264 CUVID decoder support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows: $ ffmpeg -hide_banner -decoders | grep h264 VFS..D h264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 V....D h264_qsv H264 video ( Intel Quick Sync Video acceleration ) ( codec h264 ) V..... h264_cuvid Nvidia CUVID H264 decoder ( codec h264 ) You can also use optimized HEVC CUVID decoder( hevc_cuvid ) in the similar way, if supported. Using h264_nvenc encoder : Remember to check if your FFmpeg compiled with H.264 NVENC encoder support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows: $ ffmpeg -hide_banner -encoders | grep nvenc V....D h264_amf AMD AMF H.264 Encoder ( codec h264 ) V....D h264_mf H264 via MediaFoundation ( codec h264 ) V....D h264_nvenc NVIDIA NVENC H.264 encoder ( codec h264 ) You can also use optimized HEVC NVENC encoder( hevc_nvenc ) in the similar way, if supported. Additional Parameters in WriteGear API WriteGear API only requires a valid Output filename (e.g. output_foo.mp4 ) as input, but you can easily control any output specifications (such as bitrate, codec, framerate, resolution, subtitles, etc.) supported by FFmpeg (in use) . You can use FFdecoder's metadata property object that dumps source Video's metadata information (as JSON string) to retrieve source framerate. # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import json # define suitable FFmpeg parameter ffparams = { \"-vcodec\" : \"h264_cuvid\" , # H.264 CUVID decoder \"-ffprefixes\" : [ \"-vsync\" , \"0\" , \"\u2013hwaccel\" , \"cuvid\" ], # accelerator } # initialize and formulate the decoder with suitable source and params decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve framerate from source JSON Metadata and pass it as `-input_framerate` # parameter for controlled framerate and define other parameters output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"output_framerate\" ], \"-vcodec\" : \"h264_nvenc\" , # H.264 NVENC encoder \"\u2013resize\" : \"1280x720\" , # rescale to 1280x720 } # Define writer with defined parameters and suitable # output filename for e.g. `output_foo.mp4` writer = WriteGear ( output_filename = \"output_foo.mp4\" , ** output_params ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close ()","title":"Hardware-Accelerated Video Transcoding"},{"location":"recipes/advanced/transcode-hw-acceleration/#hardware-accelerated-video-transcoding","text":"What exactly is Transcoding? Before heading directly into recipes we have to talk about Transcoding: Transcoding is the technique of transforming one media encoding format into another. This is typically done for compatibility purposes, such as when a media source provides a format that the intended target is not able to process; an in-between adaptation step is required: Decode media from its originally encoded state into raw, uncompressed information. Encode the raw data back, using a different codec that is supported by end user. DeFFcode's FFdecoder API in conjunction with VidGear's WriteGear API creates a high-level High-performance Lossless FFmpeg Transcoding (Decoding & Encoding respectively) Pipeline that is able to exploit almost any FFmpeg parameter for achieving anything imaginable with multimedia video data all while allow us to manipulate the real-time video frames with immense flexibility. Both these APIs are capable of utilizing the potential of GPU supported fully-accelerated Hardware based video Decoding(FFdecoder API with hardware decoder) and Encoding (WriteGear API with hardware encoder) , thus dramatically improving the performance of the end-to-end transcoding. We'll discuss its Hardware-Accelerated Video Transcoding capabilities using these APIs briefly in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing and encoding video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python VidGear: VidGear is required for lossless encoding of video frames into file/stream. You can easily install it directly via pip : pip install vidgear [ core ] Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. WriteGear's Compression Mode support for FFdecoder API is currently in beta so you can expect much higher than usual CPU utilization!","title":" Hardware-Accelerated Video Transcoding"},{"location":"recipes/advanced/transcode-hw-acceleration/#gpu-accelerated-hardware-based-video-transcoding-with-writegear-api","text":"Example Assumptions Please note that following recipe explicitly assumes: You're running Windows operating system with a supported NVIDIA GPU . You're using FFmpeg 4.4 or newer, configured with atleast --enable-nonfree --enable-libx264 --enable-cuda --enable-nvenc --enable-nvdec --enable-cuda-nvcc --enable-libnpp options during compilation. For manual compilation follow these instructions \u27b6 You already have appropriate Nvidia video drivers and related softwares installed on your machine. These assumptions MAY/MAY NOT suit your current setup. Kindly use suitable parameters based your system platform and hardware settings only. Limitation: Bottleneck in Hardware-Accelerated Video Transcoding Performance Generally, adding the \u2013hwaccel cuvid / \u2013hwaccel cuda -hwaccel_output_format cuda options means the raw decoded frames will not be copied between system and GPU memory (via the PCIe bus) , and the transcoding will be faster and use less system resources, and may even result in up to 2x the throughput compared to the unoptimized calls: General Memory Flow with Hardware Acceleration But unfortunately, for processing real-time frames in our python script with FFdecoder and WriteGear APIs, we're bound to sacrifice this performance gained by explicitly copying raw decoded frames between System and GPU memory via the PCIe bus, thereby creating self-made latency in transfer time and increasing PCIe bandwidth occupancy due to overheads in communication over the bus. Also, given PCIe bandwidth limits, copying uncompressed image data would quickly saturate the PCIe bus. Memory Flow with Hardware Acceleration and Real-time Processing On the bright side however, GPU supported hardware based encoding/decoding is inherently faster and more efficient (do not use much CPU resources) thus freeing up the CPU for other tasks, as compared to software based encoding/decoding that is generally known to be quite CPU intensive. Plus scaling, deinterlacing, filtering, and other post-processing tasks will be faster than usual using these hardware based decoders/encoders with same equivalent output to software ones, and will use less power and CPU to do so. On the whole, You don't have to worry about it as you're getting to manipulate the real-time video frames with immense speed and flexibility which is impossible to do otherwise. In this example, we will be using Nvidia's H.264 CUVID Video-decoder( h264_cuvid ) with \u2013hwaccel cuvid accelerator in FFdecoder API to decode and keep decoded BGR24 frames from a given Video file (say foo.mp4 ) within GPU, all while rescaling (with nvcuvid's resize ) as well as encoding them in real-time with WriteGear API using Nvidia's hardware accelerated H.264 NVENC Video-encoder( h264_nvenc ) into lossless video file within GPU. Remember to check H.264 CUVID decoder and H.264 NVENC encoder support in FFmpeg Using h264_cuvid decoder : Remember to check if your FFmpeg compiled with H.264 CUVID decoder support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows: $ ffmpeg -hide_banner -decoders | grep h264 VFS..D h264 H.264 / AVC / MPEG-4 AVC / MPEG-4 part 10 V....D h264_qsv H264 video ( Intel Quick Sync Video acceleration ) ( codec h264 ) V..... h264_cuvid Nvidia CUVID H264 decoder ( codec h264 ) You can also use optimized HEVC CUVID decoder( hevc_cuvid ) in the similar way, if supported. Using h264_nvenc encoder : Remember to check if your FFmpeg compiled with H.264 NVENC encoder support. You can easily do this by executing following one-liner command in your terminal, and observing if output contains something similar as follows: $ ffmpeg -hide_banner -encoders | grep nvenc V....D h264_amf AMD AMF H.264 Encoder ( codec h264 ) V....D h264_mf H264 via MediaFoundation ( codec h264 ) V....D h264_nvenc NVIDIA NVENC H.264 encoder ( codec h264 ) You can also use optimized HEVC NVENC encoder( hevc_nvenc ) in the similar way, if supported. Additional Parameters in WriteGear API WriteGear API only requires a valid Output filename (e.g. output_foo.mp4 ) as input, but you can easily control any output specifications (such as bitrate, codec, framerate, resolution, subtitles, etc.) supported by FFmpeg (in use) . You can use FFdecoder's metadata property object that dumps source Video's metadata information (as JSON string) to retrieve source framerate. # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import json # define suitable FFmpeg parameter ffparams = { \"-vcodec\" : \"h264_cuvid\" , # H.264 CUVID decoder \"-ffprefixes\" : [ \"-vsync\" , \"0\" , \"\u2013hwaccel\" , \"cuvid\" ], # accelerator } # initialize and formulate the decoder with suitable source and params decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve framerate from source JSON Metadata and pass it as `-input_framerate` # parameter for controlled framerate and define other parameters output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"output_framerate\" ], \"-vcodec\" : \"h264_nvenc\" , # H.264 NVENC encoder \"\u2013resize\" : \"1280x720\" , # rescale to 1280x720 } # Define writer with defined parameters and suitable # output filename for e.g. `output_foo.mp4` writer = WriteGear ( output_filename = \"output_foo.mp4\" , ** output_params ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close ()","title":"GPU-accelerated Hardware-based Video Transcoding with WriteGear API"},{"location":"recipes/advanced/transcode-live-frames-complexgraphs/","text":"Transcoding Live Complex Filtergraphs \u00b6 What are Complex filtergraphs? Before heading straight into recipes we will talk about Complex filtergraphs: Complex filtergraphs are those which cannot be described as simply a linear processing chain applied to one stream. Complex filtergraphs are configured with the -filter_complex global option. The -lavfi option is equivalent to -filter_complex . A trivial example of a complex filtergraph is the overlay filter, which has two video inputs and one video output, containing one video overlaid on top of the other. DeFFcode's FFdecoder API seamlessly supports processing multiple input streams including real-time frames through multiple filter chains combined into a filtergraph (via. -filter_complex FFmpeg parameter) , and use their outputs as inputs for other filter chains. We'll discuss the transcoding of live complex filtergraphs in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing and encoding video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python VidGear: VidGear is required for lossless encoding of video frames into file/stream. You can easily install it directly via pip : pip install vidgear [ core ] Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. WriteGear's Compression Mode support for FFdecoder API is currently in beta so you can expect much higher than usual CPU utilization! \u2009 Transcoding video with Live Custom watermark image overlay \u00b6 Big Buck Bunny with custom watermark In this example we will apply a watermark image (say watermark.png with transparent background) overlay to the 10 seconds of video file (say foo.mp4 ) using FFmpeg's overlay filter with some additional filtering, , and decode live BGR24 video frames in FFdecoder API. We'll also be encoding those decoded frames in real-time into lossless video file using WriteGear API with controlled framerate. You can use FFdecoder's metadata property object that dumps Source Metadata as JSON to retrieve source framerate and frame-size. To learn about exclusive -ffprefixes & -clones parameter. See Exclusive Parameters \u27b6 Remember to replace watermark.png watermark image file-path with yours before using this recipe. # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import json , cv2 # define the Complex Video Filter with additional `watermark.png` image input ffparams = { \"-ffprefixes\" : [ \"-t\" , \"10\" ], # playback time of 10 seconds \"-clones\" : [ \"-i\" , \"watermark.png\" , # !!! [WARNING] define your `watermark.png` here. ], \"-filter_complex\" : \"[1]format=rgba,\" # change 2nd(image) input format to yuv444p + \"colorchannelmixer=aa=0.7[logo];\" # apply colorchannelmixer to image for controlling alpha [logo] + \"[0][logo]overlay=W-w- {pixel} :H-h- {pixel} :format=auto,\" . format ( # apply overlay to 1st(video) with [logo] pixel = 5 # at 5 pixels from the bottom right corner of the input video ) + \"format=bgr24\" , # change output format to `yuv422p10le` } # initialize and formulate the decoder for BGR24 output with given params decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve framerate from source JSON Metadata and pass it as `-input_framerate` # parameter for controlled framerate and define other parameters output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"output_framerate\" ], } # Define writer with default parameters and suitable # output filename for e.g. `output_foo.mp4` writer = WriteGear ( output_filename = \"output_foo.mp4\" , ** output_params ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close () Transcoding video from sequence of Images with additional filtering \u00b6 Mandelbrot pattern blend with Fish school video Available blend mode options Other blend mode options for blend filter include: addition , addition128 , grainmerge , and , average , burn , darken , difference , difference128 , grainextract , divide , dodge , freeze , exclusion , extremity , glow , hardlight , hardmix , heat , lighten , linearlight , multiply , multiply128 , negation , normal , or , overlay , phoenix , pinlight , reflect , screen , softlight , subtract , vividlight , xor In this example we will blend 10 seconds of Mandelbrot test pattern (generated using lavfi input virtual device) that serves as the \"top\" layer with 10 seconds of Image Sequence that serves as the \"bottom\" layer, using blend filter (with heat blend mode) , and decode live BGR24 video frames in FFdecoder API. We'll also be encoding those decoded frames in real-time into lossless video file using WriteGear API with controlled framerate. Extracting Image Sequences from a video You can use following FFmpeg command to extract sequences of images from a video file foo.mp4 (restricted to 12 seconds) : $ ffmpeg -t 12 -i foo.mp4 /path/to/image-%03d.png The default framerate is 25 fps, therefore this command will extract 25 images/sec from the video file, and save them as sequences of images (starting from image-000.png , image-001.png , image-002.png up to image-999.png ) . If there are more than 1000 frames then the last image will be overwritten with the remaining frames leaving only the last frame. The default images width and height is same as the video. How to start with specific number image? You can use -start_number FFmpeg parameter if you want to start with specific number image: # define `-start_number` such as `5` ffparams = { \"-ffprefixes\" :[ \"-start_number\" , \"5\" ]} # initialize and formulate the decoder with define parameters decoder = FFdecoder ( '/path/to/img %03d .png' , verbose = True , ** ffparams ) . formulate () FFdecoder API also accepts Glob pattern( *.png ) as well Single looping image as as input to its source parameter. See this Basic Recipe \u27b6 for more information. # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import cv2 , json # define mandelbrot pattern generator # and the Video Filter definition ffparams = { \"-ffprefixes\" : [ \"-t\" , \"10\" , # playback time of 10 seconds for mandelbrot pattern \"-f\" , \"lavfi\" , # use input virtual device \"-i\" , \"mandelbrot=rate=25\" , # create mandelbrot pattern at 25 fps \"-t\" , \"10\" , # playback time of 10 seconds for video ], \"-custom_resolution\" : ( 1280 , 720 ), # resize to 1280x720 \"-filter_complex\" : \"[1:v]format=yuv444p[v1];\" # change 2nd(video) input format to yuv444p + \"[0:v]format=gbrp10le[v0];\" # change 1st(mandelbrot pattern) input format to gbrp10le + \"[v1][v0]scale2ref[v1][v0];\" # resize the 1st(mandelbrot pattern), based on a 2nd(video). + \"[v0][v1]blend=all_mode='heat',\" # apply heat blend mode to output + \"format=yuv422p10le[v]\" , # change output format to `yuv422p10le` \"-map\" : \"[v]\" , # map the output } # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"/path/to/image- %03d .png\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # define your parameters # [WARNING] framerate must match original source framerate !!! output_params = { \"-input_framerate\" : 25 , # Default } # Define writer with default parameters and suitable # output filename for e.g. `output_foo.mp4` writer = WriteGear ( output_filename = \"output_foo.mp4\" , ** output_params ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close ()","title":"Transcoding Live Complex Filtergraphs"},{"location":"recipes/advanced/transcode-live-frames-complexgraphs/#transcoding-live-complex-filtergraphs","text":"What are Complex filtergraphs? Before heading straight into recipes we will talk about Complex filtergraphs: Complex filtergraphs are those which cannot be described as simply a linear processing chain applied to one stream. Complex filtergraphs are configured with the -filter_complex global option. The -lavfi option is equivalent to -filter_complex . A trivial example of a complex filtergraph is the overlay filter, which has two video inputs and one video output, containing one video overlaid on top of the other. DeFFcode's FFdecoder API seamlessly supports processing multiple input streams including real-time frames through multiple filter chains combined into a filtergraph (via. -filter_complex FFmpeg parameter) , and use their outputs as inputs for other filter chains. We'll discuss the transcoding of live complex filtergraphs in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing and encoding video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python VidGear: VidGear is required for lossless encoding of video frames into file/stream. You can easily install it directly via pip : pip install vidgear [ core ] Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. WriteGear's Compression Mode support for FFdecoder API is currently in beta so you can expect much higher than usual CPU utilization!","title":" Transcoding Live Complex Filtergraphs"},{"location":"recipes/advanced/transcode-live-frames-complexgraphs/#transcoding-video-with-live-custom-watermark-image-overlay","text":"Big Buck Bunny with custom watermark In this example we will apply a watermark image (say watermark.png with transparent background) overlay to the 10 seconds of video file (say foo.mp4 ) using FFmpeg's overlay filter with some additional filtering, , and decode live BGR24 video frames in FFdecoder API. We'll also be encoding those decoded frames in real-time into lossless video file using WriteGear API with controlled framerate. You can use FFdecoder's metadata property object that dumps Source Metadata as JSON to retrieve source framerate and frame-size. To learn about exclusive -ffprefixes & -clones parameter. See Exclusive Parameters \u27b6 Remember to replace watermark.png watermark image file-path with yours before using this recipe. # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import json , cv2 # define the Complex Video Filter with additional `watermark.png` image input ffparams = { \"-ffprefixes\" : [ \"-t\" , \"10\" ], # playback time of 10 seconds \"-clones\" : [ \"-i\" , \"watermark.png\" , # !!! [WARNING] define your `watermark.png` here. ], \"-filter_complex\" : \"[1]format=rgba,\" # change 2nd(image) input format to yuv444p + \"colorchannelmixer=aa=0.7[logo];\" # apply colorchannelmixer to image for controlling alpha [logo] + \"[0][logo]overlay=W-w- {pixel} :H-h- {pixel} :format=auto,\" . format ( # apply overlay to 1st(video) with [logo] pixel = 5 # at 5 pixels from the bottom right corner of the input video ) + \"format=bgr24\" , # change output format to `yuv422p10le` } # initialize and formulate the decoder for BGR24 output with given params decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve framerate from source JSON Metadata and pass it as `-input_framerate` # parameter for controlled framerate and define other parameters output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"output_framerate\" ], } # Define writer with default parameters and suitable # output filename for e.g. `output_foo.mp4` writer = WriteGear ( output_filename = \"output_foo.mp4\" , ** output_params ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close ()","title":"Transcoding video with Live Custom watermark image overlay"},{"location":"recipes/advanced/transcode-live-frames-complexgraphs/#transcoding-video-from-sequence-of-images-with-additional-filtering","text":"Mandelbrot pattern blend with Fish school video Available blend mode options Other blend mode options for blend filter include: addition , addition128 , grainmerge , and , average , burn , darken , difference , difference128 , grainextract , divide , dodge , freeze , exclusion , extremity , glow , hardlight , hardmix , heat , lighten , linearlight , multiply , multiply128 , negation , normal , or , overlay , phoenix , pinlight , reflect , screen , softlight , subtract , vividlight , xor In this example we will blend 10 seconds of Mandelbrot test pattern (generated using lavfi input virtual device) that serves as the \"top\" layer with 10 seconds of Image Sequence that serves as the \"bottom\" layer, using blend filter (with heat blend mode) , and decode live BGR24 video frames in FFdecoder API. We'll also be encoding those decoded frames in real-time into lossless video file using WriteGear API with controlled framerate. Extracting Image Sequences from a video You can use following FFmpeg command to extract sequences of images from a video file foo.mp4 (restricted to 12 seconds) : $ ffmpeg -t 12 -i foo.mp4 /path/to/image-%03d.png The default framerate is 25 fps, therefore this command will extract 25 images/sec from the video file, and save them as sequences of images (starting from image-000.png , image-001.png , image-002.png up to image-999.png ) . If there are more than 1000 frames then the last image will be overwritten with the remaining frames leaving only the last frame. The default images width and height is same as the video. How to start with specific number image? You can use -start_number FFmpeg parameter if you want to start with specific number image: # define `-start_number` such as `5` ffparams = { \"-ffprefixes\" :[ \"-start_number\" , \"5\" ]} # initialize and formulate the decoder with define parameters decoder = FFdecoder ( '/path/to/img %03d .png' , verbose = True , ** ffparams ) . formulate () FFdecoder API also accepts Glob pattern( *.png ) as well Single looping image as as input to its source parameter. See this Basic Recipe \u27b6 for more information. # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import cv2 , json # define mandelbrot pattern generator # and the Video Filter definition ffparams = { \"-ffprefixes\" : [ \"-t\" , \"10\" , # playback time of 10 seconds for mandelbrot pattern \"-f\" , \"lavfi\" , # use input virtual device \"-i\" , \"mandelbrot=rate=25\" , # create mandelbrot pattern at 25 fps \"-t\" , \"10\" , # playback time of 10 seconds for video ], \"-custom_resolution\" : ( 1280 , 720 ), # resize to 1280x720 \"-filter_complex\" : \"[1:v]format=yuv444p[v1];\" # change 2nd(video) input format to yuv444p + \"[0:v]format=gbrp10le[v0];\" # change 1st(mandelbrot pattern) input format to gbrp10le + \"[v1][v0]scale2ref[v1][v0];\" # resize the 1st(mandelbrot pattern), based on a 2nd(video). + \"[v0][v1]blend=all_mode='heat',\" # apply heat blend mode to output + \"format=yuv422p10le[v]\" , # change output format to `yuv422p10le` \"-map\" : \"[v]\" , # map the output } # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"/path/to/image- %03d .png\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # define your parameters # [WARNING] framerate must match original source framerate !!! output_params = { \"-input_framerate\" : 25 , # Default } # Define writer with default parameters and suitable # output filename for e.g. `output_foo.mp4` writer = WriteGear ( output_filename = \"output_foo.mp4\" , ** output_params ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close ()","title":"Transcoding video from sequence of Images with additional filtering"},{"location":"recipes/advanced/update-metadata/","text":"Updating Video Metadata \u00b6 In addition of using metadata property object in FFdecoder API for probing metadata information (only as JSON string) for each multimedia stream available in the given video source, you can also easily update the video metadata on-the-fly by assigning desired data as python dictionary to the same overloaded metadata property object. This feature can be used either for adding new custom properties to metadata, or to override source metadata properties used by FFdecoder API to formulate its default Decoder Pipeline for real-time video-frames generation. We'll discuss video metadata extraction using both these APIs briefly in the following recipes: This feature is not yet fully explored, but in the near future you'll be able to use it to dynamically override any Video frames Decoder Pipeline property (such as frame-size, pixel-format, etc.) in real-time like a pro. Stay tuned for more updates \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error. \u2009 Added new properties to metadata in FFdecoder API \u00b6 In FFdecoder API, you can easily define any number of new properties for its metadata (formatted as python dictionary) with desired data of any datatype(s) 1 , without affecting its default Video frames Decoder pipeline. In this example we will probe all metadata information available within foo.mp4 video file on Windows machine, thereby add new propertys (formatted as python dictionary) with desired data of different datatype(s) through overloaded metadata property object, and then finally print it as JSON string using the same metadata property object in FFdecoder API. The value assigned to metadata property object can be of dictionary datatype only. Any other type will immediately raise ValueError ! # import the necessary packages from deffcode import FFdecoder import json # initialize the decoder using suitable source decoder = FFdecoder ( \"foo.mp4\" , verbose = True ) # format your data as dictionary (with data of any [printable] datatype) data = dict ( mystring = \"abcd\" , # string data myint = 1234 , # integers data mylist = [ 1 , \"Rohan\" , [ \"inner_list\" ]], # list data mytuple = ( 1 , \"John\" , ( \"inner_tuple\" )), # tuple data mydict = { \"anotherstring\" : \"hello\" }, # dictionary data myjson = json . loads ( '{\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}' ), # json data ) # assign your dictionary data decoder . metadata = data # finally formulate the decoder decoder . formulate () # print metadata as `json.dump` print ( decoder . metadata ) # terminate the decoder decoder . terminate () After running above python code, the resultant Terminal Output will look something as following on Windows machine: { \"ffmpeg_binary_path\" : \"C:\\\\Users\\\\foo\\\\AppData\\\\Local\\\\Temp\\\\ffmpeg-static-win64-gpl/bin/ffmpeg.exe\" , \"source\" : \"D:\\\\foo.mp4\" , \"source_extension\" : \".mp4\" , \"source_video_resolution\" : [ 1920 , 1080 ], \"source_video_framerate\" : 29.97 , \"source_video_pixfmt\" : \"yuv420p\" , \"source_video_decoder\" : \"h264\" , \"source_duration_sec\" : 21.03 , \"approx_video_nframes\" : 630 , \"source_video_bitrate\" : \"4937k\" , \"source_audio_bitrate\" : \"256k\" , \"source_audio_samplerate\" : \"48000 Hz\" , \"source_has_video\" : true , \"source_has_audio\" : true , \"source_has_image_sequence\" : false , \"ffdecoder_operational_mode\" : \"Video-Only\" , \"output_frames_pixfmt\" : \"rgb24\" , \"mystring\" : \"abcd\" , \"myint\" : 1234 , \"mylist\" : [ 1 , \"Rohan\" , [ \"inner_list\" ] ], \"mytuple\" : [ 1 , \"John\" , \"inner_tuple\" ], \"mydict\" : { \"anotherstring\" : \"hello\" }, \"myjson\" : { \"name\" : \"John\" , \"age\" : 30 , \"city\" : \"New York\" } } Overriding source video metadata in FFdecoder API \u00b6 In FFdecoder API, you can also use its metadata to manually override the source properties (as frame-size, frame pixel-format, video-framerate, video-decoder etc.) that directly affects its default Video frames Decoder pipeline that decodes real-time video-frames. The \"source\" property in metadata cannot be altered in any manner. Source Video metadata values must be handled carefully Source Video metadata information is used by FFdecoder API to formulate its default Video frames Decoder pipeline, and any improper or invalid inputted source property could crash the pipeline with RuntimeError . Therefore to safeguard against it, FFdecoder API discards any Source Video metadata dictionary keys, if its value's datatype fails to match the exact valid datatype defined in following table: Only either source_demuxer or source_extension property can be present in source metadata. Not all Source Video metadata properties directly affects the pipeline (as mentioned in the table) . But this might change in future versions. Source Video Metadata Keys Valid Value Datatype Effect on Pipeline \"source_extension\" string None \"source_demuxer\" string Direct \"source_video_resolution\" list of integers e.g. [1280,720] Direct \"source_video_framerate\" float Direct \"source_video_pixfmt\" string Direct \"source_video_decoder\" string Direct \"source_duration_sec\" float None \"approx_video_nframes\" integer Direct \"source_video_bitrate\" string None \"source_audio_bitrate\" string None \"source_audio_samplerate\" string None \"source_has_video\" bool Direct \"source_has_audio\" bool None \"source_has_image_sequence\" bool Direct \"ffdecoder_operational_mode\" str None \"output_frames_pixfmt\" str Direct Hence for instance, if \"source_video_resolution\" is assigned \"1280x720\" (i.e. string datatype value instead of list ) , then it will be discarded. In this example we will probe all metadata information available within foo.mp4 video file, and override frame size (originally 1920x1080 ) and pixel-format (originally rgb24 ) to our desired values through overloaded metadata property object in FFdecoder API, and thereby preview them using OpenCV Library's cv2.imshow() method. The value assigned to metadata property object can be of dictionary datatype only. Any other type will immediately raise ValueError ! Once the formulate() method is called, the metadata information present in FFdecoder API is finalized and thereby used to formulate its default pipeline for decoding real-time video-frames. Therefore make all changes to video properties beforehand. # import the necessary packages from deffcode import FFdecoder import cv2 # initialize and formulate the decoder using suitable source decoder = FFdecoder ( \"foo.mp4\" , verbose = True ) # override source metadata values # !!! [WARNING] Make sure each value datatype matches the table !!! decoder . metadata = { \"output_frames_pixfmt\" : \"gray\" , # gray frame-pixfmt \"source_video_resolution\" : [ 1280 , 720 ], # 1280x720 frame-size } # finally formulate the decoder decoder . formulate () # [NOTE] uncomment following line to debug values # print(decoder.metadata) # let's grab the 1280x720 sized gray frames from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with gray frame here} # Show gray frames in output window cv2 . imshow ( \"Output gray\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () There is no concept of tuple datatype in the JSON format. Thereby, Python's json module auto-converts all tuple python values into JSON list because that's the closest thing in JSON format to a tuple. \u21a9","title":"Updating Video Metadata"},{"location":"recipes/advanced/update-metadata/#updating-video-metadata","text":"In addition of using metadata property object in FFdecoder API for probing metadata information (only as JSON string) for each multimedia stream available in the given video source, you can also easily update the video metadata on-the-fly by assigning desired data as python dictionary to the same overloaded metadata property object. This feature can be used either for adding new custom properties to metadata, or to override source metadata properties used by FFdecoder API to formulate its default Decoder Pipeline for real-time video-frames generation. We'll discuss video metadata extraction using both these APIs briefly in the following recipes: This feature is not yet fully explored, but in the near future you'll be able to use it to dynamically override any Video frames Decoder Pipeline property (such as frame-size, pixel-format, etc.) in real-time like a pro. Stay tuned for more updates \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error.","title":" Updating Video Metadata"},{"location":"recipes/advanced/update-metadata/#added-new-properties-to-metadata-in-ffdecoder-api","text":"In FFdecoder API, you can easily define any number of new properties for its metadata (formatted as python dictionary) with desired data of any datatype(s) 1 , without affecting its default Video frames Decoder pipeline. In this example we will probe all metadata information available within foo.mp4 video file on Windows machine, thereby add new propertys (formatted as python dictionary) with desired data of different datatype(s) through overloaded metadata property object, and then finally print it as JSON string using the same metadata property object in FFdecoder API. The value assigned to metadata property object can be of dictionary datatype only. Any other type will immediately raise ValueError ! # import the necessary packages from deffcode import FFdecoder import json # initialize the decoder using suitable source decoder = FFdecoder ( \"foo.mp4\" , verbose = True ) # format your data as dictionary (with data of any [printable] datatype) data = dict ( mystring = \"abcd\" , # string data myint = 1234 , # integers data mylist = [ 1 , \"Rohan\" , [ \"inner_list\" ]], # list data mytuple = ( 1 , \"John\" , ( \"inner_tuple\" )), # tuple data mydict = { \"anotherstring\" : \"hello\" }, # dictionary data myjson = json . loads ( '{\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}' ), # json data ) # assign your dictionary data decoder . metadata = data # finally formulate the decoder decoder . formulate () # print metadata as `json.dump` print ( decoder . metadata ) # terminate the decoder decoder . terminate () After running above python code, the resultant Terminal Output will look something as following on Windows machine: { \"ffmpeg_binary_path\" : \"C:\\\\Users\\\\foo\\\\AppData\\\\Local\\\\Temp\\\\ffmpeg-static-win64-gpl/bin/ffmpeg.exe\" , \"source\" : \"D:\\\\foo.mp4\" , \"source_extension\" : \".mp4\" , \"source_video_resolution\" : [ 1920 , 1080 ], \"source_video_framerate\" : 29.97 , \"source_video_pixfmt\" : \"yuv420p\" , \"source_video_decoder\" : \"h264\" , \"source_duration_sec\" : 21.03 , \"approx_video_nframes\" : 630 , \"source_video_bitrate\" : \"4937k\" , \"source_audio_bitrate\" : \"256k\" , \"source_audio_samplerate\" : \"48000 Hz\" , \"source_has_video\" : true , \"source_has_audio\" : true , \"source_has_image_sequence\" : false , \"ffdecoder_operational_mode\" : \"Video-Only\" , \"output_frames_pixfmt\" : \"rgb24\" , \"mystring\" : \"abcd\" , \"myint\" : 1234 , \"mylist\" : [ 1 , \"Rohan\" , [ \"inner_list\" ] ], \"mytuple\" : [ 1 , \"John\" , \"inner_tuple\" ], \"mydict\" : { \"anotherstring\" : \"hello\" }, \"myjson\" : { \"name\" : \"John\" , \"age\" : 30 , \"city\" : \"New York\" } }","title":"Added new properties to metadata in FFdecoder API"},{"location":"recipes/advanced/update-metadata/#overriding-source-video-metadata-in-ffdecoder-api","text":"In FFdecoder API, you can also use its metadata to manually override the source properties (as frame-size, frame pixel-format, video-framerate, video-decoder etc.) that directly affects its default Video frames Decoder pipeline that decodes real-time video-frames. The \"source\" property in metadata cannot be altered in any manner. Source Video metadata values must be handled carefully Source Video metadata information is used by FFdecoder API to formulate its default Video frames Decoder pipeline, and any improper or invalid inputted source property could crash the pipeline with RuntimeError . Therefore to safeguard against it, FFdecoder API discards any Source Video metadata dictionary keys, if its value's datatype fails to match the exact valid datatype defined in following table: Only either source_demuxer or source_extension property can be present in source metadata. Not all Source Video metadata properties directly affects the pipeline (as mentioned in the table) . But this might change in future versions. Source Video Metadata Keys Valid Value Datatype Effect on Pipeline \"source_extension\" string None \"source_demuxer\" string Direct \"source_video_resolution\" list of integers e.g. [1280,720] Direct \"source_video_framerate\" float Direct \"source_video_pixfmt\" string Direct \"source_video_decoder\" string Direct \"source_duration_sec\" float None \"approx_video_nframes\" integer Direct \"source_video_bitrate\" string None \"source_audio_bitrate\" string None \"source_audio_samplerate\" string None \"source_has_video\" bool Direct \"source_has_audio\" bool None \"source_has_image_sequence\" bool Direct \"ffdecoder_operational_mode\" str None \"output_frames_pixfmt\" str Direct Hence for instance, if \"source_video_resolution\" is assigned \"1280x720\" (i.e. string datatype value instead of list ) , then it will be discarded. In this example we will probe all metadata information available within foo.mp4 video file, and override frame size (originally 1920x1080 ) and pixel-format (originally rgb24 ) to our desired values through overloaded metadata property object in FFdecoder API, and thereby preview them using OpenCV Library's cv2.imshow() method. The value assigned to metadata property object can be of dictionary datatype only. Any other type will immediately raise ValueError ! Once the formulate() method is called, the metadata information present in FFdecoder API is finalized and thereby used to formulate its default pipeline for decoding real-time video-frames. Therefore make all changes to video properties beforehand. # import the necessary packages from deffcode import FFdecoder import cv2 # initialize and formulate the decoder using suitable source decoder = FFdecoder ( \"foo.mp4\" , verbose = True ) # override source metadata values # !!! [WARNING] Make sure each value datatype matches the table !!! decoder . metadata = { \"output_frames_pixfmt\" : \"gray\" , # gray frame-pixfmt \"source_video_resolution\" : [ 1280 , 720 ], # 1280x720 frame-size } # finally formulate the decoder decoder . formulate () # [NOTE] uncomment following line to debug values # print(decoder.metadata) # let's grab the 1280x720 sized gray frames from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with gray frame here} # Show gray frames in output window cv2 . imshow ( \"Output gray\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () There is no concept of tuple datatype in the JSON format. Thereby, Python's json module auto-converts all tuple python values into JSON list because that's the closest thing in JSON format to a tuple. \u21a9","title":"Overriding source video metadata in FFdecoder API"},{"location":"recipes/basic/","text":"Basic Recipes \u00b6 The following recipes should be reasonably accessible to beginners of any skill level to get started with DeFFcode APIs: Courtesy - tenor Refer Installation doc first! If this is your first time using DeFFcode, head straight to the Installation Notes to install DeFFcode with required prerequisites on your machine . Any proficiency with OpenCV-Python will be Helpful If you've any proficiency with OpenCV-Python (Python API for OpenCV) , you will find these recipes really easy. Wanna suggest any improvements or additional recipes? Please feel free to suggest any improvements or additional recipes on our Gitter community channel \u27b6 Frames are actually 3D Numpy arrays In python, \" Frames \" are actually three-dimensional NumPy ndarray composed of 3 nested levels of arrays, one for each dimension. \u2009 Basic Decoding Recipes \u00b6 Decoding Video files Accessing RGB frames from a video file Capturing and Previewing BGR frames from a video file (OpenCV Support) Playing with any other FFmpeg pixel formats Decoding Live Feed Devices Capturing and Previewing frames from a Webcam Capturing and Previewing frames from your Desktop (Screen Recording) Decoding Network Streams Capturing and Previewing frames from a HTTPs Stream Capturing and Previewing frames from a RTSP/RTP Stream Decoding Image sequences Capturing and Previewing frames from Sequence of images Capturing and Previewing frames from Single looping image Basic Transcoding Recipes \u00b6 Transcoding Live frames Transcoding video using OpenCV VideoWriter API Transcoding lossless video using WriteGear API Transcoding Live Simple Filtergraphs Transcoding Trimmed and Reversed video Transcoding Cropped video Transcoding Rotated video (with rotate filter) Transcoding Rotated video (with transpose filter) Transcoding Horizontally flipped and Scaled video Saving Key-frames as Image (Image processing) Extracting Key-frames as PNG image Generating Thumbnail with a Fancy filter Basic Metadata Recipes \u00b6 Extracting Video Metadata Extracting video metadata using Sourcer API Extracting video metadata using FFdecoder API \u2009 What's next? \u00b6 Done already! Let's checkout Advanced Recipes to level up your skills!","title":"Overview"},{"location":"recipes/basic/#basic-recipes","text":"The following recipes should be reasonably accessible to beginners of any skill level to get started with DeFFcode APIs: Courtesy - tenor Refer Installation doc first! If this is your first time using DeFFcode, head straight to the Installation Notes to install DeFFcode with required prerequisites on your machine . Any proficiency with OpenCV-Python will be Helpful If you've any proficiency with OpenCV-Python (Python API for OpenCV) , you will find these recipes really easy. Wanna suggest any improvements or additional recipes? Please feel free to suggest any improvements or additional recipes on our Gitter community channel \u27b6 Frames are actually 3D Numpy arrays In python, \" Frames \" are actually three-dimensional NumPy ndarray composed of 3 nested levels of arrays, one for each dimension.","title":"Basic Recipes"},{"location":"recipes/basic/#basic-decoding-recipes","text":"Decoding Video files Accessing RGB frames from a video file Capturing and Previewing BGR frames from a video file (OpenCV Support) Playing with any other FFmpeg pixel formats Decoding Live Feed Devices Capturing and Previewing frames from a Webcam Capturing and Previewing frames from your Desktop (Screen Recording) Decoding Network Streams Capturing and Previewing frames from a HTTPs Stream Capturing and Previewing frames from a RTSP/RTP Stream Decoding Image sequences Capturing and Previewing frames from Sequence of images Capturing and Previewing frames from Single looping image","title":"Basic  Decoding Recipes"},{"location":"recipes/basic/#basic-transcoding-recipes","text":"Transcoding Live frames Transcoding video using OpenCV VideoWriter API Transcoding lossless video using WriteGear API Transcoding Live Simple Filtergraphs Transcoding Trimmed and Reversed video Transcoding Cropped video Transcoding Rotated video (with rotate filter) Transcoding Rotated video (with transpose filter) Transcoding Horizontally flipped and Scaled video Saving Key-frames as Image (Image processing) Extracting Key-frames as PNG image Generating Thumbnail with a Fancy filter","title":"Basic  Transcoding Recipes"},{"location":"recipes/basic/#basic-metadata-recipes","text":"Extracting Video Metadata Extracting video metadata using Sourcer API Extracting video metadata using FFdecoder API","title":"Basic  Metadata Recipes"},{"location":"recipes/basic/#whats-next","text":"Done already! Let's checkout Advanced Recipes to level up your skills!","title":"What's next?"},{"location":"recipes/basic/decode-image-sequences/","text":"Decoding Image sequences \u00b6 DeFFcode's FFdecoder API supports a wide-ranging media streams as input to its source parameter, which also includes Image Sequences such as Sequential( img%03d.png ) and Glob pattern( *.png ) as well as Single looping image . We'll discuss both briefly in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error. \u2009 Capturing and Previewing frames from Sequence of images \u00b6 In this example we will capture video frames from a given Image Sequence using FFdecoder API, and preview them using OpenCV Library's cv2.imshow() method in real-time. OpenCV expects BGR format frames in its cv2.imshow() method. Extracting Image Sequences from a video You can use following FFmpeg command to extract sequences of images from a video file foo.mp4 : $ ffmpeg -i foo.mp4 /path/to/image-%03d.png The default framerate is 25 fps, therefore this command will extract 25 images/sec from the video file, and save them as sequences of images (starting from image-000.png , image-001.png , image-002.png up to image-999.png ) . If there are more than 1000 frames then the last image will be overwritten with the remaining frames leaving only the last frame. The default images width and height is same as the video. Sequential Glob pattern How to start with specific number image? You can use -start_number FFmpeg parameter if you want to start with specific number image: # define `-start_number` such as `5` ffparams = { \"-ffprefixes\" :[ \"-start_number\" , \"5\" ]} # initialize and formulate the decoder with define parameters decoder = FFdecoder ( 'img %03d .png' , verbose = True , ** ffparams ) . formulate () # import the necessary packages from deffcode import FFdecoder import cv2 # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"/path/to/pngs/img %03d .png\" , frame_format = \"bgr24\" , verbose = True ) . formulate () # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () Bash-style globbing ( * represents any number of any characters) is useful if your images are sequential but not necessarily in a numerically sequential order. The glob pattern is not available on Windows FFmpeg builds. To learn more about exclusive -ffprefixes parameter. See Exclusive Parameters \u27b6 # import the necessary packages from deffcode import FFdecoder import cv2 # define `-pattern_type glob` for accepting glob pattern ffparams = { \"-ffprefixes\" :[ \"-pattern_type\" , \"glob\" ]} # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"/path/to/pngs/img*.png\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # grab the GRAYSCALE frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () Capturing and Previewing frames from Single looping image \u00b6 In this example we will capture video frames from a Single Looping image using FFdecoder API, and preview them using OpenCV Library's cv2.imshow() method in real-time. By default, OpenCV expects BGR format frames in its cv2.imshow() method. To learn more about exclusive -ffprefixes parameter. See Exclusive Parameters \u27b6 # import the necessary packages from deffcode import FFdecoder import cv2 # define `-loop 1` for infinite looping ffparams = { \"-ffprefixes\" :[ \"-loop\" , \"1\" ]} # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"img.png\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"Decoding Image sequences"},{"location":"recipes/basic/decode-image-sequences/#decoding-image-sequences","text":"DeFFcode's FFdecoder API supports a wide-ranging media streams as input to its source parameter, which also includes Image Sequences such as Sequential( img%03d.png ) and Glob pattern( *.png ) as well as Single looping image . We'll discuss both briefly in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error.","title":" Decoding Image sequences"},{"location":"recipes/basic/decode-image-sequences/#capturing-and-previewing-frames-from-sequence-of-images","text":"In this example we will capture video frames from a given Image Sequence using FFdecoder API, and preview them using OpenCV Library's cv2.imshow() method in real-time. OpenCV expects BGR format frames in its cv2.imshow() method. Extracting Image Sequences from a video You can use following FFmpeg command to extract sequences of images from a video file foo.mp4 : $ ffmpeg -i foo.mp4 /path/to/image-%03d.png The default framerate is 25 fps, therefore this command will extract 25 images/sec from the video file, and save them as sequences of images (starting from image-000.png , image-001.png , image-002.png up to image-999.png ) . If there are more than 1000 frames then the last image will be overwritten with the remaining frames leaving only the last frame. The default images width and height is same as the video. Sequential Glob pattern How to start with specific number image? You can use -start_number FFmpeg parameter if you want to start with specific number image: # define `-start_number` such as `5` ffparams = { \"-ffprefixes\" :[ \"-start_number\" , \"5\" ]} # initialize and formulate the decoder with define parameters decoder = FFdecoder ( 'img %03d .png' , verbose = True , ** ffparams ) . formulate () # import the necessary packages from deffcode import FFdecoder import cv2 # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"/path/to/pngs/img %03d .png\" , frame_format = \"bgr24\" , verbose = True ) . formulate () # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () Bash-style globbing ( * represents any number of any characters) is useful if your images are sequential but not necessarily in a numerically sequential order. The glob pattern is not available on Windows FFmpeg builds. To learn more about exclusive -ffprefixes parameter. See Exclusive Parameters \u27b6 # import the necessary packages from deffcode import FFdecoder import cv2 # define `-pattern_type glob` for accepting glob pattern ffparams = { \"-ffprefixes\" :[ \"-pattern_type\" , \"glob\" ]} # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"/path/to/pngs/img*.png\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # grab the GRAYSCALE frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"Capturing and Previewing frames from Sequence of images"},{"location":"recipes/basic/decode-image-sequences/#capturing-and-previewing-frames-from-single-looping-image","text":"In this example we will capture video frames from a Single Looping image using FFdecoder API, and preview them using OpenCV Library's cv2.imshow() method in real-time. By default, OpenCV expects BGR format frames in its cv2.imshow() method. To learn more about exclusive -ffprefixes parameter. See Exclusive Parameters \u27b6 # import the necessary packages from deffcode import FFdecoder import cv2 # define `-loop 1` for infinite looping ffparams = { \"-ffprefixes\" :[ \"-loop\" , \"1\" ]} # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"img.png\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"Capturing and Previewing frames from Single looping image"},{"location":"recipes/basic/decode-live-feed-devices/","text":"Decoding Live Feed Devices \u00b6 DeFFcode's FFdecoder API provide effortless support for Live Feed Devices using two parameters: source parameter which accepts device name or its path, and source_demuxer parameter to specify demuxer for the given input device. We'll discuss the Live Feed Devices support using both these parameters briefly in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error. \u2009 Capturing and Previewing frames from a Webcam \u00b6 Example Assumptions FFmpeg provide set of specific Demuxers on different platforms to read the multimedia streams from a particular type of Video Capture source/device. Please note that following recipe explicitly assumes: You're running Linux Machine with USB webcam connected to it at node/path /dev/video0 . You already have appropriate Linux video drivers and related softwares installed on your machine. You machine uses FFmpeg binaries built with --enable-libv4l2 flag to support video4linux2, v4l2 demuxer. BTW, you can list all supported demuxers using the ffmpeg --list-demuxers terminal command. These assumptions MAY/MAY NOT suit your current setup. Kindly use suitable parameters based your system platform and hardware settings only. In this example we will decode BGR24 video frames from a USB webcam device connected at path /dev/video0 on a Linux Machine with video4linux2 (or simply v4l2 ) demuxer, and preview them using OpenCV Library's cv2.imshow() method. Identifying and Specifying Video Capture Device Name/Path/Index and suitable Demuxer on different OS platforms Windows Linux MacOS Windows OS users can use the dshow (DirectShow) to list video input device which is the preferred option for Windows users. You can refer following steps to identify and specify your input video device's name: Identify Video Devices: You can locate your video device's name (already connected to your system) using dshow as follows: c: \\> ffmpeg.exe -list_devices true -f dshow -i dummy ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ dshow @ 03ACF580 ] DirectShow video devices [ dshow @ 03ACF580 ] \"Integrated Camera\" [ dshow @ 03ACF580 ] \"USB2.0 Camera\" [ dshow @ 03ACF580 ] DirectShow audio devices [ dshow @ 03ACF580 ] \"Microphone (Realtek High Definition Audio)\" [ dshow @ 03ACF580 ] \"Microphone (USB2.0 Camera)\" dummy: Immediate exit requested Specify Video Device's name: Then, you can specify and initialize your located Video device's name in FFdecoder API as follows: # initialize and formulate the decoder with \"USB2.0 Camera\" source for BGR24 output decoder = FFdecoder ( \"USB2.0 Camera\" , source_demuxer = \"dshow\" , frame_format = \"bgr24\" , verbose = True ) . formulate () [OPTIONAL] Specify Video Device's index along with name: If there are multiple Video devices with similar name, then you can use -video_device_number parameter to specify the arbitrary index of the particular device. For instance, to open second video device with name \"Camera\" you can do as follows: # define video_device_number as 1 (numbering start from 0) ffparams = { \"-ffprefixes\" :[ \"-video_device_number\" , \"1\" ]} # initialize and formulate the decoder with \"Camera\" source for BGR24 output decoder = FFdecoder ( \"Camera\" , source_demuxer = \"dshow\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () Linux OS users can use the video4linux2 (or its alias v4l2 ) to list to all capture video devices such as from an USB webcam. You can refer following steps to identify and specify your capture video device's path: Identify Video Devices: Linux systems tend to automatically create file device node/path when the device (e.g. an USB webcam) is plugged into the system, and has a name of the kind '/dev/videoN' , where N is a index associated to the device. To get the list of all available file device node/path on your Linux machine, you can use the v4l-ctl command. You can use sudo apt install v4l-utils APT command to install v4l-ctl tool on Debian-based Linux distros. $ v4l2-ctl --list-devices USB2.0 PC CAMERA ( usb-0000:00:1d.7-1 ) : /dev/video1 UVC Camera ( 046d:0819 ) ( usb-0000:00:1d.7-2 ) : /dev/video0 Specify Video Device's path: Then, you can specify and initialize your located Video device's path in FFdecoder API as follows: # initialize and formulate the decoder with \"/dev/video0\" source for BGR24 output decoder = FFdecoder ( \"/dev/video0\" , source_demuxer = \"v4l2\" , frame_format = \"bgr24\" , verbose = True ) . formulate () [OPTIONAL] Specify Video Device's additional specifications: You can also specify additional specifications (such as pixel format(s), video format(s), framerate, and frame dimensions) supported by your Video Device as follows: You can use ffmpeg -f v4l2 -list_formats all -i /dev/video0 terminal command to list available specifications. # define video device specifications ffparams = { \"-ffprefixes\" :[ \"-framerate\" , \"25\" , \"-video_size\" , \"640x480\" ]} # initialize and formulate the decoder with \"/dev/video0\" source for BGR24 output decoder = FFdecoder ( \"/dev/video0\" , source_demuxer = \"v4l2\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () MacOS users can use the AVFoundation to list input devices and is the currently recommended framework by Apple for streamgrabbing on Mac OSX-10.7 (Lion) and later as well as on iOS. You can refer following steps to identify and specify your capture video device's name or index on MacOS/OSX machines: QTKit is also available for streamgrabbing on Mac OS X 10.4 (Tiger) and later, but has been marked deprecated since OS X 10.7 (Lion) and may not be available on future releases. Identify Video Devices: Then, You can locate your Video device's name and index using avfoundation as follows: $ ffmpeg -f avfoundation -list_devices true -i \"\" ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation video devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] FaceTime HD camera ( built-in ) [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Capture screen 0 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation audio devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] Blackmagic Audio [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Built-in Microphone Specify Video Device's name or index: Then, you can specify and initialize your located Video device in FFdecoder API using its either the name or the index shown in the device listing: Using device's index Using device's name # initialize and formulate the decoder with `1` index source for BGR24 output decoder = FFdecoder ( \"1\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True ) . formulate () When specifying device's name, abbreviations using just the beginning of the device name are possible. Thus, to capture from a device named \"Integrated iSight-camera\" just \"Integrated\" is sufficient: # initialize and formulate the decoder with \"Integrated iSight-camera\" source for BGR24 output decoder = FFdecoder ( \"Integrated\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True ) . formulate () [OPTIONAL] Specify Default Video device: You can also use the default device which is usually the first device in the listing by using \"default\" as source: # initialize and formulate the decoder with \"default\" source for BGR24 output decoder = FFdecoder ( \"default\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True ) . formulate () If these steps doesn't work for you then reach us out on Gitter \u27b6 Community channel # import the necessary packages from deffcode import FFdecoder import cv2 # initialize and formulate the decoder with \"/dev/video0\" source for BGR24 output decoder = FFdecoder ( \"/dev/video0\" , source_demuxer = \"v4l2\" , frame_format = \"bgr24\" , verbose = True ) . formulate () # grab the BGR24 frames from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () Capturing and Previewing frames from your Desktop \u00b6 Example Assumptions Similar to Webcam capturing, FFmpeg provide set of specific Demuxers on different platforms for capturing your desktop (Screen recording) . Please note that following recipe explicitly assumes: You're running Linux Machine with libxcb module installed properly on your machine. You machine uses FFmpeg binaries built with --enable-libxcb flag to support x11grab demuxer. BTW, you can list all supported demuxers using the ffmpeg --list-demuxers terminal command. These assumptions MAY/MAY NOT suit your current setup. Kindly use suitable parameters based your system platform and hardware settings only. In this example we will decode live BGR video frames from your complete screen as well as a region in FFdecoder API, and preview them using OpenCV Library's cv2.imshow() method. Specifying suitable Parameter(s) and Demuxer for Capturing your Desktop on different OS platforms Windows Linux MacOS Windows OS users can use the gdigrab to grab video from the Windows screen. You can refer following steps to specify source for capturing different regions of your display: For Windows OS users dshow is also available for grabbing frames from your desktop. But it is highly unreliable and don't works most of the times. Capturing entire desktop: For capturing all your displays as one big contiguous display, you can specify source, suitable parameters and demuxers in FFdecoder API as follows: # define framerate ffparams = { \"-framerate\" : \"30\" } # initialize and formulate the decoder with \"desktop\" source for BGR24 output decoder = FFdecoder ( \"desktop\" , source_demuxer = \"gdigrab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () Capturing a region: If you want to limit capturing to a region, and show the area being grabbed, you can specify source and suitable parameters in FFdecoder API as follows: x_offset and y_offset specify the offsets of the grabbed area with respect to the top-left border of the desktop screen. They default to 0 . # define suitable parameters ffparams = { \"-framerate\" : \"30\" , # input framerate \"-ffprefixes\" : [ \"-offset_x\" , \"10\" , \"-offset_y\" , \"20\" , # grab at position 10,20 \"-video_size\" , \"640x480\" , # frame size \"-show_region\" , \"1\" , # show only region ], } # initialize and formulate the decoder with \"desktop\" source for BGR24 output decoder = FFdecoder ( \"desktop\" , source_demuxer = \"gdigrab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () Linux OS users can use the x11grab to capture an X11 display. You can refer following steps to specify source for capturing different regions of your display: For X11 display, the source input has the syntax: \"display_number.screen_number[+x_offset,y_offset]\" . Capturing entire desktop: For capturing all your displays as one big contiguous display, you can specify source, suitable parameters and demuxers in FFdecoder API as follows: # define framerate ffparams = { \"-framerate\" : \"30\" } # initialize and formulate the decoder with \":0.0\" desktop source for BGR24 output decoder = FFdecoder ( \":0.0\" , source_demuxer = \"x11grab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () Capturing a region: If you want to limit capturing to a region, and show the area being grabbed, you can specify source and suitable parameters in FFdecoder API as follows: x_offset and y_offset specify the offsets of the grabbed area with respect to the top-left border of the X11 screen. They default to 0 . # define suitable parameters ffparams = { \"-framerate\" : \"30\" , # input framerate \"-ffprefixes\" : [ \"-video_size\" , \"1024x768\" , # frame size ], } # initialize and formulate the decoder with \":0.0\" desktop source(starting with the upper-left corner at x=10, y=20) # for BGR24 output decoder = FFdecoder ( \":0.0+10,20\" , source_demuxer = \"x11grab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () MacOS users can use the AVFoundation to list input devices and is the currently recommended framework by Apple for streamgrabbing on Mac OSX-10.7 (Lion) and later as well as on iOS. You can refer following steps to identify and specify your capture video device's name or index on MacOS/OSX machines: QTKit is also available for streamgrabbing on Mac OS X 10.4 (Tiger) and later, but has been marked deprecated since OS X 10.7 (Lion) and may not be available on future releases. Identify Video Devices: You can enumerate all the available input devices including screens ready to be captured using avfoundation as follows: $ ffmpeg -f avfoundation -list_devices true -i \"\" ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation video devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] FaceTime HD camera ( built-in ) [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Capture screen 0 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation audio devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] Blackmagic Audio [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Built-in Microphone Capturing entire desktop: Then, you can specify and initialize your located screens in FFdecoder API using its index shown: # initialize and formulate the decoder with `0:` index desktop screen for BGR24 output decoder = FFdecoder ( \"0:\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True ) . formulate () [OPTIONAL] Capturing mouse: You can also specify additional specifications to capture the mouse pointer and screen mouse clicks as follows: # define specifications ffparams = { \"-ffprefixes\" :[ \"-capture_cursor\" , \"1\" , \"-capture_mouse_clicks\" , \"0\" ]} # initialize and formulate the decoder with \"0:\" source for BGR24 output decoder = FFdecoder ( \"0:\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () If these steps doesn't work for you then reach us out on Gitter \u27b6 Community channel Capturing entire desktop Capturing a region For capturing all your displays as one big contiguous display in FFdecoder API: # import the necessary packages from deffcode import FFdecoder import cv2 # define framerate ffparams = { \"-framerate\" : \"30\" } # initialize and formulate the decoder with \":0.0\" desktop source for BGR24 output decoder = FFdecoder ( \":0.0\" , source_demuxer = \"x11grab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # grab the BGR24 frames from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () For limit capturing to a region, and show the area being grabbed: x_offset and y_offset specify the offsets of the grabbed area with respect to the top-left border of the X11 screen. They default to 0 . # import the necessary packages from deffcode import FFdecoder import cv2 # define suitable parameters ffparams = { \"-framerate\" : \"30\" , # input framerate \"-ffprefixes\" : [ \"-video_size\" , \"1024x768\" , # frame size ], } # initialize and formulate the decoder with \":0.0\" desktop source(starting with the upper-left corner at x=10, y=20) # for BGR24 output decoder = FFdecoder ( \":0.0+10,20\" , source_demuxer = \"x11grab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # grab the BGR24 frames from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"Decoding Live Feed Devices"},{"location":"recipes/basic/decode-live-feed-devices/#decoding-live-feed-devices","text":"DeFFcode's FFdecoder API provide effortless support for Live Feed Devices using two parameters: source parameter which accepts device name or its path, and source_demuxer parameter to specify demuxer for the given input device. We'll discuss the Live Feed Devices support using both these parameters briefly in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error.","title":" Decoding Live Feed Devices"},{"location":"recipes/basic/decode-live-feed-devices/#capturing-and-previewing-frames-from-a-webcam","text":"Example Assumptions FFmpeg provide set of specific Demuxers on different platforms to read the multimedia streams from a particular type of Video Capture source/device. Please note that following recipe explicitly assumes: You're running Linux Machine with USB webcam connected to it at node/path /dev/video0 . You already have appropriate Linux video drivers and related softwares installed on your machine. You machine uses FFmpeg binaries built with --enable-libv4l2 flag to support video4linux2, v4l2 demuxer. BTW, you can list all supported demuxers using the ffmpeg --list-demuxers terminal command. These assumptions MAY/MAY NOT suit your current setup. Kindly use suitable parameters based your system platform and hardware settings only. In this example we will decode BGR24 video frames from a USB webcam device connected at path /dev/video0 on a Linux Machine with video4linux2 (or simply v4l2 ) demuxer, and preview them using OpenCV Library's cv2.imshow() method. Identifying and Specifying Video Capture Device Name/Path/Index and suitable Demuxer on different OS platforms Windows Linux MacOS Windows OS users can use the dshow (DirectShow) to list video input device which is the preferred option for Windows users. You can refer following steps to identify and specify your input video device's name: Identify Video Devices: You can locate your video device's name (already connected to your system) using dshow as follows: c: \\> ffmpeg.exe -list_devices true -f dshow -i dummy ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ dshow @ 03ACF580 ] DirectShow video devices [ dshow @ 03ACF580 ] \"Integrated Camera\" [ dshow @ 03ACF580 ] \"USB2.0 Camera\" [ dshow @ 03ACF580 ] DirectShow audio devices [ dshow @ 03ACF580 ] \"Microphone (Realtek High Definition Audio)\" [ dshow @ 03ACF580 ] \"Microphone (USB2.0 Camera)\" dummy: Immediate exit requested Specify Video Device's name: Then, you can specify and initialize your located Video device's name in FFdecoder API as follows: # initialize and formulate the decoder with \"USB2.0 Camera\" source for BGR24 output decoder = FFdecoder ( \"USB2.0 Camera\" , source_demuxer = \"dshow\" , frame_format = \"bgr24\" , verbose = True ) . formulate () [OPTIONAL] Specify Video Device's index along with name: If there are multiple Video devices with similar name, then you can use -video_device_number parameter to specify the arbitrary index of the particular device. For instance, to open second video device with name \"Camera\" you can do as follows: # define video_device_number as 1 (numbering start from 0) ffparams = { \"-ffprefixes\" :[ \"-video_device_number\" , \"1\" ]} # initialize and formulate the decoder with \"Camera\" source for BGR24 output decoder = FFdecoder ( \"Camera\" , source_demuxer = \"dshow\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () Linux OS users can use the video4linux2 (or its alias v4l2 ) to list to all capture video devices such as from an USB webcam. You can refer following steps to identify and specify your capture video device's path: Identify Video Devices: Linux systems tend to automatically create file device node/path when the device (e.g. an USB webcam) is plugged into the system, and has a name of the kind '/dev/videoN' , where N is a index associated to the device. To get the list of all available file device node/path on your Linux machine, you can use the v4l-ctl command. You can use sudo apt install v4l-utils APT command to install v4l-ctl tool on Debian-based Linux distros. $ v4l2-ctl --list-devices USB2.0 PC CAMERA ( usb-0000:00:1d.7-1 ) : /dev/video1 UVC Camera ( 046d:0819 ) ( usb-0000:00:1d.7-2 ) : /dev/video0 Specify Video Device's path: Then, you can specify and initialize your located Video device's path in FFdecoder API as follows: # initialize and formulate the decoder with \"/dev/video0\" source for BGR24 output decoder = FFdecoder ( \"/dev/video0\" , source_demuxer = \"v4l2\" , frame_format = \"bgr24\" , verbose = True ) . formulate () [OPTIONAL] Specify Video Device's additional specifications: You can also specify additional specifications (such as pixel format(s), video format(s), framerate, and frame dimensions) supported by your Video Device as follows: You can use ffmpeg -f v4l2 -list_formats all -i /dev/video0 terminal command to list available specifications. # define video device specifications ffparams = { \"-ffprefixes\" :[ \"-framerate\" , \"25\" , \"-video_size\" , \"640x480\" ]} # initialize and formulate the decoder with \"/dev/video0\" source for BGR24 output decoder = FFdecoder ( \"/dev/video0\" , source_demuxer = \"v4l2\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () MacOS users can use the AVFoundation to list input devices and is the currently recommended framework by Apple for streamgrabbing on Mac OSX-10.7 (Lion) and later as well as on iOS. You can refer following steps to identify and specify your capture video device's name or index on MacOS/OSX machines: QTKit is also available for streamgrabbing on Mac OS X 10.4 (Tiger) and later, but has been marked deprecated since OS X 10.7 (Lion) and may not be available on future releases. Identify Video Devices: Then, You can locate your Video device's name and index using avfoundation as follows: $ ffmpeg -f avfoundation -list_devices true -i \"\" ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation video devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] FaceTime HD camera ( built-in ) [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Capture screen 0 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation audio devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] Blackmagic Audio [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Built-in Microphone Specify Video Device's name or index: Then, you can specify and initialize your located Video device in FFdecoder API using its either the name or the index shown in the device listing: Using device's index Using device's name # initialize and formulate the decoder with `1` index source for BGR24 output decoder = FFdecoder ( \"1\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True ) . formulate () When specifying device's name, abbreviations using just the beginning of the device name are possible. Thus, to capture from a device named \"Integrated iSight-camera\" just \"Integrated\" is sufficient: # initialize and formulate the decoder with \"Integrated iSight-camera\" source for BGR24 output decoder = FFdecoder ( \"Integrated\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True ) . formulate () [OPTIONAL] Specify Default Video device: You can also use the default device which is usually the first device in the listing by using \"default\" as source: # initialize and formulate the decoder with \"default\" source for BGR24 output decoder = FFdecoder ( \"default\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True ) . formulate () If these steps doesn't work for you then reach us out on Gitter \u27b6 Community channel # import the necessary packages from deffcode import FFdecoder import cv2 # initialize and formulate the decoder with \"/dev/video0\" source for BGR24 output decoder = FFdecoder ( \"/dev/video0\" , source_demuxer = \"v4l2\" , frame_format = \"bgr24\" , verbose = True ) . formulate () # grab the BGR24 frames from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"Capturing and Previewing frames from a Webcam"},{"location":"recipes/basic/decode-live-feed-devices/#capturing-and-previewing-frames-from-your-desktop","text":"Example Assumptions Similar to Webcam capturing, FFmpeg provide set of specific Demuxers on different platforms for capturing your desktop (Screen recording) . Please note that following recipe explicitly assumes: You're running Linux Machine with libxcb module installed properly on your machine. You machine uses FFmpeg binaries built with --enable-libxcb flag to support x11grab demuxer. BTW, you can list all supported demuxers using the ffmpeg --list-demuxers terminal command. These assumptions MAY/MAY NOT suit your current setup. Kindly use suitable parameters based your system platform and hardware settings only. In this example we will decode live BGR video frames from your complete screen as well as a region in FFdecoder API, and preview them using OpenCV Library's cv2.imshow() method. Specifying suitable Parameter(s) and Demuxer for Capturing your Desktop on different OS platforms Windows Linux MacOS Windows OS users can use the gdigrab to grab video from the Windows screen. You can refer following steps to specify source for capturing different regions of your display: For Windows OS users dshow is also available for grabbing frames from your desktop. But it is highly unreliable and don't works most of the times. Capturing entire desktop: For capturing all your displays as one big contiguous display, you can specify source, suitable parameters and demuxers in FFdecoder API as follows: # define framerate ffparams = { \"-framerate\" : \"30\" } # initialize and formulate the decoder with \"desktop\" source for BGR24 output decoder = FFdecoder ( \"desktop\" , source_demuxer = \"gdigrab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () Capturing a region: If you want to limit capturing to a region, and show the area being grabbed, you can specify source and suitable parameters in FFdecoder API as follows: x_offset and y_offset specify the offsets of the grabbed area with respect to the top-left border of the desktop screen. They default to 0 . # define suitable parameters ffparams = { \"-framerate\" : \"30\" , # input framerate \"-ffprefixes\" : [ \"-offset_x\" , \"10\" , \"-offset_y\" , \"20\" , # grab at position 10,20 \"-video_size\" , \"640x480\" , # frame size \"-show_region\" , \"1\" , # show only region ], } # initialize and formulate the decoder with \"desktop\" source for BGR24 output decoder = FFdecoder ( \"desktop\" , source_demuxer = \"gdigrab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () Linux OS users can use the x11grab to capture an X11 display. You can refer following steps to specify source for capturing different regions of your display: For X11 display, the source input has the syntax: \"display_number.screen_number[+x_offset,y_offset]\" . Capturing entire desktop: For capturing all your displays as one big contiguous display, you can specify source, suitable parameters and demuxers in FFdecoder API as follows: # define framerate ffparams = { \"-framerate\" : \"30\" } # initialize and formulate the decoder with \":0.0\" desktop source for BGR24 output decoder = FFdecoder ( \":0.0\" , source_demuxer = \"x11grab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () Capturing a region: If you want to limit capturing to a region, and show the area being grabbed, you can specify source and suitable parameters in FFdecoder API as follows: x_offset and y_offset specify the offsets of the grabbed area with respect to the top-left border of the X11 screen. They default to 0 . # define suitable parameters ffparams = { \"-framerate\" : \"30\" , # input framerate \"-ffprefixes\" : [ \"-video_size\" , \"1024x768\" , # frame size ], } # initialize and formulate the decoder with \":0.0\" desktop source(starting with the upper-left corner at x=10, y=20) # for BGR24 output decoder = FFdecoder ( \":0.0+10,20\" , source_demuxer = \"x11grab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () MacOS users can use the AVFoundation to list input devices and is the currently recommended framework by Apple for streamgrabbing on Mac OSX-10.7 (Lion) and later as well as on iOS. You can refer following steps to identify and specify your capture video device's name or index on MacOS/OSX machines: QTKit is also available for streamgrabbing on Mac OS X 10.4 (Tiger) and later, but has been marked deprecated since OS X 10.7 (Lion) and may not be available on future releases. Identify Video Devices: You can enumerate all the available input devices including screens ready to be captured using avfoundation as follows: $ ffmpeg -f avfoundation -list_devices true -i \"\" ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation video devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] FaceTime HD camera ( built-in ) [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Capture screen 0 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation audio devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] Blackmagic Audio [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Built-in Microphone Capturing entire desktop: Then, you can specify and initialize your located screens in FFdecoder API using its index shown: # initialize and formulate the decoder with `0:` index desktop screen for BGR24 output decoder = FFdecoder ( \"0:\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True ) . formulate () [OPTIONAL] Capturing mouse: You can also specify additional specifications to capture the mouse pointer and screen mouse clicks as follows: # define specifications ffparams = { \"-ffprefixes\" :[ \"-capture_cursor\" , \"1\" , \"-capture_mouse_clicks\" , \"0\" ]} # initialize and formulate the decoder with \"0:\" source for BGR24 output decoder = FFdecoder ( \"0:\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () If these steps doesn't work for you then reach us out on Gitter \u27b6 Community channel Capturing entire desktop Capturing a region For capturing all your displays as one big contiguous display in FFdecoder API: # import the necessary packages from deffcode import FFdecoder import cv2 # define framerate ffparams = { \"-framerate\" : \"30\" } # initialize and formulate the decoder with \":0.0\" desktop source for BGR24 output decoder = FFdecoder ( \":0.0\" , source_demuxer = \"x11grab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # grab the BGR24 frames from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () For limit capturing to a region, and show the area being grabbed: x_offset and y_offset specify the offsets of the grabbed area with respect to the top-left border of the X11 screen. They default to 0 . # import the necessary packages from deffcode import FFdecoder import cv2 # define suitable parameters ffparams = { \"-framerate\" : \"30\" , # input framerate \"-ffprefixes\" : [ \"-video_size\" , \"1024x768\" , # frame size ], } # initialize and formulate the decoder with \":0.0\" desktop source(starting with the upper-left corner at x=10, y=20) # for BGR24 output decoder = FFdecoder ( \":0.0+10,20\" , source_demuxer = \"x11grab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # grab the BGR24 frames from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"Capturing and Previewing frames from your Desktop"},{"location":"recipes/basic/decode-network-streams/","text":"Decoding Network Streams \u00b6 Similar to decoding Video files, DeFFcode's FFdecoder API directly supports Network Streams with specific protocols (such as RTSP/RTP, HTTP(s), MPEG-TS, etc.) as input to its source parameter. We'll discuss Network Streams support briefly in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error. \u2009 Capturing and Previewing frames from a HTTPs Stream \u00b6 In this example we will decode live BGR24 video frames from a HTTPs protocol Stream in FFdecoder API, and preview them using OpenCV Library's cv2.imshow() method. # import the necessary packages from deffcode import FFdecoder import cv2 # initialize and formulate the decoder for BGR24 pixel format output decoder = FFdecoder ( \"https://abhitronix.github.io/html/Big_Buck_Bunny_1080_10s_1MB.mp4\" , frame_format = \"bgr24\" ) . formulate () # grab the BGR24 frames from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () Capturing and Previewing frames from a RTSP/RTP Stream \u00b6 In this example we will decode live BGR24 video frames from RTSP/RTP protocol Streams in FFdecoder API, and preview them using OpenCV Library's cv2.imshow() method. This example assume you already have a RSTP Server running at specified RSTP address with syntax rtsp://[RTSP_ADDRESS]:[RTSP_PORT]/[RTSP_PATH] and video data already being published to it. For creating your own RSTP Server locally and publishing video data to it, You can refer this WriteGear API's bonus example \u27b6 Make sure to change RSTP address rtsp://localhost:8554/mystream with yours in following code before running # import the necessary packages from deffcode import FFdecoder import cv2 # define suitable parameters ffparams = { \"-rtsp_transport\" : \"tcp\" } # initialize and formulate the decoder with RTSP protocol source for BGR24 output # [WARNING] Change your RSTP address `rtsp://localhost:8554/mystream` with yours! decoder = FFdecoder ( \"rtsp://localhost:8554/mystream\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # grab the BGR24 frames from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"Decoding Network Streams"},{"location":"recipes/basic/decode-network-streams/#decoding-network-streams","text":"Similar to decoding Video files, DeFFcode's FFdecoder API directly supports Network Streams with specific protocols (such as RTSP/RTP, HTTP(s), MPEG-TS, etc.) as input to its source parameter. We'll discuss Network Streams support briefly in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error.","title":" Decoding Network Streams"},{"location":"recipes/basic/decode-network-streams/#capturing-and-previewing-frames-from-a-https-stream","text":"In this example we will decode live BGR24 video frames from a HTTPs protocol Stream in FFdecoder API, and preview them using OpenCV Library's cv2.imshow() method. # import the necessary packages from deffcode import FFdecoder import cv2 # initialize and formulate the decoder for BGR24 pixel format output decoder = FFdecoder ( \"https://abhitronix.github.io/html/Big_Buck_Bunny_1080_10s_1MB.mp4\" , frame_format = \"bgr24\" ) . formulate () # grab the BGR24 frames from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"Capturing and Previewing frames from a HTTPs Stream"},{"location":"recipes/basic/decode-network-streams/#capturing-and-previewing-frames-from-a-rtsprtp-stream","text":"In this example we will decode live BGR24 video frames from RTSP/RTP protocol Streams in FFdecoder API, and preview them using OpenCV Library's cv2.imshow() method. This example assume you already have a RSTP Server running at specified RSTP address with syntax rtsp://[RTSP_ADDRESS]:[RTSP_PORT]/[RTSP_PATH] and video data already being published to it. For creating your own RSTP Server locally and publishing video data to it, You can refer this WriteGear API's bonus example \u27b6 Make sure to change RSTP address rtsp://localhost:8554/mystream with yours in following code before running # import the necessary packages from deffcode import FFdecoder import cv2 # define suitable parameters ffparams = { \"-rtsp_transport\" : \"tcp\" } # initialize and formulate the decoder with RTSP protocol source for BGR24 output # [WARNING] Change your RSTP address `rtsp://localhost:8554/mystream` with yours! decoder = FFdecoder ( \"rtsp://localhost:8554/mystream\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # grab the BGR24 frames from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"Capturing and Previewing frames from a RTSP/RTP Stream"},{"location":"recipes/basic/decode-video-files/","text":"Decoding Video files \u00b6 DeFFcode's FFdecoder API readily supports multimedia Video files path as input to its source parameter. And with its frame_format parameter, you can easily decode video frames in any pixel format(s) that are readily supported by all well known Computer Vision libraries (such as OpenCV) . We'll discuss its video files support and pixel format capabilities briefly in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error. \u2009 Accessing RGB frames from a video file \u00b6 The default function of FFdecoder API is to decode 24-bit RGB video frames from the given source. FFdecoder API's generateFrame() function can be used in multiple methods to access RGB frames from a given source, such as as a Generator (Recommended Approach) , calling with Statement , and as a Iterator . In this example we will decode the default RGB24 video frames from a given Video file (say foo.mp4 ) using above mentioned accessing methods: As a Generator (Recommended) Calling with Statement As a Iterator This is a recommended approach for faster and error-proof access of decoded frames. We'll use it throughout the recipes. # import the necessary packages from deffcode import FFdecoder # initialize and formulate the decoder decoder = FFdecoder ( \"foo.mp4\" ) . formulate () # grab RGB24(default) frame from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # lets print its shape print ( frame . shape ) # for e.g. (1080, 1920, 3) # terminate the decoder decoder . terminate () Calling with Statement approach can be used to make the code easier, cleaner, and much more readable. This approach also automatically handles management of formulate() and terminate() methods in FFdecoder API, so don't need to explicitly call them. See PEP343 -- The 'with' statement' for more information on this approach. # import the necessary packages from deffcode import FFdecoder import cv2 # initialize and formulate the decoder with FFdecoder ( \"foo.mp4\" ) as decoder : # grab the BGR24 frames from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # lets print its shape print ( frame . shape ) # for e.g. (1080, 1920, 3) This Iterator Approach bears a close resemblance to OpenCV-Python (Python API for OpenCV) coding syntax, thereby easier to learn and remember. # import the necessary packages from deffcode import FFdecoder # initialize and formulate the decoder decoder = FFdecoder ( \"foo.mp4\" ) . formulate () # loop over frames while True : # grab RGB24(default) frames from decoder frame = next ( decoder . generateFrame (), None ) # check if frame is None if frame is None : break # {do something with the frame here} # lets print its shape print ( frame . shape ) # for e.g. (1080, 1920, 3) # terminate the decoder decoder . terminate () Capturing and Previewing BGR frames from a video file \u00b6 In this example we will decode OpenCV supported live BGR24 video frames from a given Video file (say foo.mp4 ) in FFdecoder API, and preview them using OpenCV Library's cv2.imshow() method. By default, OpenCV expects BGR format frames in its cv2.imshow() method by using two accessing methods. As a Generator (Recommended) Calling with Statement # import the necessary packages from deffcode import FFdecoder import cv2 # initialize and formulate the decoder for BGR24 pixel format output decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" ) . formulate () # grab the BGR24 frames from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () Calling with Statement approach can be used to make the code easier, cleaner, and much more readable. This approach also automatically handles management of formulate() and terminate() methods in FFdecoder API, so don't need to explicitly call them. See PEP343 -- The 'with' statement' for more information on this approach. # import the necessary packages from deffcode import FFdecoder import cv2 # initialize and formulate the decoder for BGR24 pixel format output with FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" ) as decoder : # grab the BGR24 frames from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () Playing with any other FFmpeg pixel formats \u00b6 Similar to BGR, you can input any pixel format (supported by installed FFmpeg) by way of frame_format parameter of FFdecoder API for the desired video frame format. In this example we will decode live Grayscale and YUV video frames from a given Video file (say foo.mp4 ) in FFdecoder API, and preview them using OpenCV Library's cv2.imshow() method. Use ffmpeg -pix_fmts terminal command to lists all FFmpeg supported pixel formats. Decode Grayscale Decode YUV # import the necessary packages from deffcode import FFdecoder import cv2 # initialize and formulate the decoder for GRAYSCALE output decoder = FFdecoder ( \"input_foo.mp4\" , frame_format = \"gray\" , verbose = True ) . formulate () # grab the GRAYSCALE frames from the decoder for gray in decoder . generateFrame (): # check if frame is None if gray is None : break # {do something with the gray frame here} # Show output window cv2 . imshow ( \"Gray Output\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () You can also use yuv422p (4:2:2 subsampling) or yuv444p (4:4:4 subsampling) instead for more higher dynamic range. # import the necessary packages from deffcode import FFdecoder import cv2 # initialize and formulate the decoder for YUV420 output decoder = FFdecoder ( \"input_foo.mp4\" , frame_format = \"yuv420p\" , verbose = True ) . formulate () # grab the YUV420 frames from the decoder for yuv in decoder . generateFrame (): # check if frame is None if yuv is None : break # {do something with the yuv frame here} # Show output window cv2 . imshow ( \"YUV Output\" , yuv ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"Decoding Video Files"},{"location":"recipes/basic/decode-video-files/#decoding-video-files","text":"DeFFcode's FFdecoder API readily supports multimedia Video files path as input to its source parameter. And with its frame_format parameter, you can easily decode video frames in any pixel format(s) that are readily supported by all well known Computer Vision libraries (such as OpenCV) . We'll discuss its video files support and pixel format capabilities briefly in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error.","title":" Decoding Video files"},{"location":"recipes/basic/decode-video-files/#accessing-rgb-frames-from-a-video-file","text":"The default function of FFdecoder API is to decode 24-bit RGB video frames from the given source. FFdecoder API's generateFrame() function can be used in multiple methods to access RGB frames from a given source, such as as a Generator (Recommended Approach) , calling with Statement , and as a Iterator . In this example we will decode the default RGB24 video frames from a given Video file (say foo.mp4 ) using above mentioned accessing methods: As a Generator (Recommended) Calling with Statement As a Iterator This is a recommended approach for faster and error-proof access of decoded frames. We'll use it throughout the recipes. # import the necessary packages from deffcode import FFdecoder # initialize and formulate the decoder decoder = FFdecoder ( \"foo.mp4\" ) . formulate () # grab RGB24(default) frame from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # lets print its shape print ( frame . shape ) # for e.g. (1080, 1920, 3) # terminate the decoder decoder . terminate () Calling with Statement approach can be used to make the code easier, cleaner, and much more readable. This approach also automatically handles management of formulate() and terminate() methods in FFdecoder API, so don't need to explicitly call them. See PEP343 -- The 'with' statement' for more information on this approach. # import the necessary packages from deffcode import FFdecoder import cv2 # initialize and formulate the decoder with FFdecoder ( \"foo.mp4\" ) as decoder : # grab the BGR24 frames from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # lets print its shape print ( frame . shape ) # for e.g. (1080, 1920, 3) This Iterator Approach bears a close resemblance to OpenCV-Python (Python API for OpenCV) coding syntax, thereby easier to learn and remember. # import the necessary packages from deffcode import FFdecoder # initialize and formulate the decoder decoder = FFdecoder ( \"foo.mp4\" ) . formulate () # loop over frames while True : # grab RGB24(default) frames from decoder frame = next ( decoder . generateFrame (), None ) # check if frame is None if frame is None : break # {do something with the frame here} # lets print its shape print ( frame . shape ) # for e.g. (1080, 1920, 3) # terminate the decoder decoder . terminate ()","title":"Accessing RGB frames from a video file"},{"location":"recipes/basic/decode-video-files/#capturing-and-previewing-bgr-frames-from-a-video-file","text":"In this example we will decode OpenCV supported live BGR24 video frames from a given Video file (say foo.mp4 ) in FFdecoder API, and preview them using OpenCV Library's cv2.imshow() method. By default, OpenCV expects BGR format frames in its cv2.imshow() method by using two accessing methods. As a Generator (Recommended) Calling with Statement # import the necessary packages from deffcode import FFdecoder import cv2 # initialize and formulate the decoder for BGR24 pixel format output decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" ) . formulate () # grab the BGR24 frames from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () Calling with Statement approach can be used to make the code easier, cleaner, and much more readable. This approach also automatically handles management of formulate() and terminate() methods in FFdecoder API, so don't need to explicitly call them. See PEP343 -- The 'with' statement' for more information on this approach. # import the necessary packages from deffcode import FFdecoder import cv2 # initialize and formulate the decoder for BGR24 pixel format output with FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" ) as decoder : # grab the BGR24 frames from decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # Show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows ()","title":"Capturing and Previewing BGR frames from a video file"},{"location":"recipes/basic/decode-video-files/#playing-with-any-other-ffmpeg-pixel-formats","text":"Similar to BGR, you can input any pixel format (supported by installed FFmpeg) by way of frame_format parameter of FFdecoder API for the desired video frame format. In this example we will decode live Grayscale and YUV video frames from a given Video file (say foo.mp4 ) in FFdecoder API, and preview them using OpenCV Library's cv2.imshow() method. Use ffmpeg -pix_fmts terminal command to lists all FFmpeg supported pixel formats. Decode Grayscale Decode YUV # import the necessary packages from deffcode import FFdecoder import cv2 # initialize and formulate the decoder for GRAYSCALE output decoder = FFdecoder ( \"input_foo.mp4\" , frame_format = \"gray\" , verbose = True ) . formulate () # grab the GRAYSCALE frames from the decoder for gray in decoder . generateFrame (): # check if frame is None if gray is None : break # {do something with the gray frame here} # Show output window cv2 . imshow ( \"Gray Output\" , gray ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () You can also use yuv422p (4:2:2 subsampling) or yuv444p (4:4:4 subsampling) instead for more higher dynamic range. # import the necessary packages from deffcode import FFdecoder import cv2 # initialize and formulate the decoder for YUV420 output decoder = FFdecoder ( \"input_foo.mp4\" , frame_format = \"yuv420p\" , verbose = True ) . formulate () # grab the YUV420 frames from the decoder for yuv in decoder . generateFrame (): # check if frame is None if yuv is None : break # {do something with the yuv frame here} # Show output window cv2 . imshow ( \"YUV Output\" , yuv ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate ()","title":"Playing with any other FFmpeg pixel formats"},{"location":"recipes/basic/extract-video-metadata/","text":"Extracting Video Metadata \u00b6 DeFFcode's Sourcer API acts as Source Probing Utility for easily probing metadata information for each multimedia stream available in the given video source, and return it as in Human-readable (as JSON string) or Machine-readable (as Dictionary object) type with its retrieve_metadata() class method. Apart from this, you can also use metadata property object in FFdecoder API to extract this metadata information (only as JSON string) . We'll discuss video metadata extraction using both these APIs briefly in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error. \u2009 Extracting video metadata using Sourcer API \u00b6 This is the recommended way for extracting video metadata. In this example we will probe all metadata information available within foo.mp4 video file on Windows machine, and print it in both Human-readable (as JSON string) and Machine-readable (as Dictionary object) types using retrieve_metadata() class method in Sourcer API: The Sourcer API's retrieve_metadata() class method provides pretty_json boolean parameter to return metadata as JSON string (if True ) and as Dictionary (if False ) . As JSON string As Dictionary object # import the necessary packages from deffcode import Sourcer # initialize and formulate the decoder using suitable source sourcer = Sourcer ( \"foo.mp4\" ) . probe_stream () # print metadata as `json.dump` print ( sourcer . retrieve_metadata ( pretty_json = True )) After running above python code, the resultant Terminal Output will look something as following on Windows machine: { \"ffmpeg_binary_path\" : \"C:\\\\Users\\\\foo\\\\AppData\\\\Local\\\\Temp\\\\ffmpeg-static-win64-gpl/bin/ffmpeg.exe\" , \"source\" : \"foo.mp4\" , \"source_extension\" : \".mp4\" , \"source_video_resolution\" : [ 1280 , 720 ], \"source_video_framerate\" : 25.0 , \"source_video_pixfmt\" : \"yuv420p\" , \"source_video_decoder\" : \"h264\" , \"source_duration_sec\" : 5.31 , \"approx_video_nframes\" : 133 , \"source_video_bitrate\" : \"1205k\" , \"source_audio_bitrate\" : \"384k\" , \"source_audio_samplerate\" : \"48000 Hz\" , \"source_has_video\" : true , \"source_has_audio\" : true , \"source_has_image_sequence\" : false , } # import the necessary packages from deffcode import Sourcer # initialize and formulate the decoder using suitable source sourcer = Sourcer ( \"foo.mp4\" ) . probe_stream () # print metadata as `dict` print ( sourcer . retrieve_metadata ()) After running above python code, the resultant Terminal Output will look something as following on Windows machine: { 'ffmpeg_binary_path' : 'C: \\\\ Users \\\\ foo \\\\ AppData \\\\ Local \\\\ Temp \\\\ ffmpeg-static-win64-gpl/bin/ffmpeg.exe' , 'source' : 'foo.mp4' , 'source_extension' : '.mp4' , 'source_video_resolution' : [ 1280 , 720 ], 'source_video_framerate' : 25.0 , 'source_video_pixfmt' : 'yuv420p' , 'source_video_decoder' : 'h264' , 'source_duration_sec' : 5.31 , 'approx_video_nframes' : 133 , 'source_video_bitrate' : '1205k' , 'source_audio_bitrate' : '384k' , 'source_audio_samplerate' : '48000 Hz' , 'source_has_video' : True , 'source_has_audio' : True , 'source_has_image_sequence' : False } Extracting video metadata using FFdecoder API \u00b6 In this example we will probe all metadata information available within foo.mp4 video file on Windows machine, and print it as JSON string using metadata property object in FFdecoder API. You can also update video's metadata by using the same overloaded metadata property object in FFdecoder API. More information can be found in this Advanced Recipe \u27b6 # import the necessary packages from deffcode import FFdecoder # initialize and formulate the decoder using suitable source decoder = FFdecoder ( \"foo.mp4\" ) . formulate () # print metadata as `json.dump` print ( decoder . metadata ) # terminate the decoder decoder . terminate () After running above python code, the resultant Terminal Output will look something as following on Windows machine: { \"ffmpeg_binary_path\" : \"C:\\\\Users\\\\foo\\\\AppData\\\\Local\\\\Temp\\\\ffmpeg-static-win64-gpl/bin/ffmpeg.exe\" , \"source\" : \"foo.mp4\" , \"source_extension\" : \".mp4\" , \"source_video_resolution\" : [ 1280 , 720 ], \"source_video_framerate\" : 25.0 , \"source_video_pixfmt\" : \"yuv420p\" , \"source_video_decoder\" : \"h264\" , \"source_duration_sec\" : 5.31 , \"approx_video_nframes\" : 133 , \"source_video_bitrate\" : \"1205k\" , \"source_audio_bitrate\" : \"384k\" , \"source_audio_samplerate\" : \"48000 Hz\" , \"source_has_video\" : true , \"source_has_audio\" : true , \"source_has_image_sequence\" : false , \"ffdecoder_operational_mode\" : \"Video-Only\" , \"output_frames_pixfmt\" : \"rgb24\" }","title":"Extracting video metadata"},{"location":"recipes/basic/extract-video-metadata/#extracting-video-metadata","text":"DeFFcode's Sourcer API acts as Source Probing Utility for easily probing metadata information for each multimedia stream available in the given video source, and return it as in Human-readable (as JSON string) or Machine-readable (as Dictionary object) type with its retrieve_metadata() class method. Apart from this, you can also use metadata property object in FFdecoder API to extract this metadata information (only as JSON string) . We'll discuss video metadata extraction using both these APIs briefly in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error.","title":" Extracting Video Metadata"},{"location":"recipes/basic/extract-video-metadata/#extracting-video-metadata-using-sourcer-api","text":"This is the recommended way for extracting video metadata. In this example we will probe all metadata information available within foo.mp4 video file on Windows machine, and print it in both Human-readable (as JSON string) and Machine-readable (as Dictionary object) types using retrieve_metadata() class method in Sourcer API: The Sourcer API's retrieve_metadata() class method provides pretty_json boolean parameter to return metadata as JSON string (if True ) and as Dictionary (if False ) . As JSON string As Dictionary object # import the necessary packages from deffcode import Sourcer # initialize and formulate the decoder using suitable source sourcer = Sourcer ( \"foo.mp4\" ) . probe_stream () # print metadata as `json.dump` print ( sourcer . retrieve_metadata ( pretty_json = True )) After running above python code, the resultant Terminal Output will look something as following on Windows machine: { \"ffmpeg_binary_path\" : \"C:\\\\Users\\\\foo\\\\AppData\\\\Local\\\\Temp\\\\ffmpeg-static-win64-gpl/bin/ffmpeg.exe\" , \"source\" : \"foo.mp4\" , \"source_extension\" : \".mp4\" , \"source_video_resolution\" : [ 1280 , 720 ], \"source_video_framerate\" : 25.0 , \"source_video_pixfmt\" : \"yuv420p\" , \"source_video_decoder\" : \"h264\" , \"source_duration_sec\" : 5.31 , \"approx_video_nframes\" : 133 , \"source_video_bitrate\" : \"1205k\" , \"source_audio_bitrate\" : \"384k\" , \"source_audio_samplerate\" : \"48000 Hz\" , \"source_has_video\" : true , \"source_has_audio\" : true , \"source_has_image_sequence\" : false , } # import the necessary packages from deffcode import Sourcer # initialize and formulate the decoder using suitable source sourcer = Sourcer ( \"foo.mp4\" ) . probe_stream () # print metadata as `dict` print ( sourcer . retrieve_metadata ()) After running above python code, the resultant Terminal Output will look something as following on Windows machine: { 'ffmpeg_binary_path' : 'C: \\\\ Users \\\\ foo \\\\ AppData \\\\ Local \\\\ Temp \\\\ ffmpeg-static-win64-gpl/bin/ffmpeg.exe' , 'source' : 'foo.mp4' , 'source_extension' : '.mp4' , 'source_video_resolution' : [ 1280 , 720 ], 'source_video_framerate' : 25.0 , 'source_video_pixfmt' : 'yuv420p' , 'source_video_decoder' : 'h264' , 'source_duration_sec' : 5.31 , 'approx_video_nframes' : 133 , 'source_video_bitrate' : '1205k' , 'source_audio_bitrate' : '384k' , 'source_audio_samplerate' : '48000 Hz' , 'source_has_video' : True , 'source_has_audio' : True , 'source_has_image_sequence' : False }","title":"Extracting video metadata using Sourcer API"},{"location":"recipes/basic/extract-video-metadata/#extracting-video-metadata-using-ffdecoder-api","text":"In this example we will probe all metadata information available within foo.mp4 video file on Windows machine, and print it as JSON string using metadata property object in FFdecoder API. You can also update video's metadata by using the same overloaded metadata property object in FFdecoder API. More information can be found in this Advanced Recipe \u27b6 # import the necessary packages from deffcode import FFdecoder # initialize and formulate the decoder using suitable source decoder = FFdecoder ( \"foo.mp4\" ) . formulate () # print metadata as `json.dump` print ( decoder . metadata ) # terminate the decoder decoder . terminate () After running above python code, the resultant Terminal Output will look something as following on Windows machine: { \"ffmpeg_binary_path\" : \"C:\\\\Users\\\\foo\\\\AppData\\\\Local\\\\Temp\\\\ffmpeg-static-win64-gpl/bin/ffmpeg.exe\" , \"source\" : \"foo.mp4\" , \"source_extension\" : \".mp4\" , \"source_video_resolution\" : [ 1280 , 720 ], \"source_video_framerate\" : 25.0 , \"source_video_pixfmt\" : \"yuv420p\" , \"source_video_decoder\" : \"h264\" , \"source_duration_sec\" : 5.31 , \"approx_video_nframes\" : 133 , \"source_video_bitrate\" : \"1205k\" , \"source_audio_bitrate\" : \"384k\" , \"source_audio_samplerate\" : \"48000 Hz\" , \"source_has_video\" : true , \"source_has_audio\" : true , \"source_has_image_sequence\" : false , \"ffdecoder_operational_mode\" : \"Video-Only\" , \"output_frames_pixfmt\" : \"rgb24\" }","title":"Extracting video metadata using FFdecoder API"},{"location":"recipes/basic/save-keyframe-image/","text":"Saving Key-frames as Image \u00b6 DeFFcode's FFdecoder API provide effortless and precise Frame Seeking with -ss FFmpeg parameter that enable us to save any frame from a specific part of our input source. We'll discuss aboout it briefly in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for saving video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python Pillow: Pillow is a Imaging Library required for saving frame as Image. You can easily install it directly via pip : pip install Pillow Matplotlib: Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations, also required for saving frame as Image. You can easily install it directly via pip : pip install matplotlib Imageio: Imageio is a Library for reading and writing a wide range of image, video, scientific, and volumetric data formats, also required for saving frame as Image. You can easily install it directly via pip : pip install imageio Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error. \u2009 Extracting Key-frames as PNG image \u00b6 In this example we will seek to 00:00:01.45 (or 1045msec) in time and decode one single frame in FFdecoder API, and thereby saving it as PNG image using few prominent Image processing python libraries by providing valid filename (e.g. foo_image.png ) . Time unit syntax in -ss FFmpeg parameter You can use two different time unit formats with -ss FFmpeg parameter: Sexagesimal(in seconds): Uses (HOURS:MM:SS.MILLISECONDS) format, such as in 01:23:45.678 . Fractional: such as in 02:30.05 . This is interpreted as 2 minutes, 30 and a half a second , which would be the same as using 150.5 in seconds. Using Pillow Using OpenCV Using Matplotlib Using Imageio In Pillow, the fromarray() function can be used to create an image memory from an RGB frame: # import the necessary packages from deffcode import FFdecoder from PIL import Image # define the FFmpeg parameter to seek to 00:00:01.45(or 1s and 45msec) # in time and get one single frame ffparams = { \"-ss\" : \"00:00:01.45\" , \"-frames:v\" : 1 } # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"foo.mp4\" , ** ffparams ) . formulate () # grab the RGB24(default) frame from the decoder frame = next ( decoder . generateFrame (), None ) # check if frame is None if not ( frame is None ): # Convert to Image im = Image . fromarray ( frame ) # Save Image as PNG im . save ( \"foo_image.png\" ) else : raise ValueError ( \"Something is wrong!\" ) # terminate the decoder decoder . terminate () In OpenCV, the imwrite() function can export BGR frame as an image file: # import the necessary packages from deffcode import FFdecoder import cv2 # define the FFmpeg parameter to seek to 00:00:01.45(or 1s and 45msec) # in time and get one single frame ffparams = { \"-ss\" : \"00:00:01.45\" , \"-frames:v\" : 1 } # initialize and formulate the decoder for BGR24 outputwith suitable source decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , ** ffparams ) . formulate () # grab the BGR24 frame from the decoder frame = next ( decoder . generateFrame (), None ) # check if frame is None if not ( frame is None ): # Save our image as PNG cv2 . imwrite ( 'foo_image.png' , frame ) else : raise ValueError ( \"Something is wrong!\" ) # terminate the decoder decoder . terminate () In Matplotlib, the imsave() function can save an RGB frame as an image file: # import the necessary packages from deffcode import FFdecoder import matplotlib.pyplot as plt # define the FFmpeg parameter to seek to 00:00:01.45(or 1s and 45msec) # in time and get one single frame ffparams = { \"-ss\" : \"00:00:01.45\" , \"-frames:v\" : 1 } # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"foo.mp4\" , ** ffparams ) . formulate () # grab the RGB24(default) frame from the decoder frame = next ( decoder . generateFrame (), None ) # check if frame is None if not ( frame is None ): # Save our image as PNG plt . imsave ( 'foo_image.png' , frame ) else : raise ValueError ( \"Something is wrong!\" ) # terminate the decoder decoder . terminate () In Imageio, the imwrite() function can be used to create an image memory from an RGB frame: # import the necessary packages from deffcode import FFdecoder import imageio # define the FFmpeg parameter to seek to 00:00:01.45(or 1s and 45msec) # in time and get one single frame ffparams = { \"-ss\" : \"00:00:01.45\" , \"-frames:v\" : 1 } # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"foo.mp4\" , ** ffparams ) . formulate () # grab the RGB24(default) frame from the decoder frame = next ( decoder . generateFrame (), None ) # check if frame is None if not ( frame is None ): # Save our output imageio . imwrite ( 'foo_image.jpeg' , frame ) else : raise ValueError ( \"Something is wrong!\" ) # terminate the decoder decoder . terminate () Generating Thumbnail with a Fancy filter \u00b6 fancy_thumbnail.jpg (Courtesy - BigBuckBunny ) In this example we first apply FFmpeg\u2019s tblend filter with an hardmix blend mode (cool stuff) and then seek to 00:00:25.917 (or 25.917sec) in time to retrieve our single frame thumbnail, and thereby save it as JPEG image with valid filename (e.g. fancy_thumbnail.jpg ) using Pillow library. Time unit syntax in -ss FFmpeg parameter You can use two different time unit formats with -ss FFmpeg parameter: - [x] Sexagesimal(in seconds): Uses (HOURS:MM:SS.MILLISECONDS) , such as in 01:23:45.678 - [x] Fractional: such as in 02:30.05 , this is interpreted as 2 minutes, 30 seconds, and a half a second, which would be the same as using 150.5 in seconds. Available blend mode options Other blend mode options for tblend filter include: addition , addition128 , grainmerge , and , average , burn , darken , difference , difference128 , grainextract , divide , dodge , freeze , exclusion , extremity , glow , hardlight , hardmix , heat , lighten , linearlight , multiply , multiply128 , negation , normal , or , overlay , phoenix , pinlight , reflect , screen , softlight , subtract , vividlight , xor # import the necessary packages from deffcode import FFdecoder from PIL import Image # define the FFmpeg parameter to ffparams = { \"-vf\" : \"tblend=all_mode='hardmix'\" , # trim and reverse \"-ss\" : \"00:00:25.917\" , # seek to 00:00:25.917(or 25s 917msec) \"-frames:v\" : 1 , # get one single frame } # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"BigBuckBunny.mp4\" , ** ffparams ) . formulate () # grab the RGB24(default) frame from the decoder frame = next ( decoder . generateFrame (), None ) # check if frame is None if not ( frame is None ): # Convert to Image im = Image . fromarray ( frame ) # Save Image as JPEG im . save ( \"fancy_thumbnail.jpg\" ) else : raise ValueError ( \"Something is wrong!\" ) # terminate the decoder decoder . terminate ()","title":"Saving Key-frames as Image"},{"location":"recipes/basic/save-keyframe-image/#saving-key-frames-as-image","text":"DeFFcode's FFdecoder API provide effortless and precise Frame Seeking with -ss FFmpeg parameter that enable us to save any frame from a specific part of our input source. We'll discuss aboout it briefly in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for saving video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python Pillow: Pillow is a Imaging Library required for saving frame as Image. You can easily install it directly via pip : pip install Pillow Matplotlib: Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations, also required for saving frame as Image. You can easily install it directly via pip : pip install matplotlib Imageio: Imageio is a Library for reading and writing a wide range of image, video, scientific, and volumetric data formats, also required for saving frame as Image. You can easily install it directly via pip : pip install imageio Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error.","title":" Saving Key-frames as Image"},{"location":"recipes/basic/save-keyframe-image/#extracting-key-frames-as-png-image","text":"In this example we will seek to 00:00:01.45 (or 1045msec) in time and decode one single frame in FFdecoder API, and thereby saving it as PNG image using few prominent Image processing python libraries by providing valid filename (e.g. foo_image.png ) . Time unit syntax in -ss FFmpeg parameter You can use two different time unit formats with -ss FFmpeg parameter: Sexagesimal(in seconds): Uses (HOURS:MM:SS.MILLISECONDS) format, such as in 01:23:45.678 . Fractional: such as in 02:30.05 . This is interpreted as 2 minutes, 30 and a half a second , which would be the same as using 150.5 in seconds. Using Pillow Using OpenCV Using Matplotlib Using Imageio In Pillow, the fromarray() function can be used to create an image memory from an RGB frame: # import the necessary packages from deffcode import FFdecoder from PIL import Image # define the FFmpeg parameter to seek to 00:00:01.45(or 1s and 45msec) # in time and get one single frame ffparams = { \"-ss\" : \"00:00:01.45\" , \"-frames:v\" : 1 } # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"foo.mp4\" , ** ffparams ) . formulate () # grab the RGB24(default) frame from the decoder frame = next ( decoder . generateFrame (), None ) # check if frame is None if not ( frame is None ): # Convert to Image im = Image . fromarray ( frame ) # Save Image as PNG im . save ( \"foo_image.png\" ) else : raise ValueError ( \"Something is wrong!\" ) # terminate the decoder decoder . terminate () In OpenCV, the imwrite() function can export BGR frame as an image file: # import the necessary packages from deffcode import FFdecoder import cv2 # define the FFmpeg parameter to seek to 00:00:01.45(or 1s and 45msec) # in time and get one single frame ffparams = { \"-ss\" : \"00:00:01.45\" , \"-frames:v\" : 1 } # initialize and formulate the decoder for BGR24 outputwith suitable source decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , ** ffparams ) . formulate () # grab the BGR24 frame from the decoder frame = next ( decoder . generateFrame (), None ) # check if frame is None if not ( frame is None ): # Save our image as PNG cv2 . imwrite ( 'foo_image.png' , frame ) else : raise ValueError ( \"Something is wrong!\" ) # terminate the decoder decoder . terminate () In Matplotlib, the imsave() function can save an RGB frame as an image file: # import the necessary packages from deffcode import FFdecoder import matplotlib.pyplot as plt # define the FFmpeg parameter to seek to 00:00:01.45(or 1s and 45msec) # in time and get one single frame ffparams = { \"-ss\" : \"00:00:01.45\" , \"-frames:v\" : 1 } # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"foo.mp4\" , ** ffparams ) . formulate () # grab the RGB24(default) frame from the decoder frame = next ( decoder . generateFrame (), None ) # check if frame is None if not ( frame is None ): # Save our image as PNG plt . imsave ( 'foo_image.png' , frame ) else : raise ValueError ( \"Something is wrong!\" ) # terminate the decoder decoder . terminate () In Imageio, the imwrite() function can be used to create an image memory from an RGB frame: # import the necessary packages from deffcode import FFdecoder import imageio # define the FFmpeg parameter to seek to 00:00:01.45(or 1s and 45msec) # in time and get one single frame ffparams = { \"-ss\" : \"00:00:01.45\" , \"-frames:v\" : 1 } # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"foo.mp4\" , ** ffparams ) . formulate () # grab the RGB24(default) frame from the decoder frame = next ( decoder . generateFrame (), None ) # check if frame is None if not ( frame is None ): # Save our output imageio . imwrite ( 'foo_image.jpeg' , frame ) else : raise ValueError ( \"Something is wrong!\" ) # terminate the decoder decoder . terminate ()","title":"Extracting Key-frames as PNG image"},{"location":"recipes/basic/save-keyframe-image/#generating-thumbnail-with-a-fancy-filter","text":"fancy_thumbnail.jpg (Courtesy - BigBuckBunny ) In this example we first apply FFmpeg\u2019s tblend filter with an hardmix blend mode (cool stuff) and then seek to 00:00:25.917 (or 25.917sec) in time to retrieve our single frame thumbnail, and thereby save it as JPEG image with valid filename (e.g. fancy_thumbnail.jpg ) using Pillow library. Time unit syntax in -ss FFmpeg parameter You can use two different time unit formats with -ss FFmpeg parameter: - [x] Sexagesimal(in seconds): Uses (HOURS:MM:SS.MILLISECONDS) , such as in 01:23:45.678 - [x] Fractional: such as in 02:30.05 , this is interpreted as 2 minutes, 30 seconds, and a half a second, which would be the same as using 150.5 in seconds. Available blend mode options Other blend mode options for tblend filter include: addition , addition128 , grainmerge , and , average , burn , darken , difference , difference128 , grainextract , divide , dodge , freeze , exclusion , extremity , glow , hardlight , hardmix , heat , lighten , linearlight , multiply , multiply128 , negation , normal , or , overlay , phoenix , pinlight , reflect , screen , softlight , subtract , vividlight , xor # import the necessary packages from deffcode import FFdecoder from PIL import Image # define the FFmpeg parameter to ffparams = { \"-vf\" : \"tblend=all_mode='hardmix'\" , # trim and reverse \"-ss\" : \"00:00:25.917\" , # seek to 00:00:25.917(or 25s 917msec) \"-frames:v\" : 1 , # get one single frame } # initialize and formulate the decoder with suitable source decoder = FFdecoder ( \"BigBuckBunny.mp4\" , ** ffparams ) . formulate () # grab the RGB24(default) frame from the decoder frame = next ( decoder . generateFrame (), None ) # check if frame is None if not ( frame is None ): # Convert to Image im = Image . fromarray ( frame ) # Save Image as JPEG im . save ( \"fancy_thumbnail.jpg\" ) else : raise ValueError ( \"Something is wrong!\" ) # terminate the decoder decoder . terminate ()","title":"Generating Thumbnail with a Fancy filter"},{"location":"recipes/basic/transcode-live-frames-simplegraphs/","text":"Transcoding Live Simple Filtergraphs \u00b6 What are Simple filtergraphs? Before heading straight into recipes we will talk about Simple filtergraphs: Simple filtergraphs are those filters that have exactly one input and output, both of the same type. They can be processed by simply inserting an additional step between decoding and encoding of video frames: Simple filtergraphs are configured with the per-stream -filter option (with -vf for video) . DeFFcode's FFdecoder API handles a single chain of filtergraphs (through -vf FFmpeg parameter) to the to real-time frames quite effortlessly. We'll discuss the transcoding of live simple filtergraphs in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing and encoding video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. OpenCV's' VideoWriter() class lacks the ability to control output quality, bitrate, compression, and other important features which are only available with VidGear's WriteGear API. \u2009 Transcoding Trimmed and Reversed video \u00b6 Big Buck Bunny Reversed In this example we will take the first 5 seconds of a video clip (using trim filter) and reverse it (by applying reverse filter) , and encode them using OpenCV Library's VideoWriter() method in real-time. The reverse filter requires memory to buffer the entire clip, so applying trim filter first is strongly recommended. Otherwise you might probably run Out of Memory. OpenCV's VideoWriter() class requires a valid Output filename (e.g. output_foo.avi) , FourCC code, framerate, and resolution as input. You can use FFdecoder's metadata property object that dumps source Video's metadata information (as JSON string) to retrieve output framerate and resolution. By default, OpenCV expects BGR format frames in its cv2.write() method. # import the necessary packages from deffcode import FFdecoder import json , cv2 # define the Video Filter definition # trim 5 sec from end and reverse ffparams = { \"-vf\" : \"trim=end=5,reverse\" } # initialize and formulate the decoder for BGR24 output with given params decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve JSON Metadata and convert it to dict metadata_dict = json . loads ( decoder . metadata ) # prepare OpenCV parameters FOURCC = cv2 . VideoWriter_fourcc ( \"M\" , \"J\" , \"P\" , \"G\" ) FRAMERATE = metadata_dict [ \"output_framerate\" ] FRAMESIZE = tuple ( metadata_dict [ \"output_frames_resolution\" ]) # Define writer with parameters and suitable output filename for e.g. `output_foo.avi` writer = cv2 . VideoWriter ( \"output_foo.avi\" , FOURCC , FRAMERATE , FRAMESIZE ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . release () Transcoding Cropped video \u00b6 Big Buck Bunny Cropped In this example we will crop real-time video frames by an area with size \u2154 of the input video (say foo.mp4 ) by applying crop filter in FFdecoder API, all while encoding them using OpenCV Library's VideoWriter() method in real-time. OpenCV's VideoWriter() class requires a valid Output filename (e.g. output_foo.avi) , FourCC code, framerate, and resolution as input. You can use FFdecoder's metadata property object that dumps source Video's metadata information (as JSON string) to retrieve output framerate and resolution. More complex examples using crop filter can be found here \u27b6 and can be applied similarly. # import the necessary packages from deffcode import FFdecoder import json , cv2 # define the Video Filter definition # cropped the central input area with size 2/3 of the input video ffparams = { \"-vf\" : \"crop=2/3*in_w:2/3*in_h\" } # initialize and formulate the decoder for BGR24 output with given params decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve JSON Metadata and convert it to dict metadata_dict = json . loads ( decoder . metadata ) # prepare OpenCV parameters FOURCC = cv2 . VideoWriter_fourcc ( \"M\" , \"J\" , \"P\" , \"G\" ) FRAMERATE = metadata_dict [ \"output_framerate\" ] FRAMESIZE = tuple ( metadata_dict [ \"output_frames_resolution\" ]) # Define writer with parameters and suitable output filename for e.g. `output_foo.avi` writer = cv2 . VideoWriter ( \"output_foo.avi\" , FOURCC , FRAMERATE , FRAMESIZE ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . release () Transcoding Rotated video (with rotate filter) \u00b6 FFmpeg features Rotate Filter that is used to rotate videos by an arbitrary angle (expressed in radians). Big Buck Bunny Rotated (with rotate filter) In this example we will rotate real-time video frames at an arbitrary angle by applying rotate filter in FFdecoder API and also using green color to fill the output area not covered by the rotated image, all while encoding them using OpenCV Library's VideoWriter() method in real-time. OpenCV's VideoWriter() class requires a valid Output filename (e.g. output_foo.avi) , FourCC code, framerate, and resolution as input. You can use FFdecoder's metadata property object that dumps source Video's metadata information (as JSON string) to retrieve output framerate and resolution. # import the necessary packages from deffcode import FFdecoder import json , cv2 # define the Video Filter definition # rotate by 0.35 rad and fill green ffparams = { \"-vf\" : \"rotate=angle=-20*PI/180:fillcolor=green\" } # initialize and formulate the decoder for BGR24 output with given params decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve JSON Metadata and convert it to dict metadata_dict = json . loads ( decoder . metadata ) # prepare OpenCV parameters FOURCC = cv2 . VideoWriter_fourcc ( \"M\" , \"J\" , \"P\" , \"G\" ) FRAMERATE = metadata_dict [ \"output_framerate\" ] FRAMESIZE = tuple ( metadata_dict [ \"output_frames_resolution\" ]) # Define writer with parameters and suitable output filename for e.g. `output_foo.avi` writer = cv2 . VideoWriter ( \"output_foo.avi\" , FOURCC , FRAMERATE , FRAMESIZE ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . release () Transcoding Rotated video (with transpose filter) \u00b6 FFmpeg also features Transpose Filter that is used to rotate videos by 90 degrees clockwise and counter-clockwise direction as well as flip them vertically and horizontally. Big Buck Bunny Rotated (with transpose filter) In this example we will rotate real-time video frames by 90 degrees counterclockwise and preserve portrait geometry by applying transpose filter in FFdecoder API, all while encoding them using OpenCV Library's VideoWriter() method in real-time. OpenCV's VideoWriter() class requires a valid Output filename (e.g. output_foo.avi) , FourCC code, framerate, and resolution as input. You can use FFdecoder's metadata property object that dumps source Video's metadata information (as JSON string) to retrieve output framerate and resolution. # import the necessary packages from deffcode import FFdecoder import json , cv2 # define the Video Filter definition # rotate by 90 degrees counter-clockwise and preserve portrait layout ffparams = { \"-vf\" : \"transpose=dir=2:passthrough=portrait\" } # initialize and formulate the decoder for BGR24 output with given params decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve JSON Metadata and convert it to dict metadata_dict = json . loads ( decoder . metadata ) # prepare OpenCV parameters FOURCC = cv2 . VideoWriter_fourcc ( \"M\" , \"J\" , \"P\" , \"G\" ) FRAMERATE = metadata_dict [ \"output_framerate\" ] FRAMESIZE = tuple ( metadata_dict [ \"output_frames_resolution\" ]) # Define writer with parameters and suitable output filename for e.g. `output_foo.avi` writer = cv2 . VideoWriter ( \"output_foo.avi\" , FOURCC , FRAMERATE , FRAMESIZE ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . release () Transcoding Horizontally flipped and Scaled video \u00b6 Big Buck Bunny Horizontally flipped and Scaled In this example we will horizontally flip and scale real-time video frames to half its original size by applying hflip and scale filter one-by-one in FFdecoder API, all while encoding them using OpenCV Library's VideoWriter() method in real-time. OpenCV's VideoWriter() class requires a valid Output filename (e.g. output_foo.avi) , FourCC code, framerate, and resolution as input. You can use FFdecoder's metadata property object that dumps source Video's metadata information (as JSON string) to retrieve output framerate and resolution. More complex examples using scale filter can be found here \u27b6 and can be applied similarly. # import the necessary packages from deffcode import FFdecoder import json , cv2 # define the Video Filter definition # horizontally flip and scale to half its original size ffparams = { \"-vf\" : \"hflip,scale=w=iw/2:h=ih/2\" } # initialize and formulate the decoder for BGR24 output with given params decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve JSON Metadata and convert it to dict metadata_dict = json . loads ( decoder . metadata ) # prepare OpenCV parameters FOURCC = cv2 . VideoWriter_fourcc ( \"M\" , \"J\" , \"P\" , \"G\" ) FRAMERATE = metadata_dict [ \"output_framerate\" ] FRAMESIZE = tuple ( metadata_dict [ \"output_frames_resolution\" ]) # Define writer with parameters and suitable output filename for e.g. `output_foo.avi` writer = cv2 . VideoWriter ( \"output_foo.avi\" , FOURCC , FRAMERATE , FRAMESIZE ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . release ()","title":"Transcoding Live Simple Filtergraphs"},{"location":"recipes/basic/transcode-live-frames-simplegraphs/#transcoding-live-simple-filtergraphs","text":"What are Simple filtergraphs? Before heading straight into recipes we will talk about Simple filtergraphs: Simple filtergraphs are those filters that have exactly one input and output, both of the same type. They can be processed by simply inserting an additional step between decoding and encoding of video frames: Simple filtergraphs are configured with the per-stream -filter option (with -vf for video) . DeFFcode's FFdecoder API handles a single chain of filtergraphs (through -vf FFmpeg parameter) to the to real-time frames quite effortlessly. We'll discuss the transcoding of live simple filtergraphs in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing and encoding video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. OpenCV's' VideoWriter() class lacks the ability to control output quality, bitrate, compression, and other important features which are only available with VidGear's WriteGear API.","title":" Transcoding Live Simple Filtergraphs"},{"location":"recipes/basic/transcode-live-frames-simplegraphs/#transcoding-trimmed-and-reversed-video","text":"Big Buck Bunny Reversed In this example we will take the first 5 seconds of a video clip (using trim filter) and reverse it (by applying reverse filter) , and encode them using OpenCV Library's VideoWriter() method in real-time. The reverse filter requires memory to buffer the entire clip, so applying trim filter first is strongly recommended. Otherwise you might probably run Out of Memory. OpenCV's VideoWriter() class requires a valid Output filename (e.g. output_foo.avi) , FourCC code, framerate, and resolution as input. You can use FFdecoder's metadata property object that dumps source Video's metadata information (as JSON string) to retrieve output framerate and resolution. By default, OpenCV expects BGR format frames in its cv2.write() method. # import the necessary packages from deffcode import FFdecoder import json , cv2 # define the Video Filter definition # trim 5 sec from end and reverse ffparams = { \"-vf\" : \"trim=end=5,reverse\" } # initialize and formulate the decoder for BGR24 output with given params decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve JSON Metadata and convert it to dict metadata_dict = json . loads ( decoder . metadata ) # prepare OpenCV parameters FOURCC = cv2 . VideoWriter_fourcc ( \"M\" , \"J\" , \"P\" , \"G\" ) FRAMERATE = metadata_dict [ \"output_framerate\" ] FRAMESIZE = tuple ( metadata_dict [ \"output_frames_resolution\" ]) # Define writer with parameters and suitable output filename for e.g. `output_foo.avi` writer = cv2 . VideoWriter ( \"output_foo.avi\" , FOURCC , FRAMERATE , FRAMESIZE ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . release ()","title":"Transcoding Trimmed and Reversed video"},{"location":"recipes/basic/transcode-live-frames-simplegraphs/#transcoding-cropped-video","text":"Big Buck Bunny Cropped In this example we will crop real-time video frames by an area with size \u2154 of the input video (say foo.mp4 ) by applying crop filter in FFdecoder API, all while encoding them using OpenCV Library's VideoWriter() method in real-time. OpenCV's VideoWriter() class requires a valid Output filename (e.g. output_foo.avi) , FourCC code, framerate, and resolution as input. You can use FFdecoder's metadata property object that dumps source Video's metadata information (as JSON string) to retrieve output framerate and resolution. More complex examples using crop filter can be found here \u27b6 and can be applied similarly. # import the necessary packages from deffcode import FFdecoder import json , cv2 # define the Video Filter definition # cropped the central input area with size 2/3 of the input video ffparams = { \"-vf\" : \"crop=2/3*in_w:2/3*in_h\" } # initialize and formulate the decoder for BGR24 output with given params decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve JSON Metadata and convert it to dict metadata_dict = json . loads ( decoder . metadata ) # prepare OpenCV parameters FOURCC = cv2 . VideoWriter_fourcc ( \"M\" , \"J\" , \"P\" , \"G\" ) FRAMERATE = metadata_dict [ \"output_framerate\" ] FRAMESIZE = tuple ( metadata_dict [ \"output_frames_resolution\" ]) # Define writer with parameters and suitable output filename for e.g. `output_foo.avi` writer = cv2 . VideoWriter ( \"output_foo.avi\" , FOURCC , FRAMERATE , FRAMESIZE ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . release ()","title":"Transcoding Cropped video"},{"location":"recipes/basic/transcode-live-frames-simplegraphs/#transcoding-rotated-video-with-rotate-filter","text":"FFmpeg features Rotate Filter that is used to rotate videos by an arbitrary angle (expressed in radians). Big Buck Bunny Rotated (with rotate filter) In this example we will rotate real-time video frames at an arbitrary angle by applying rotate filter in FFdecoder API and also using green color to fill the output area not covered by the rotated image, all while encoding them using OpenCV Library's VideoWriter() method in real-time. OpenCV's VideoWriter() class requires a valid Output filename (e.g. output_foo.avi) , FourCC code, framerate, and resolution as input. You can use FFdecoder's metadata property object that dumps source Video's metadata information (as JSON string) to retrieve output framerate and resolution. # import the necessary packages from deffcode import FFdecoder import json , cv2 # define the Video Filter definition # rotate by 0.35 rad and fill green ffparams = { \"-vf\" : \"rotate=angle=-20*PI/180:fillcolor=green\" } # initialize and formulate the decoder for BGR24 output with given params decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve JSON Metadata and convert it to dict metadata_dict = json . loads ( decoder . metadata ) # prepare OpenCV parameters FOURCC = cv2 . VideoWriter_fourcc ( \"M\" , \"J\" , \"P\" , \"G\" ) FRAMERATE = metadata_dict [ \"output_framerate\" ] FRAMESIZE = tuple ( metadata_dict [ \"output_frames_resolution\" ]) # Define writer with parameters and suitable output filename for e.g. `output_foo.avi` writer = cv2 . VideoWriter ( \"output_foo.avi\" , FOURCC , FRAMERATE , FRAMESIZE ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . release ()","title":"Transcoding Rotated video (with rotate filter)"},{"location":"recipes/basic/transcode-live-frames-simplegraphs/#transcoding-rotated-video-with-transpose-filter","text":"FFmpeg also features Transpose Filter that is used to rotate videos by 90 degrees clockwise and counter-clockwise direction as well as flip them vertically and horizontally. Big Buck Bunny Rotated (with transpose filter) In this example we will rotate real-time video frames by 90 degrees counterclockwise and preserve portrait geometry by applying transpose filter in FFdecoder API, all while encoding them using OpenCV Library's VideoWriter() method in real-time. OpenCV's VideoWriter() class requires a valid Output filename (e.g. output_foo.avi) , FourCC code, framerate, and resolution as input. You can use FFdecoder's metadata property object that dumps source Video's metadata information (as JSON string) to retrieve output framerate and resolution. # import the necessary packages from deffcode import FFdecoder import json , cv2 # define the Video Filter definition # rotate by 90 degrees counter-clockwise and preserve portrait layout ffparams = { \"-vf\" : \"transpose=dir=2:passthrough=portrait\" } # initialize and formulate the decoder for BGR24 output with given params decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve JSON Metadata and convert it to dict metadata_dict = json . loads ( decoder . metadata ) # prepare OpenCV parameters FOURCC = cv2 . VideoWriter_fourcc ( \"M\" , \"J\" , \"P\" , \"G\" ) FRAMERATE = metadata_dict [ \"output_framerate\" ] FRAMESIZE = tuple ( metadata_dict [ \"output_frames_resolution\" ]) # Define writer with parameters and suitable output filename for e.g. `output_foo.avi` writer = cv2 . VideoWriter ( \"output_foo.avi\" , FOURCC , FRAMERATE , FRAMESIZE ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . release ()","title":"Transcoding Rotated video (with transpose filter)"},{"location":"recipes/basic/transcode-live-frames-simplegraphs/#transcoding-horizontally-flipped-and-scaled-video","text":"Big Buck Bunny Horizontally flipped and Scaled In this example we will horizontally flip and scale real-time video frames to half its original size by applying hflip and scale filter one-by-one in FFdecoder API, all while encoding them using OpenCV Library's VideoWriter() method in real-time. OpenCV's VideoWriter() class requires a valid Output filename (e.g. output_foo.avi) , FourCC code, framerate, and resolution as input. You can use FFdecoder's metadata property object that dumps source Video's metadata information (as JSON string) to retrieve output framerate and resolution. More complex examples using scale filter can be found here \u27b6 and can be applied similarly. # import the necessary packages from deffcode import FFdecoder import json , cv2 # define the Video Filter definition # horizontally flip and scale to half its original size ffparams = { \"-vf\" : \"hflip,scale=w=iw/2:h=ih/2\" } # initialize and formulate the decoder for BGR24 output with given params decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () # retrieve JSON Metadata and convert it to dict metadata_dict = json . loads ( decoder . metadata ) # prepare OpenCV parameters FOURCC = cv2 . VideoWriter_fourcc ( \"M\" , \"J\" , \"P\" , \"G\" ) FRAMERATE = metadata_dict [ \"output_framerate\" ] FRAMESIZE = tuple ( metadata_dict [ \"output_frames_resolution\" ]) # Define writer with parameters and suitable output filename for e.g. `output_foo.avi` writer = cv2 . VideoWriter ( \"output_foo.avi\" , FOURCC , FRAMERATE , FRAMESIZE ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . release ()","title":"Transcoding Horizontally flipped and Scaled video"},{"location":"recipes/basic/transcode-live-frames/","text":"Transcoding Live frames \u00b6 What exactly is Transcoding? Before heading directly into recipes we have to talk about Transcoding: Transcoding is the technique of transforming one media encoding format into another. This is typically done for compatibility purposes, such as when a media source provides a format that the intended target is not able to process; an in-between adaptation step is required: Decode media from its originally encoded state into raw, uncompressed information. Encode the raw data back, using a different codec that is supported by end user. While decoding media into video frames is purely managed by DeFFcode's FFdecoder API, you can easily encode those video frames back into multimedia files using any well-known video processing library such as OpenCV and VidGear. We'll discuss transcoding using both these libraries briefly in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing and encoding video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python VidGear: VidGear is required for lossless encoding of video frames into file/stream. You can easily install it directly via pip : pip install vidgear [ core ] Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error. \u2009 Transcoding video using OpenCV VideoWriter API \u00b6 OpenCV's' VideoWriter() class can be used directly with DeFFcode's FFdecoder API to encode video frames into a multimedia video file but it lacks the ability to control output quality, bitrate, compression, and other important features which are only available with VidGear's WriteGear API. In this example we will decode different pixel formats video frames from a given Video file (say foo.mp4 ) in FFdecoder API, and encode them using OpenCV Library's VideoWriter() method in real-time. OpenCV's VideoWriter() class requires a valid Output filename (e.g. output_foo.avi) , FourCC code, framerate, and resolution as input. You can use FFdecoder's metadata property object that dumps source Video's metadata information (as JSON string) to retrieve output framerate and resolution. By default, OpenCV expects BGR format frames in its cv2.write() method. The YUV pixel-format frames are NOT yet supported by OpenCV VideoWriter, try using WriteGear API instead. BGR frames RGB frames GRAYSCALE frames # import the necessary packages from deffcode import FFdecoder import json , cv2 # initialize and formulate the decoder for BGR24 pixel format output decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" ) . formulate () # retrieve JSON Metadata and convert it to dict metadata_dict = json . loads ( decoder . metadata ) # prepare OpenCV parameters FOURCC = cv2 . VideoWriter_fourcc ( \"M\" , \"J\" , \"P\" , \"G\" ) FRAMERATE = metadata_dict [ \"output_framerate\" ] FRAMESIZE = tuple ( metadata_dict [ \"output_frames_resolution\" ]) # Define writer with parameters and suitable output filename for e.g. `output_foo.avi` writer = cv2 . VideoWriter ( \"output_foo.avi\" , FOURCC , FRAMERATE , FRAMESIZE ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # let's also show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () # safely close writer writer . release () Since OpenCV expects BGR format frames in its cv2.write() method, therefore we need to convert RGB frames into BGR before encoding. # import the necessary packages from deffcode import FFdecoder import json , cv2 # initialize and formulate the decoder for RGB24 pixel format output decoder = FFdecoder ( \"foo.mp4\" ) . formulate () # retrieve JSON Metadata and convert it to dict metadata_dict = json . loads ( decoder . metadata ) # prepare OpenCV parameters FOURCC = cv2 . VideoWriter_fourcc ( \"M\" , \"J\" , \"P\" , \"G\" ) FRAMERATE = metadata_dict [ \"output_framerate\" ] FRAMESIZE = tuple ( metadata_dict [ \"output_frames_resolution\" ]) # Define writer with parameters and suitable output filename for e.g. `output_foo.avi` writer = cv2 . VideoWriter ( \"output_foo.avi\" , FOURCC , FRAMERATE , FRAMESIZE ) # grab the RGB24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # converting RGB24 to BGR24 frame frame_bgr = cv2 . cvtColor ( frame , cv2 . COLOR_RGB2BGR ) # writing BGR24 frame to writer writer . write ( frame_bgr ) # terminate the decoder decoder . terminate () # safely close writer writer . release () OpenCV directly consumes GRAYSCALE format frames in its cv2.write() method. # import the necessary packages from deffcode import FFdecoder import json , cv2 # initialize and formulate the decoder for GRAYSCALE output decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"gray\" , verbose = True ) . formulate () # retrieve JSON Metadata and convert it to dict metadata_dict = json . loads ( decoder . metadata ) # prepare OpenCV parameters FOURCC = cv2 . VideoWriter_fourcc ( \"M\" , \"J\" , \"P\" , \"G\" ) FRAMERATE = metadata_dict [ \"output_framerate\" ] FRAMESIZE = tuple ( metadata_dict [ \"output_frames_resolution\" ]) # Define writer with parameters and suitable output filename for e.g. `output_foo_gray.avi` writer = cv2 . VideoWriter ( \"output_foo_gray.avi\" , FOURCC , FRAMERATE , FRAMESIZE ) # grab the GRAYSCALE frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing GRAYSCALE frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . release () Transcoding lossless video using WriteGear API \u00b6 WriteGear's Compression Mode support for FFdecoder API is currently in beta so you can expect much higher than usual CPU utilization! Lossless transcoding with FFdecoder and WriteGear API VidGear's WriteGear API implements a complete, flexible, and robust wrapper around FFmpeg in compression mode for encoding real-time video frames to a lossless compressed multimedia output file(s)/stream(s). DeFFcode's FFdecoder API in conjunction with WriteGear API creates a high-level High-performance Lossless FFmpeg Transcoding (Decoding + Encoding) Pipeline that is able to exploit almost any FFmpeg parameter for achieving anything imaginable with multimedia video data all while allow us to manipulate the real-time video frames with immense flexibility. In this example we will decode different pixel formats video frames from a given Video file (say foo.mp4 ) in FFdecoder API, and encode them into lossless video file with controlled framerate using WriteGear API in real-time. Additional Parameters in WriteGear API WriteGear API only requires a valid Output filename (e.g. output_foo.mp4 ) as input, but you can easily control any output specifications (such as bitrate, codec, framerate, resolution, subtitles, etc.) supported by FFmpeg (in use) . You can use FFdecoder's metadata property object that dumps source Video's metadata information (as JSON string) to retrieve source framerate. WriteGear API by default expects BGR format frames in its write() class method. BGR frames RGB frames GRAYSCALE frames YUV frames # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import json # initialize and formulate the decoder for BGR24 output decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True ) . formulate () # retrieve framerate from source JSON Metadata and pass it as `-input_framerate` # parameter for controlled framerate output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"source_video_framerate\" ] } # Define writer with default parameters and suitable # output filename for e.g. `output_foo.mp4` writer = WriteGear ( output_filename = \"output_foo.mp4\" , ** output_params ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close () You can use rgb_mode parameter in write() class method to write RGB format frames instead of default BGR . # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import json # initialize and formulate the decoder decoder = FFdecoder ( \"foo.mp4\" , verbose = True ) . formulate () # retrieve framerate from source JSON Metadata and pass it as `-input_framerate` # parameter for controlled framerate output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"source_video_framerate\" ] } # Define writer with default parameters and suitable # output filename for e.g. `output_foo.mp4` writer = WriteGear ( output_filename = \"output_foo.mp4\" , ** output_params ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing RGB24 frame to writer writer . write ( frame , rgb_mode = True ) # terminate the decoder decoder . terminate () # safely close writer writer . close () !!! info \"WriteGear API directly consumes GRAYSCALE format frames in its write() class method. # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import json # initialize and formulate the decoder for GRAYSCALE output decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"gray\" , verbose = True ) . formulate () # retrieve framerate from source JSON Metadata and pass it as `-input_framerate` parameter # for controlled output framerate output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"source_video_framerate\" ] } # Define writer with default parameters and suitable # output filename for e.g. `output_foo_gray.mp4` writer = WriteGear ( output_filename = \"output_foo_gray.mp4\" , ** output_params ) # grab the GRAYSCALE frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing GRAYSCALE frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close () WriteGear API can easily consumes YUV format frames in its write() class method only in compression mode. You can also use yuv422p (4:2:2 subsampling) or yuv444p (4:4:4 subsampling) instead for more higher dynamic ranges. In WriteGear API, the support for -input_pixfmt attribute in output_params dictionary parameter was added in v0.3.0 . # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import json # initialize and formulate the decoder for YUV420 output decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"yuv420p\" ) . formulate () # retrieve framerate from source JSON Metadata and pass it as # `-input_framerate` parameter for controlled framerate # and add input pixfmt as yuv420p also output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"output_framerate\" ], \"-input_pixfmt\" : \"yuv420p\" } # Define writer with default parameters and suitable # output filename for e.g. `output_foo_yuv.mp4` writer = WriteGear ( output_filename = \"output_foo_yuv.mp4\" , logging = True , ** output_params ) # grab the YUV420 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing YUV420 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close ()","title":"Transcoding Live frames"},{"location":"recipes/basic/transcode-live-frames/#transcoding-live-frames","text":"What exactly is Transcoding? Before heading directly into recipes we have to talk about Transcoding: Transcoding is the technique of transforming one media encoding format into another. This is typically done for compatibility purposes, such as when a media source provides a format that the intended target is not able to process; an in-between adaptation step is required: Decode media from its originally encoded state into raw, uncompressed information. Encode the raw data back, using a different codec that is supported by end user. While decoding media into video frames is purely managed by DeFFcode's FFdecoder API, you can easily encode those video frames back into multimedia files using any well-known video processing library such as OpenCV and VidGear. We'll discuss transcoding using both these libraries briefly in the following recipes: \u2009 DeFFcode APIs requires FFmpeg executable DeFFcode APIs MUST requires valid FFmpeg executable for all of its core functionality , and any failure in detection will raise RuntimeError immediately. Follow dedicated FFmpeg Installation doc \u27b6 for its installation. Additional Python Dependencies for following recipes Following recipes requires additional python dependencies which can be installed easily as below: OpenCV: OpenCV is required for previewing and encoding video frames. You can easily install it directly via pip : OpenCV installation from source You can also follow online tutorials for building & installing OpenCV on Windows , Linux , MacOS and Raspberry Pi machines manually from its source. Make sure not to install both pip and source version together. Otherwise installation will fail to work! Other OpenCV binaries OpenCV mainainers also provide additional binaries via pip that contains both main modules and contrib/extra modules opencv-contrib-python , and for server (headless) environments like opencv-python-headless and opencv-contrib-python-headless . You can also install any one of them in similar manner. More information can be found here . pip install opencv-python VidGear: VidGear is required for lossless encoding of video frames into file/stream. You can easily install it directly via pip : pip install vidgear [ core ] Always use FFdecoder API's terminate() method at the end to avoid undesired behavior. Never name your python script deffcode.py When trying out these recipes, never name your python script deffcode.py otherwise it will result in ModuleNotFound error.","title":" Transcoding Live frames"},{"location":"recipes/basic/transcode-live-frames/#transcoding-video-using-opencv-videowriter-api","text":"OpenCV's' VideoWriter() class can be used directly with DeFFcode's FFdecoder API to encode video frames into a multimedia video file but it lacks the ability to control output quality, bitrate, compression, and other important features which are only available with VidGear's WriteGear API. In this example we will decode different pixel formats video frames from a given Video file (say foo.mp4 ) in FFdecoder API, and encode them using OpenCV Library's VideoWriter() method in real-time. OpenCV's VideoWriter() class requires a valid Output filename (e.g. output_foo.avi) , FourCC code, framerate, and resolution as input. You can use FFdecoder's metadata property object that dumps source Video's metadata information (as JSON string) to retrieve output framerate and resolution. By default, OpenCV expects BGR format frames in its cv2.write() method. The YUV pixel-format frames are NOT yet supported by OpenCV VideoWriter, try using WriteGear API instead. BGR frames RGB frames GRAYSCALE frames # import the necessary packages from deffcode import FFdecoder import json , cv2 # initialize and formulate the decoder for BGR24 pixel format output decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" ) . formulate () # retrieve JSON Metadata and convert it to dict metadata_dict = json . loads ( decoder . metadata ) # prepare OpenCV parameters FOURCC = cv2 . VideoWriter_fourcc ( \"M\" , \"J\" , \"P\" , \"G\" ) FRAMERATE = metadata_dict [ \"output_framerate\" ] FRAMESIZE = tuple ( metadata_dict [ \"output_frames_resolution\" ]) # Define writer with parameters and suitable output filename for e.g. `output_foo.avi` writer = cv2 . VideoWriter ( \"output_foo.avi\" , FOURCC , FRAMERATE , FRAMESIZE ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # let's also show output window cv2 . imshow ( \"Output\" , frame ) # check for 'q' key if pressed key = cv2 . waitKey ( 1 ) & 0xFF if key == ord ( \"q\" ): break # close output window cv2 . destroyAllWindows () # terminate the decoder decoder . terminate () # safely close writer writer . release () Since OpenCV expects BGR format frames in its cv2.write() method, therefore we need to convert RGB frames into BGR before encoding. # import the necessary packages from deffcode import FFdecoder import json , cv2 # initialize and formulate the decoder for RGB24 pixel format output decoder = FFdecoder ( \"foo.mp4\" ) . formulate () # retrieve JSON Metadata and convert it to dict metadata_dict = json . loads ( decoder . metadata ) # prepare OpenCV parameters FOURCC = cv2 . VideoWriter_fourcc ( \"M\" , \"J\" , \"P\" , \"G\" ) FRAMERATE = metadata_dict [ \"output_framerate\" ] FRAMESIZE = tuple ( metadata_dict [ \"output_frames_resolution\" ]) # Define writer with parameters and suitable output filename for e.g. `output_foo.avi` writer = cv2 . VideoWriter ( \"output_foo.avi\" , FOURCC , FRAMERATE , FRAMESIZE ) # grab the RGB24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # converting RGB24 to BGR24 frame frame_bgr = cv2 . cvtColor ( frame , cv2 . COLOR_RGB2BGR ) # writing BGR24 frame to writer writer . write ( frame_bgr ) # terminate the decoder decoder . terminate () # safely close writer writer . release () OpenCV directly consumes GRAYSCALE format frames in its cv2.write() method. # import the necessary packages from deffcode import FFdecoder import json , cv2 # initialize and formulate the decoder for GRAYSCALE output decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"gray\" , verbose = True ) . formulate () # retrieve JSON Metadata and convert it to dict metadata_dict = json . loads ( decoder . metadata ) # prepare OpenCV parameters FOURCC = cv2 . VideoWriter_fourcc ( \"M\" , \"J\" , \"P\" , \"G\" ) FRAMERATE = metadata_dict [ \"output_framerate\" ] FRAMESIZE = tuple ( metadata_dict [ \"output_frames_resolution\" ]) # Define writer with parameters and suitable output filename for e.g. `output_foo_gray.avi` writer = cv2 . VideoWriter ( \"output_foo_gray.avi\" , FOURCC , FRAMERATE , FRAMESIZE ) # grab the GRAYSCALE frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing GRAYSCALE frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . release ()","title":"Transcoding video using OpenCV VideoWriter API"},{"location":"recipes/basic/transcode-live-frames/#transcoding-lossless-video-using-writegear-api","text":"WriteGear's Compression Mode support for FFdecoder API is currently in beta so you can expect much higher than usual CPU utilization! Lossless transcoding with FFdecoder and WriteGear API VidGear's WriteGear API implements a complete, flexible, and robust wrapper around FFmpeg in compression mode for encoding real-time video frames to a lossless compressed multimedia output file(s)/stream(s). DeFFcode's FFdecoder API in conjunction with WriteGear API creates a high-level High-performance Lossless FFmpeg Transcoding (Decoding + Encoding) Pipeline that is able to exploit almost any FFmpeg parameter for achieving anything imaginable with multimedia video data all while allow us to manipulate the real-time video frames with immense flexibility. In this example we will decode different pixel formats video frames from a given Video file (say foo.mp4 ) in FFdecoder API, and encode them into lossless video file with controlled framerate using WriteGear API in real-time. Additional Parameters in WriteGear API WriteGear API only requires a valid Output filename (e.g. output_foo.mp4 ) as input, but you can easily control any output specifications (such as bitrate, codec, framerate, resolution, subtitles, etc.) supported by FFmpeg (in use) . You can use FFdecoder's metadata property object that dumps source Video's metadata information (as JSON string) to retrieve source framerate. WriteGear API by default expects BGR format frames in its write() class method. BGR frames RGB frames GRAYSCALE frames YUV frames # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import json # initialize and formulate the decoder for BGR24 output decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"bgr24\" , verbose = True ) . formulate () # retrieve framerate from source JSON Metadata and pass it as `-input_framerate` # parameter for controlled framerate output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"source_video_framerate\" ] } # Define writer with default parameters and suitable # output filename for e.g. `output_foo.mp4` writer = WriteGear ( output_filename = \"output_foo.mp4\" , ** output_params ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing BGR24 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close () You can use rgb_mode parameter in write() class method to write RGB format frames instead of default BGR . # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import json # initialize and formulate the decoder decoder = FFdecoder ( \"foo.mp4\" , verbose = True ) . formulate () # retrieve framerate from source JSON Metadata and pass it as `-input_framerate` # parameter for controlled framerate output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"source_video_framerate\" ] } # Define writer with default parameters and suitable # output filename for e.g. `output_foo.mp4` writer = WriteGear ( output_filename = \"output_foo.mp4\" , ** output_params ) # grab the BGR24 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing RGB24 frame to writer writer . write ( frame , rgb_mode = True ) # terminate the decoder decoder . terminate () # safely close writer writer . close () !!! info \"WriteGear API directly consumes GRAYSCALE format frames in its write() class method. # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import json # initialize and formulate the decoder for GRAYSCALE output decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"gray\" , verbose = True ) . formulate () # retrieve framerate from source JSON Metadata and pass it as `-input_framerate` parameter # for controlled output framerate output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"source_video_framerate\" ] } # Define writer with default parameters and suitable # output filename for e.g. `output_foo_gray.mp4` writer = WriteGear ( output_filename = \"output_foo_gray.mp4\" , ** output_params ) # grab the GRAYSCALE frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing GRAYSCALE frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close () WriteGear API can easily consumes YUV format frames in its write() class method only in compression mode. You can also use yuv422p (4:2:2 subsampling) or yuv444p (4:4:4 subsampling) instead for more higher dynamic ranges. In WriteGear API, the support for -input_pixfmt attribute in output_params dictionary parameter was added in v0.3.0 . # import the necessary packages from deffcode import FFdecoder from vidgear.gears import WriteGear import json # initialize and formulate the decoder for YUV420 output decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"yuv420p\" ) . formulate () # retrieve framerate from source JSON Metadata and pass it as # `-input_framerate` parameter for controlled framerate # and add input pixfmt as yuv420p also output_params = { \"-input_framerate\" : json . loads ( decoder . metadata )[ \"output_framerate\" ], \"-input_pixfmt\" : \"yuv420p\" } # Define writer with default parameters and suitable # output filename for e.g. `output_foo_yuv.mp4` writer = WriteGear ( output_filename = \"output_foo_yuv.mp4\" , logging = True , ** output_params ) # grab the YUV420 frame from the decoder for frame in decoder . generateFrame (): # check if frame is None if frame is None : break # {do something with the frame here} # writing YUV420 frame to writer writer . write ( frame ) # terminate the decoder decoder . terminate () # safely close writer writer . close ()","title":"Transcoding lossless video using WriteGear API"},{"location":"reference/ffhelper/","text":"Following methods are exclusively design to handle FFmpeg related tasks. These tasks includes validation of installed FFmpeg binaries, downloading of FFmpeg binaries(on Windows), and parsing of FFmpeg metadata into useful information using various pattern matching methods. For usage examples, kindly refer our Basic Recipes and Advanced Recipes get_valid_ffmpeg_path \u00b6 Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: Name Type Description Default custom_ffmpeg string path to custom FFmpeg executables '' is_windows boolean is running on Windows OS? False ffmpeg_download_path string FFmpeg static binaries download location (Windows only) '' verbose bool enables verbose for its operations False Returns: A valid FFmpeg executable path string. Source code in deffcode/ffhelper.py def get_valid_ffmpeg_path ( custom_ffmpeg = \"\" , is_windows = False , ffmpeg_download_path = \"\" , verbose = False ): \"\"\" ## get_valid_ffmpeg_path Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: custom_ffmpeg (string): path to custom FFmpeg executables is_windows (boolean): is running on Windows OS? ffmpeg_download_path (string): FFmpeg static binaries download location _(Windows only)_ verbose (bool): enables verbose for its operations **Returns:** A valid FFmpeg executable path string. \"\"\" final_path = \"\" if is_windows : # checks if current os is windows if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable final_path += custom_ffmpeg else : # otherwise auto-download them try : if not ( ffmpeg_download_path ): # otherwise save to Temp Directory import tempfile ffmpeg_download_path = tempfile . gettempdir () verbose and logger . debug ( \"FFmpeg Windows Download Path: {} \" . format ( ffmpeg_download_path ) ) # download Binaries os_bit = ( ( \"win64\" if platform . machine () . endswith ( \"64\" ) else \"win32\" ) if is_windows else \"\" ) _path = download_ffmpeg_binaries ( path = ffmpeg_download_path , os_windows = is_windows , os_bit = os_bit ) # assign to local variable final_path += _path except Exception as e : # log if any error occurred logger . exception ( str ( e )) logger . error ( \"Error in downloading FFmpeg binaries, Check your network and Try again!\" ) return False if os . path . isfile ( final_path ): # check if valid FFmpeg file exist pass elif os . path . isfile ( os . path . join ( final_path , \"ffmpeg.exe\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( final_path , \"ffmpeg.exe\" ) else : # else return False verbose and logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise perform test for Unix if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable if os . path . isfile ( custom_ffmpeg ): # check if valid FFmpeg file exist final_path += custom_ffmpeg elif os . path . isfile ( os . path . join ( custom_ffmpeg , \"ffmpeg\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( custom_ffmpeg , \"ffmpeg\" ) else : # else return False verbose and logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise assign ffmpeg binaries from system final_path += \"ffmpeg\" verbose and logger . debug ( \"Final FFmpeg Path: {} \" . format ( final_path )) # Final Auto-Validation for FFmeg Binaries. returns final path if test is passed return final_path if validate_ffmpeg ( final_path , verbose = verbose ) else False get_valid_ffmpeg_path \u00b6 Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: Name Type Description Default custom_ffmpeg string path to custom FFmpeg executables '' is_windows boolean is running on Windows OS? False ffmpeg_download_path string FFmpeg static binaries download location (Windows only) '' verbose bool enables verbose for its operations False Returns: A valid FFmpeg executable path string. Source code in deffcode/ffhelper.py def get_valid_ffmpeg_path ( custom_ffmpeg = \"\" , is_windows = False , ffmpeg_download_path = \"\" , verbose = False ): \"\"\" ## get_valid_ffmpeg_path Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: custom_ffmpeg (string): path to custom FFmpeg executables is_windows (boolean): is running on Windows OS? ffmpeg_download_path (string): FFmpeg static binaries download location _(Windows only)_ verbose (bool): enables verbose for its operations **Returns:** A valid FFmpeg executable path string. \"\"\" final_path = \"\" if is_windows : # checks if current os is windows if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable final_path += custom_ffmpeg else : # otherwise auto-download them try : if not ( ffmpeg_download_path ): # otherwise save to Temp Directory import tempfile ffmpeg_download_path = tempfile . gettempdir () verbose and logger . debug ( \"FFmpeg Windows Download Path: {} \" . format ( ffmpeg_download_path ) ) # download Binaries os_bit = ( ( \"win64\" if platform . machine () . endswith ( \"64\" ) else \"win32\" ) if is_windows else \"\" ) _path = download_ffmpeg_binaries ( path = ffmpeg_download_path , os_windows = is_windows , os_bit = os_bit ) # assign to local variable final_path += _path except Exception as e : # log if any error occurred logger . exception ( str ( e )) logger . error ( \"Error in downloading FFmpeg binaries, Check your network and Try again!\" ) return False if os . path . isfile ( final_path ): # check if valid FFmpeg file exist pass elif os . path . isfile ( os . path . join ( final_path , \"ffmpeg.exe\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( final_path , \"ffmpeg.exe\" ) else : # else return False verbose and logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise perform test for Unix if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable if os . path . isfile ( custom_ffmpeg ): # check if valid FFmpeg file exist final_path += custom_ffmpeg elif os . path . isfile ( os . path . join ( custom_ffmpeg , \"ffmpeg\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( custom_ffmpeg , \"ffmpeg\" ) else : # else return False verbose and logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise assign ffmpeg binaries from system final_path += \"ffmpeg\" verbose and logger . debug ( \"Final FFmpeg Path: {} \" . format ( final_path )) # Final Auto-Validation for FFmeg Binaries. returns final path if test is passed return final_path if validate_ffmpeg ( final_path , verbose = verbose ) else False download_ffmpeg_binaries \u00b6 Generates FFmpeg Static Binaries for windows(if not available) Parameters: Name Type Description Default path string path for downloading custom FFmpeg executables required os_windows boolean is running on Windows OS? False os_bit string 32-bit or 64-bit OS? '' Returns: A valid FFmpeg executable path string. Source code in deffcode/ffhelper.py def download_ffmpeg_binaries ( path , os_windows = False , os_bit = \"\" ): \"\"\" ## download_ffmpeg_binaries Generates FFmpeg Static Binaries for windows(if not available) Parameters: path (string): path for downloading custom FFmpeg executables os_windows (boolean): is running on Windows OS? os_bit (string): 32-bit or 64-bit OS? **Returns:** A valid FFmpeg executable path string. \"\"\" final_path = \"\" if os_windows and os_bit : # initialize with available FFmpeg Static Binaries GitHub Server file_url = \"https://github.com/abhiTronix/FFmpeg-Builds/releases/latest/download/ffmpeg-static- {} -gpl.zip\" . format ( os_bit ) file_name = os . path . join ( os . path . abspath ( path ), \"ffmpeg-static- {} -gpl.zip\" . format ( os_bit ) ) file_path = os . path . join ( os . path . abspath ( path ), \"ffmpeg-static- {} -gpl/bin/ffmpeg.exe\" . format ( os_bit ), ) base_path , _ = os . path . split ( file_name ) # extract file base path # check if file already exists if os . path . isfile ( file_path ): final_path += file_path # skip download if does else : # import libs import zipfile # check if given path has write access assert os . access ( path , os . W_OK ), ( \"[Helper:ERROR] :: Permission Denied, Cannot write binaries to directory = \" + path ) # remove leftovers if exists os . path . isfile ( file_name ) and delete_file_safe ( file_name ) # download and write file to the given path with open ( file_name , \"wb\" ) as f : logger . debug ( \"No Custom FFmpeg path provided. Auto-Installing FFmpeg static binaries from GitHub Mirror now. Please wait...\" ) # create session with requests . Session () as http : # setup retry strategy retries = Retry ( total = 3 , backoff_factor = 1 , status_forcelist = [ 429 , 500 , 502 , 503 , 504 ], ) # Mount it for https usage adapter = TimeoutHTTPAdapter ( timeout = 2.0 , max_retries = retries ) http . mount ( \"https://\" , adapter ) response = http . get ( file_url , stream = True ) response . raise_for_status () total_length = response . headers . get ( \"content-length\" ) assert not ( total_length is None ), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\" bar = tqdm ( total = int ( total_length ), unit = \"B\" , unit_scale = True ) for data in response . iter_content ( chunk_size = 4096 ): f . write ( data ) len ( data ) > 0 and bar . update ( len ( data )) bar . close () logger . debug ( \"Extracting executables.\" ) with zipfile . ZipFile ( file_name , \"r\" ) as zip_ref : zip_fname , _ = os . path . split ( zip_ref . infolist ()[ 0 ] . filename ) zip_ref . extractall ( base_path ) # perform cleaning delete_file_safe ( file_name ) logger . debug ( \"FFmpeg binaries for Windows configured successfully!\" ) final_path += file_path # return final path return final_path validate_ffmpeg \u00b6 Validate FFmpeg Binaries. Returns True if validity test passes successfully. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required verbose bool enables verbose for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in deffcode/ffhelper.py def validate_ffmpeg ( path , verbose = False ): \"\"\" ## validate_ffmpeg Validate FFmpeg Binaries. Returns `True` if validity test passes successfully. Parameters: path (string): absolute path of FFmpeg binaries verbose (bool): enables verbose for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" try : # get the FFmpeg version version = check_sp_output ([ path , \"-version\" ]) firstline = version . split ( b \" \\n \" )[ 0 ] version = firstline . split ( b \" \" )[ 2 ] . strip () if verbose : # log if test are passed logger . debug ( \"FFmpeg validity Test Passed!\" ) logger . debug ( \"Found valid FFmpeg Version: ` {} ` installed on this system\" . format ( version ) ) except Exception as e : # log if test are failed if verbose : logger . exception ( str ( e )) logger . warning ( \"FFmpeg validity Test Failed!\" ) return False return True get_supported_pixfmts \u00b6 Find and returns all FFmpeg's supported pixel formats. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required Returns: List of supported pixel formats as (PIXEL FORMAT, NB_COMPONENTS, BITS_PER_PIXEL). Source code in deffcode/ffhelper.py def get_supported_pixfmts ( path ): \"\"\" ## get_supported_pixfmts Find and returns all FFmpeg's supported pixel formats. Parameters: path (string): absolute path of FFmpeg binaries **Returns:** List of supported pixel formats as (PIXEL FORMAT, NB_COMPONENTS, BITS_PER_PIXEL). \"\"\" pxfmts = check_sp_output ([ path , \"-hide_banner\" , \"-pix_fmts\" ]) splitted = pxfmts . split ( b \" \\n \" ) srtindex = [ i for i , s in enumerate ( splitted ) if b \"-----\" in s ] # extract video encoders supported_pxfmts = [ x . decode ( \"utf-8\" ) . strip () for x in splitted [ srtindex [ 0 ] + 1 :] if x . decode ( \"utf-8\" ) . strip () ] # compile regex finder = re . compile ( r \"([A-Z]*[\\.]+[A-Z]*\\s[a-z0-9_-]*)(\\s+[0-4])(\\s+[0-9]+)\" ) # find all outputs outputs = finder . findall ( \" \\n \" . join ( supported_pxfmts )) # return output findings return [ ([ s for s in o [ 0 ] . split ( \" \" )][ - 1 ], o [ 1 ] . strip (), o [ 2 ] . strip ()) for o in outputs if len ( o ) == 3 ] get_supported_vdecoders \u00b6 Find and returns all FFmpeg's supported video decoders. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required Returns: List of supported decoders. Source code in deffcode/ffhelper.py def get_supported_vdecoders ( path ): \"\"\" ## get_supported_vdecoders Find and returns all FFmpeg's supported video decoders. Parameters: path (string): absolute path of FFmpeg binaries **Returns:** List of supported decoders. \"\"\" decoders = check_sp_output ([ path , \"-hide_banner\" , \"-decoders\" ]) splitted = decoders . split ( b \" \\n \" ) # extract video encoders supported_vdecoders = [ x . decode ( \"utf-8\" ) . strip () for x in splitted [ 2 : len ( splitted ) - 1 ] if x . decode ( \"utf-8\" ) . strip () . startswith ( \"V\" ) ] # compile regex finder = re . compile ( r \"[A-Z]*[\\.]+[A-Z]*\\s[a-z0-9_-]*\" ) # find all outputs outputs = finder . findall ( \" \\n \" . join ( supported_vdecoders )) # return output findings return [[ s for s in o . split ( \" \" )][ - 1 ] for o in outputs ] get_supported_demuxers \u00b6 Find and returns all FFmpeg's supported demuxers. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required Returns: List of supported demuxers. Source code in deffcode/ffhelper.py def get_supported_demuxers ( path ): \"\"\" ## get_supported_demuxers Find and returns all FFmpeg's supported demuxers. Parameters: path (string): absolute path of FFmpeg binaries **Returns:** List of supported demuxers. \"\"\" demuxers = check_sp_output ([ path , \"-hide_banner\" , \"-demuxers\" ]) splitted = [ x . decode ( \"utf-8\" ) . strip () for x in demuxers . split ( b \" \\n \" )] supported_demuxers = splitted [ splitted . index ( \"--\" ) + 1 : len ( splitted ) - 1 ] # compile regex finder = re . compile ( r \"\\s\\s[a-z0-9_,-]+\\s+\" ) # find all outputs outputs = finder . findall ( \" \\n \" . join ( supported_demuxers )) # return output findings return [ o . strip () if not ( \",\" in o ) else o . split ( \",\" )[ - 1 ] . strip () for o in outputs ] validate_imgseqdir \u00b6 Validates Image Sequence by counting number of Image files. Parameters: Name Type Description Default source string video source to be validated required extension string extension of image sequence. 'jpg' Returns: A boolean value, confirming whether tests passed, or not?. Source code in deffcode/ffhelper.py def validate_imgseqdir ( source , extension = \"jpg\" , verbose = False ): \"\"\" ## validate_imgseqdir Validates Image Sequence by counting number of Image files. Parameters: source (string): video source to be validated extension (string): extension of image sequence. **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" # check if path exists dirpath = Path ( source ) . parent try : if not ( dirpath . exists () and dirpath . is_dir ()): verbose and logger . warning ( \"Specified path ` {} ` doesn't exists or valid.\" . format ( dirpath ) ) return False else : return ( True if len ( list ( dirpath . glob ( \"*. {} \" . format ( extension )))) > 2 else False ) except : return False is_valid_image_seq \u00b6 Checks Image sequence validity by testing its extension against FFmpeg's supported pipe formats and number of Image files. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required source string video source to be validated None verbose bool enables verbose for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in deffcode/ffhelper.py def is_valid_image_seq ( path , source = None , verbose = False ): \"\"\" ## is_valid_image_seq Checks Image sequence validity by testing its extension against FFmpeg's supported pipe formats and number of Image files. Parameters: path (string): absolute path of FFmpeg binaries source (string): video source to be validated verbose (bool): enables verbose for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" if source is None or not ( source ): logger . error ( \"Source is empty!\" ) return False # extract all FFmpeg supported protocols formats = check_sp_output ([ path , \"-hide_banner\" , \"-formats\" ]) extract_formats = re . findall ( r \"\\w+_pipe\" , formats . decode ( \"utf-8\" ) . strip ()) supported_image_formats = [ x . split ( \"_\" )[ 0 ] for x in extract_formats if x . endswith ( \"_pipe\" ) ] filename , extension = os . path . splitext ( source ) # Test and return result whether scheme is supported if extension and source . endswith ( tuple ( supported_image_formats )): if validate_imgseqdir ( source , extension = extension [ 1 :], verbose = verbose ): verbose and logger . debug ( \"A valid Image Sequence source of format ` {} ` found.\" . format ( extension ) ) return True else : ValueError ( \"Given Image Sequence source of format ` {} ` contains insignificant(invalid) sample size, Check the `source` parameter value again!\" . format ( source . split ( \".\" )[ 1 ] ) ) else : verbose and logger . warning ( \"Source isn't a valid Image Sequence\" ) return False is_valid_url \u00b6 Checks URL validity by testing its scheme against FFmpeg's supported protocols. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required url string URL to be validated None verbose bool enables verbose for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in deffcode/ffhelper.py def is_valid_url ( path , url = None , verbose = False ): \"\"\" ## is_valid_url Checks URL validity by testing its scheme against FFmpeg's supported protocols. Parameters: path (string): absolute path of FFmpeg binaries url (string): URL to be validated verbose (bool): enables verbose for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" if url is None or not ( url ): logger . warning ( \"URL is empty!\" ) return False # extract URL scheme extracted_scheme_url = url . split ( \"://\" , 1 )[ 0 ] # extract all FFmpeg supported protocols protocols = check_sp_output ([ path , \"-hide_banner\" , \"-protocols\" ]) splitted = [ x . decode ( \"utf-8\" ) . strip () for x in protocols . split ( b \" \\n \" )] supported_protocols = splitted [ splitted . index ( \"Output:\" ) + 1 : len ( splitted ) - 1 ] # rtsp is a demuxer somehow supported_protocols += [ \"rtsp\" ] if \"rtsp\" in get_supported_demuxers ( path ) else [] # Test and return result whether scheme is supported if extracted_scheme_url and extracted_scheme_url in supported_protocols : verbose and logger . debug ( \"URL scheme ` {} ` is supported by FFmpeg.\" . format ( extracted_scheme_url ) ) return True else : verbose and logger . warning ( \"URL scheme ` {} ` isn't supported by FFmpeg!\" . format ( extracted_scheme_url ) ) return False check_sp_output \u00b6 Returns FFmpeg stdout output from subprocess module. Parameters: Name Type Description Default args based on input Non Keyword Arguments () kwargs based on input Keyword Arguments {} Returns: A string value. Source code in deffcode/ffhelper.py def check_sp_output ( * args , ** kwargs ): \"\"\" ## check_sp_output Returns FFmpeg `stdout` output from subprocess module. Parameters: args (based on input): Non Keyword Arguments kwargs (based on input): Keyword Arguments **Returns:** A string value. \"\"\" # workaround for python bug: https://bugs.python.org/issue37380 if platform . system () == \"Windows\" : # see comment https://bugs.python.org/msg370334 sp . _cleanup = lambda : None # handle additional params retrieve_stderr = kwargs . pop ( \"force_retrieve_stderr\" , False ) # execute command in subprocess process = sp . Popen ( stdout = sp . PIPE , stderr = sp . DEVNULL if not ( retrieve_stderr ) else sp . PIPE , * args , ** kwargs , ) # communicate and poll process output , stderr = process . communicate () retcode = process . poll () # handle return code if retcode and not ( retrieve_stderr ): logger . error ( \"[Pipline-Error] :: {} \" . format ( output . decode ( \"utf-8\" ))) cmd = kwargs . get ( \"args\" ) if cmd is None : cmd = args [ 0 ] error = sp . CalledProcessError ( retcode , cmd ) error . output = output raise error # raise error if no output bool ( output ) or bool ( stderr ) or logger . error ( \"[Pipline-Error] :: Pipline failed to exact any data from command: {} !\" . format ( args [ 0 ] if args else [] ) ) # return output otherwise return stderr if retrieve_stderr and stderr else output","title":"deffcode.ffhelper"},{"location":"reference/ffhelper/#deffcode.ffhelper.get_valid_ffmpeg_path--get_valid_ffmpeg_path","text":"Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: Name Type Description Default custom_ffmpeg string path to custom FFmpeg executables '' is_windows boolean is running on Windows OS? False ffmpeg_download_path string FFmpeg static binaries download location (Windows only) '' verbose bool enables verbose for its operations False Returns: A valid FFmpeg executable path string. Source code in deffcode/ffhelper.py def get_valid_ffmpeg_path ( custom_ffmpeg = \"\" , is_windows = False , ffmpeg_download_path = \"\" , verbose = False ): \"\"\" ## get_valid_ffmpeg_path Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: custom_ffmpeg (string): path to custom FFmpeg executables is_windows (boolean): is running on Windows OS? ffmpeg_download_path (string): FFmpeg static binaries download location _(Windows only)_ verbose (bool): enables verbose for its operations **Returns:** A valid FFmpeg executable path string. \"\"\" final_path = \"\" if is_windows : # checks if current os is windows if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable final_path += custom_ffmpeg else : # otherwise auto-download them try : if not ( ffmpeg_download_path ): # otherwise save to Temp Directory import tempfile ffmpeg_download_path = tempfile . gettempdir () verbose and logger . debug ( \"FFmpeg Windows Download Path: {} \" . format ( ffmpeg_download_path ) ) # download Binaries os_bit = ( ( \"win64\" if platform . machine () . endswith ( \"64\" ) else \"win32\" ) if is_windows else \"\" ) _path = download_ffmpeg_binaries ( path = ffmpeg_download_path , os_windows = is_windows , os_bit = os_bit ) # assign to local variable final_path += _path except Exception as e : # log if any error occurred logger . exception ( str ( e )) logger . error ( \"Error in downloading FFmpeg binaries, Check your network and Try again!\" ) return False if os . path . isfile ( final_path ): # check if valid FFmpeg file exist pass elif os . path . isfile ( os . path . join ( final_path , \"ffmpeg.exe\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( final_path , \"ffmpeg.exe\" ) else : # else return False verbose and logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise perform test for Unix if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable if os . path . isfile ( custom_ffmpeg ): # check if valid FFmpeg file exist final_path += custom_ffmpeg elif os . path . isfile ( os . path . join ( custom_ffmpeg , \"ffmpeg\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( custom_ffmpeg , \"ffmpeg\" ) else : # else return False verbose and logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise assign ffmpeg binaries from system final_path += \"ffmpeg\" verbose and logger . debug ( \"Final FFmpeg Path: {} \" . format ( final_path )) # Final Auto-Validation for FFmeg Binaries. returns final path if test is passed return final_path if validate_ffmpeg ( final_path , verbose = verbose ) else False","title":"get_valid_ffmpeg_path"},{"location":"reference/ffhelper/#deffcode.ffhelper.get_valid_ffmpeg_path--get_valid_ffmpeg_path","text":"Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: Name Type Description Default custom_ffmpeg string path to custom FFmpeg executables '' is_windows boolean is running on Windows OS? False ffmpeg_download_path string FFmpeg static binaries download location (Windows only) '' verbose bool enables verbose for its operations False Returns: A valid FFmpeg executable path string. Source code in deffcode/ffhelper.py def get_valid_ffmpeg_path ( custom_ffmpeg = \"\" , is_windows = False , ffmpeg_download_path = \"\" , verbose = False ): \"\"\" ## get_valid_ffmpeg_path Validate the given FFmpeg path/binaries, and returns a valid FFmpeg executable path. Parameters: custom_ffmpeg (string): path to custom FFmpeg executables is_windows (boolean): is running on Windows OS? ffmpeg_download_path (string): FFmpeg static binaries download location _(Windows only)_ verbose (bool): enables verbose for its operations **Returns:** A valid FFmpeg executable path string. \"\"\" final_path = \"\" if is_windows : # checks if current os is windows if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable final_path += custom_ffmpeg else : # otherwise auto-download them try : if not ( ffmpeg_download_path ): # otherwise save to Temp Directory import tempfile ffmpeg_download_path = tempfile . gettempdir () verbose and logger . debug ( \"FFmpeg Windows Download Path: {} \" . format ( ffmpeg_download_path ) ) # download Binaries os_bit = ( ( \"win64\" if platform . machine () . endswith ( \"64\" ) else \"win32\" ) if is_windows else \"\" ) _path = download_ffmpeg_binaries ( path = ffmpeg_download_path , os_windows = is_windows , os_bit = os_bit ) # assign to local variable final_path += _path except Exception as e : # log if any error occurred logger . exception ( str ( e )) logger . error ( \"Error in downloading FFmpeg binaries, Check your network and Try again!\" ) return False if os . path . isfile ( final_path ): # check if valid FFmpeg file exist pass elif os . path . isfile ( os . path . join ( final_path , \"ffmpeg.exe\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( final_path , \"ffmpeg.exe\" ) else : # else return False verbose and logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise perform test for Unix if custom_ffmpeg : # if custom FFmpeg path is given assign to local variable if os . path . isfile ( custom_ffmpeg ): # check if valid FFmpeg file exist final_path += custom_ffmpeg elif os . path . isfile ( os . path . join ( custom_ffmpeg , \"ffmpeg\" )): # check if FFmpeg directory exists, if does, then check for valid file final_path = os . path . join ( custom_ffmpeg , \"ffmpeg\" ) else : # else return False verbose and logger . debug ( \"No valid FFmpeg executables found at Custom FFmpeg path!\" ) return False else : # otherwise assign ffmpeg binaries from system final_path += \"ffmpeg\" verbose and logger . debug ( \"Final FFmpeg Path: {} \" . format ( final_path )) # Final Auto-Validation for FFmeg Binaries. returns final path if test is passed return final_path if validate_ffmpeg ( final_path , verbose = verbose ) else False","title":"get_valid_ffmpeg_path"},{"location":"reference/ffhelper/#deffcode.ffhelper.download_ffmpeg_binaries--download_ffmpeg_binaries","text":"Generates FFmpeg Static Binaries for windows(if not available) Parameters: Name Type Description Default path string path for downloading custom FFmpeg executables required os_windows boolean is running on Windows OS? False os_bit string 32-bit or 64-bit OS? '' Returns: A valid FFmpeg executable path string. Source code in deffcode/ffhelper.py def download_ffmpeg_binaries ( path , os_windows = False , os_bit = \"\" ): \"\"\" ## download_ffmpeg_binaries Generates FFmpeg Static Binaries for windows(if not available) Parameters: path (string): path for downloading custom FFmpeg executables os_windows (boolean): is running on Windows OS? os_bit (string): 32-bit or 64-bit OS? **Returns:** A valid FFmpeg executable path string. \"\"\" final_path = \"\" if os_windows and os_bit : # initialize with available FFmpeg Static Binaries GitHub Server file_url = \"https://github.com/abhiTronix/FFmpeg-Builds/releases/latest/download/ffmpeg-static- {} -gpl.zip\" . format ( os_bit ) file_name = os . path . join ( os . path . abspath ( path ), \"ffmpeg-static- {} -gpl.zip\" . format ( os_bit ) ) file_path = os . path . join ( os . path . abspath ( path ), \"ffmpeg-static- {} -gpl/bin/ffmpeg.exe\" . format ( os_bit ), ) base_path , _ = os . path . split ( file_name ) # extract file base path # check if file already exists if os . path . isfile ( file_path ): final_path += file_path # skip download if does else : # import libs import zipfile # check if given path has write access assert os . access ( path , os . W_OK ), ( \"[Helper:ERROR] :: Permission Denied, Cannot write binaries to directory = \" + path ) # remove leftovers if exists os . path . isfile ( file_name ) and delete_file_safe ( file_name ) # download and write file to the given path with open ( file_name , \"wb\" ) as f : logger . debug ( \"No Custom FFmpeg path provided. Auto-Installing FFmpeg static binaries from GitHub Mirror now. Please wait...\" ) # create session with requests . Session () as http : # setup retry strategy retries = Retry ( total = 3 , backoff_factor = 1 , status_forcelist = [ 429 , 500 , 502 , 503 , 504 ], ) # Mount it for https usage adapter = TimeoutHTTPAdapter ( timeout = 2.0 , max_retries = retries ) http . mount ( \"https://\" , adapter ) response = http . get ( file_url , stream = True ) response . raise_for_status () total_length = response . headers . get ( \"content-length\" ) assert not ( total_length is None ), \"[Helper:ERROR] :: Failed to retrieve files, check your Internet connectivity!\" bar = tqdm ( total = int ( total_length ), unit = \"B\" , unit_scale = True ) for data in response . iter_content ( chunk_size = 4096 ): f . write ( data ) len ( data ) > 0 and bar . update ( len ( data )) bar . close () logger . debug ( \"Extracting executables.\" ) with zipfile . ZipFile ( file_name , \"r\" ) as zip_ref : zip_fname , _ = os . path . split ( zip_ref . infolist ()[ 0 ] . filename ) zip_ref . extractall ( base_path ) # perform cleaning delete_file_safe ( file_name ) logger . debug ( \"FFmpeg binaries for Windows configured successfully!\" ) final_path += file_path # return final path return final_path","title":"download_ffmpeg_binaries"},{"location":"reference/ffhelper/#deffcode.ffhelper.validate_ffmpeg--validate_ffmpeg","text":"Validate FFmpeg Binaries. Returns True if validity test passes successfully. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required verbose bool enables verbose for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in deffcode/ffhelper.py def validate_ffmpeg ( path , verbose = False ): \"\"\" ## validate_ffmpeg Validate FFmpeg Binaries. Returns `True` if validity test passes successfully. Parameters: path (string): absolute path of FFmpeg binaries verbose (bool): enables verbose for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" try : # get the FFmpeg version version = check_sp_output ([ path , \"-version\" ]) firstline = version . split ( b \" \\n \" )[ 0 ] version = firstline . split ( b \" \" )[ 2 ] . strip () if verbose : # log if test are passed logger . debug ( \"FFmpeg validity Test Passed!\" ) logger . debug ( \"Found valid FFmpeg Version: ` {} ` installed on this system\" . format ( version ) ) except Exception as e : # log if test are failed if verbose : logger . exception ( str ( e )) logger . warning ( \"FFmpeg validity Test Failed!\" ) return False return True","title":"validate_ffmpeg"},{"location":"reference/ffhelper/#deffcode.ffhelper.get_supported_pixfmts--get_supported_pixfmts","text":"Find and returns all FFmpeg's supported pixel formats. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required Returns: List of supported pixel formats as (PIXEL FORMAT, NB_COMPONENTS, BITS_PER_PIXEL). Source code in deffcode/ffhelper.py def get_supported_pixfmts ( path ): \"\"\" ## get_supported_pixfmts Find and returns all FFmpeg's supported pixel formats. Parameters: path (string): absolute path of FFmpeg binaries **Returns:** List of supported pixel formats as (PIXEL FORMAT, NB_COMPONENTS, BITS_PER_PIXEL). \"\"\" pxfmts = check_sp_output ([ path , \"-hide_banner\" , \"-pix_fmts\" ]) splitted = pxfmts . split ( b \" \\n \" ) srtindex = [ i for i , s in enumerate ( splitted ) if b \"-----\" in s ] # extract video encoders supported_pxfmts = [ x . decode ( \"utf-8\" ) . strip () for x in splitted [ srtindex [ 0 ] + 1 :] if x . decode ( \"utf-8\" ) . strip () ] # compile regex finder = re . compile ( r \"([A-Z]*[\\.]+[A-Z]*\\s[a-z0-9_-]*)(\\s+[0-4])(\\s+[0-9]+)\" ) # find all outputs outputs = finder . findall ( \" \\n \" . join ( supported_pxfmts )) # return output findings return [ ([ s for s in o [ 0 ] . split ( \" \" )][ - 1 ], o [ 1 ] . strip (), o [ 2 ] . strip ()) for o in outputs if len ( o ) == 3 ]","title":"get_supported_pixfmts"},{"location":"reference/ffhelper/#deffcode.ffhelper.get_supported_vdecoders--get_supported_vdecoders","text":"Find and returns all FFmpeg's supported video decoders. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required Returns: List of supported decoders. Source code in deffcode/ffhelper.py def get_supported_vdecoders ( path ): \"\"\" ## get_supported_vdecoders Find and returns all FFmpeg's supported video decoders. Parameters: path (string): absolute path of FFmpeg binaries **Returns:** List of supported decoders. \"\"\" decoders = check_sp_output ([ path , \"-hide_banner\" , \"-decoders\" ]) splitted = decoders . split ( b \" \\n \" ) # extract video encoders supported_vdecoders = [ x . decode ( \"utf-8\" ) . strip () for x in splitted [ 2 : len ( splitted ) - 1 ] if x . decode ( \"utf-8\" ) . strip () . startswith ( \"V\" ) ] # compile regex finder = re . compile ( r \"[A-Z]*[\\.]+[A-Z]*\\s[a-z0-9_-]*\" ) # find all outputs outputs = finder . findall ( \" \\n \" . join ( supported_vdecoders )) # return output findings return [[ s for s in o . split ( \" \" )][ - 1 ] for o in outputs ]","title":"get_supported_vdecoders"},{"location":"reference/ffhelper/#deffcode.ffhelper.get_supported_demuxers--get_supported_demuxers","text":"Find and returns all FFmpeg's supported demuxers. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required Returns: List of supported demuxers. Source code in deffcode/ffhelper.py def get_supported_demuxers ( path ): \"\"\" ## get_supported_demuxers Find and returns all FFmpeg's supported demuxers. Parameters: path (string): absolute path of FFmpeg binaries **Returns:** List of supported demuxers. \"\"\" demuxers = check_sp_output ([ path , \"-hide_banner\" , \"-demuxers\" ]) splitted = [ x . decode ( \"utf-8\" ) . strip () for x in demuxers . split ( b \" \\n \" )] supported_demuxers = splitted [ splitted . index ( \"--\" ) + 1 : len ( splitted ) - 1 ] # compile regex finder = re . compile ( r \"\\s\\s[a-z0-9_,-]+\\s+\" ) # find all outputs outputs = finder . findall ( \" \\n \" . join ( supported_demuxers )) # return output findings return [ o . strip () if not ( \",\" in o ) else o . split ( \",\" )[ - 1 ] . strip () for o in outputs ]","title":"get_supported_demuxers"},{"location":"reference/ffhelper/#deffcode.ffhelper.validate_imgseqdir--validate_imgseqdir","text":"Validates Image Sequence by counting number of Image files. Parameters: Name Type Description Default source string video source to be validated required extension string extension of image sequence. 'jpg' Returns: A boolean value, confirming whether tests passed, or not?. Source code in deffcode/ffhelper.py def validate_imgseqdir ( source , extension = \"jpg\" , verbose = False ): \"\"\" ## validate_imgseqdir Validates Image Sequence by counting number of Image files. Parameters: source (string): video source to be validated extension (string): extension of image sequence. **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" # check if path exists dirpath = Path ( source ) . parent try : if not ( dirpath . exists () and dirpath . is_dir ()): verbose and logger . warning ( \"Specified path ` {} ` doesn't exists or valid.\" . format ( dirpath ) ) return False else : return ( True if len ( list ( dirpath . glob ( \"*. {} \" . format ( extension )))) > 2 else False ) except : return False","title":"validate_imgseqdir"},{"location":"reference/ffhelper/#deffcode.ffhelper.is_valid_image_seq--is_valid_image_seq","text":"Checks Image sequence validity by testing its extension against FFmpeg's supported pipe formats and number of Image files. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required source string video source to be validated None verbose bool enables verbose for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in deffcode/ffhelper.py def is_valid_image_seq ( path , source = None , verbose = False ): \"\"\" ## is_valid_image_seq Checks Image sequence validity by testing its extension against FFmpeg's supported pipe formats and number of Image files. Parameters: path (string): absolute path of FFmpeg binaries source (string): video source to be validated verbose (bool): enables verbose for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" if source is None or not ( source ): logger . error ( \"Source is empty!\" ) return False # extract all FFmpeg supported protocols formats = check_sp_output ([ path , \"-hide_banner\" , \"-formats\" ]) extract_formats = re . findall ( r \"\\w+_pipe\" , formats . decode ( \"utf-8\" ) . strip ()) supported_image_formats = [ x . split ( \"_\" )[ 0 ] for x in extract_formats if x . endswith ( \"_pipe\" ) ] filename , extension = os . path . splitext ( source ) # Test and return result whether scheme is supported if extension and source . endswith ( tuple ( supported_image_formats )): if validate_imgseqdir ( source , extension = extension [ 1 :], verbose = verbose ): verbose and logger . debug ( \"A valid Image Sequence source of format ` {} ` found.\" . format ( extension ) ) return True else : ValueError ( \"Given Image Sequence source of format ` {} ` contains insignificant(invalid) sample size, Check the `source` parameter value again!\" . format ( source . split ( \".\" )[ 1 ] ) ) else : verbose and logger . warning ( \"Source isn't a valid Image Sequence\" ) return False","title":"is_valid_image_seq"},{"location":"reference/ffhelper/#deffcode.ffhelper.is_valid_url--is_valid_url","text":"Checks URL validity by testing its scheme against FFmpeg's supported protocols. Parameters: Name Type Description Default path string absolute path of FFmpeg binaries required url string URL to be validated None verbose bool enables verbose for its operations False Returns: A boolean value, confirming whether tests passed, or not?. Source code in deffcode/ffhelper.py def is_valid_url ( path , url = None , verbose = False ): \"\"\" ## is_valid_url Checks URL validity by testing its scheme against FFmpeg's supported protocols. Parameters: path (string): absolute path of FFmpeg binaries url (string): URL to be validated verbose (bool): enables verbose for its operations **Returns:** A boolean value, confirming whether tests passed, or not?. \"\"\" if url is None or not ( url ): logger . warning ( \"URL is empty!\" ) return False # extract URL scheme extracted_scheme_url = url . split ( \"://\" , 1 )[ 0 ] # extract all FFmpeg supported protocols protocols = check_sp_output ([ path , \"-hide_banner\" , \"-protocols\" ]) splitted = [ x . decode ( \"utf-8\" ) . strip () for x in protocols . split ( b \" \\n \" )] supported_protocols = splitted [ splitted . index ( \"Output:\" ) + 1 : len ( splitted ) - 1 ] # rtsp is a demuxer somehow supported_protocols += [ \"rtsp\" ] if \"rtsp\" in get_supported_demuxers ( path ) else [] # Test and return result whether scheme is supported if extracted_scheme_url and extracted_scheme_url in supported_protocols : verbose and logger . debug ( \"URL scheme ` {} ` is supported by FFmpeg.\" . format ( extracted_scheme_url ) ) return True else : verbose and logger . warning ( \"URL scheme ` {} ` isn't supported by FFmpeg!\" . format ( extracted_scheme_url ) ) return False","title":"is_valid_url"},{"location":"reference/ffhelper/#deffcode.ffhelper.check_sp_output--check_sp_output","text":"Returns FFmpeg stdout output from subprocess module. Parameters: Name Type Description Default args based on input Non Keyword Arguments () kwargs based on input Keyword Arguments {} Returns: A string value. Source code in deffcode/ffhelper.py def check_sp_output ( * args , ** kwargs ): \"\"\" ## check_sp_output Returns FFmpeg `stdout` output from subprocess module. Parameters: args (based on input): Non Keyword Arguments kwargs (based on input): Keyword Arguments **Returns:** A string value. \"\"\" # workaround for python bug: https://bugs.python.org/issue37380 if platform . system () == \"Windows\" : # see comment https://bugs.python.org/msg370334 sp . _cleanup = lambda : None # handle additional params retrieve_stderr = kwargs . pop ( \"force_retrieve_stderr\" , False ) # execute command in subprocess process = sp . Popen ( stdout = sp . PIPE , stderr = sp . DEVNULL if not ( retrieve_stderr ) else sp . PIPE , * args , ** kwargs , ) # communicate and poll process output , stderr = process . communicate () retcode = process . poll () # handle return code if retcode and not ( retrieve_stderr ): logger . error ( \"[Pipline-Error] :: {} \" . format ( output . decode ( \"utf-8\" ))) cmd = kwargs . get ( \"args\" ) if cmd is None : cmd = args [ 0 ] error = sp . CalledProcessError ( retcode , cmd ) error . output = output raise error # raise error if no output bool ( output ) or bool ( stderr ) or logger . error ( \"[Pipline-Error] :: Pipline failed to exact any data from command: {} !\" . format ( args [ 0 ] if args else [] ) ) # return output otherwise return stderr if retrieve_stderr and stderr else output","title":"check_sp_output"},{"location":"reference/utils/","text":"Following are the helper methods required by the DeFFcode APIs. For usage examples, kindly refer our Basic Recipes and Advanced Recipes logger_handler \u00b6 Returns the logger handler Returns: A logger handler Source code in deffcode/utils.py def logger_handler (): \"\"\" ## logger_handler Returns the logger handler **Returns:** A logger handler \"\"\" # logging formatter formatter = ColoredFormatter ( \" {green}{asctime}{reset} :: {bold_purple}{name:^13}{reset} :: {log_color}{levelname:^8}{reset} :: {bold_white}{message} \" , datefmt = \"%H:%M:%S\" , reset = True , log_colors = { \"INFO\" : \"bold_cyan\" , \"DEBUG\" : \"bold_yellow\" , \"WARNING\" : \"bold_red,fg_thin_yellow\" , \"ERROR\" : \"bold_red\" , \"CRITICAL\" : \"bold_red,bg_white\" , }, style = \"{\" , ) # check if FFdecoder_LOGFILE defined file_mode = os . environ . get ( \"DEFFCODE_LOGFILE\" , False ) # define handler handler = logging . StreamHandler () if file_mode and isinstance ( file_mode , str ): file_path = os . path . abspath ( file_mode ) if ( os . name == \"nt\" or os . access in os . supports_effective_ids ) and os . access ( os . path . dirname ( file_path ), os . W_OK ): file_path = ( os . path . join ( file_path , \"deffcode.log\" ) if os . path . isdir ( file_path ) else file_path ) handler = logging . FileHandler ( file_path , mode = \"a\" ) formatter = logging . Formatter ( \" {asctime} :: {name} :: {levelname} :: {message} \" , datefmt = \"%H:%M:%S\" , style = \"{\" , ) handler . setFormatter ( formatter ) return handler dict2Args \u00b6 Converts dictionary attributes to list(args) Parameters: Name Type Description Default param_dict dict Parameters dictionary required Returns: Arguments list Source code in deffcode/utils.py def dict2Args ( param_dict ): \"\"\" ## dict2Args Converts dictionary attributes to list(args) Parameters: param_dict (dict): Parameters dictionary **Returns:** Arguments list \"\"\" args = [] for key in param_dict . keys (): if key in [ \"-clones\" ] or key . startswith ( \"-core\" ): if isinstance ( param_dict [ key ], list ): args . extend ( param_dict [ key ]) else : logger . warning ( \" {} with invalid datatype:` {} `, Skipped!\" . format ( \"Core parameter\" if key . startswith ( \"-core\" ) else \"Clone\" , param_dict [ key ], ) ) else : args . append ( key ) args . append ( str ( param_dict [ key ])) return args delete_ext_safe \u00b6 Safely deletes files at given path. Parameters: Name Type Description Default file_path string path to the file required Source code in deffcode/utils.py def delete_file_safe ( file_path ): \"\"\" ## delete_ext_safe Safely deletes files at given path. Parameters: file_path (string): path to the file \"\"\" try : dfile = Path ( file_path ) if sys . version_info >= ( 3 , 8 , 0 ): dfile . unlink ( missing_ok = True ) else : dfile . exists () and dfile . unlink () except Exception as e : logger . exception ( str ( e ))","title":"deffcode.utils"},{"location":"reference/utils/#deffcode.utils.logger_handler--logger_handler","text":"Returns the logger handler Returns: A logger handler Source code in deffcode/utils.py def logger_handler (): \"\"\" ## logger_handler Returns the logger handler **Returns:** A logger handler \"\"\" # logging formatter formatter = ColoredFormatter ( \" {green}{asctime}{reset} :: {bold_purple}{name:^13}{reset} :: {log_color}{levelname:^8}{reset} :: {bold_white}{message} \" , datefmt = \"%H:%M:%S\" , reset = True , log_colors = { \"INFO\" : \"bold_cyan\" , \"DEBUG\" : \"bold_yellow\" , \"WARNING\" : \"bold_red,fg_thin_yellow\" , \"ERROR\" : \"bold_red\" , \"CRITICAL\" : \"bold_red,bg_white\" , }, style = \"{\" , ) # check if FFdecoder_LOGFILE defined file_mode = os . environ . get ( \"DEFFCODE_LOGFILE\" , False ) # define handler handler = logging . StreamHandler () if file_mode and isinstance ( file_mode , str ): file_path = os . path . abspath ( file_mode ) if ( os . name == \"nt\" or os . access in os . supports_effective_ids ) and os . access ( os . path . dirname ( file_path ), os . W_OK ): file_path = ( os . path . join ( file_path , \"deffcode.log\" ) if os . path . isdir ( file_path ) else file_path ) handler = logging . FileHandler ( file_path , mode = \"a\" ) formatter = logging . Formatter ( \" {asctime} :: {name} :: {levelname} :: {message} \" , datefmt = \"%H:%M:%S\" , style = \"{\" , ) handler . setFormatter ( formatter ) return handler","title":"logger_handler"},{"location":"reference/utils/#deffcode.utils.dict2Args--dict2args","text":"Converts dictionary attributes to list(args) Parameters: Name Type Description Default param_dict dict Parameters dictionary required Returns: Arguments list Source code in deffcode/utils.py def dict2Args ( param_dict ): \"\"\" ## dict2Args Converts dictionary attributes to list(args) Parameters: param_dict (dict): Parameters dictionary **Returns:** Arguments list \"\"\" args = [] for key in param_dict . keys (): if key in [ \"-clones\" ] or key . startswith ( \"-core\" ): if isinstance ( param_dict [ key ], list ): args . extend ( param_dict [ key ]) else : logger . warning ( \" {} with invalid datatype:` {} `, Skipped!\" . format ( \"Core parameter\" if key . startswith ( \"-core\" ) else \"Clone\" , param_dict [ key ], ) ) else : args . append ( key ) args . append ( str ( param_dict [ key ])) return args","title":"dict2Args"},{"location":"reference/utils/#deffcode.utils.delete_file_safe--delete_ext_safe","text":"Safely deletes files at given path. Parameters: Name Type Description Default file_path string path to the file required Source code in deffcode/utils.py def delete_file_safe ( file_path ): \"\"\" ## delete_ext_safe Safely deletes files at given path. Parameters: file_path (string): path to the file \"\"\" try : dfile = Path ( file_path ) if sys . version_info >= ( 3 , 8 , 0 ): dfile . unlink ( missing_ok = True ) else : dfile . exists () and dfile . unlink () except Exception as e : logger . exception ( str ( e ))","title":"delete_ext_safe"},{"location":"reference/ffdecoder/","text":"FFdecoder API \u00b6 FFdecoder API compiles and executes the FFmpeg pipeline inside a subprocess pipe for generating real-time, low-overhead, lightning fast video frames with robust error-handling in python \ud83c\udf9e\ufe0f\u26a1 FFdecoder API implements a standalone highly-extensible wrapper around FFmpeg multimedia framework that provides complete control over the underline pipeline including access to almost any FFmpeg specification thinkable such as framerate, resolution, hardware decoder(s), complex filter(s), and pixel format(s) that are readily supported by all well known Computer Vision libraries. FFdecoder API compiles its FFmpeg pipeline by processing input Video Source metadata and User-defined options, and runs it inside a subprocess pipe concurrently with the main thread, while extracting output dataframes(1D arrays) into a Numpy buffer. These dataframes are consecutively grabbed from the buffer and decoded into 24-bit RGB (default) ndarray 3D frames that are readily available through its generateFrame() method. FFdecoder API employs Sourcer API at its backend for gathering, processing, and validating metadata of all multimedia streams available in the given source for formulating/compiling its default FFmpeg pipeline. This metadata information is also available as a JSON string with its metadata property object and can be updated as desired. FFdecoder API supports a wide-ranging media stream as input source such as USB/Virtual/IP Camera Feed, Multimedia video file, Screen Capture, Image Sequence, Network protocols (such as HTTP(s), RTP/RSTP, etc.) , so on and so forth. Furthermore, FFdecoder API maintains the standard OpenCV-Python (Python API for OpenCV) coding syntax , thereby making it even easier to integrate this API in any Computer Vision application. For usage examples, kindly refer our Basic Recipes and Advanced Recipes FFdecoder API parameters are explained here \u27b6 Source code in deffcode/ffdecoder.py class FFdecoder : \"\"\" > FFdecoder API compiles and executes the FFmpeg pipeline inside a subprocess pipe for generating real-time, low-overhead, lightning fast video frames with robust error-handling in python \ud83c\udf9e\ufe0f\u26a1 FFdecoder API implements a **standalone highly-extensible wrapper around [FFmpeg](https://ffmpeg.org/)** multimedia framework that provides complete control over the underline pipeline including **access to almost any FFmpeg specification thinkable** such as framerate, resolution, hardware decoder(s), complex filter(s), and pixel format(s) that are readily supported by all well known Computer Vision libraries. FFdecoder API **compiles its FFmpeg pipeline** by processing input Video Source metadata and User-defined options, and **runs it inside a [`subprocess`](https://docs.python.org/3/library/subprocess.html) pipe** concurrently with the main thread, while extracting output dataframes(1D arrays) into a Numpy buffer. These dataframes are consecutively grabbed from the buffer and decoded into ==[24-bit RGB](https://en.wikipedia.org/wiki/List_of_monochrome_and_RGB_color_formats#24-bit_RGB) _(default)_ [`ndarray`](https://numpy.org/doc/stable/reference/arrays.ndarray.html#the-n-dimensional-array-ndarray) 3D frames== that are readily available through its [`generateFrame()`](#deffcode.ffdecoder.FFdecoder.generateFrame) method. FFdecoder API **employs [Sourcer API](../../reference/sourcer) at its backend** for gathering, processing, and validating metadata of all multimedia streams available in the given source for formulating/compiling its default FFmpeg pipeline. This metadata information is also available as a JSON string with its [`metadata`](#deffcode.ffdecoder.FFdecoder.metadata) property object and can be updated as desired. FFdecoder API **supports a wide-ranging media stream** as input source such as USB/Virtual/IP Camera Feed, Multimedia video file, Screen Capture, Image Sequence, Network protocols _(such as HTTP(s), RTP/RSTP, etc.)_, so on and so forth. Furthermore, FFdecoder API maintains the **standard [OpenCV-Python](https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html) _(Python API for OpenCV)_ coding syntax**, thereby making it even easier to integrate this API in any Computer Vision application. !!! example \"For usage examples, kindly refer our **[Basic Recipes :cake:](../../recipes/basic)** and **[Advanced Recipes :croissant:](../../recipes/advanced)**\" !!! info \"FFdecoder API parameters are explained [here \u27b6](params/)\" \"\"\" def __init__ ( self , source , source_demuxer = None , frame_format = None , custom_ffmpeg = \"\" , verbose = False , ** ffparams ): \"\"\" This constructor method initializes the object state and attributes of the FFdecoder Class. Parameters: source (str): defines the input(`-i`) source filename/URL/device-name/device-path. source_demuxer (str): specifies the demuxer(`-f`) for the input source. frame_format (str): sets pixel format(`-pix_fmt`) of the decoded frames. custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executable. verbose (bool): enables/disables verbose. ffparams (dict): provides the flexibility to control supported internal and FFmpeg parameters. \"\"\" # enable verbose if specified self . __verbose_logs = ( verbose if ( verbose and isinstance ( verbose , bool )) else False ) # define whether initializing self . __initializing = True # define frame pixel-format for decoded frames self . __frame_format = ( frame_format . lower () . strip () if isinstance ( frame_format , str ) else None ) # handles user-defined parameters self . __extra_params = {} # handle process to be frames written self . __process = None # handle exclusive metadata self . __ff_pixfmt_metadata = None # metadata self . __raw_frame_num = None # raw-frame number self . __raw_frame_pixfmt = None # raw-frame pixformat self . __raw_frame_dtype = None # raw-frame dtype self . __raw_frame_depth = None # raw-frame depth self . __raw_frame_resolution = None # raw-frame resolution/dimension # define supported mode of operation self . __supported_opmodes = { \"av\" : \"Audio-Video\" , # audio is only for pass-through, not really for audio decoding yet. \"vo\" : \"Video-Only\" , \"imgseq\" : \"Image-Sequence\" , # \"ao\":\"Audio-Only\", # reserved for future } # operation mode variable self . __opmode = None # handle termination self . __terminate_stream = False # cleans and reformat user-defined parameters self . __extra_params = { str ( k ) . strip (): str ( v ) . strip () if not ( v is None ) and not isinstance ( v , ( dict , list , int , float , tuple )) else v for k , v in ffparams . items () } # handle custom Sourcer API params sourcer_params = self . __extra_params . pop ( \"-custom_sourcer_params\" , {}) # reset improper values sourcer_params = {} if not isinstance ( sourcer_params , dict ) else sourcer_params # handle user ffmpeg pre-headers(parameters such as `-re`) parameters (must be a list) self . __ffmpeg_prefixes = self . __extra_params . pop ( \"-ffprefixes\" , []) # check if not valid type if not isinstance ( self . __ffmpeg_prefixes , list ): # log it logger . warning ( \"Discarding invalid `-ffprefixes` value of wrong type: ` {} `!\" . format ( type ( self . __ffmpeg_prefixes ) . __name__ ) ) # reset improper values self . __ffmpeg_prefixes = [] else : # also pass valid ffmpeg pre-headers to Sourcer API sourcer_params [ \"-ffprefixes\" ] = self . __ffmpeg_prefixes # pass parameter(if specified) to Sourcer API, specifying where to save the downloaded FFmpeg Static # assets on Windows(if specified) sourcer_params [ \"-ffmpeg_download_path\" ] = self . __extra_params . pop ( \"-ffmpeg_download_path\" , \"\" ) # handle video and audio stream indexes in case of multiple ones. default_stream_indexes = self . __extra_params . pop ( \"-default_stream_indexes\" , ( 0 , 0 ) ) # reset improper values default_stream_indexes = ( ( 0 , 0 ) if not isinstance ( default_stream_indexes , ( list , tuple )) else default_stream_indexes ) # pass FFmpeg filter to Sourcer API params for processing if set ([ \"-vf\" , \"-filter_complex\" ]) . intersection ( self . __extra_params . keys ()): key = \"-vf\" if \"-vf\" in self . __extra_params else \"-filter_complex\" sourcer_params [ key ] = self . __extra_params [ key ] # define dict to store user-defined parameters self . __user_metadata = {} # extract and assign source metadata as dict ( self . __sourcer_metadata , self . __missing_prop ) = ( Sourcer ( source = source , source_demuxer = source_demuxer , verbose = verbose , custom_ffmpeg = custom_ffmpeg if isinstance ( custom_ffmpeg , str ) else \"\" , ** sourcer_params ) . probe_stream ( default_stream_indexes = default_stream_indexes ) . retrieve_metadata ( force_retrieve_missing = True ) ) # handle valid FFmpeg assets location self . __ffmpeg = self . __sourcer_metadata [ \"ffmpeg_binary_path\" ] # handle pass-through audio mode works in conjunction with WriteGear [TODO] self . __passthrough_mode = self . __extra_params . pop ( \"-passthrough_audio\" , False ) if not ( isinstance ( self . __passthrough_mode , bool )): self . __passthrough_mode = False # handle mode of operation if self . __sourcer_metadata [ \"source_has_image_sequence\" ]: # image-sequence mode self . __opmode = \"imgseq\" elif ( self . __sourcer_metadata [ \"source_has_video\" ] # audio is only for pass-through, not really for audio decoding yet. and self . __sourcer_metadata [ \"source_has_audio\" ] and self . __passthrough_mode # [TODO] ): self . __opmode = \"av\" # elif __defop_mode == \"ao\" and self.__sourcer_metadata.contains_audio: # [TODO] # self.__opmode = \"ao\" elif self . __sourcer_metadata [ \"source_has_video\" ]: # video-only mode self . __opmode = \"vo\" else : # raise if unknown mode raise ValueError ( \"Unable to find any usable video stream in the given source!\" ) # store as metadata self . __missing_prop [ \"ffdecoder_operational_mode\" ] = self . __supported_opmodes [ self . __opmode ] # handle user-defined output framerate __framerate = self . __extra_params . pop ( \"-framerate\" , None ) if ( isinstance ( __framerate , str ) and __framerate == \"null\" # special mode to discard `-framerate/-r` parameter ): self . __inputframerate = __framerate elif isinstance ( __framerate , ( float , int )): self . __inputframerate = float ( __framerate ) if __framerate > 0.0 else 0.0 else : # warn if wrong type not ( __framerate is None ) and logger . warning ( \"Discarding invalid `-framerate` value of wrong type ` {} `!\" . format ( type ( __framerate ) . __name__ ) ) # reset to default self . __inputframerate = 0.0 # handle user defined decoded frame resolution self . __custom_resolution = self . __extra_params . pop ( \"-custom_resolution\" , None ) if ( isinstance ( self . __custom_resolution , str ) and self . __custom_resolution == \"null\" # special mode to discard `-size/-s` parameter ) or ( isinstance ( self . __custom_resolution , ( list , tuple )) and len ( self . __custom_resolution ) == 2 # valid resolution(must be a tuple or list) ): # log it self . __verbose_logs and not isinstance ( self . __custom_resolution , str ) and logger . debug ( \"Setting raw frames size: ` {} `.\" . format ( self . __custom_resolution ) ) else : # log it not ( self . __custom_resolution is None ) and logger . warning ( \"Discarding invalid `-custom_resolution` value: ` {} `!\" . format ( self . __custom_resolution ) ) # reset improper values self . __custom_resolution = None def formulate ( self ): \"\"\" This method formulates all necessary FFmpeg pipeline arguments and executes it inside the FFmpeg `subprocess` pipe. **Returns:** A reference to the FFdecoder class object. \"\"\" # assign values to class variables on first run if self . __initializing : # prepare parameter dict input_params = OrderedDict () output_params = OrderedDict () # dynamically pre-assign a default video-decoder (if not assigned by user). supported_vdecodecs = get_supported_vdecoders ( self . __ffmpeg ) default_vdecodec = ( self . __sourcer_metadata [ \"source_video_decoder\" ] if self . __sourcer_metadata [ \"source_video_decoder\" ] in supported_vdecodecs else \"unknown\" ) if \"-c:v\" in self . __extra_params : self . __extra_params [ \"-vcodec\" ] = self . __extra_params . pop ( \"-c:v\" , default_vdecodec ) # handle image sequence separately if self . __opmode == \"imgseq\" : # -vcodec is discarded by default # (This is correct or maybe -vcodec required in some unknown case) [TODO] self . __extra_params . pop ( \"-vcodec\" , None ) elif ( \"-vcodec\" in self . __extra_params and self . __extra_params [ \"-vcodec\" ] is None ): # special case when -vcodec is not needed intentionally self . __extra_params . pop ( \"-vcodec\" , None ) else : # assign video decoder selected here. if not \"-vcodec\" in self . __extra_params : input_params [ \"-vcodec\" ] = default_vdecodec else : input_params [ \"-vcodec\" ] = self . __extra_params . pop ( \"-vcodec\" , default_vdecodec ) if ( default_vdecodec != \"unknown\" and not input_params [ \"-vcodec\" ] in supported_vdecodecs ): # reset to default if not supported logger . warning ( \"Provided FFmpeg does not support ` {} ` video decoder. Switching to default supported ` {} ` decoder!\" . format ( input_params [ \"-vcodec\" ], default_vdecodec ) ) input_params [ \"-vcodec\" ] = default_vdecodec # raise error if not valid decoder found if not input_params [ \"-vcodec\" ] in supported_vdecodecs : raise RuntimeError ( \"Provided FFmpeg does not support any known usable video-decoders.\" \" Either define your own manually or switch to another FFmpeg binaries(if available).\" ) # handle user-defined number of frames. if \"-vframes\" in self . __extra_params : self . __extra_params [ \"-frames:v\" ] = self . __extra_params . pop ( \"-vframes\" , None ) if \"-frames:v\" in self . __extra_params : value = self . __extra_params . pop ( \"-frames:v\" , None ) if not ( value is None ) and value > 0 : output_params [ \"-frames:v\" ] = value # dynamically calculate default raw-frames pixel format(if not assigned by user). # notify FFmpeg `-pix_fmt` parameter cannot be assigned directly if \"-pix_fmt\" in self . __extra_params : logger . warning ( \"Discarding user-defined `-pix_fmt` value as it can only be assigned with `frame_format` parameter!\" ) self . __extra_params . pop ( \"-pix_fmt\" , None ) # get supported FFmpeg pixfmt data with depth and bpp(bits-per-pixel) self . __ff_pixfmt_metadata = get_supported_pixfmts ( self . __ffmpeg ) supported_pixfmts = [ fmts [ 0 ] for fmts in self . __ff_pixfmt_metadata ] # calculate default pixel-format # Check special case - `frame_format`(or `-pix_fmt`) parameter discarded from pipeline self . __frame_format == \"null\" and logger . critical ( \"Manually discarding `frame_format`(or `-pix_fmt`) parameter from this pipeline.\" ) # choose between rgb24(if available) or source pixel-format # otherwise, only source pixel-format for special case default_pixfmt = ( \"rgb24\" if \"rgb24\" in supported_pixfmts and self . __frame_format != \"null\" else self . __sourcer_metadata [ \"source_video_pixfmt\" ] ) # assign output raw-frames pixel format rawframe_pixfmt = None if ( not ( self . __frame_format is None ) and self . __frame_format in supported_pixfmts ): # check if valid and supported `frame_format` parameter assigned rawframe_pixfmt = self . __frame_format . strip () self . __verbose_logs and logger . info ( \"User-defined ` {} ` frame pixel-format will be used for this pipeline.\" . format ( rawframe_pixfmt ) ) elif ( \"output_frames_pixfmt\" in self . __sourcer_metadata # means `format` filter is defined and self . __sourcer_metadata [ \"output_frames_pixfmt\" ] in supported_pixfmts ): # assign if valid and supported rawframe_pixfmt = self . __sourcer_metadata [ \"output_frames_pixfmt\" ] . strip () self . __verbose_logs and logger . info ( \"FFmpeg filter values will be used for this pipeline for defining output pixel-format.\" ) else : # reset to default if not supported rawframe_pixfmt = default_pixfmt # log it accordingly if self . __frame_format is None : logger . info ( \"Using default ` {} ` pixel-format for this pipeline.\" . format ( default_pixfmt ) ) else : logger . warning ( \" {} Switching to default ` {} ` pixel-format!\" . format ( \"Provided FFmpeg does not supports ` {} ` pixel-format.\" . format ( self . __sourcer_metadata [ \"output_frames_pixfmt\" ] if \"output_frames_pixfmt\" in self . __sourcer_metadata else self . __frame_format ) if self . __frame_format != \"null\" else \"No usable pixel-format defined.\" , default_pixfmt , ) ) # dynamically calculate raw-frame datatype based on pixel-format selected ( self . __raw_frame_depth , rawframesbpp ) = [ ( int ( x [ 1 ]), int ( x [ 2 ])) for x in self . __ff_pixfmt_metadata if x [ 0 ] == rawframe_pixfmt ][ 0 ] raw_bit_per_component = rawframesbpp // self . __raw_frame_depth if 4 <= raw_bit_per_component <= 8 : self . __raw_frame_dtype = np . dtype ( \"u1\" ) elif 8 < raw_bit_per_component <= 16 and rawframe_pixfmt . endswith ( ( \"le\" , \"be\" ) ): if rawframe_pixfmt . endswith ( \"le\" ): self . __raw_frame_dtype = np . dtype ( \"<u2\" ) else : self . __raw_frame_dtype = np . dtype ( \">u2\" ) else : # reset to both pixel-format and datatype to default if not supported not ( self . __frame_format is None ) and logger . warning ( \"Selected pixel-format ` {} ` dtype is not supported by FFdecoder API. Switching to default `rgb24` pixel-format!\" . format ( rawframe_pixfmt ) ) rawframe_pixfmt = \"rgb24\" self . __raw_frame_dtype = np . dtype ( \"u1\" ) # Check if not special case if self . __frame_format != \"null\" : # assign to FFmpeg pipeline otherwise output_params [ \"-pix_fmt\" ] = rawframe_pixfmt # assign to global parameter further usage self . __raw_frame_pixfmt = rawframe_pixfmt # also override as metadata(if available) if \"output_frames_pixfmt\" in self . __sourcer_metadata : self . __sourcer_metadata [ \"output_frames_pixfmt\" ] = self . __raw_frame_pixfmt # handle raw-frame resolution # notify FFmpeg `-s` parameter cannot be assigned directly if \"-s\" in self . __extra_params : logger . warning ( \"Discarding user-defined `-s` FFmpeg parameter as it can only be assigned with `-custom_resolution` attribute! Read docs for more details.\" ) self . __extra_params . pop ( \"-s\" , None ) # assign output rawframe resolution if not ( self . __custom_resolution is None ) and not isinstance ( self . __custom_resolution , str ): # assign if assigned by user and not \"null\"(str) self . __raw_frame_resolution = self . __custom_resolution self . __verbose_logs and logger . info ( \"User-defined ` {} ` frame resolution will be used for this pipeline.\" . format ( self . __raw_frame_resolution ) ) elif ( \"output_frames_resolution\" in self . __sourcer_metadata # means `scale` filter is defined and self . __sourcer_metadata [ \"output_frames_resolution\" ] and len ( self . __sourcer_metadata [ \"output_frames_resolution\" ]) == 2 ): # calculate raw-frame resolution/dimensions based on output. self . __raw_frame_resolution = self . __sourcer_metadata [ \"output_frames_resolution\" ] elif ( self . __sourcer_metadata [ \"source_video_resolution\" ] and len ( self . __sourcer_metadata [ \"source_video_resolution\" ]) == 2 ): # calculate raw-frame resolution/dimensions based on source. self . __raw_frame_resolution = self . __sourcer_metadata [ \"source_video_resolution\" ] else : # otherwise raise error raise RuntimeError ( \"Both source and output metadata values found Invalid with {} `-custom_resolution` attribute. Aborting!\" . format ( \"null\" if isinstance ( self . __inputframerate , str ) else \"undefined\" ) ) # special mode to discard `-size/-s` FFmpeg parameter completely if isinstance ( self . __custom_resolution , str ): logger . critical ( \"Manually discarding `-size/-s` FFmpeg parameter from this pipeline.\" ) else : # add to pipeline dimensions = \" {} x {} \" . format ( self . __raw_frame_resolution [ 0 ], self . __raw_frame_resolution [ 1 ] ) output_params [ \"-s\" ] = str ( dimensions ) # log if filters or default source is used self . __verbose_logs and ( self . __custom_resolution is None or isinstance ( self . __custom_resolution , str ) ) and logger . info ( \" {} for this pipeline for defining output resolution.\" . format ( \"FFmpeg filter values will be used\" if \"output_frames_resolution\" in self . __sourcer_metadata else \"Default source resolution will be used\" ) ) # dynamically calculate raw-frame framerate based on source (if not assigned by user). if ( not isinstance ( self . __inputframerate , str ) and self . __inputframerate > 0.0 ): # assign if assigned by user and not \"null\"(str) output_params [ \"-framerate\" ] = str ( self . __inputframerate ) self . __verbose_logs and logger . info ( \"User-defined ` {} ` output framerate will be used for this pipeline.\" . format ( str ( self . __inputframerate ) ) ) elif ( \"output_framerate\" in self . __sourcer_metadata # means `fps` filter is defined and self . __sourcer_metadata [ \"output_framerate\" ] > 0.0 ): # special mode to discard `-framerate/-r` FFmpeg parameter completely if self . __inputframerate == \"null\" : logger . critical ( \"Manually discarding `-framerate/-r` FFmpeg parameter from this pipeline.\" ) else : # calculate raw-frame framerate based on output output_params [ \"-framerate\" ] = str ( self . __sourcer_metadata [ \"output_framerate\" ] ) self . __verbose_logs and logger . info ( \"FFmpeg filter values will be used for this pipeline for defining output framerate.\" ) elif self . __sourcer_metadata [ \"source_video_framerate\" ] > 0.0 : # special mode to discard `-framerate/-r` FFmpeg parameter completely if self . __inputframerate == \"null\" : logger . critical ( \"Manually disabling `-framerate/-r` FFmpeg parameter for this pipeline.\" ) else : # calculate raw-frame framerate based on source output_params [ \"-framerate\" ] = str ( self . __sourcer_metadata [ \"source_video_framerate\" ] ) self . __verbose_logs and logger . info ( \"Default source framerate will be used for this pipeline for defining output framerate.\" ) else : # otherwise raise error raise RuntimeError ( \"Both source and output metadata values found Invalid with {} `-framerate` attribute. Aborting!\" . format ( \"null\" if isinstance ( self . __inputframerate , str ) else \"undefined\" ) ) # add rest to output parameters output_params . update ( self . __extra_params ) # dynamically calculate raw-frame numbers based on source (if not assigned by user). # TODO Added support for `-re -stream_loop` and `-loop` if \"-frames:v\" in input_params : self . __raw_frame_num = input_params [ \"-frames:v\" ] elif ( not ( self . __sourcer_metadata [ \"approx_video_nframes\" ] is None ) and self . __sourcer_metadata [ \"approx_video_nframes\" ] > 0 ): self . __raw_frame_num = self . __sourcer_metadata [ \"approx_video_nframes\" ] else : self . __raw_frame_num = None # log that number of frames are unknown self . __verbose_logs and logger . info ( \"Live/Network Stream detected! Number of frames in given source are not known.\" ) # log Mode of Operation self . __verbose_logs and logger . critical ( \"Activating {} Mode of Operation.\" . format ( self . __supported_opmodes [ self . __opmode ] ) ) # compose the Pipeline using formulated FFmpeg parameters self . __launch_FFdecoderline ( input_params , output_params ) # inform the initialization is completed self . __initializing = False else : # warn if pipeline is recreated logger . error ( \"This pipeline is already created and running!\" ) return self def __fetchNextfromPipeline ( self ): \"\"\" This Internal method to fetch next dataframes(1D arrays) from `subprocess` pipe's standard output(`stdout`) into a Numpy buffer. \"\"\" assert not ( self . __process is None ), \"Pipeline is not running! You must call `formulate()` method first.\" # formulated raw frame size raw_frame_size = ( self . __raw_frame_depth * self . __raw_frame_resolution [ 0 ] * self . __raw_frame_resolution [ 1 ] ) # next dataframe as numpy ndarray nparray = None try : # read bytes frames from buffer nparray = np . frombuffer ( self . __process . stdout . read ( raw_frame_size * self . __raw_frame_dtype . itemsize ), dtype = self . __raw_frame_dtype , ) except Exception as e : raise RuntimeError ( \"Frame buffering failed with error: {} \" . format ( str ( e ))) return ( nparray if not ( nparray is None ) and len ( nparray ) == raw_frame_size else None ) def __fetchNextFrame ( self ): \"\"\" This Internal method grabs and decodes next 3D `ndarray` video-frame from the buffer. \"\"\" # Read next and reconstruct as numpy array frame = self . __fetchNextfromPipeline () # check if empty if frame is None : return frame elif self . __raw_frame_pixfmt . startswith ( \"gray\" ): # reconstruct exclusive `gray` frames frame = frame . reshape ( ( self . __raw_frame_resolution [ 1 ], self . __raw_frame_resolution [ 0 ], self . __raw_frame_depth , ) )[:, :, 0 ] else : # reconstruct default frames frame = frame . reshape ( ( self . __raw_frame_resolution [ 1 ], self . __raw_frame_resolution [ 0 ], self . __raw_frame_depth , ) ) # return frame return frame def generateFrame ( self ): \"\"\" This method returns a [Generator function](https://wiki.python.org/moin/Generators) _(also an Iterator using `next()`)_ of video frames, grabbed continuously from the buffer. \"\"\" if self . __raw_frame_num is None or not self . __raw_frame_num : while not self . __terminate_stream : # infinite raw frames frame = self . __fetchNextFrame () if frame is None : self . __terminate_stream = True break yield frame else : for _ in range ( self . __raw_frame_num ): # finite raw frames frame = self . __fetchNextFrame () if frame is None : self . __terminate_stream = True break yield frame def __enter__ ( self ): \"\"\" Handles entry with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/). **Returns:** Output of `formulate()` method. \"\"\" return self . formulate () def __exit__ ( self , exc_type , exc_val , exc_tb ): \"\"\" Handles exit with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/). \"\"\" self . terminate () @property def metadata ( self ): \"\"\" A property object that dumps metadata information as JSON string. **Returns:** Metadata as JSON string. \"\"\" # import dependency import json # return complete metadata information as JSON string return json . dumps ( { ** self . __sourcer_metadata , # source video ** self . __missing_prop , # missing properties ** self . __user_metadata , # user-defined }, indent = 2 , ) @metadata . setter def metadata ( self , value ): \"\"\" A property object that updates metadata information with user-defined dictionary. Parameters: value (dict): User-defined dictionary. \"\"\" # check if value dict type if value and isinstance ( value , dict ): # log it self . __verbose_logs and logger . info ( \"Updating Metadata...\" ) # extract any source and output internal metadata keys default_keys = set ( value ) . intersection ( { ** self . __sourcer_metadata , ** self . __missing_prop } ) # counterpart source properties for each output properties counterpart_prop = { \"output_frames_resolution\" : \"source_video_resolution\" , \"output_frames_pixfmt\" : \"source_video_pixfmt\" , \"output_framerate\" : \"source_video_framerate\" , } # iterate over source metadata keys and sanitize it for key in default_keys or []: if key == \"source\" : # metadata properties that cannot be altered logger . warning ( \"` {} ` metadata property value cannot be altered. Discarding!\" . format ( key ) ) elif key in self . __missing_prop : # missing metadata properties are unavailable and read-only # notify user about alternative counterpart property (if available) logger . warning ( \"` {} ` metadata property is read-only\" . format ( key ) + ( \". Try updating ` {} ` property instead!\" . format ( counterpart_prop [ key ] ) if key in counterpart_prop . keys () else \" and cannot be updated!\" ) ) elif isinstance ( value [ key ], type ( self . __sourcer_metadata [ key ])): # check if correct datatype as original self . __verbose_logs and logger . info ( \"Updating ` {} ` {} metadata property to ` {} `.\" . format ( key , \" and its counterpart\" if key in counterpart_prop . values () else \"\" , value [ key ], ) ) # update source metadata if valid self . __sourcer_metadata [ key ] = value [ key ] # also update missing counterpart property (if available) counter_key = next ( ( k for k , v in counterpart_prop . items () if v == key ), \"\" ) if counter_key : self . __missing_prop [ counter_key ] = value [ key ] else : # otherwise discard and log it logger . warning ( \"Manually assigned ` {} ` metadata property value is of invalid type. Discarding!\" ) . format ( key ) # delete invalid key del value [ key ] # There is no concept of a tuple in the JSON format. # Python's `json` module converts Python tuples to JSON lists # because that's the closest thing in JSON to a tuple. any ( isinstance ( value [ x ], tuple ) for x in value ) and logger . warning ( \"All TUPLE metadata properties will be converted to LIST datatype. Read docs for more details.\" ) # update user-defined metadata self . __user_metadata . update ( value ) else : # otherwise raise error raise ValueError ( \"Invalid datatype metadata assigned. Aborting!\" ) def __launch_FFdecoderline ( self , input_params , output_params ): \"\"\" This Internal method executes FFmpeg pipeline arguments inside a `subprocess` pipe in a new process. Parameters: input_params (dict): Input FFmpeg parameters output_params (dict): Output FFmpeg parameters \"\"\" # convert input parameters to list input_parameters = dict2Args ( input_params ) # convert output parameters to list output_parameters = dict2Args ( output_params ) # format command cmd = ( [ self . __ffmpeg ] + ([ \"-hide_banner\" ] if not self . __verbose_logs else []) + self . __ffmpeg_prefixes + input_parameters + ( [ \"-f\" , self . __sourcer_metadata [ \"source_demuxer\" ]] if ( \"source_demuxer\" in self . __sourcer_metadata . keys ()) else [] ) + [ \"-i\" , self . __sourcer_metadata [ \"source\" ]] + output_parameters + [ \"-f\" , \"rawvideo\" , \"-\" ] ) # compose the FFmpeg process if self . __verbose_logs : logger . debug ( \"Executing FFmpeg command: ` {} `\" . format ( \" \" . join ( cmd ))) # In debugging mode self . __process = sp . Popen ( cmd , stdin = sp . DEVNULL , stdout = sp . PIPE , stderr = None ) else : # In silent mode self . __process = sp . Popen ( cmd , stdin = sp . DEVNULL , stdout = sp . PIPE , stderr = sp . DEVNULL ) def terminate ( self ): \"\"\" Safely terminates all processes. \"\"\" # signal we are closing self . __verbose_logs and logger . debug ( \"Terminating FFdecoder Pipeline...\" ) self . __terminate_stream = True # check if no process was initiated at first place if self . __process is None or not ( self . __process . poll () is None ): logger . info ( \"Pipeline already terminated.\" ) return # Attempt to close pipeline. # close `stdin` output self . __process . stdin and self . __process . stdin . close () # close `stdout` output self . __process . stdout and self . __process . stdout . close () # terminate/kill process if still processing if self . __process . poll () is None : # demuxers prefer kill self . __process . kill () # wait if not exiting self . __process . wait () self . __process = None logger . info ( \"Pipeline terminated successfully.\" ) metadata property writable \u00b6 A property object that dumps metadata information as JSON string. Returns: Metadata as JSON string. __enter__ ( self ) special \u00b6 Handles entry with the with statement. See PEP343 -- The 'with' statement' . Returns: Output of formulate() method. Source code in deffcode/ffdecoder.py def __enter__ ( self ): \"\"\" Handles entry with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/). **Returns:** Output of `formulate()` method. \"\"\" return self . formulate () __exit__ ( self , exc_type , exc_val , exc_tb ) special \u00b6 Handles exit with the with statement. See PEP343 -- The 'with' statement' . Source code in deffcode/ffdecoder.py def __exit__ ( self , exc_type , exc_val , exc_tb ): \"\"\" Handles exit with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/). \"\"\" self . terminate () __init__ ( self , source , source_demuxer = None , frame_format = None , custom_ffmpeg = '' , verbose = False , ** ffparams ) special \u00b6 This constructor method initializes the object state and attributes of the FFdecoder Class. Parameters: Name Type Description Default source str defines the input( -i ) source filename/URL/device-name/device-path. required source_demuxer str specifies the demuxer( -f ) for the input source. None frame_format str sets pixel format( -pix_fmt ) of the decoded frames. None custom_ffmpeg str assigns the location of custom path/directory for custom FFmpeg executable. '' verbose bool enables/disables verbose. False ffparams dict provides the flexibility to control supported internal and FFmpeg parameters. {} Source code in deffcode/ffdecoder.py def __init__ ( self , source , source_demuxer = None , frame_format = None , custom_ffmpeg = \"\" , verbose = False , ** ffparams ): \"\"\" This constructor method initializes the object state and attributes of the FFdecoder Class. Parameters: source (str): defines the input(`-i`) source filename/URL/device-name/device-path. source_demuxer (str): specifies the demuxer(`-f`) for the input source. frame_format (str): sets pixel format(`-pix_fmt`) of the decoded frames. custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executable. verbose (bool): enables/disables verbose. ffparams (dict): provides the flexibility to control supported internal and FFmpeg parameters. \"\"\" # enable verbose if specified self . __verbose_logs = ( verbose if ( verbose and isinstance ( verbose , bool )) else False ) # define whether initializing self . __initializing = True # define frame pixel-format for decoded frames self . __frame_format = ( frame_format . lower () . strip () if isinstance ( frame_format , str ) else None ) # handles user-defined parameters self . __extra_params = {} # handle process to be frames written self . __process = None # handle exclusive metadata self . __ff_pixfmt_metadata = None # metadata self . __raw_frame_num = None # raw-frame number self . __raw_frame_pixfmt = None # raw-frame pixformat self . __raw_frame_dtype = None # raw-frame dtype self . __raw_frame_depth = None # raw-frame depth self . __raw_frame_resolution = None # raw-frame resolution/dimension # define supported mode of operation self . __supported_opmodes = { \"av\" : \"Audio-Video\" , # audio is only for pass-through, not really for audio decoding yet. \"vo\" : \"Video-Only\" , \"imgseq\" : \"Image-Sequence\" , # \"ao\":\"Audio-Only\", # reserved for future } # operation mode variable self . __opmode = None # handle termination self . __terminate_stream = False # cleans and reformat user-defined parameters self . __extra_params = { str ( k ) . strip (): str ( v ) . strip () if not ( v is None ) and not isinstance ( v , ( dict , list , int , float , tuple )) else v for k , v in ffparams . items () } # handle custom Sourcer API params sourcer_params = self . __extra_params . pop ( \"-custom_sourcer_params\" , {}) # reset improper values sourcer_params = {} if not isinstance ( sourcer_params , dict ) else sourcer_params # handle user ffmpeg pre-headers(parameters such as `-re`) parameters (must be a list) self . __ffmpeg_prefixes = self . __extra_params . pop ( \"-ffprefixes\" , []) # check if not valid type if not isinstance ( self . __ffmpeg_prefixes , list ): # log it logger . warning ( \"Discarding invalid `-ffprefixes` value of wrong type: ` {} `!\" . format ( type ( self . __ffmpeg_prefixes ) . __name__ ) ) # reset improper values self . __ffmpeg_prefixes = [] else : # also pass valid ffmpeg pre-headers to Sourcer API sourcer_params [ \"-ffprefixes\" ] = self . __ffmpeg_prefixes # pass parameter(if specified) to Sourcer API, specifying where to save the downloaded FFmpeg Static # assets on Windows(if specified) sourcer_params [ \"-ffmpeg_download_path\" ] = self . __extra_params . pop ( \"-ffmpeg_download_path\" , \"\" ) # handle video and audio stream indexes in case of multiple ones. default_stream_indexes = self . __extra_params . pop ( \"-default_stream_indexes\" , ( 0 , 0 ) ) # reset improper values default_stream_indexes = ( ( 0 , 0 ) if not isinstance ( default_stream_indexes , ( list , tuple )) else default_stream_indexes ) # pass FFmpeg filter to Sourcer API params for processing if set ([ \"-vf\" , \"-filter_complex\" ]) . intersection ( self . __extra_params . keys ()): key = \"-vf\" if \"-vf\" in self . __extra_params else \"-filter_complex\" sourcer_params [ key ] = self . __extra_params [ key ] # define dict to store user-defined parameters self . __user_metadata = {} # extract and assign source metadata as dict ( self . __sourcer_metadata , self . __missing_prop ) = ( Sourcer ( source = source , source_demuxer = source_demuxer , verbose = verbose , custom_ffmpeg = custom_ffmpeg if isinstance ( custom_ffmpeg , str ) else \"\" , ** sourcer_params ) . probe_stream ( default_stream_indexes = default_stream_indexes ) . retrieve_metadata ( force_retrieve_missing = True ) ) # handle valid FFmpeg assets location self . __ffmpeg = self . __sourcer_metadata [ \"ffmpeg_binary_path\" ] # handle pass-through audio mode works in conjunction with WriteGear [TODO] self . __passthrough_mode = self . __extra_params . pop ( \"-passthrough_audio\" , False ) if not ( isinstance ( self . __passthrough_mode , bool )): self . __passthrough_mode = False # handle mode of operation if self . __sourcer_metadata [ \"source_has_image_sequence\" ]: # image-sequence mode self . __opmode = \"imgseq\" elif ( self . __sourcer_metadata [ \"source_has_video\" ] # audio is only for pass-through, not really for audio decoding yet. and self . __sourcer_metadata [ \"source_has_audio\" ] and self . __passthrough_mode # [TODO] ): self . __opmode = \"av\" # elif __defop_mode == \"ao\" and self.__sourcer_metadata.contains_audio: # [TODO] # self.__opmode = \"ao\" elif self . __sourcer_metadata [ \"source_has_video\" ]: # video-only mode self . __opmode = \"vo\" else : # raise if unknown mode raise ValueError ( \"Unable to find any usable video stream in the given source!\" ) # store as metadata self . __missing_prop [ \"ffdecoder_operational_mode\" ] = self . __supported_opmodes [ self . __opmode ] # handle user-defined output framerate __framerate = self . __extra_params . pop ( \"-framerate\" , None ) if ( isinstance ( __framerate , str ) and __framerate == \"null\" # special mode to discard `-framerate/-r` parameter ): self . __inputframerate = __framerate elif isinstance ( __framerate , ( float , int )): self . __inputframerate = float ( __framerate ) if __framerate > 0.0 else 0.0 else : # warn if wrong type not ( __framerate is None ) and logger . warning ( \"Discarding invalid `-framerate` value of wrong type ` {} `!\" . format ( type ( __framerate ) . __name__ ) ) # reset to default self . __inputframerate = 0.0 # handle user defined decoded frame resolution self . __custom_resolution = self . __extra_params . pop ( \"-custom_resolution\" , None ) if ( isinstance ( self . __custom_resolution , str ) and self . __custom_resolution == \"null\" # special mode to discard `-size/-s` parameter ) or ( isinstance ( self . __custom_resolution , ( list , tuple )) and len ( self . __custom_resolution ) == 2 # valid resolution(must be a tuple or list) ): # log it self . __verbose_logs and not isinstance ( self . __custom_resolution , str ) and logger . debug ( \"Setting raw frames size: ` {} `.\" . format ( self . __custom_resolution ) ) else : # log it not ( self . __custom_resolution is None ) and logger . warning ( \"Discarding invalid `-custom_resolution` value: ` {} `!\" . format ( self . __custom_resolution ) ) # reset improper values self . __custom_resolution = None formulate ( self ) \u00b6 This method formulates all necessary FFmpeg pipeline arguments and executes it inside the FFmpeg subprocess pipe. Returns: A reference to the FFdecoder class object. Source code in deffcode/ffdecoder.py def formulate ( self ): \"\"\" This method formulates all necessary FFmpeg pipeline arguments and executes it inside the FFmpeg `subprocess` pipe. **Returns:** A reference to the FFdecoder class object. \"\"\" # assign values to class variables on first run if self . __initializing : # prepare parameter dict input_params = OrderedDict () output_params = OrderedDict () # dynamically pre-assign a default video-decoder (if not assigned by user). supported_vdecodecs = get_supported_vdecoders ( self . __ffmpeg ) default_vdecodec = ( self . __sourcer_metadata [ \"source_video_decoder\" ] if self . __sourcer_metadata [ \"source_video_decoder\" ] in supported_vdecodecs else \"unknown\" ) if \"-c:v\" in self . __extra_params : self . __extra_params [ \"-vcodec\" ] = self . __extra_params . pop ( \"-c:v\" , default_vdecodec ) # handle image sequence separately if self . __opmode == \"imgseq\" : # -vcodec is discarded by default # (This is correct or maybe -vcodec required in some unknown case) [TODO] self . __extra_params . pop ( \"-vcodec\" , None ) elif ( \"-vcodec\" in self . __extra_params and self . __extra_params [ \"-vcodec\" ] is None ): # special case when -vcodec is not needed intentionally self . __extra_params . pop ( \"-vcodec\" , None ) else : # assign video decoder selected here. if not \"-vcodec\" in self . __extra_params : input_params [ \"-vcodec\" ] = default_vdecodec else : input_params [ \"-vcodec\" ] = self . __extra_params . pop ( \"-vcodec\" , default_vdecodec ) if ( default_vdecodec != \"unknown\" and not input_params [ \"-vcodec\" ] in supported_vdecodecs ): # reset to default if not supported logger . warning ( \"Provided FFmpeg does not support ` {} ` video decoder. Switching to default supported ` {} ` decoder!\" . format ( input_params [ \"-vcodec\" ], default_vdecodec ) ) input_params [ \"-vcodec\" ] = default_vdecodec # raise error if not valid decoder found if not input_params [ \"-vcodec\" ] in supported_vdecodecs : raise RuntimeError ( \"Provided FFmpeg does not support any known usable video-decoders.\" \" Either define your own manually or switch to another FFmpeg binaries(if available).\" ) # handle user-defined number of frames. if \"-vframes\" in self . __extra_params : self . __extra_params [ \"-frames:v\" ] = self . __extra_params . pop ( \"-vframes\" , None ) if \"-frames:v\" in self . __extra_params : value = self . __extra_params . pop ( \"-frames:v\" , None ) if not ( value is None ) and value > 0 : output_params [ \"-frames:v\" ] = value # dynamically calculate default raw-frames pixel format(if not assigned by user). # notify FFmpeg `-pix_fmt` parameter cannot be assigned directly if \"-pix_fmt\" in self . __extra_params : logger . warning ( \"Discarding user-defined `-pix_fmt` value as it can only be assigned with `frame_format` parameter!\" ) self . __extra_params . pop ( \"-pix_fmt\" , None ) # get supported FFmpeg pixfmt data with depth and bpp(bits-per-pixel) self . __ff_pixfmt_metadata = get_supported_pixfmts ( self . __ffmpeg ) supported_pixfmts = [ fmts [ 0 ] for fmts in self . __ff_pixfmt_metadata ] # calculate default pixel-format # Check special case - `frame_format`(or `-pix_fmt`) parameter discarded from pipeline self . __frame_format == \"null\" and logger . critical ( \"Manually discarding `frame_format`(or `-pix_fmt`) parameter from this pipeline.\" ) # choose between rgb24(if available) or source pixel-format # otherwise, only source pixel-format for special case default_pixfmt = ( \"rgb24\" if \"rgb24\" in supported_pixfmts and self . __frame_format != \"null\" else self . __sourcer_metadata [ \"source_video_pixfmt\" ] ) # assign output raw-frames pixel format rawframe_pixfmt = None if ( not ( self . __frame_format is None ) and self . __frame_format in supported_pixfmts ): # check if valid and supported `frame_format` parameter assigned rawframe_pixfmt = self . __frame_format . strip () self . __verbose_logs and logger . info ( \"User-defined ` {} ` frame pixel-format will be used for this pipeline.\" . format ( rawframe_pixfmt ) ) elif ( \"output_frames_pixfmt\" in self . __sourcer_metadata # means `format` filter is defined and self . __sourcer_metadata [ \"output_frames_pixfmt\" ] in supported_pixfmts ): # assign if valid and supported rawframe_pixfmt = self . __sourcer_metadata [ \"output_frames_pixfmt\" ] . strip () self . __verbose_logs and logger . info ( \"FFmpeg filter values will be used for this pipeline for defining output pixel-format.\" ) else : # reset to default if not supported rawframe_pixfmt = default_pixfmt # log it accordingly if self . __frame_format is None : logger . info ( \"Using default ` {} ` pixel-format for this pipeline.\" . format ( default_pixfmt ) ) else : logger . warning ( \" {} Switching to default ` {} ` pixel-format!\" . format ( \"Provided FFmpeg does not supports ` {} ` pixel-format.\" . format ( self . __sourcer_metadata [ \"output_frames_pixfmt\" ] if \"output_frames_pixfmt\" in self . __sourcer_metadata else self . __frame_format ) if self . __frame_format != \"null\" else \"No usable pixel-format defined.\" , default_pixfmt , ) ) # dynamically calculate raw-frame datatype based on pixel-format selected ( self . __raw_frame_depth , rawframesbpp ) = [ ( int ( x [ 1 ]), int ( x [ 2 ])) for x in self . __ff_pixfmt_metadata if x [ 0 ] == rawframe_pixfmt ][ 0 ] raw_bit_per_component = rawframesbpp // self . __raw_frame_depth if 4 <= raw_bit_per_component <= 8 : self . __raw_frame_dtype = np . dtype ( \"u1\" ) elif 8 < raw_bit_per_component <= 16 and rawframe_pixfmt . endswith ( ( \"le\" , \"be\" ) ): if rawframe_pixfmt . endswith ( \"le\" ): self . __raw_frame_dtype = np . dtype ( \"<u2\" ) else : self . __raw_frame_dtype = np . dtype ( \">u2\" ) else : # reset to both pixel-format and datatype to default if not supported not ( self . __frame_format is None ) and logger . warning ( \"Selected pixel-format ` {} ` dtype is not supported by FFdecoder API. Switching to default `rgb24` pixel-format!\" . format ( rawframe_pixfmt ) ) rawframe_pixfmt = \"rgb24\" self . __raw_frame_dtype = np . dtype ( \"u1\" ) # Check if not special case if self . __frame_format != \"null\" : # assign to FFmpeg pipeline otherwise output_params [ \"-pix_fmt\" ] = rawframe_pixfmt # assign to global parameter further usage self . __raw_frame_pixfmt = rawframe_pixfmt # also override as metadata(if available) if \"output_frames_pixfmt\" in self . __sourcer_metadata : self . __sourcer_metadata [ \"output_frames_pixfmt\" ] = self . __raw_frame_pixfmt # handle raw-frame resolution # notify FFmpeg `-s` parameter cannot be assigned directly if \"-s\" in self . __extra_params : logger . warning ( \"Discarding user-defined `-s` FFmpeg parameter as it can only be assigned with `-custom_resolution` attribute! Read docs for more details.\" ) self . __extra_params . pop ( \"-s\" , None ) # assign output rawframe resolution if not ( self . __custom_resolution is None ) and not isinstance ( self . __custom_resolution , str ): # assign if assigned by user and not \"null\"(str) self . __raw_frame_resolution = self . __custom_resolution self . __verbose_logs and logger . info ( \"User-defined ` {} ` frame resolution will be used for this pipeline.\" . format ( self . __raw_frame_resolution ) ) elif ( \"output_frames_resolution\" in self . __sourcer_metadata # means `scale` filter is defined and self . __sourcer_metadata [ \"output_frames_resolution\" ] and len ( self . __sourcer_metadata [ \"output_frames_resolution\" ]) == 2 ): # calculate raw-frame resolution/dimensions based on output. self . __raw_frame_resolution = self . __sourcer_metadata [ \"output_frames_resolution\" ] elif ( self . __sourcer_metadata [ \"source_video_resolution\" ] and len ( self . __sourcer_metadata [ \"source_video_resolution\" ]) == 2 ): # calculate raw-frame resolution/dimensions based on source. self . __raw_frame_resolution = self . __sourcer_metadata [ \"source_video_resolution\" ] else : # otherwise raise error raise RuntimeError ( \"Both source and output metadata values found Invalid with {} `-custom_resolution` attribute. Aborting!\" . format ( \"null\" if isinstance ( self . __inputframerate , str ) else \"undefined\" ) ) # special mode to discard `-size/-s` FFmpeg parameter completely if isinstance ( self . __custom_resolution , str ): logger . critical ( \"Manually discarding `-size/-s` FFmpeg parameter from this pipeline.\" ) else : # add to pipeline dimensions = \" {} x {} \" . format ( self . __raw_frame_resolution [ 0 ], self . __raw_frame_resolution [ 1 ] ) output_params [ \"-s\" ] = str ( dimensions ) # log if filters or default source is used self . __verbose_logs and ( self . __custom_resolution is None or isinstance ( self . __custom_resolution , str ) ) and logger . info ( \" {} for this pipeline for defining output resolution.\" . format ( \"FFmpeg filter values will be used\" if \"output_frames_resolution\" in self . __sourcer_metadata else \"Default source resolution will be used\" ) ) # dynamically calculate raw-frame framerate based on source (if not assigned by user). if ( not isinstance ( self . __inputframerate , str ) and self . __inputframerate > 0.0 ): # assign if assigned by user and not \"null\"(str) output_params [ \"-framerate\" ] = str ( self . __inputframerate ) self . __verbose_logs and logger . info ( \"User-defined ` {} ` output framerate will be used for this pipeline.\" . format ( str ( self . __inputframerate ) ) ) elif ( \"output_framerate\" in self . __sourcer_metadata # means `fps` filter is defined and self . __sourcer_metadata [ \"output_framerate\" ] > 0.0 ): # special mode to discard `-framerate/-r` FFmpeg parameter completely if self . __inputframerate == \"null\" : logger . critical ( \"Manually discarding `-framerate/-r` FFmpeg parameter from this pipeline.\" ) else : # calculate raw-frame framerate based on output output_params [ \"-framerate\" ] = str ( self . __sourcer_metadata [ \"output_framerate\" ] ) self . __verbose_logs and logger . info ( \"FFmpeg filter values will be used for this pipeline for defining output framerate.\" ) elif self . __sourcer_metadata [ \"source_video_framerate\" ] > 0.0 : # special mode to discard `-framerate/-r` FFmpeg parameter completely if self . __inputframerate == \"null\" : logger . critical ( \"Manually disabling `-framerate/-r` FFmpeg parameter for this pipeline.\" ) else : # calculate raw-frame framerate based on source output_params [ \"-framerate\" ] = str ( self . __sourcer_metadata [ \"source_video_framerate\" ] ) self . __verbose_logs and logger . info ( \"Default source framerate will be used for this pipeline for defining output framerate.\" ) else : # otherwise raise error raise RuntimeError ( \"Both source and output metadata values found Invalid with {} `-framerate` attribute. Aborting!\" . format ( \"null\" if isinstance ( self . __inputframerate , str ) else \"undefined\" ) ) # add rest to output parameters output_params . update ( self . __extra_params ) # dynamically calculate raw-frame numbers based on source (if not assigned by user). # TODO Added support for `-re -stream_loop` and `-loop` if \"-frames:v\" in input_params : self . __raw_frame_num = input_params [ \"-frames:v\" ] elif ( not ( self . __sourcer_metadata [ \"approx_video_nframes\" ] is None ) and self . __sourcer_metadata [ \"approx_video_nframes\" ] > 0 ): self . __raw_frame_num = self . __sourcer_metadata [ \"approx_video_nframes\" ] else : self . __raw_frame_num = None # log that number of frames are unknown self . __verbose_logs and logger . info ( \"Live/Network Stream detected! Number of frames in given source are not known.\" ) # log Mode of Operation self . __verbose_logs and logger . critical ( \"Activating {} Mode of Operation.\" . format ( self . __supported_opmodes [ self . __opmode ] ) ) # compose the Pipeline using formulated FFmpeg parameters self . __launch_FFdecoderline ( input_params , output_params ) # inform the initialization is completed self . __initializing = False else : # warn if pipeline is recreated logger . error ( \"This pipeline is already created and running!\" ) return self generateFrame ( self ) \u00b6 This method returns a Generator function (also an Iterator using next() ) of video frames, grabbed continuously from the buffer. Source code in deffcode/ffdecoder.py def generateFrame ( self ): \"\"\" This method returns a [Generator function](https://wiki.python.org/moin/Generators) _(also an Iterator using `next()`)_ of video frames, grabbed continuously from the buffer. \"\"\" if self . __raw_frame_num is None or not self . __raw_frame_num : while not self . __terminate_stream : # infinite raw frames frame = self . __fetchNextFrame () if frame is None : self . __terminate_stream = True break yield frame else : for _ in range ( self . __raw_frame_num ): # finite raw frames frame = self . __fetchNextFrame () if frame is None : self . __terminate_stream = True break yield frame terminate ( self ) \u00b6 Safely terminates all processes. Source code in deffcode/ffdecoder.py def terminate ( self ): \"\"\" Safely terminates all processes. \"\"\" # signal we are closing self . __verbose_logs and logger . debug ( \"Terminating FFdecoder Pipeline...\" ) self . __terminate_stream = True # check if no process was initiated at first place if self . __process is None or not ( self . __process . poll () is None ): logger . info ( \"Pipeline already terminated.\" ) return # Attempt to close pipeline. # close `stdin` output self . __process . stdin and self . __process . stdin . close () # close `stdout` output self . __process . stdout and self . __process . stdout . close () # terminate/kill process if still processing if self . __process . poll () is None : # demuxers prefer kill self . __process . kill () # wait if not exiting self . __process . wait () self . __process = None logger . info ( \"Pipeline terminated successfully.\" )","title":"API"},{"location":"reference/ffdecoder/#ffdecoder-api","text":"FFdecoder API compiles and executes the FFmpeg pipeline inside a subprocess pipe for generating real-time, low-overhead, lightning fast video frames with robust error-handling in python \ud83c\udf9e\ufe0f\u26a1 FFdecoder API implements a standalone highly-extensible wrapper around FFmpeg multimedia framework that provides complete control over the underline pipeline including access to almost any FFmpeg specification thinkable such as framerate, resolution, hardware decoder(s), complex filter(s), and pixel format(s) that are readily supported by all well known Computer Vision libraries. FFdecoder API compiles its FFmpeg pipeline by processing input Video Source metadata and User-defined options, and runs it inside a subprocess pipe concurrently with the main thread, while extracting output dataframes(1D arrays) into a Numpy buffer. These dataframes are consecutively grabbed from the buffer and decoded into 24-bit RGB (default) ndarray 3D frames that are readily available through its generateFrame() method. FFdecoder API employs Sourcer API at its backend for gathering, processing, and validating metadata of all multimedia streams available in the given source for formulating/compiling its default FFmpeg pipeline. This metadata information is also available as a JSON string with its metadata property object and can be updated as desired. FFdecoder API supports a wide-ranging media stream as input source such as USB/Virtual/IP Camera Feed, Multimedia video file, Screen Capture, Image Sequence, Network protocols (such as HTTP(s), RTP/RSTP, etc.) , so on and so forth. Furthermore, FFdecoder API maintains the standard OpenCV-Python (Python API for OpenCV) coding syntax , thereby making it even easier to integrate this API in any Computer Vision application. For usage examples, kindly refer our Basic Recipes and Advanced Recipes FFdecoder API parameters are explained here \u27b6 Source code in deffcode/ffdecoder.py class FFdecoder : \"\"\" > FFdecoder API compiles and executes the FFmpeg pipeline inside a subprocess pipe for generating real-time, low-overhead, lightning fast video frames with robust error-handling in python \ud83c\udf9e\ufe0f\u26a1 FFdecoder API implements a **standalone highly-extensible wrapper around [FFmpeg](https://ffmpeg.org/)** multimedia framework that provides complete control over the underline pipeline including **access to almost any FFmpeg specification thinkable** such as framerate, resolution, hardware decoder(s), complex filter(s), and pixel format(s) that are readily supported by all well known Computer Vision libraries. FFdecoder API **compiles its FFmpeg pipeline** by processing input Video Source metadata and User-defined options, and **runs it inside a [`subprocess`](https://docs.python.org/3/library/subprocess.html) pipe** concurrently with the main thread, while extracting output dataframes(1D arrays) into a Numpy buffer. These dataframes are consecutively grabbed from the buffer and decoded into ==[24-bit RGB](https://en.wikipedia.org/wiki/List_of_monochrome_and_RGB_color_formats#24-bit_RGB) _(default)_ [`ndarray`](https://numpy.org/doc/stable/reference/arrays.ndarray.html#the-n-dimensional-array-ndarray) 3D frames== that are readily available through its [`generateFrame()`](#deffcode.ffdecoder.FFdecoder.generateFrame) method. FFdecoder API **employs [Sourcer API](../../reference/sourcer) at its backend** for gathering, processing, and validating metadata of all multimedia streams available in the given source for formulating/compiling its default FFmpeg pipeline. This metadata information is also available as a JSON string with its [`metadata`](#deffcode.ffdecoder.FFdecoder.metadata) property object and can be updated as desired. FFdecoder API **supports a wide-ranging media stream** as input source such as USB/Virtual/IP Camera Feed, Multimedia video file, Screen Capture, Image Sequence, Network protocols _(such as HTTP(s), RTP/RSTP, etc.)_, so on and so forth. Furthermore, FFdecoder API maintains the **standard [OpenCV-Python](https://docs.opencv.org/4.x/d6/d00/tutorial_py_root.html) _(Python API for OpenCV)_ coding syntax**, thereby making it even easier to integrate this API in any Computer Vision application. !!! example \"For usage examples, kindly refer our **[Basic Recipes :cake:](../../recipes/basic)** and **[Advanced Recipes :croissant:](../../recipes/advanced)**\" !!! info \"FFdecoder API parameters are explained [here \u27b6](params/)\" \"\"\" def __init__ ( self , source , source_demuxer = None , frame_format = None , custom_ffmpeg = \"\" , verbose = False , ** ffparams ): \"\"\" This constructor method initializes the object state and attributes of the FFdecoder Class. Parameters: source (str): defines the input(`-i`) source filename/URL/device-name/device-path. source_demuxer (str): specifies the demuxer(`-f`) for the input source. frame_format (str): sets pixel format(`-pix_fmt`) of the decoded frames. custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executable. verbose (bool): enables/disables verbose. ffparams (dict): provides the flexibility to control supported internal and FFmpeg parameters. \"\"\" # enable verbose if specified self . __verbose_logs = ( verbose if ( verbose and isinstance ( verbose , bool )) else False ) # define whether initializing self . __initializing = True # define frame pixel-format for decoded frames self . __frame_format = ( frame_format . lower () . strip () if isinstance ( frame_format , str ) else None ) # handles user-defined parameters self . __extra_params = {} # handle process to be frames written self . __process = None # handle exclusive metadata self . __ff_pixfmt_metadata = None # metadata self . __raw_frame_num = None # raw-frame number self . __raw_frame_pixfmt = None # raw-frame pixformat self . __raw_frame_dtype = None # raw-frame dtype self . __raw_frame_depth = None # raw-frame depth self . __raw_frame_resolution = None # raw-frame resolution/dimension # define supported mode of operation self . __supported_opmodes = { \"av\" : \"Audio-Video\" , # audio is only for pass-through, not really for audio decoding yet. \"vo\" : \"Video-Only\" , \"imgseq\" : \"Image-Sequence\" , # \"ao\":\"Audio-Only\", # reserved for future } # operation mode variable self . __opmode = None # handle termination self . __terminate_stream = False # cleans and reformat user-defined parameters self . __extra_params = { str ( k ) . strip (): str ( v ) . strip () if not ( v is None ) and not isinstance ( v , ( dict , list , int , float , tuple )) else v for k , v in ffparams . items () } # handle custom Sourcer API params sourcer_params = self . __extra_params . pop ( \"-custom_sourcer_params\" , {}) # reset improper values sourcer_params = {} if not isinstance ( sourcer_params , dict ) else sourcer_params # handle user ffmpeg pre-headers(parameters such as `-re`) parameters (must be a list) self . __ffmpeg_prefixes = self . __extra_params . pop ( \"-ffprefixes\" , []) # check if not valid type if not isinstance ( self . __ffmpeg_prefixes , list ): # log it logger . warning ( \"Discarding invalid `-ffprefixes` value of wrong type: ` {} `!\" . format ( type ( self . __ffmpeg_prefixes ) . __name__ ) ) # reset improper values self . __ffmpeg_prefixes = [] else : # also pass valid ffmpeg pre-headers to Sourcer API sourcer_params [ \"-ffprefixes\" ] = self . __ffmpeg_prefixes # pass parameter(if specified) to Sourcer API, specifying where to save the downloaded FFmpeg Static # assets on Windows(if specified) sourcer_params [ \"-ffmpeg_download_path\" ] = self . __extra_params . pop ( \"-ffmpeg_download_path\" , \"\" ) # handle video and audio stream indexes in case of multiple ones. default_stream_indexes = self . __extra_params . pop ( \"-default_stream_indexes\" , ( 0 , 0 ) ) # reset improper values default_stream_indexes = ( ( 0 , 0 ) if not isinstance ( default_stream_indexes , ( list , tuple )) else default_stream_indexes ) # pass FFmpeg filter to Sourcer API params for processing if set ([ \"-vf\" , \"-filter_complex\" ]) . intersection ( self . __extra_params . keys ()): key = \"-vf\" if \"-vf\" in self . __extra_params else \"-filter_complex\" sourcer_params [ key ] = self . __extra_params [ key ] # define dict to store user-defined parameters self . __user_metadata = {} # extract and assign source metadata as dict ( self . __sourcer_metadata , self . __missing_prop ) = ( Sourcer ( source = source , source_demuxer = source_demuxer , verbose = verbose , custom_ffmpeg = custom_ffmpeg if isinstance ( custom_ffmpeg , str ) else \"\" , ** sourcer_params ) . probe_stream ( default_stream_indexes = default_stream_indexes ) . retrieve_metadata ( force_retrieve_missing = True ) ) # handle valid FFmpeg assets location self . __ffmpeg = self . __sourcer_metadata [ \"ffmpeg_binary_path\" ] # handle pass-through audio mode works in conjunction with WriteGear [TODO] self . __passthrough_mode = self . __extra_params . pop ( \"-passthrough_audio\" , False ) if not ( isinstance ( self . __passthrough_mode , bool )): self . __passthrough_mode = False # handle mode of operation if self . __sourcer_metadata [ \"source_has_image_sequence\" ]: # image-sequence mode self . __opmode = \"imgseq\" elif ( self . __sourcer_metadata [ \"source_has_video\" ] # audio is only for pass-through, not really for audio decoding yet. and self . __sourcer_metadata [ \"source_has_audio\" ] and self . __passthrough_mode # [TODO] ): self . __opmode = \"av\" # elif __defop_mode == \"ao\" and self.__sourcer_metadata.contains_audio: # [TODO] # self.__opmode = \"ao\" elif self . __sourcer_metadata [ \"source_has_video\" ]: # video-only mode self . __opmode = \"vo\" else : # raise if unknown mode raise ValueError ( \"Unable to find any usable video stream in the given source!\" ) # store as metadata self . __missing_prop [ \"ffdecoder_operational_mode\" ] = self . __supported_opmodes [ self . __opmode ] # handle user-defined output framerate __framerate = self . __extra_params . pop ( \"-framerate\" , None ) if ( isinstance ( __framerate , str ) and __framerate == \"null\" # special mode to discard `-framerate/-r` parameter ): self . __inputframerate = __framerate elif isinstance ( __framerate , ( float , int )): self . __inputframerate = float ( __framerate ) if __framerate > 0.0 else 0.0 else : # warn if wrong type not ( __framerate is None ) and logger . warning ( \"Discarding invalid `-framerate` value of wrong type ` {} `!\" . format ( type ( __framerate ) . __name__ ) ) # reset to default self . __inputframerate = 0.0 # handle user defined decoded frame resolution self . __custom_resolution = self . __extra_params . pop ( \"-custom_resolution\" , None ) if ( isinstance ( self . __custom_resolution , str ) and self . __custom_resolution == \"null\" # special mode to discard `-size/-s` parameter ) or ( isinstance ( self . __custom_resolution , ( list , tuple )) and len ( self . __custom_resolution ) == 2 # valid resolution(must be a tuple or list) ): # log it self . __verbose_logs and not isinstance ( self . __custom_resolution , str ) and logger . debug ( \"Setting raw frames size: ` {} `.\" . format ( self . __custom_resolution ) ) else : # log it not ( self . __custom_resolution is None ) and logger . warning ( \"Discarding invalid `-custom_resolution` value: ` {} `!\" . format ( self . __custom_resolution ) ) # reset improper values self . __custom_resolution = None def formulate ( self ): \"\"\" This method formulates all necessary FFmpeg pipeline arguments and executes it inside the FFmpeg `subprocess` pipe. **Returns:** A reference to the FFdecoder class object. \"\"\" # assign values to class variables on first run if self . __initializing : # prepare parameter dict input_params = OrderedDict () output_params = OrderedDict () # dynamically pre-assign a default video-decoder (if not assigned by user). supported_vdecodecs = get_supported_vdecoders ( self . __ffmpeg ) default_vdecodec = ( self . __sourcer_metadata [ \"source_video_decoder\" ] if self . __sourcer_metadata [ \"source_video_decoder\" ] in supported_vdecodecs else \"unknown\" ) if \"-c:v\" in self . __extra_params : self . __extra_params [ \"-vcodec\" ] = self . __extra_params . pop ( \"-c:v\" , default_vdecodec ) # handle image sequence separately if self . __opmode == \"imgseq\" : # -vcodec is discarded by default # (This is correct or maybe -vcodec required in some unknown case) [TODO] self . __extra_params . pop ( \"-vcodec\" , None ) elif ( \"-vcodec\" in self . __extra_params and self . __extra_params [ \"-vcodec\" ] is None ): # special case when -vcodec is not needed intentionally self . __extra_params . pop ( \"-vcodec\" , None ) else : # assign video decoder selected here. if not \"-vcodec\" in self . __extra_params : input_params [ \"-vcodec\" ] = default_vdecodec else : input_params [ \"-vcodec\" ] = self . __extra_params . pop ( \"-vcodec\" , default_vdecodec ) if ( default_vdecodec != \"unknown\" and not input_params [ \"-vcodec\" ] in supported_vdecodecs ): # reset to default if not supported logger . warning ( \"Provided FFmpeg does not support ` {} ` video decoder. Switching to default supported ` {} ` decoder!\" . format ( input_params [ \"-vcodec\" ], default_vdecodec ) ) input_params [ \"-vcodec\" ] = default_vdecodec # raise error if not valid decoder found if not input_params [ \"-vcodec\" ] in supported_vdecodecs : raise RuntimeError ( \"Provided FFmpeg does not support any known usable video-decoders.\" \" Either define your own manually or switch to another FFmpeg binaries(if available).\" ) # handle user-defined number of frames. if \"-vframes\" in self . __extra_params : self . __extra_params [ \"-frames:v\" ] = self . __extra_params . pop ( \"-vframes\" , None ) if \"-frames:v\" in self . __extra_params : value = self . __extra_params . pop ( \"-frames:v\" , None ) if not ( value is None ) and value > 0 : output_params [ \"-frames:v\" ] = value # dynamically calculate default raw-frames pixel format(if not assigned by user). # notify FFmpeg `-pix_fmt` parameter cannot be assigned directly if \"-pix_fmt\" in self . __extra_params : logger . warning ( \"Discarding user-defined `-pix_fmt` value as it can only be assigned with `frame_format` parameter!\" ) self . __extra_params . pop ( \"-pix_fmt\" , None ) # get supported FFmpeg pixfmt data with depth and bpp(bits-per-pixel) self . __ff_pixfmt_metadata = get_supported_pixfmts ( self . __ffmpeg ) supported_pixfmts = [ fmts [ 0 ] for fmts in self . __ff_pixfmt_metadata ] # calculate default pixel-format # Check special case - `frame_format`(or `-pix_fmt`) parameter discarded from pipeline self . __frame_format == \"null\" and logger . critical ( \"Manually discarding `frame_format`(or `-pix_fmt`) parameter from this pipeline.\" ) # choose between rgb24(if available) or source pixel-format # otherwise, only source pixel-format for special case default_pixfmt = ( \"rgb24\" if \"rgb24\" in supported_pixfmts and self . __frame_format != \"null\" else self . __sourcer_metadata [ \"source_video_pixfmt\" ] ) # assign output raw-frames pixel format rawframe_pixfmt = None if ( not ( self . __frame_format is None ) and self . __frame_format in supported_pixfmts ): # check if valid and supported `frame_format` parameter assigned rawframe_pixfmt = self . __frame_format . strip () self . __verbose_logs and logger . info ( \"User-defined ` {} ` frame pixel-format will be used for this pipeline.\" . format ( rawframe_pixfmt ) ) elif ( \"output_frames_pixfmt\" in self . __sourcer_metadata # means `format` filter is defined and self . __sourcer_metadata [ \"output_frames_pixfmt\" ] in supported_pixfmts ): # assign if valid and supported rawframe_pixfmt = self . __sourcer_metadata [ \"output_frames_pixfmt\" ] . strip () self . __verbose_logs and logger . info ( \"FFmpeg filter values will be used for this pipeline for defining output pixel-format.\" ) else : # reset to default if not supported rawframe_pixfmt = default_pixfmt # log it accordingly if self . __frame_format is None : logger . info ( \"Using default ` {} ` pixel-format for this pipeline.\" . format ( default_pixfmt ) ) else : logger . warning ( \" {} Switching to default ` {} ` pixel-format!\" . format ( \"Provided FFmpeg does not supports ` {} ` pixel-format.\" . format ( self . __sourcer_metadata [ \"output_frames_pixfmt\" ] if \"output_frames_pixfmt\" in self . __sourcer_metadata else self . __frame_format ) if self . __frame_format != \"null\" else \"No usable pixel-format defined.\" , default_pixfmt , ) ) # dynamically calculate raw-frame datatype based on pixel-format selected ( self . __raw_frame_depth , rawframesbpp ) = [ ( int ( x [ 1 ]), int ( x [ 2 ])) for x in self . __ff_pixfmt_metadata if x [ 0 ] == rawframe_pixfmt ][ 0 ] raw_bit_per_component = rawframesbpp // self . __raw_frame_depth if 4 <= raw_bit_per_component <= 8 : self . __raw_frame_dtype = np . dtype ( \"u1\" ) elif 8 < raw_bit_per_component <= 16 and rawframe_pixfmt . endswith ( ( \"le\" , \"be\" ) ): if rawframe_pixfmt . endswith ( \"le\" ): self . __raw_frame_dtype = np . dtype ( \"<u2\" ) else : self . __raw_frame_dtype = np . dtype ( \">u2\" ) else : # reset to both pixel-format and datatype to default if not supported not ( self . __frame_format is None ) and logger . warning ( \"Selected pixel-format ` {} ` dtype is not supported by FFdecoder API. Switching to default `rgb24` pixel-format!\" . format ( rawframe_pixfmt ) ) rawframe_pixfmt = \"rgb24\" self . __raw_frame_dtype = np . dtype ( \"u1\" ) # Check if not special case if self . __frame_format != \"null\" : # assign to FFmpeg pipeline otherwise output_params [ \"-pix_fmt\" ] = rawframe_pixfmt # assign to global parameter further usage self . __raw_frame_pixfmt = rawframe_pixfmt # also override as metadata(if available) if \"output_frames_pixfmt\" in self . __sourcer_metadata : self . __sourcer_metadata [ \"output_frames_pixfmt\" ] = self . __raw_frame_pixfmt # handle raw-frame resolution # notify FFmpeg `-s` parameter cannot be assigned directly if \"-s\" in self . __extra_params : logger . warning ( \"Discarding user-defined `-s` FFmpeg parameter as it can only be assigned with `-custom_resolution` attribute! Read docs for more details.\" ) self . __extra_params . pop ( \"-s\" , None ) # assign output rawframe resolution if not ( self . __custom_resolution is None ) and not isinstance ( self . __custom_resolution , str ): # assign if assigned by user and not \"null\"(str) self . __raw_frame_resolution = self . __custom_resolution self . __verbose_logs and logger . info ( \"User-defined ` {} ` frame resolution will be used for this pipeline.\" . format ( self . __raw_frame_resolution ) ) elif ( \"output_frames_resolution\" in self . __sourcer_metadata # means `scale` filter is defined and self . __sourcer_metadata [ \"output_frames_resolution\" ] and len ( self . __sourcer_metadata [ \"output_frames_resolution\" ]) == 2 ): # calculate raw-frame resolution/dimensions based on output. self . __raw_frame_resolution = self . __sourcer_metadata [ \"output_frames_resolution\" ] elif ( self . __sourcer_metadata [ \"source_video_resolution\" ] and len ( self . __sourcer_metadata [ \"source_video_resolution\" ]) == 2 ): # calculate raw-frame resolution/dimensions based on source. self . __raw_frame_resolution = self . __sourcer_metadata [ \"source_video_resolution\" ] else : # otherwise raise error raise RuntimeError ( \"Both source and output metadata values found Invalid with {} `-custom_resolution` attribute. Aborting!\" . format ( \"null\" if isinstance ( self . __inputframerate , str ) else \"undefined\" ) ) # special mode to discard `-size/-s` FFmpeg parameter completely if isinstance ( self . __custom_resolution , str ): logger . critical ( \"Manually discarding `-size/-s` FFmpeg parameter from this pipeline.\" ) else : # add to pipeline dimensions = \" {} x {} \" . format ( self . __raw_frame_resolution [ 0 ], self . __raw_frame_resolution [ 1 ] ) output_params [ \"-s\" ] = str ( dimensions ) # log if filters or default source is used self . __verbose_logs and ( self . __custom_resolution is None or isinstance ( self . __custom_resolution , str ) ) and logger . info ( \" {} for this pipeline for defining output resolution.\" . format ( \"FFmpeg filter values will be used\" if \"output_frames_resolution\" in self . __sourcer_metadata else \"Default source resolution will be used\" ) ) # dynamically calculate raw-frame framerate based on source (if not assigned by user). if ( not isinstance ( self . __inputframerate , str ) and self . __inputframerate > 0.0 ): # assign if assigned by user and not \"null\"(str) output_params [ \"-framerate\" ] = str ( self . __inputframerate ) self . __verbose_logs and logger . info ( \"User-defined ` {} ` output framerate will be used for this pipeline.\" . format ( str ( self . __inputframerate ) ) ) elif ( \"output_framerate\" in self . __sourcer_metadata # means `fps` filter is defined and self . __sourcer_metadata [ \"output_framerate\" ] > 0.0 ): # special mode to discard `-framerate/-r` FFmpeg parameter completely if self . __inputframerate == \"null\" : logger . critical ( \"Manually discarding `-framerate/-r` FFmpeg parameter from this pipeline.\" ) else : # calculate raw-frame framerate based on output output_params [ \"-framerate\" ] = str ( self . __sourcer_metadata [ \"output_framerate\" ] ) self . __verbose_logs and logger . info ( \"FFmpeg filter values will be used for this pipeline for defining output framerate.\" ) elif self . __sourcer_metadata [ \"source_video_framerate\" ] > 0.0 : # special mode to discard `-framerate/-r` FFmpeg parameter completely if self . __inputframerate == \"null\" : logger . critical ( \"Manually disabling `-framerate/-r` FFmpeg parameter for this pipeline.\" ) else : # calculate raw-frame framerate based on source output_params [ \"-framerate\" ] = str ( self . __sourcer_metadata [ \"source_video_framerate\" ] ) self . __verbose_logs and logger . info ( \"Default source framerate will be used for this pipeline for defining output framerate.\" ) else : # otherwise raise error raise RuntimeError ( \"Both source and output metadata values found Invalid with {} `-framerate` attribute. Aborting!\" . format ( \"null\" if isinstance ( self . __inputframerate , str ) else \"undefined\" ) ) # add rest to output parameters output_params . update ( self . __extra_params ) # dynamically calculate raw-frame numbers based on source (if not assigned by user). # TODO Added support for `-re -stream_loop` and `-loop` if \"-frames:v\" in input_params : self . __raw_frame_num = input_params [ \"-frames:v\" ] elif ( not ( self . __sourcer_metadata [ \"approx_video_nframes\" ] is None ) and self . __sourcer_metadata [ \"approx_video_nframes\" ] > 0 ): self . __raw_frame_num = self . __sourcer_metadata [ \"approx_video_nframes\" ] else : self . __raw_frame_num = None # log that number of frames are unknown self . __verbose_logs and logger . info ( \"Live/Network Stream detected! Number of frames in given source are not known.\" ) # log Mode of Operation self . __verbose_logs and logger . critical ( \"Activating {} Mode of Operation.\" . format ( self . __supported_opmodes [ self . __opmode ] ) ) # compose the Pipeline using formulated FFmpeg parameters self . __launch_FFdecoderline ( input_params , output_params ) # inform the initialization is completed self . __initializing = False else : # warn if pipeline is recreated logger . error ( \"This pipeline is already created and running!\" ) return self def __fetchNextfromPipeline ( self ): \"\"\" This Internal method to fetch next dataframes(1D arrays) from `subprocess` pipe's standard output(`stdout`) into a Numpy buffer. \"\"\" assert not ( self . __process is None ), \"Pipeline is not running! You must call `formulate()` method first.\" # formulated raw frame size raw_frame_size = ( self . __raw_frame_depth * self . __raw_frame_resolution [ 0 ] * self . __raw_frame_resolution [ 1 ] ) # next dataframe as numpy ndarray nparray = None try : # read bytes frames from buffer nparray = np . frombuffer ( self . __process . stdout . read ( raw_frame_size * self . __raw_frame_dtype . itemsize ), dtype = self . __raw_frame_dtype , ) except Exception as e : raise RuntimeError ( \"Frame buffering failed with error: {} \" . format ( str ( e ))) return ( nparray if not ( nparray is None ) and len ( nparray ) == raw_frame_size else None ) def __fetchNextFrame ( self ): \"\"\" This Internal method grabs and decodes next 3D `ndarray` video-frame from the buffer. \"\"\" # Read next and reconstruct as numpy array frame = self . __fetchNextfromPipeline () # check if empty if frame is None : return frame elif self . __raw_frame_pixfmt . startswith ( \"gray\" ): # reconstruct exclusive `gray` frames frame = frame . reshape ( ( self . __raw_frame_resolution [ 1 ], self . __raw_frame_resolution [ 0 ], self . __raw_frame_depth , ) )[:, :, 0 ] else : # reconstruct default frames frame = frame . reshape ( ( self . __raw_frame_resolution [ 1 ], self . __raw_frame_resolution [ 0 ], self . __raw_frame_depth , ) ) # return frame return frame def generateFrame ( self ): \"\"\" This method returns a [Generator function](https://wiki.python.org/moin/Generators) _(also an Iterator using `next()`)_ of video frames, grabbed continuously from the buffer. \"\"\" if self . __raw_frame_num is None or not self . __raw_frame_num : while not self . __terminate_stream : # infinite raw frames frame = self . __fetchNextFrame () if frame is None : self . __terminate_stream = True break yield frame else : for _ in range ( self . __raw_frame_num ): # finite raw frames frame = self . __fetchNextFrame () if frame is None : self . __terminate_stream = True break yield frame def __enter__ ( self ): \"\"\" Handles entry with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/). **Returns:** Output of `formulate()` method. \"\"\" return self . formulate () def __exit__ ( self , exc_type , exc_val , exc_tb ): \"\"\" Handles exit with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/). \"\"\" self . terminate () @property def metadata ( self ): \"\"\" A property object that dumps metadata information as JSON string. **Returns:** Metadata as JSON string. \"\"\" # import dependency import json # return complete metadata information as JSON string return json . dumps ( { ** self . __sourcer_metadata , # source video ** self . __missing_prop , # missing properties ** self . __user_metadata , # user-defined }, indent = 2 , ) @metadata . setter def metadata ( self , value ): \"\"\" A property object that updates metadata information with user-defined dictionary. Parameters: value (dict): User-defined dictionary. \"\"\" # check if value dict type if value and isinstance ( value , dict ): # log it self . __verbose_logs and logger . info ( \"Updating Metadata...\" ) # extract any source and output internal metadata keys default_keys = set ( value ) . intersection ( { ** self . __sourcer_metadata , ** self . __missing_prop } ) # counterpart source properties for each output properties counterpart_prop = { \"output_frames_resolution\" : \"source_video_resolution\" , \"output_frames_pixfmt\" : \"source_video_pixfmt\" , \"output_framerate\" : \"source_video_framerate\" , } # iterate over source metadata keys and sanitize it for key in default_keys or []: if key == \"source\" : # metadata properties that cannot be altered logger . warning ( \"` {} ` metadata property value cannot be altered. Discarding!\" . format ( key ) ) elif key in self . __missing_prop : # missing metadata properties are unavailable and read-only # notify user about alternative counterpart property (if available) logger . warning ( \"` {} ` metadata property is read-only\" . format ( key ) + ( \". Try updating ` {} ` property instead!\" . format ( counterpart_prop [ key ] ) if key in counterpart_prop . keys () else \" and cannot be updated!\" ) ) elif isinstance ( value [ key ], type ( self . __sourcer_metadata [ key ])): # check if correct datatype as original self . __verbose_logs and logger . info ( \"Updating ` {} ` {} metadata property to ` {} `.\" . format ( key , \" and its counterpart\" if key in counterpart_prop . values () else \"\" , value [ key ], ) ) # update source metadata if valid self . __sourcer_metadata [ key ] = value [ key ] # also update missing counterpart property (if available) counter_key = next ( ( k for k , v in counterpart_prop . items () if v == key ), \"\" ) if counter_key : self . __missing_prop [ counter_key ] = value [ key ] else : # otherwise discard and log it logger . warning ( \"Manually assigned ` {} ` metadata property value is of invalid type. Discarding!\" ) . format ( key ) # delete invalid key del value [ key ] # There is no concept of a tuple in the JSON format. # Python's `json` module converts Python tuples to JSON lists # because that's the closest thing in JSON to a tuple. any ( isinstance ( value [ x ], tuple ) for x in value ) and logger . warning ( \"All TUPLE metadata properties will be converted to LIST datatype. Read docs for more details.\" ) # update user-defined metadata self . __user_metadata . update ( value ) else : # otherwise raise error raise ValueError ( \"Invalid datatype metadata assigned. Aborting!\" ) def __launch_FFdecoderline ( self , input_params , output_params ): \"\"\" This Internal method executes FFmpeg pipeline arguments inside a `subprocess` pipe in a new process. Parameters: input_params (dict): Input FFmpeg parameters output_params (dict): Output FFmpeg parameters \"\"\" # convert input parameters to list input_parameters = dict2Args ( input_params ) # convert output parameters to list output_parameters = dict2Args ( output_params ) # format command cmd = ( [ self . __ffmpeg ] + ([ \"-hide_banner\" ] if not self . __verbose_logs else []) + self . __ffmpeg_prefixes + input_parameters + ( [ \"-f\" , self . __sourcer_metadata [ \"source_demuxer\" ]] if ( \"source_demuxer\" in self . __sourcer_metadata . keys ()) else [] ) + [ \"-i\" , self . __sourcer_metadata [ \"source\" ]] + output_parameters + [ \"-f\" , \"rawvideo\" , \"-\" ] ) # compose the FFmpeg process if self . __verbose_logs : logger . debug ( \"Executing FFmpeg command: ` {} `\" . format ( \" \" . join ( cmd ))) # In debugging mode self . __process = sp . Popen ( cmd , stdin = sp . DEVNULL , stdout = sp . PIPE , stderr = None ) else : # In silent mode self . __process = sp . Popen ( cmd , stdin = sp . DEVNULL , stdout = sp . PIPE , stderr = sp . DEVNULL ) def terminate ( self ): \"\"\" Safely terminates all processes. \"\"\" # signal we are closing self . __verbose_logs and logger . debug ( \"Terminating FFdecoder Pipeline...\" ) self . __terminate_stream = True # check if no process was initiated at first place if self . __process is None or not ( self . __process . poll () is None ): logger . info ( \"Pipeline already terminated.\" ) return # Attempt to close pipeline. # close `stdin` output self . __process . stdin and self . __process . stdin . close () # close `stdout` output self . __process . stdout and self . __process . stdout . close () # terminate/kill process if still processing if self . __process . poll () is None : # demuxers prefer kill self . __process . kill () # wait if not exiting self . __process . wait () self . __process = None logger . info ( \"Pipeline terminated successfully.\" )","title":"FFdecoder API"},{"location":"reference/ffdecoder/#deffcode.ffdecoder.FFdecoder.metadata","text":"A property object that dumps metadata information as JSON string. Returns: Metadata as JSON string.","title":"metadata"},{"location":"reference/ffdecoder/#deffcode.ffdecoder.FFdecoder.__enter__","text":"Handles entry with the with statement. See PEP343 -- The 'with' statement' . Returns: Output of formulate() method. Source code in deffcode/ffdecoder.py def __enter__ ( self ): \"\"\" Handles entry with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/). **Returns:** Output of `formulate()` method. \"\"\" return self . formulate ()","title":"__enter__()"},{"location":"reference/ffdecoder/#deffcode.ffdecoder.FFdecoder.__exit__","text":"Handles exit with the with statement. See PEP343 -- The 'with' statement' . Source code in deffcode/ffdecoder.py def __exit__ ( self , exc_type , exc_val , exc_tb ): \"\"\" Handles exit with the `with` statement. See [PEP343 -- The 'with' statement'](https://peps.python.org/pep-0343/). \"\"\" self . terminate ()","title":"__exit__()"},{"location":"reference/ffdecoder/#deffcode.ffdecoder.FFdecoder.__init__","text":"This constructor method initializes the object state and attributes of the FFdecoder Class. Parameters: Name Type Description Default source str defines the input( -i ) source filename/URL/device-name/device-path. required source_demuxer str specifies the demuxer( -f ) for the input source. None frame_format str sets pixel format( -pix_fmt ) of the decoded frames. None custom_ffmpeg str assigns the location of custom path/directory for custom FFmpeg executable. '' verbose bool enables/disables verbose. False ffparams dict provides the flexibility to control supported internal and FFmpeg parameters. {} Source code in deffcode/ffdecoder.py def __init__ ( self , source , source_demuxer = None , frame_format = None , custom_ffmpeg = \"\" , verbose = False , ** ffparams ): \"\"\" This constructor method initializes the object state and attributes of the FFdecoder Class. Parameters: source (str): defines the input(`-i`) source filename/URL/device-name/device-path. source_demuxer (str): specifies the demuxer(`-f`) for the input source. frame_format (str): sets pixel format(`-pix_fmt`) of the decoded frames. custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executable. verbose (bool): enables/disables verbose. ffparams (dict): provides the flexibility to control supported internal and FFmpeg parameters. \"\"\" # enable verbose if specified self . __verbose_logs = ( verbose if ( verbose and isinstance ( verbose , bool )) else False ) # define whether initializing self . __initializing = True # define frame pixel-format for decoded frames self . __frame_format = ( frame_format . lower () . strip () if isinstance ( frame_format , str ) else None ) # handles user-defined parameters self . __extra_params = {} # handle process to be frames written self . __process = None # handle exclusive metadata self . __ff_pixfmt_metadata = None # metadata self . __raw_frame_num = None # raw-frame number self . __raw_frame_pixfmt = None # raw-frame pixformat self . __raw_frame_dtype = None # raw-frame dtype self . __raw_frame_depth = None # raw-frame depth self . __raw_frame_resolution = None # raw-frame resolution/dimension # define supported mode of operation self . __supported_opmodes = { \"av\" : \"Audio-Video\" , # audio is only for pass-through, not really for audio decoding yet. \"vo\" : \"Video-Only\" , \"imgseq\" : \"Image-Sequence\" , # \"ao\":\"Audio-Only\", # reserved for future } # operation mode variable self . __opmode = None # handle termination self . __terminate_stream = False # cleans and reformat user-defined parameters self . __extra_params = { str ( k ) . strip (): str ( v ) . strip () if not ( v is None ) and not isinstance ( v , ( dict , list , int , float , tuple )) else v for k , v in ffparams . items () } # handle custom Sourcer API params sourcer_params = self . __extra_params . pop ( \"-custom_sourcer_params\" , {}) # reset improper values sourcer_params = {} if not isinstance ( sourcer_params , dict ) else sourcer_params # handle user ffmpeg pre-headers(parameters such as `-re`) parameters (must be a list) self . __ffmpeg_prefixes = self . __extra_params . pop ( \"-ffprefixes\" , []) # check if not valid type if not isinstance ( self . __ffmpeg_prefixes , list ): # log it logger . warning ( \"Discarding invalid `-ffprefixes` value of wrong type: ` {} `!\" . format ( type ( self . __ffmpeg_prefixes ) . __name__ ) ) # reset improper values self . __ffmpeg_prefixes = [] else : # also pass valid ffmpeg pre-headers to Sourcer API sourcer_params [ \"-ffprefixes\" ] = self . __ffmpeg_prefixes # pass parameter(if specified) to Sourcer API, specifying where to save the downloaded FFmpeg Static # assets on Windows(if specified) sourcer_params [ \"-ffmpeg_download_path\" ] = self . __extra_params . pop ( \"-ffmpeg_download_path\" , \"\" ) # handle video and audio stream indexes in case of multiple ones. default_stream_indexes = self . __extra_params . pop ( \"-default_stream_indexes\" , ( 0 , 0 ) ) # reset improper values default_stream_indexes = ( ( 0 , 0 ) if not isinstance ( default_stream_indexes , ( list , tuple )) else default_stream_indexes ) # pass FFmpeg filter to Sourcer API params for processing if set ([ \"-vf\" , \"-filter_complex\" ]) . intersection ( self . __extra_params . keys ()): key = \"-vf\" if \"-vf\" in self . __extra_params else \"-filter_complex\" sourcer_params [ key ] = self . __extra_params [ key ] # define dict to store user-defined parameters self . __user_metadata = {} # extract and assign source metadata as dict ( self . __sourcer_metadata , self . __missing_prop ) = ( Sourcer ( source = source , source_demuxer = source_demuxer , verbose = verbose , custom_ffmpeg = custom_ffmpeg if isinstance ( custom_ffmpeg , str ) else \"\" , ** sourcer_params ) . probe_stream ( default_stream_indexes = default_stream_indexes ) . retrieve_metadata ( force_retrieve_missing = True ) ) # handle valid FFmpeg assets location self . __ffmpeg = self . __sourcer_metadata [ \"ffmpeg_binary_path\" ] # handle pass-through audio mode works in conjunction with WriteGear [TODO] self . __passthrough_mode = self . __extra_params . pop ( \"-passthrough_audio\" , False ) if not ( isinstance ( self . __passthrough_mode , bool )): self . __passthrough_mode = False # handle mode of operation if self . __sourcer_metadata [ \"source_has_image_sequence\" ]: # image-sequence mode self . __opmode = \"imgseq\" elif ( self . __sourcer_metadata [ \"source_has_video\" ] # audio is only for pass-through, not really for audio decoding yet. and self . __sourcer_metadata [ \"source_has_audio\" ] and self . __passthrough_mode # [TODO] ): self . __opmode = \"av\" # elif __defop_mode == \"ao\" and self.__sourcer_metadata.contains_audio: # [TODO] # self.__opmode = \"ao\" elif self . __sourcer_metadata [ \"source_has_video\" ]: # video-only mode self . __opmode = \"vo\" else : # raise if unknown mode raise ValueError ( \"Unable to find any usable video stream in the given source!\" ) # store as metadata self . __missing_prop [ \"ffdecoder_operational_mode\" ] = self . __supported_opmodes [ self . __opmode ] # handle user-defined output framerate __framerate = self . __extra_params . pop ( \"-framerate\" , None ) if ( isinstance ( __framerate , str ) and __framerate == \"null\" # special mode to discard `-framerate/-r` parameter ): self . __inputframerate = __framerate elif isinstance ( __framerate , ( float , int )): self . __inputframerate = float ( __framerate ) if __framerate > 0.0 else 0.0 else : # warn if wrong type not ( __framerate is None ) and logger . warning ( \"Discarding invalid `-framerate` value of wrong type ` {} `!\" . format ( type ( __framerate ) . __name__ ) ) # reset to default self . __inputframerate = 0.0 # handle user defined decoded frame resolution self . __custom_resolution = self . __extra_params . pop ( \"-custom_resolution\" , None ) if ( isinstance ( self . __custom_resolution , str ) and self . __custom_resolution == \"null\" # special mode to discard `-size/-s` parameter ) or ( isinstance ( self . __custom_resolution , ( list , tuple )) and len ( self . __custom_resolution ) == 2 # valid resolution(must be a tuple or list) ): # log it self . __verbose_logs and not isinstance ( self . __custom_resolution , str ) and logger . debug ( \"Setting raw frames size: ` {} `.\" . format ( self . __custom_resolution ) ) else : # log it not ( self . __custom_resolution is None ) and logger . warning ( \"Discarding invalid `-custom_resolution` value: ` {} `!\" . format ( self . __custom_resolution ) ) # reset improper values self . __custom_resolution = None","title":"__init__()"},{"location":"reference/ffdecoder/#deffcode.ffdecoder.FFdecoder.formulate","text":"This method formulates all necessary FFmpeg pipeline arguments and executes it inside the FFmpeg subprocess pipe. Returns: A reference to the FFdecoder class object. Source code in deffcode/ffdecoder.py def formulate ( self ): \"\"\" This method formulates all necessary FFmpeg pipeline arguments and executes it inside the FFmpeg `subprocess` pipe. **Returns:** A reference to the FFdecoder class object. \"\"\" # assign values to class variables on first run if self . __initializing : # prepare parameter dict input_params = OrderedDict () output_params = OrderedDict () # dynamically pre-assign a default video-decoder (if not assigned by user). supported_vdecodecs = get_supported_vdecoders ( self . __ffmpeg ) default_vdecodec = ( self . __sourcer_metadata [ \"source_video_decoder\" ] if self . __sourcer_metadata [ \"source_video_decoder\" ] in supported_vdecodecs else \"unknown\" ) if \"-c:v\" in self . __extra_params : self . __extra_params [ \"-vcodec\" ] = self . __extra_params . pop ( \"-c:v\" , default_vdecodec ) # handle image sequence separately if self . __opmode == \"imgseq\" : # -vcodec is discarded by default # (This is correct or maybe -vcodec required in some unknown case) [TODO] self . __extra_params . pop ( \"-vcodec\" , None ) elif ( \"-vcodec\" in self . __extra_params and self . __extra_params [ \"-vcodec\" ] is None ): # special case when -vcodec is not needed intentionally self . __extra_params . pop ( \"-vcodec\" , None ) else : # assign video decoder selected here. if not \"-vcodec\" in self . __extra_params : input_params [ \"-vcodec\" ] = default_vdecodec else : input_params [ \"-vcodec\" ] = self . __extra_params . pop ( \"-vcodec\" , default_vdecodec ) if ( default_vdecodec != \"unknown\" and not input_params [ \"-vcodec\" ] in supported_vdecodecs ): # reset to default if not supported logger . warning ( \"Provided FFmpeg does not support ` {} ` video decoder. Switching to default supported ` {} ` decoder!\" . format ( input_params [ \"-vcodec\" ], default_vdecodec ) ) input_params [ \"-vcodec\" ] = default_vdecodec # raise error if not valid decoder found if not input_params [ \"-vcodec\" ] in supported_vdecodecs : raise RuntimeError ( \"Provided FFmpeg does not support any known usable video-decoders.\" \" Either define your own manually or switch to another FFmpeg binaries(if available).\" ) # handle user-defined number of frames. if \"-vframes\" in self . __extra_params : self . __extra_params [ \"-frames:v\" ] = self . __extra_params . pop ( \"-vframes\" , None ) if \"-frames:v\" in self . __extra_params : value = self . __extra_params . pop ( \"-frames:v\" , None ) if not ( value is None ) and value > 0 : output_params [ \"-frames:v\" ] = value # dynamically calculate default raw-frames pixel format(if not assigned by user). # notify FFmpeg `-pix_fmt` parameter cannot be assigned directly if \"-pix_fmt\" in self . __extra_params : logger . warning ( \"Discarding user-defined `-pix_fmt` value as it can only be assigned with `frame_format` parameter!\" ) self . __extra_params . pop ( \"-pix_fmt\" , None ) # get supported FFmpeg pixfmt data with depth and bpp(bits-per-pixel) self . __ff_pixfmt_metadata = get_supported_pixfmts ( self . __ffmpeg ) supported_pixfmts = [ fmts [ 0 ] for fmts in self . __ff_pixfmt_metadata ] # calculate default pixel-format # Check special case - `frame_format`(or `-pix_fmt`) parameter discarded from pipeline self . __frame_format == \"null\" and logger . critical ( \"Manually discarding `frame_format`(or `-pix_fmt`) parameter from this pipeline.\" ) # choose between rgb24(if available) or source pixel-format # otherwise, only source pixel-format for special case default_pixfmt = ( \"rgb24\" if \"rgb24\" in supported_pixfmts and self . __frame_format != \"null\" else self . __sourcer_metadata [ \"source_video_pixfmt\" ] ) # assign output raw-frames pixel format rawframe_pixfmt = None if ( not ( self . __frame_format is None ) and self . __frame_format in supported_pixfmts ): # check if valid and supported `frame_format` parameter assigned rawframe_pixfmt = self . __frame_format . strip () self . __verbose_logs and logger . info ( \"User-defined ` {} ` frame pixel-format will be used for this pipeline.\" . format ( rawframe_pixfmt ) ) elif ( \"output_frames_pixfmt\" in self . __sourcer_metadata # means `format` filter is defined and self . __sourcer_metadata [ \"output_frames_pixfmt\" ] in supported_pixfmts ): # assign if valid and supported rawframe_pixfmt = self . __sourcer_metadata [ \"output_frames_pixfmt\" ] . strip () self . __verbose_logs and logger . info ( \"FFmpeg filter values will be used for this pipeline for defining output pixel-format.\" ) else : # reset to default if not supported rawframe_pixfmt = default_pixfmt # log it accordingly if self . __frame_format is None : logger . info ( \"Using default ` {} ` pixel-format for this pipeline.\" . format ( default_pixfmt ) ) else : logger . warning ( \" {} Switching to default ` {} ` pixel-format!\" . format ( \"Provided FFmpeg does not supports ` {} ` pixel-format.\" . format ( self . __sourcer_metadata [ \"output_frames_pixfmt\" ] if \"output_frames_pixfmt\" in self . __sourcer_metadata else self . __frame_format ) if self . __frame_format != \"null\" else \"No usable pixel-format defined.\" , default_pixfmt , ) ) # dynamically calculate raw-frame datatype based on pixel-format selected ( self . __raw_frame_depth , rawframesbpp ) = [ ( int ( x [ 1 ]), int ( x [ 2 ])) for x in self . __ff_pixfmt_metadata if x [ 0 ] == rawframe_pixfmt ][ 0 ] raw_bit_per_component = rawframesbpp // self . __raw_frame_depth if 4 <= raw_bit_per_component <= 8 : self . __raw_frame_dtype = np . dtype ( \"u1\" ) elif 8 < raw_bit_per_component <= 16 and rawframe_pixfmt . endswith ( ( \"le\" , \"be\" ) ): if rawframe_pixfmt . endswith ( \"le\" ): self . __raw_frame_dtype = np . dtype ( \"<u2\" ) else : self . __raw_frame_dtype = np . dtype ( \">u2\" ) else : # reset to both pixel-format and datatype to default if not supported not ( self . __frame_format is None ) and logger . warning ( \"Selected pixel-format ` {} ` dtype is not supported by FFdecoder API. Switching to default `rgb24` pixel-format!\" . format ( rawframe_pixfmt ) ) rawframe_pixfmt = \"rgb24\" self . __raw_frame_dtype = np . dtype ( \"u1\" ) # Check if not special case if self . __frame_format != \"null\" : # assign to FFmpeg pipeline otherwise output_params [ \"-pix_fmt\" ] = rawframe_pixfmt # assign to global parameter further usage self . __raw_frame_pixfmt = rawframe_pixfmt # also override as metadata(if available) if \"output_frames_pixfmt\" in self . __sourcer_metadata : self . __sourcer_metadata [ \"output_frames_pixfmt\" ] = self . __raw_frame_pixfmt # handle raw-frame resolution # notify FFmpeg `-s` parameter cannot be assigned directly if \"-s\" in self . __extra_params : logger . warning ( \"Discarding user-defined `-s` FFmpeg parameter as it can only be assigned with `-custom_resolution` attribute! Read docs for more details.\" ) self . __extra_params . pop ( \"-s\" , None ) # assign output rawframe resolution if not ( self . __custom_resolution is None ) and not isinstance ( self . __custom_resolution , str ): # assign if assigned by user and not \"null\"(str) self . __raw_frame_resolution = self . __custom_resolution self . __verbose_logs and logger . info ( \"User-defined ` {} ` frame resolution will be used for this pipeline.\" . format ( self . __raw_frame_resolution ) ) elif ( \"output_frames_resolution\" in self . __sourcer_metadata # means `scale` filter is defined and self . __sourcer_metadata [ \"output_frames_resolution\" ] and len ( self . __sourcer_metadata [ \"output_frames_resolution\" ]) == 2 ): # calculate raw-frame resolution/dimensions based on output. self . __raw_frame_resolution = self . __sourcer_metadata [ \"output_frames_resolution\" ] elif ( self . __sourcer_metadata [ \"source_video_resolution\" ] and len ( self . __sourcer_metadata [ \"source_video_resolution\" ]) == 2 ): # calculate raw-frame resolution/dimensions based on source. self . __raw_frame_resolution = self . __sourcer_metadata [ \"source_video_resolution\" ] else : # otherwise raise error raise RuntimeError ( \"Both source and output metadata values found Invalid with {} `-custom_resolution` attribute. Aborting!\" . format ( \"null\" if isinstance ( self . __inputframerate , str ) else \"undefined\" ) ) # special mode to discard `-size/-s` FFmpeg parameter completely if isinstance ( self . __custom_resolution , str ): logger . critical ( \"Manually discarding `-size/-s` FFmpeg parameter from this pipeline.\" ) else : # add to pipeline dimensions = \" {} x {} \" . format ( self . __raw_frame_resolution [ 0 ], self . __raw_frame_resolution [ 1 ] ) output_params [ \"-s\" ] = str ( dimensions ) # log if filters or default source is used self . __verbose_logs and ( self . __custom_resolution is None or isinstance ( self . __custom_resolution , str ) ) and logger . info ( \" {} for this pipeline for defining output resolution.\" . format ( \"FFmpeg filter values will be used\" if \"output_frames_resolution\" in self . __sourcer_metadata else \"Default source resolution will be used\" ) ) # dynamically calculate raw-frame framerate based on source (if not assigned by user). if ( not isinstance ( self . __inputframerate , str ) and self . __inputframerate > 0.0 ): # assign if assigned by user and not \"null\"(str) output_params [ \"-framerate\" ] = str ( self . __inputframerate ) self . __verbose_logs and logger . info ( \"User-defined ` {} ` output framerate will be used for this pipeline.\" . format ( str ( self . __inputframerate ) ) ) elif ( \"output_framerate\" in self . __sourcer_metadata # means `fps` filter is defined and self . __sourcer_metadata [ \"output_framerate\" ] > 0.0 ): # special mode to discard `-framerate/-r` FFmpeg parameter completely if self . __inputframerate == \"null\" : logger . critical ( \"Manually discarding `-framerate/-r` FFmpeg parameter from this pipeline.\" ) else : # calculate raw-frame framerate based on output output_params [ \"-framerate\" ] = str ( self . __sourcer_metadata [ \"output_framerate\" ] ) self . __verbose_logs and logger . info ( \"FFmpeg filter values will be used for this pipeline for defining output framerate.\" ) elif self . __sourcer_metadata [ \"source_video_framerate\" ] > 0.0 : # special mode to discard `-framerate/-r` FFmpeg parameter completely if self . __inputframerate == \"null\" : logger . critical ( \"Manually disabling `-framerate/-r` FFmpeg parameter for this pipeline.\" ) else : # calculate raw-frame framerate based on source output_params [ \"-framerate\" ] = str ( self . __sourcer_metadata [ \"source_video_framerate\" ] ) self . __verbose_logs and logger . info ( \"Default source framerate will be used for this pipeline for defining output framerate.\" ) else : # otherwise raise error raise RuntimeError ( \"Both source and output metadata values found Invalid with {} `-framerate` attribute. Aborting!\" . format ( \"null\" if isinstance ( self . __inputframerate , str ) else \"undefined\" ) ) # add rest to output parameters output_params . update ( self . __extra_params ) # dynamically calculate raw-frame numbers based on source (if not assigned by user). # TODO Added support for `-re -stream_loop` and `-loop` if \"-frames:v\" in input_params : self . __raw_frame_num = input_params [ \"-frames:v\" ] elif ( not ( self . __sourcer_metadata [ \"approx_video_nframes\" ] is None ) and self . __sourcer_metadata [ \"approx_video_nframes\" ] > 0 ): self . __raw_frame_num = self . __sourcer_metadata [ \"approx_video_nframes\" ] else : self . __raw_frame_num = None # log that number of frames are unknown self . __verbose_logs and logger . info ( \"Live/Network Stream detected! Number of frames in given source are not known.\" ) # log Mode of Operation self . __verbose_logs and logger . critical ( \"Activating {} Mode of Operation.\" . format ( self . __supported_opmodes [ self . __opmode ] ) ) # compose the Pipeline using formulated FFmpeg parameters self . __launch_FFdecoderline ( input_params , output_params ) # inform the initialization is completed self . __initializing = False else : # warn if pipeline is recreated logger . error ( \"This pipeline is already created and running!\" ) return self","title":"formulate()"},{"location":"reference/ffdecoder/#deffcode.ffdecoder.FFdecoder.generateFrame","text":"This method returns a Generator function (also an Iterator using next() ) of video frames, grabbed continuously from the buffer. Source code in deffcode/ffdecoder.py def generateFrame ( self ): \"\"\" This method returns a [Generator function](https://wiki.python.org/moin/Generators) _(also an Iterator using `next()`)_ of video frames, grabbed continuously from the buffer. \"\"\" if self . __raw_frame_num is None or not self . __raw_frame_num : while not self . __terminate_stream : # infinite raw frames frame = self . __fetchNextFrame () if frame is None : self . __terminate_stream = True break yield frame else : for _ in range ( self . __raw_frame_num ): # finite raw frames frame = self . __fetchNextFrame () if frame is None : self . __terminate_stream = True break yield frame","title":"generateFrame()"},{"location":"reference/ffdecoder/#deffcode.ffdecoder.FFdecoder.terminate","text":"Safely terminates all processes. Source code in deffcode/ffdecoder.py def terminate ( self ): \"\"\" Safely terminates all processes. \"\"\" # signal we are closing self . __verbose_logs and logger . debug ( \"Terminating FFdecoder Pipeline...\" ) self . __terminate_stream = True # check if no process was initiated at first place if self . __process is None or not ( self . __process . poll () is None ): logger . info ( \"Pipeline already terminated.\" ) return # Attempt to close pipeline. # close `stdin` output self . __process . stdin and self . __process . stdin . close () # close `stdout` output self . __process . stdout and self . __process . stdout . close () # terminate/kill process if still processing if self . __process . poll () is None : # demuxers prefer kill self . __process . kill () # wait if not exiting self . __process . wait () self . __process = None logger . info ( \"Pipeline terminated successfully.\" )","title":"terminate()"},{"location":"reference/ffdecoder/params/","text":"FFdecoder API Parameters \u00b6 source \u00b6 This parameter defines the input source ( -i ) for decoding real-time frames. FFdecoder API will throw Assertion if source provided is invalid or missing. FFdecoder API checks for video bitrate or frame-size and framerate in video's metadata to ensure given input source has usable video stream available. Thereby, it will throw ValueError if it fails to find those parameters. Multiple video inputs are not yet supported! Data-Type: String. Its valid input can be one of the following: Filepath: Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: # initialize and formulate the decoder with `foo.mp4` source decoder = FFdecoder ( '/home/foo.mp4' ) . formulate () Related usage recipes can found here \u27b6 Image Sequence: Valid image sequence such as sequential( 'img%03d.png' ) or glob pattern( '*.png' ) or single (looping) image as input: Sequential Glob pattern Single (loop) image How to start with specific number image? You can use -start_number FFmpeg parameter if you want to start with specific number image: # define `-start_number` such as `5` ffparams = { \"-ffprefixes\" :[ \"-start_number\" , \"5\" ]} # initialize and formulate the decoder with define parameters decoder = FFdecoder ( 'img %03d .png' , verbose = True , ** ffparams ) . formulate () # initialize and formulate the decoder decoder = FFdecoder ( 'img %03d .png' ) . formulate () Bash-style globbing ( * represents any number of any characters) is useful if your images are sequential but not necessarily in a numerically sequential order. The glob pattern is not available on Windows builds. # define `-pattern_type glob` for accepting glob pattern sourcer_params = { \"-ffprefixes\" :[ \"-pattern_type\" , \"glob\" ]} # initialize and formulate the decoder with define parameters decoder = FFdecoder ( 'img*.png' , verbose = True , ** sourcer_params ) . formulate () # define `-loop 1` for looping ffparams = { \"-ffprefixes\" :[ \"-loop\" , \"1\" ]} # initialize and formulate the decoder with define parameters decoder = FFdecoder ( 'img.jpg' , verbose = True , ** ffparams ) . formulate () Related usage recipes can found here \u27b6 Network Address: Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://xx:yy@192.168.1.ee:fd/av0_0' as input: # define `rtsp_transport` or necessary parameters ffparams = { \"-ffprefixes\" :[ \"-rtsp_transport\" , \"tcp\" ]} # initialize and formulate the decoder with define parameters decoder = FFdecoder ( 'rtsp://xx:yy@192.168.1.ee:fd/av0_0' , verbose = True , ** ffparams ) . formulate () Related usage recipes can found here \u27b6 Video Capture Devices (Webcams): Valid video capture device's name (e.g. \"USB2.0 Camera\" ) or its path (e.g. \"/dev/video0\" on linux) or its index (e.g. \"0\" ) as input w.r.t source_demuxer parameter value in use. For example, for capturing \"USB2.0 Camera\" named device with dshow source demuxer on Windows, we can do as follows in FFdecoder API: Identifying and Specifying Device name/path/index and suitable Demuxer on different OSes Windows Linux MacOS Windows OS users can use the dshow (DirectShow) to list video input device which is the preferred option for Windows users. You can refer following steps to identify and specify your input video device's name: Identify Video Devices: You can locate your video device's name (already connected to your system) using dshow as follows: c: \\> ffmpeg.exe -list_devices true -f dshow -i dummy ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ dshow @ 03ACF580 ] DirectShow video devices [ dshow @ 03ACF580 ] \"Integrated Camera\" [ dshow @ 03ACF580 ] \"USB2.0 Camera\" [ dshow @ 03ACF580 ] DirectShow audio devices [ dshow @ 03ACF580 ] \"Microphone (Realtek High Definition Audio)\" [ dshow @ 03ACF580 ] \"Microphone (USB2.0 Camera)\" dummy: Immediate exit requested Specify Video Device's name: Then, you can specify and initialize your located Video device's name in FFdecoder API as follows: # initialize and formulate the decoder with \"USB2.0 Camera\" source for BGR24 output decoder = FFdecoder ( \"USB2.0 Camera\" , source_demuxer = \"dshow\" , frame_format = \"bgr24\" , verbose = True ) . formulate () [OPTIONAL] Specify Video Device's index along with name: If there are multiple Video devices with similar name, then you can use -video_device_number parameter to specify the arbitrary index of the particular device. For instance, to open second video device with name \"Camera\" you can do as follows: # define video_device_number as 1 (numbering start from 0) ffparams = { \"-ffprefixes\" :[ \"-video_device_number\" , \"1\" ]} # initialize and formulate the decoder with \"Camera\" source for BGR24 output decoder = FFdecoder ( \"Camera\" , source_demuxer = \"dshow\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () Linux OS users can use the video4linux2 (or its alias v4l2 ) to list to all capture video devices such as from an USB webcam. You can refer following steps to identify and specify your capture video device's path: Identify Video Devices: Linux systems tend to automatically create file device node/path when the device (e.g. an USB webcam) is plugged into the system, and has a name of the kind '/dev/videoN' , where N is a index associated to the device. To get the list of all available file device node/path on your Linux machine, you can use the v4l-ctl command. You can use sudo apt install v4l-utils APT command to install v4l-ctl tool on Debian-based Linux distros. $ v4l2-ctl --list-devices USB2.0 PC CAMERA ( usb-0000:00:1d.7-1 ) : /dev/video1 UVC Camera ( 046d:0819 ) ( usb-0000:00:1d.7-2 ) : /dev/video0 Specify Video Device's path: Then, you can specify and initialize your located Video device's path in FFdecoder API as follows: # initialize and formulate the decoder with \"/dev/video0\" source for BGR24 output decoder = FFdecoder ( \"/dev/video0\" , source_demuxer = \"v4l2\" , frame_format = \"bgr24\" , verbose = True ) . formulate () [OPTIONAL] Specify Video Device's additional specifications: You can also specify additional specifications (such as pixel format(s), video format(s), framerate, and frame dimensions) supported by your Video Device as follows: You can use ffmpeg -f v4l2 -list_formats all -i /dev/video0 terminal command to list available specifications. # define video device specifications ffparams = { \"-ffprefixes\" :[ \"-framerate\" , \"25\" , \"-video_size\" , \"640x480\" ]} # initialize and formulate the decoder with \"/dev/video0\" source for BGR24 output decoder = FFdecoder ( \"/dev/video0\" , source_demuxer = \"v4l2\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () MacOS users can use the AVFoundation to list input devices and is the currently recommended framework by Apple for streamgrabbing on Mac OSX-10.7 (Lion) and later as well as on iOS. You can refer following steps to identify and specify your capture video device's name or index on MacOS/OSX machines: QTKit is also available for streamgrabbing on Mac OS X 10.4 (Tiger) and later, but has been marked deprecated since OS X 10.7 (Lion) and may not be available on future releases. Identify Video Devices: Then, You can locate your Video device's name and index using avfoundation as follows: $ ffmpeg -f avfoundation -list_devices true -i \"\" ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation video devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] FaceTime HD camera ( built-in ) [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Capture screen 0 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation audio devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] Blackmagic Audio [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Built-in Microphone Specify Video Device's name or index: Then, you can specify and initialize your located Video device in FFdecoder API using its either the name or the index shown in the device listing: Using device's index Using device's name # initialize and formulate the decoder with `1` index source for BGR24 output decoder = FFdecoder ( \"1\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True ) . formulate () When specifying device's name, abbreviations using just the beginning of the device name are possible. Thus, to capture from a device named \"Integrated iSight-camera\" just \"Integrated\" is sufficient: # initialize and formulate the decoder with \"Integrated iSight-camera\" source for BGR24 output decoder = FFdecoder ( \"Integrated\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True ) . formulate () [OPTIONAL] Specify Default Video device: You can also use the default device which is usually the first device in the listing by using \"default\" as source: # initialize and formulate the decoder with \"default\" source for BGR24 output decoder = FFdecoder ( \"default\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True ) . formulate () If these steps doesn't work for you then reach us out on Gitter \u27b6 Community channel # initialize and formulate the decoder with \"USB2.0 Camera\" source for BGR24 output decoder = FFdecoder ( \"USB2.0 Camera\" , source_demuxer = \"dshow\" , frame_format = \"bgr24\" , verbose = True ) . formulate () Related usage recipe can found here \u27b6 Screen Capturing/Recording: Valid screen capture device's name (e.g. \"desktop\" ) or its index (e.g. \":0.0\" ) as input w.r.t source_demuxer parameter value in use. You can also specify additional specifications (such as limiting capture area to a region, setting capturing coordinates, whether to capture mouse pointer and clicks etc.) . For example, for capturing \"0:\" indexed device with avfoundation source demuxer on MacOS along with mouse pointer and clicks, we can do as follows in FFdecoder API: Specifying suitable Parameter(s) and Demuxer for Capturing your Desktop on different OSes Windows Linux MacOS Windows OS users can use the gdigrab to grab video from the Windows screen. You can refer following steps to specify source for capturing different regions of your display: For Windows OS users dshow is also available for grabbing frames from your desktop. But it is highly unreliable and don't works most of the times. Capturing entire desktop: For capturing all your displays as one big contiguous display, you can specify source, suitable parameters and demuxers in FFdecoder API as follows: # define framerate ffparams = { \"-framerate\" : \"30\" } # initialize and formulate the decoder with \"desktop\" source for BGR24 output decoder = FFdecoder ( \"desktop\" , source_demuxer = \"gdigrab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () Capturing a region: If you want to limit capturing to a region, and show the area being grabbed, you can specify source and suitable parameters in FFdecoder API as follows: x_offset and y_offset specify the offsets of the grabbed area with respect to the top-left border of the desktop screen. They default to 0 . # define suitable parameters ffparams = { \"-framerate\" : \"30\" , # input framerate \"-ffprefixes\" : [ \"-offset_x\" , \"10\" , \"-offset_y\" , \"20\" , # grab at position 10,20 \"-video_size\" , \"640x480\" , # frame size \"-show_region\" , \"1\" , # show only region ], } # initialize and formulate the decoder with \"desktop\" source for BGR24 output decoder = FFdecoder ( \"desktop\" , source_demuxer = \"gdigrab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () Linux OS users can use the x11grab to capture an X11 display. You can refer following steps to specify source for capturing different regions of your display: For X11 display, the source input has the syntax: \"display_number.screen_number[+x_offset,y_offset]\" . Capturing entire desktop: For capturing all your displays as one big contiguous display, you can specify source, suitable parameters and demuxers in FFdecoder API as follows: # define framerate ffparams = { \"-framerate\" : \"30\" } # initialize and formulate the decoder with \":0.0\" desktop source for BGR24 output decoder = FFdecoder ( \":0.0\" , source_demuxer = \"x11grab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () Capturing a region: If you want to limit capturing to a region, and show the area being grabbed, you can specify source and suitable parameters in FFdecoder API as follows: x_offset and y_offset specify the offsets of the grabbed area with respect to the top-left border of the X11 screen. They default to 0 . # define suitable parameters ffparams = { \"-framerate\" : \"30\" , # input framerate \"-ffprefixes\" : [ \"-video_size\" , \"1024x768\" , # frame size ], } # initialize and formulate the decoder with \":0.0\" desktop source(starting with the upper-left corner at x=10, y=20) # for BGR24 output decoder = FFdecoder ( \":0.0+10,20\" , source_demuxer = \"x11grab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () MacOS users can use the AVFoundation to list input devices and is the currently recommended framework by Apple for streamgrabbing on Mac OSX-10.7 (Lion) and later as well as on iOS. You can refer following steps to identify and specify your capture video device's name or index on MacOS/OSX machines: QTKit is also available for streamgrabbing on Mac OS X 10.4 (Tiger) and later, but has been marked deprecated since OS X 10.7 (Lion) and may not be available on future releases. Identify Video Devices: You can enumerate all the available input devices including screens ready to be captured using avfoundation as follows: $ ffmpeg -f avfoundation -list_devices true -i \"\" ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation video devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] FaceTime HD camera ( built-in ) [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Capture screen 0 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation audio devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] Blackmagic Audio [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Built-in Microphone Capturing entire desktop: Then, you can specify and initialize your located screens in FFdecoder API using its index shown: # initialize and formulate the decoder with `0:` index desktop screen for BGR24 output decoder = FFdecoder ( \"0:\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True ) . formulate () [OPTIONAL] Capturing mouse: You can also specify additional specifications to capture the mouse pointer and screen mouse clicks as follows: # define specifications ffparams = { \"-ffprefixes\" :[ \"-capture_cursor\" , \"1\" , \"-capture_mouse_clicks\" , \"0\" ]} # initialize and formulate the decoder with \"0:\" source for BGR24 output decoder = FFdecoder ( \"0:\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () If these steps doesn't work for you then reach us out on Gitter \u27b6 Community channel # define specifications ffparams = { \"-ffprefixes\" :[ \"-capture_cursor\" , \"1\" , \"-capture_mouse_clicks\" , \"0\" ]} # initialize and formulate the decoder with \"0:\" source for BGR24 output decoder = FFdecoder ( \"0:\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () Related usage recipe can found here \u27b6 Virtual Sources: Valid filtergraph to use as input with lavfi ( Libavfilter input virtual device) source that reads data from the open output pads of a libavfilter filtergraph. For example, for generating and decoding Mandelbrot graph of 1280x720 frame size and 30 framerate using lavfi input virtual device, we can do as follows in FFdecoder API: # initialize and formulate the decoder with \"mandelbrot\" source of # `1280x720` frame size and `30` framerate for BGR24 output decoder = FFdecoder ( \"mandelbrot=size=1280x720:rate=30\" , source_demuxer = \"lavfi\" , frame_format = \"bgr24\" , ) . formulate () Related usage recipes can found here \u27b6 source_demuxer \u00b6 This parameter specifies the demuxer( -f ) for the input source (such as dshow , v4l2 , gdigrab etc.) to support Live Feed Devices, as well as lavfi (Libavfilter input virtual device) that reads data from the open output pads of a libavfilter filtergraph. Any invalid or unsupported value to source_demuxer parameter value will raise Assertion error! Use ffmpeg -demuxers terminal command to lists all FFmpeg supported demuxers. Data-Type: String Default Value: Its default value is None . Usage: # initialize and formulate the decoder with `dshow` demuxer decoder = FFdecoder ( \"foo.mp4\" , source_demuxer = \"dshow\" ) . formulate () frame_format \u00b6 This parameter select the pixel format for output video frames (such as gray for grayscale output) . Any invalid or unsupported value to frame_format parameter will discarded! Any improper frame_format parameter value (i.e. either null (special-case), undefined, or invalid type) , then -pix_fmt FFmpeg parameter value in Decoding pipeline uses output_frames_pixfmt metadata property extracted from Output Stream. Thereby, in case if no valid output_frames_resolution metadata property is found, then API finally defaults to Default pixel-format 1 (calculated variably) . The output_frame_pixfmt metadata property is only available when FFmpeg filters via. -vf or -filter_complex are manually defined. Use frame_format = \"null\" to manually discard -pix_fmt FFmpeg parameter entirely from Decoding pipeline. This feature allows users to manually skip -pix_fmt FFmpeg parameter in Decoding pipeline, essentially for using only format filter values, or even better, let FFmpeg itself choose the best available output frame pixel-format for the given source. Data-Type: String Default Value: Its default value is Default pixel-format 1 (calculated variably) . Usage: # initialize and formulate the decoder for grayscale frames decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"gray\" ) . formulate () Use ffmpeg -pix_fmts terminal command to lists all FFmpeg supported pixel formats. Various Pixel formats related usage recipes can found here \u27b6 custom_ffmpeg \u00b6 This parameter can be used to manually assigns the system file-path/directory where the custom or downloaded FFmpeg executable is located. Behavior on Windows If custom FFmpeg executable binary file-path/directory is not assigned through custom_ffmpeg parameter on Windows machine, then FFdecoder API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine . More information can be found here \u27b6 . How to change FFmpeg Static Binaries download directory? You can use -ffmpeg_download_path (via. -custom_sourcer_params ) exclusive parameter in FFdecoder API to set the custom directory for downloading FFmpeg Static Binaries during the Auto-Installation step on Windows Machines. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. C:/User/temp ) on your windows machine. It can be used as follows in FFdecoder API: # # define suitable parameter to download at \"C:/User/foo/foo1\" ffparams = { \"-custom_sourcer_params\" : { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" }} # initialize and formulate the decoder FFdecoder ( \"foo.mp4\" , verbose = True , ** ffparams ) . formulate () If binaries were not found at the manually specified path, DeFFcode APIs will throw RuntimeError ! Data-Type: String Default Value: Its default value is None . Usage: # If ffmpeg executables are located at \"/foo/foo1/ffmpeg\" FFdecoder ( \"foo.mp4\" , custom_ffmpeg = \"/foo/foo1/ffmpeg\" ) . formulate () verbose \u00b6 This parameter enables verbose logs (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: # initialize and formulate decoder with verbose logs FFdecoder ( \"foo.mp4\" , verbose = True ) . formulate () ffparams \u00b6 This dictionary parameter accepts all supported parameters formatted as its attributes: Data-Type: Dictionary Default Value: Its default value is {} . Supported Parameters \u00b6 A. FFmpeg Parameters \u00b6 Almost any FFmpeg parameter (supported by installed FFmpeg) can be passed as dictionary attributes in ffparams parameter. Let's assume we want to 00:00:01.45 (or 1045msec) in time and decode one single frame from given source (say foo.mp4 ) in FFdecoder API, then we can assign required FFmpeg parameters as dictionary attributes as follows: Kindly read FFmpeg Docs carefully before passing any additional values to ffparams parameter. Wrong invalid values may result in undesired errors or no output at all. All FFmpeg parameters are case-sensitive. Remember to double check every parameter if any error(s) occurred. # define the FFmpeg parameter to seek to 00:00:01.45(or 1s and 45msec) # in time and get one single frame ffparams = { \"-ss\" : \"00:00:01.45\" , \"-frames:v\" : 1 } # initialize and formulate decoder with suitable source and FFmpeg params decoder = FFdecoder ( \"foo.mp4\" , verbose = True , ** ffparams ) . formulate () \u2009 B. Exclusive Parameters \u00b6 In addition to FFmpeg parameters, FFdecoder API also supports few Exclusive Parameters to allow users to flexibly change its internal pipeline, properties, and handle some special FFmpeg parameters (such as repeated map ) that cannot be assigned via. python dictionary. These parameters are discussed below: -vcodec (str) : This attribute works similar to -vcodec FFmpeg parameter for specifying supported decoders that are compiled with FFmpeg in use. If not specified, it's value is derived from source video metadata. Its usage is as follows: Use ffmpeg -decoders terminal command to lists all FFmpeg supported decoders. Use { \"-vcodec\" : None } in ffparams to discard -vcodec FFmpeg parameter entirely from Decoding pipeline. This feature allows users to manually skip -vcodec FFmpeg parameter in Decoding pipeline, for letting FFmpeg itself choose the best available video decoder for the given source. # define suitable parameter ffparams = { \"-vcodec\" : \"h264\" } # set decoder to `h264` \u2002 -framerate (float/int) : This attribute works similar to -framerate FFmpeg parameter for generating video-frames at specified framerate. If not specified, it calculated from video metadata. Its usage is as follows: Any invalid or unsupported value to -framerate attribute will discarded! The output_frames_framerate metadata property is only available when FFmpeg filters via. -vf or -filter_complex are manually defined. Any improper -framerate parameter value (i.e. either null (special-case), undefined, or invalid type) , then -framerate/-r FFmpeg parameter value in Decoding pipeline uses output_frames_framerate metadata property extracted from Output Stream. Thereby, in case if no valid output_framerate metadata property is found, then API finally defaults to source_video_framerate metadata property extracted from Input Source Stream. In case neither output_framerate nor source_video_framerate valid metadata properties are found, then RuntimeError is raised. Use { \"-framerate\" : \"null\" } in ffparams to discard -framerate/-r FFmpeg parameter entirely from Decoding pipeline. This feature allows users to manually skip -framerate/-r FFmpeg parameter in Decoding pipeline, essentially for using only fps filter values, or even better, let FFmpeg itself choose the best available output framerate for the given source. # define suitable parameter ffparams = { \"-framerate\" : 60.0 } # set input video source framerate to 60fps \u2002 -custom_resolution (tuple/list) : This attribute sets the custom resolution/size of the output frames. Its value can either be a tuple ( (width,height) ) or a list ( [width, height] ). If not specified, it calculated from video metadata. Its usage is as follows: Any invalid or unsupported value to -custom_resolution attribute will discarded! The output_frames_resolution metadata property is only available when FFmpeg filters via. -vf or -filter_complex are manually defined. Any improper -custom_resolution parameter value (i.e. either null (special-case), undefined, or invalid type) , then -s/-size FFmpeg parameter value in Decoding pipeline uses output_frames_resolution metadata property extracted from Output Stream. Thereby, in case if no valid output_frames_resolution metadata property is found, then API finally defaults to source_video_resolution metadata property extracted from Input Source Stream. In case neither output_frames_resolution nor source_video_resolution valid metadata properties are found, then RuntimeError is raised. Use { \"-custom_resolution\" : \"null\" } in ffparams to discard -size/-s FFmpeg parameter entirely from Decoding pipeline. This feature allows users to manually skip -size/-s FFmpeg parameter in Decoding pipeline, essentially for using only fps filter values, or even better, let FFmpeg itself choose the best available output frames resolution for the given source. # define suitable parameter ffparams = { \"-output_dimensions\" : ( 1280 , 720 )} # to produce a 1280x720 resolution/scale output video \u2002 -ffprefixes (list) : This attribute sets the special FFmpeg parameters that generally occurs at the very beginning (such as -re ) before input ( -i ) source. The FFmpeg parameters defined with this attribute can repeated more than once and maintains its original order in the FFmpeg command. Its value can be of datatype list only and its usage is as follows: Difference from -clones parameter The -clones and -ffprefixes parameters even tho fundamentally work the same, they're meant to serve at different positions in the FFmpeg command. Normally, FFdecoder API pipeline looks something like following with these parameters in place: ffmpeg {{ -ffprefixes FFmpeg params }} -vcodec h264 -i foo.mp4 -pix_fmt rgb24 -s 1280x720 -framerate 25 .0 {{ -clones FFmpeg params }} -f rawvideo - Turn on verbose parameter ( verbose = True ) to see the FFmpeg command that is being executed in FFdecoder's pipeline. This helps you debug/address any issues and make adjustments accordingly. # define suitable parameter ffparams = { \"-ffprefixes\" : [ '-re' ]} # executes as `ffmpeg -re <rest of command>` \u2002 -clones (list) : This attribute sets the special FFmpeg parameters after that are repeated more than once or occurs in a specific order (that cannot be altered) in the FFmpeg command. Its value can be of datatype list only and its usage is as follows: Turn on verbose parameter ( verbose = True ) to see the FFmpeg command that is being executed in FFdecoder's pipeline. This helps you debug/address any issues and make adjustments accordingly. # define suitable parameter ffparams = { \"-clones\" : [ '-map' , '0:v:0' , '-map' , '1:a?' ]} # NOTE: Will be format as `ffmpeg -vcodec -i foo.mp4 -pix_fmt rgb24 -s 1280x720 -framerate 25.0 -map 0:v:0 -map 1:a -f rawvideo -` \u2002 -custom_sourcer_params (dict) : This attribute assigns all Exclusive Parameter meant for Sourcer API's sourcer_params dictionary parameter directly through FFdecoder API. Its usage is as follows: # define suitable parameter meant for `sourcer_params` ffparams = { \"-custom_sourcer_params\" : { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" }} \u2002 -default_stream_indexes (list/tuple) : This attribute assign value directly to default_stream_indexes parameter in Sourcer API's probe_stream() method for selecting specific video and audio stream index in case of multiple ones. Value can be of format: (int,int) or [int,int] as follows: # define suitable parameter meant for `probe_stream()` method ffparams = { \"-default_stream_indexes\" : ( 0 , 1 )} # (\"0th video stream\", \"1st audio stream\") \u2002 -passthrough_audio (bool/list) : (Yet to be supported) Default pixel-format is calculated variably in FFdecoder API: If frame_format != \"null\" : If frame_format parameter is valid and supported: Default pixel-format is frame_format parameter value. If frame_format parameter is NOT valid or supported: If output_frame_pixfmt metadata is available: Default pixel-format is output_frame_pixfmt metadata value. If output_frame_pixfmt metadata is NOT available: Default pixel-format is rgb24 if supported otherwise source_video_pixfmt metadata value. If frame_format == \"null\" : Default pixel-format is source_video_pixfmt metadata value \u21a9 \u21a9","title":"API Parameters"},{"location":"reference/ffdecoder/params/#ffdecoder-api-parameters","text":"","title":"FFdecoder API Parameters"},{"location":"reference/ffdecoder/params/#source","text":"This parameter defines the input source ( -i ) for decoding real-time frames. FFdecoder API will throw Assertion if source provided is invalid or missing. FFdecoder API checks for video bitrate or frame-size and framerate in video's metadata to ensure given input source has usable video stream available. Thereby, it will throw ValueError if it fails to find those parameters. Multiple video inputs are not yet supported! Data-Type: String. Its valid input can be one of the following: Filepath: Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: # initialize and formulate the decoder with `foo.mp4` source decoder = FFdecoder ( '/home/foo.mp4' ) . formulate () Related usage recipes can found here \u27b6 Image Sequence: Valid image sequence such as sequential( 'img%03d.png' ) or glob pattern( '*.png' ) or single (looping) image as input: Sequential Glob pattern Single (loop) image How to start with specific number image? You can use -start_number FFmpeg parameter if you want to start with specific number image: # define `-start_number` such as `5` ffparams = { \"-ffprefixes\" :[ \"-start_number\" , \"5\" ]} # initialize and formulate the decoder with define parameters decoder = FFdecoder ( 'img %03d .png' , verbose = True , ** ffparams ) . formulate () # initialize and formulate the decoder decoder = FFdecoder ( 'img %03d .png' ) . formulate () Bash-style globbing ( * represents any number of any characters) is useful if your images are sequential but not necessarily in a numerically sequential order. The glob pattern is not available on Windows builds. # define `-pattern_type glob` for accepting glob pattern sourcer_params = { \"-ffprefixes\" :[ \"-pattern_type\" , \"glob\" ]} # initialize and formulate the decoder with define parameters decoder = FFdecoder ( 'img*.png' , verbose = True , ** sourcer_params ) . formulate () # define `-loop 1` for looping ffparams = { \"-ffprefixes\" :[ \"-loop\" , \"1\" ]} # initialize and formulate the decoder with define parameters decoder = FFdecoder ( 'img.jpg' , verbose = True , ** ffparams ) . formulate () Related usage recipes can found here \u27b6 Network Address: Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://xx:yy@192.168.1.ee:fd/av0_0' as input: # define `rtsp_transport` or necessary parameters ffparams = { \"-ffprefixes\" :[ \"-rtsp_transport\" , \"tcp\" ]} # initialize and formulate the decoder with define parameters decoder = FFdecoder ( 'rtsp://xx:yy@192.168.1.ee:fd/av0_0' , verbose = True , ** ffparams ) . formulate () Related usage recipes can found here \u27b6 Video Capture Devices (Webcams): Valid video capture device's name (e.g. \"USB2.0 Camera\" ) or its path (e.g. \"/dev/video0\" on linux) or its index (e.g. \"0\" ) as input w.r.t source_demuxer parameter value in use. For example, for capturing \"USB2.0 Camera\" named device with dshow source demuxer on Windows, we can do as follows in FFdecoder API: Identifying and Specifying Device name/path/index and suitable Demuxer on different OSes Windows Linux MacOS Windows OS users can use the dshow (DirectShow) to list video input device which is the preferred option for Windows users. You can refer following steps to identify and specify your input video device's name: Identify Video Devices: You can locate your video device's name (already connected to your system) using dshow as follows: c: \\> ffmpeg.exe -list_devices true -f dshow -i dummy ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ dshow @ 03ACF580 ] DirectShow video devices [ dshow @ 03ACF580 ] \"Integrated Camera\" [ dshow @ 03ACF580 ] \"USB2.0 Camera\" [ dshow @ 03ACF580 ] DirectShow audio devices [ dshow @ 03ACF580 ] \"Microphone (Realtek High Definition Audio)\" [ dshow @ 03ACF580 ] \"Microphone (USB2.0 Camera)\" dummy: Immediate exit requested Specify Video Device's name: Then, you can specify and initialize your located Video device's name in FFdecoder API as follows: # initialize and formulate the decoder with \"USB2.0 Camera\" source for BGR24 output decoder = FFdecoder ( \"USB2.0 Camera\" , source_demuxer = \"dshow\" , frame_format = \"bgr24\" , verbose = True ) . formulate () [OPTIONAL] Specify Video Device's index along with name: If there are multiple Video devices with similar name, then you can use -video_device_number parameter to specify the arbitrary index of the particular device. For instance, to open second video device with name \"Camera\" you can do as follows: # define video_device_number as 1 (numbering start from 0) ffparams = { \"-ffprefixes\" :[ \"-video_device_number\" , \"1\" ]} # initialize and formulate the decoder with \"Camera\" source for BGR24 output decoder = FFdecoder ( \"Camera\" , source_demuxer = \"dshow\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () Linux OS users can use the video4linux2 (or its alias v4l2 ) to list to all capture video devices such as from an USB webcam. You can refer following steps to identify and specify your capture video device's path: Identify Video Devices: Linux systems tend to automatically create file device node/path when the device (e.g. an USB webcam) is plugged into the system, and has a name of the kind '/dev/videoN' , where N is a index associated to the device. To get the list of all available file device node/path on your Linux machine, you can use the v4l-ctl command. You can use sudo apt install v4l-utils APT command to install v4l-ctl tool on Debian-based Linux distros. $ v4l2-ctl --list-devices USB2.0 PC CAMERA ( usb-0000:00:1d.7-1 ) : /dev/video1 UVC Camera ( 046d:0819 ) ( usb-0000:00:1d.7-2 ) : /dev/video0 Specify Video Device's path: Then, you can specify and initialize your located Video device's path in FFdecoder API as follows: # initialize and formulate the decoder with \"/dev/video0\" source for BGR24 output decoder = FFdecoder ( \"/dev/video0\" , source_demuxer = \"v4l2\" , frame_format = \"bgr24\" , verbose = True ) . formulate () [OPTIONAL] Specify Video Device's additional specifications: You can also specify additional specifications (such as pixel format(s), video format(s), framerate, and frame dimensions) supported by your Video Device as follows: You can use ffmpeg -f v4l2 -list_formats all -i /dev/video0 terminal command to list available specifications. # define video device specifications ffparams = { \"-ffprefixes\" :[ \"-framerate\" , \"25\" , \"-video_size\" , \"640x480\" ]} # initialize and formulate the decoder with \"/dev/video0\" source for BGR24 output decoder = FFdecoder ( \"/dev/video0\" , source_demuxer = \"v4l2\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () MacOS users can use the AVFoundation to list input devices and is the currently recommended framework by Apple for streamgrabbing on Mac OSX-10.7 (Lion) and later as well as on iOS. You can refer following steps to identify and specify your capture video device's name or index on MacOS/OSX machines: QTKit is also available for streamgrabbing on Mac OS X 10.4 (Tiger) and later, but has been marked deprecated since OS X 10.7 (Lion) and may not be available on future releases. Identify Video Devices: Then, You can locate your Video device's name and index using avfoundation as follows: $ ffmpeg -f avfoundation -list_devices true -i \"\" ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation video devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] FaceTime HD camera ( built-in ) [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Capture screen 0 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation audio devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] Blackmagic Audio [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Built-in Microphone Specify Video Device's name or index: Then, you can specify and initialize your located Video device in FFdecoder API using its either the name or the index shown in the device listing: Using device's index Using device's name # initialize and formulate the decoder with `1` index source for BGR24 output decoder = FFdecoder ( \"1\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True ) . formulate () When specifying device's name, abbreviations using just the beginning of the device name are possible. Thus, to capture from a device named \"Integrated iSight-camera\" just \"Integrated\" is sufficient: # initialize and formulate the decoder with \"Integrated iSight-camera\" source for BGR24 output decoder = FFdecoder ( \"Integrated\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True ) . formulate () [OPTIONAL] Specify Default Video device: You can also use the default device which is usually the first device in the listing by using \"default\" as source: # initialize and formulate the decoder with \"default\" source for BGR24 output decoder = FFdecoder ( \"default\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True ) . formulate () If these steps doesn't work for you then reach us out on Gitter \u27b6 Community channel # initialize and formulate the decoder with \"USB2.0 Camera\" source for BGR24 output decoder = FFdecoder ( \"USB2.0 Camera\" , source_demuxer = \"dshow\" , frame_format = \"bgr24\" , verbose = True ) . formulate () Related usage recipe can found here \u27b6 Screen Capturing/Recording: Valid screen capture device's name (e.g. \"desktop\" ) or its index (e.g. \":0.0\" ) as input w.r.t source_demuxer parameter value in use. You can also specify additional specifications (such as limiting capture area to a region, setting capturing coordinates, whether to capture mouse pointer and clicks etc.) . For example, for capturing \"0:\" indexed device with avfoundation source demuxer on MacOS along with mouse pointer and clicks, we can do as follows in FFdecoder API: Specifying suitable Parameter(s) and Demuxer for Capturing your Desktop on different OSes Windows Linux MacOS Windows OS users can use the gdigrab to grab video from the Windows screen. You can refer following steps to specify source for capturing different regions of your display: For Windows OS users dshow is also available for grabbing frames from your desktop. But it is highly unreliable and don't works most of the times. Capturing entire desktop: For capturing all your displays as one big contiguous display, you can specify source, suitable parameters and demuxers in FFdecoder API as follows: # define framerate ffparams = { \"-framerate\" : \"30\" } # initialize and formulate the decoder with \"desktop\" source for BGR24 output decoder = FFdecoder ( \"desktop\" , source_demuxer = \"gdigrab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () Capturing a region: If you want to limit capturing to a region, and show the area being grabbed, you can specify source and suitable parameters in FFdecoder API as follows: x_offset and y_offset specify the offsets of the grabbed area with respect to the top-left border of the desktop screen. They default to 0 . # define suitable parameters ffparams = { \"-framerate\" : \"30\" , # input framerate \"-ffprefixes\" : [ \"-offset_x\" , \"10\" , \"-offset_y\" , \"20\" , # grab at position 10,20 \"-video_size\" , \"640x480\" , # frame size \"-show_region\" , \"1\" , # show only region ], } # initialize and formulate the decoder with \"desktop\" source for BGR24 output decoder = FFdecoder ( \"desktop\" , source_demuxer = \"gdigrab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () Linux OS users can use the x11grab to capture an X11 display. You can refer following steps to specify source for capturing different regions of your display: For X11 display, the source input has the syntax: \"display_number.screen_number[+x_offset,y_offset]\" . Capturing entire desktop: For capturing all your displays as one big contiguous display, you can specify source, suitable parameters and demuxers in FFdecoder API as follows: # define framerate ffparams = { \"-framerate\" : \"30\" } # initialize and formulate the decoder with \":0.0\" desktop source for BGR24 output decoder = FFdecoder ( \":0.0\" , source_demuxer = \"x11grab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () Capturing a region: If you want to limit capturing to a region, and show the area being grabbed, you can specify source and suitable parameters in FFdecoder API as follows: x_offset and y_offset specify the offsets of the grabbed area with respect to the top-left border of the X11 screen. They default to 0 . # define suitable parameters ffparams = { \"-framerate\" : \"30\" , # input framerate \"-ffprefixes\" : [ \"-video_size\" , \"1024x768\" , # frame size ], } # initialize and formulate the decoder with \":0.0\" desktop source(starting with the upper-left corner at x=10, y=20) # for BGR24 output decoder = FFdecoder ( \":0.0+10,20\" , source_demuxer = \"x11grab\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () MacOS users can use the AVFoundation to list input devices and is the currently recommended framework by Apple for streamgrabbing on Mac OSX-10.7 (Lion) and later as well as on iOS. You can refer following steps to identify and specify your capture video device's name or index on MacOS/OSX machines: QTKit is also available for streamgrabbing on Mac OS X 10.4 (Tiger) and later, but has been marked deprecated since OS X 10.7 (Lion) and may not be available on future releases. Identify Video Devices: You can enumerate all the available input devices including screens ready to be captured using avfoundation as follows: $ ffmpeg -f avfoundation -list_devices true -i \"\" ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation video devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] FaceTime HD camera ( built-in ) [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Capture screen 0 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation audio devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] Blackmagic Audio [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Built-in Microphone Capturing entire desktop: Then, you can specify and initialize your located screens in FFdecoder API using its index shown: # initialize and formulate the decoder with `0:` index desktop screen for BGR24 output decoder = FFdecoder ( \"0:\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True ) . formulate () [OPTIONAL] Capturing mouse: You can also specify additional specifications to capture the mouse pointer and screen mouse clicks as follows: # define specifications ffparams = { \"-ffprefixes\" :[ \"-capture_cursor\" , \"1\" , \"-capture_mouse_clicks\" , \"0\" ]} # initialize and formulate the decoder with \"0:\" source for BGR24 output decoder = FFdecoder ( \"0:\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () If these steps doesn't work for you then reach us out on Gitter \u27b6 Community channel # define specifications ffparams = { \"-ffprefixes\" :[ \"-capture_cursor\" , \"1\" , \"-capture_mouse_clicks\" , \"0\" ]} # initialize and formulate the decoder with \"0:\" source for BGR24 output decoder = FFdecoder ( \"0:\" , source_demuxer = \"avfoundation\" , frame_format = \"bgr24\" , verbose = True , ** ffparams ) . formulate () Related usage recipe can found here \u27b6 Virtual Sources: Valid filtergraph to use as input with lavfi ( Libavfilter input virtual device) source that reads data from the open output pads of a libavfilter filtergraph. For example, for generating and decoding Mandelbrot graph of 1280x720 frame size and 30 framerate using lavfi input virtual device, we can do as follows in FFdecoder API: # initialize and formulate the decoder with \"mandelbrot\" source of # `1280x720` frame size and `30` framerate for BGR24 output decoder = FFdecoder ( \"mandelbrot=size=1280x720:rate=30\" , source_demuxer = \"lavfi\" , frame_format = \"bgr24\" , ) . formulate () Related usage recipes can found here \u27b6","title":"source"},{"location":"reference/ffdecoder/params/#source_demuxer","text":"This parameter specifies the demuxer( -f ) for the input source (such as dshow , v4l2 , gdigrab etc.) to support Live Feed Devices, as well as lavfi (Libavfilter input virtual device) that reads data from the open output pads of a libavfilter filtergraph. Any invalid or unsupported value to source_demuxer parameter value will raise Assertion error! Use ffmpeg -demuxers terminal command to lists all FFmpeg supported demuxers. Data-Type: String Default Value: Its default value is None . Usage: # initialize and formulate the decoder with `dshow` demuxer decoder = FFdecoder ( \"foo.mp4\" , source_demuxer = \"dshow\" ) . formulate ()","title":"source_demuxer"},{"location":"reference/ffdecoder/params/#frame_format","text":"This parameter select the pixel format for output video frames (such as gray for grayscale output) . Any invalid or unsupported value to frame_format parameter will discarded! Any improper frame_format parameter value (i.e. either null (special-case), undefined, or invalid type) , then -pix_fmt FFmpeg parameter value in Decoding pipeline uses output_frames_pixfmt metadata property extracted from Output Stream. Thereby, in case if no valid output_frames_resolution metadata property is found, then API finally defaults to Default pixel-format 1 (calculated variably) . The output_frame_pixfmt metadata property is only available when FFmpeg filters via. -vf or -filter_complex are manually defined. Use frame_format = \"null\" to manually discard -pix_fmt FFmpeg parameter entirely from Decoding pipeline. This feature allows users to manually skip -pix_fmt FFmpeg parameter in Decoding pipeline, essentially for using only format filter values, or even better, let FFmpeg itself choose the best available output frame pixel-format for the given source. Data-Type: String Default Value: Its default value is Default pixel-format 1 (calculated variably) . Usage: # initialize and formulate the decoder for grayscale frames decoder = FFdecoder ( \"foo.mp4\" , frame_format = \"gray\" ) . formulate () Use ffmpeg -pix_fmts terminal command to lists all FFmpeg supported pixel formats. Various Pixel formats related usage recipes can found here \u27b6","title":"frame_format"},{"location":"reference/ffdecoder/params/#custom_ffmpeg","text":"This parameter can be used to manually assigns the system file-path/directory where the custom or downloaded FFmpeg executable is located. Behavior on Windows If custom FFmpeg executable binary file-path/directory is not assigned through custom_ffmpeg parameter on Windows machine, then FFdecoder API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine . More information can be found here \u27b6 . How to change FFmpeg Static Binaries download directory? You can use -ffmpeg_download_path (via. -custom_sourcer_params ) exclusive parameter in FFdecoder API to set the custom directory for downloading FFmpeg Static Binaries during the Auto-Installation step on Windows Machines. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. C:/User/temp ) on your windows machine. It can be used as follows in FFdecoder API: # # define suitable parameter to download at \"C:/User/foo/foo1\" ffparams = { \"-custom_sourcer_params\" : { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" }} # initialize and formulate the decoder FFdecoder ( \"foo.mp4\" , verbose = True , ** ffparams ) . formulate () If binaries were not found at the manually specified path, DeFFcode APIs will throw RuntimeError ! Data-Type: String Default Value: Its default value is None . Usage: # If ffmpeg executables are located at \"/foo/foo1/ffmpeg\" FFdecoder ( \"foo.mp4\" , custom_ffmpeg = \"/foo/foo1/ffmpeg\" ) . formulate ()","title":"custom_ffmpeg"},{"location":"reference/ffdecoder/params/#verbose","text":"This parameter enables verbose logs (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: # initialize and formulate decoder with verbose logs FFdecoder ( \"foo.mp4\" , verbose = True ) . formulate ()","title":"verbose"},{"location":"reference/ffdecoder/params/#ffparams","text":"This dictionary parameter accepts all supported parameters formatted as its attributes: Data-Type: Dictionary Default Value: Its default value is {} .","title":"ffparams"},{"location":"reference/ffdecoder/params/#supported-parameters","text":"","title":"Supported Parameters"},{"location":"reference/ffdecoder/params/#a-ffmpeg-parameters","text":"Almost any FFmpeg parameter (supported by installed FFmpeg) can be passed as dictionary attributes in ffparams parameter. Let's assume we want to 00:00:01.45 (or 1045msec) in time and decode one single frame from given source (say foo.mp4 ) in FFdecoder API, then we can assign required FFmpeg parameters as dictionary attributes as follows: Kindly read FFmpeg Docs carefully before passing any additional values to ffparams parameter. Wrong invalid values may result in undesired errors or no output at all. All FFmpeg parameters are case-sensitive. Remember to double check every parameter if any error(s) occurred. # define the FFmpeg parameter to seek to 00:00:01.45(or 1s and 45msec) # in time and get one single frame ffparams = { \"-ss\" : \"00:00:01.45\" , \"-frames:v\" : 1 } # initialize and formulate decoder with suitable source and FFmpeg params decoder = FFdecoder ( \"foo.mp4\" , verbose = True , ** ffparams ) . formulate ()","title":"A. FFmpeg Parameters"},{"location":"reference/ffdecoder/params/#b-exclusive-parameters","text":"In addition to FFmpeg parameters, FFdecoder API also supports few Exclusive Parameters to allow users to flexibly change its internal pipeline, properties, and handle some special FFmpeg parameters (such as repeated map ) that cannot be assigned via. python dictionary. These parameters are discussed below: -vcodec (str) : This attribute works similar to -vcodec FFmpeg parameter for specifying supported decoders that are compiled with FFmpeg in use. If not specified, it's value is derived from source video metadata. Its usage is as follows: Use ffmpeg -decoders terminal command to lists all FFmpeg supported decoders. Use { \"-vcodec\" : None } in ffparams to discard -vcodec FFmpeg parameter entirely from Decoding pipeline. This feature allows users to manually skip -vcodec FFmpeg parameter in Decoding pipeline, for letting FFmpeg itself choose the best available video decoder for the given source. # define suitable parameter ffparams = { \"-vcodec\" : \"h264\" } # set decoder to `h264` \u2002 -framerate (float/int) : This attribute works similar to -framerate FFmpeg parameter for generating video-frames at specified framerate. If not specified, it calculated from video metadata. Its usage is as follows: Any invalid or unsupported value to -framerate attribute will discarded! The output_frames_framerate metadata property is only available when FFmpeg filters via. -vf or -filter_complex are manually defined. Any improper -framerate parameter value (i.e. either null (special-case), undefined, or invalid type) , then -framerate/-r FFmpeg parameter value in Decoding pipeline uses output_frames_framerate metadata property extracted from Output Stream. Thereby, in case if no valid output_framerate metadata property is found, then API finally defaults to source_video_framerate metadata property extracted from Input Source Stream. In case neither output_framerate nor source_video_framerate valid metadata properties are found, then RuntimeError is raised. Use { \"-framerate\" : \"null\" } in ffparams to discard -framerate/-r FFmpeg parameter entirely from Decoding pipeline. This feature allows users to manually skip -framerate/-r FFmpeg parameter in Decoding pipeline, essentially for using only fps filter values, or even better, let FFmpeg itself choose the best available output framerate for the given source. # define suitable parameter ffparams = { \"-framerate\" : 60.0 } # set input video source framerate to 60fps \u2002 -custom_resolution (tuple/list) : This attribute sets the custom resolution/size of the output frames. Its value can either be a tuple ( (width,height) ) or a list ( [width, height] ). If not specified, it calculated from video metadata. Its usage is as follows: Any invalid or unsupported value to -custom_resolution attribute will discarded! The output_frames_resolution metadata property is only available when FFmpeg filters via. -vf or -filter_complex are manually defined. Any improper -custom_resolution parameter value (i.e. either null (special-case), undefined, or invalid type) , then -s/-size FFmpeg parameter value in Decoding pipeline uses output_frames_resolution metadata property extracted from Output Stream. Thereby, in case if no valid output_frames_resolution metadata property is found, then API finally defaults to source_video_resolution metadata property extracted from Input Source Stream. In case neither output_frames_resolution nor source_video_resolution valid metadata properties are found, then RuntimeError is raised. Use { \"-custom_resolution\" : \"null\" } in ffparams to discard -size/-s FFmpeg parameter entirely from Decoding pipeline. This feature allows users to manually skip -size/-s FFmpeg parameter in Decoding pipeline, essentially for using only fps filter values, or even better, let FFmpeg itself choose the best available output frames resolution for the given source. # define suitable parameter ffparams = { \"-output_dimensions\" : ( 1280 , 720 )} # to produce a 1280x720 resolution/scale output video \u2002 -ffprefixes (list) : This attribute sets the special FFmpeg parameters that generally occurs at the very beginning (such as -re ) before input ( -i ) source. The FFmpeg parameters defined with this attribute can repeated more than once and maintains its original order in the FFmpeg command. Its value can be of datatype list only and its usage is as follows: Difference from -clones parameter The -clones and -ffprefixes parameters even tho fundamentally work the same, they're meant to serve at different positions in the FFmpeg command. Normally, FFdecoder API pipeline looks something like following with these parameters in place: ffmpeg {{ -ffprefixes FFmpeg params }} -vcodec h264 -i foo.mp4 -pix_fmt rgb24 -s 1280x720 -framerate 25 .0 {{ -clones FFmpeg params }} -f rawvideo - Turn on verbose parameter ( verbose = True ) to see the FFmpeg command that is being executed in FFdecoder's pipeline. This helps you debug/address any issues and make adjustments accordingly. # define suitable parameter ffparams = { \"-ffprefixes\" : [ '-re' ]} # executes as `ffmpeg -re <rest of command>` \u2002 -clones (list) : This attribute sets the special FFmpeg parameters after that are repeated more than once or occurs in a specific order (that cannot be altered) in the FFmpeg command. Its value can be of datatype list only and its usage is as follows: Turn on verbose parameter ( verbose = True ) to see the FFmpeg command that is being executed in FFdecoder's pipeline. This helps you debug/address any issues and make adjustments accordingly. # define suitable parameter ffparams = { \"-clones\" : [ '-map' , '0:v:0' , '-map' , '1:a?' ]} # NOTE: Will be format as `ffmpeg -vcodec -i foo.mp4 -pix_fmt rgb24 -s 1280x720 -framerate 25.0 -map 0:v:0 -map 1:a -f rawvideo -` \u2002 -custom_sourcer_params (dict) : This attribute assigns all Exclusive Parameter meant for Sourcer API's sourcer_params dictionary parameter directly through FFdecoder API. Its usage is as follows: # define suitable parameter meant for `sourcer_params` ffparams = { \"-custom_sourcer_params\" : { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" }} \u2002 -default_stream_indexes (list/tuple) : This attribute assign value directly to default_stream_indexes parameter in Sourcer API's probe_stream() method for selecting specific video and audio stream index in case of multiple ones. Value can be of format: (int,int) or [int,int] as follows: # define suitable parameter meant for `probe_stream()` method ffparams = { \"-default_stream_indexes\" : ( 0 , 1 )} # (\"0th video stream\", \"1st audio stream\") \u2002 -passthrough_audio (bool/list) : (Yet to be supported) Default pixel-format is calculated variably in FFdecoder API: If frame_format != \"null\" : If frame_format parameter is valid and supported: Default pixel-format is frame_format parameter value. If frame_format parameter is NOT valid or supported: If output_frame_pixfmt metadata is available: Default pixel-format is output_frame_pixfmt metadata value. If output_frame_pixfmt metadata is NOT available: Default pixel-format is rgb24 if supported otherwise source_video_pixfmt metadata value. If frame_format == \"null\" : Default pixel-format is source_video_pixfmt metadata value \u21a9 \u21a9","title":"B. Exclusive Parameters"},{"location":"reference/sourcer/","text":"Sourcer API \u00b6 \u2003 Sourcer API acts as Source Probing Utility that unlike other FFmpeg Wrappers which mostly uses ffprobe module, attempts to open the given Input Source directly with FFmpeg inside a subprocess pipe, and parses/probes the standard output(stdout) employing various pattern matching methods in order to recognize all the properties(metadata) of each media stream contained in it. Sourcer API primarily acts as a backend for FFdecoder API for gathering, processing, and validating all multimedia streams metadata available in the given Input Source. Sourcer shares this information with FFdecoder API which helps in formulating its default FFmpeg pipeline parameters for real-time video-frames generation. Sourcer API is design as a standalone Metadata Extraction API for easily parsing information from multimedia streams available in the given Input Source and returns it in either Human-readable (JSON string) or Machine-readable (Dictionary object) type with its retrieve_metadata() method. All metadata attributes available with Sourcer API(On Windows) are discussed here \u27b6 . Furthermore, Sourcer's sourcer_params dictionary parameter can be used to define almost any FFmpeg parameter as well as alter internal API settings. For usage examples, kindly refer our Basic Recipes and Advanced Recipes Sourcer API parameters are explained here \u27b6 Source code in deffcode/sourcer.py class Sourcer : \"\"\" > Sourcer API acts as **Source Probing Utility** that unlike other FFmpeg Wrappers which mostly uses [`ffprobe`](https://ffmpeg.org/ffprobe.html) module, attempts to open the given Input Source directly with [**FFmpeg**](https://ffmpeg.org/) inside a [`subprocess`](https://docs.python.org/3/library/subprocess.html) pipe, and parses/probes the standard output(stdout) employing various pattern matching methods in order to recognize all the properties(metadata) of each media stream contained in it. Sourcer API primarily acts as a **backend for [FFdecoder API](../../reference/ffdecoder)** for gathering, processing, and validating all multimedia streams metadata available in the given Input Source. Sourcer shares this information with FFdecoder API which helps in formulating its default FFmpeg pipeline parameters for real-time video-frames generation. Sourcer API is design as a standalone **Metadata Extraction API** for easily parsing information from multimedia streams available in the given Input Source and returns it in either Human-readable _(JSON string)_ or Machine-readable _(Dictionary object)_ type with its [`retrieve_metadata()`](#deffcode.sourcer.Sourcer.retrieve_metadata) method. !!! info \"All metadata attributes available with Sourcer API(On :fontawesome-brands-windows: Windows) are discussed [here \u27b6](../../recipes/basic/#display-source-video-metadata).\" Furthermore, Sourcer's [`sourcer_params`](params/#sourcer_params) dictionary parameter can be used to define almost any FFmpeg parameter as well as alter internal API settings. !!! example \"For usage examples, kindly refer our **[Basic Recipes :cake:](../../recipes/basic)** and **[Advanced Recipes :croissant:](../../recipes/advanced)**\" !!! info \"Sourcer API parameters are explained [here \u27b6](params/)\" \"\"\" def __init__ ( self , source , source_demuxer = None , custom_ffmpeg = \"\" , verbose = False , ** sourcer_params , ): \"\"\" This constructor method initializes the object state and attributes of the Sourcer Class. Parameters: source (str): defines the input(`-i`) source filename/URL/device-name/device-path. source_demuxer (str): specifies the demuxer(`-f`) for the input source. custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executable. verbose (bool): enables/disables verbose. sourcer_params (dict): provides the flexibility to control supported internal and FFmpeg parameters. \"\"\" # checks if machine in-use is running windows os or not self . __machine_OS = platform . system () # define internal parameters self . __verbose_logs = ( # enable verbose if specified verbose if ( verbose and isinstance ( verbose , bool )) else False ) # handle metadata received self . __ffsp_output = None # sanitize sourcer_params self . __sourcer_params = { str ( k ) . strip (): str ( v ) . strip () if not isinstance ( v , ( dict , list , int , float , tuple )) else v for k , v in sourcer_params . items () } # handle whether to force validate source self . __forcevalidatesource = self . __sourcer_params . pop ( \"-force_validate_source\" , False ) if not isinstance ( self . __forcevalidatesource , bool ): # reset improper values self . __forcevalidatesource = False # handle user defined ffmpeg pre-headers(parameters such as `-re`) parameters (must be a list) self . __ffmpeg_prefixes = self . __sourcer_params . pop ( \"-ffprefixes\" , []) if not isinstance ( self . __ffmpeg_prefixes , list ): # log it logger . warning ( \"Discarding invalid `-ffprefixes` value of wrong type ` {} `!\" . format ( type ( self . __ffmpeg_prefixes ) . __name__ ) ) # reset improper values self . __ffmpeg_prefixes = [] # handle where to save the downloaded FFmpeg Static assets on Windows(if specified) __ffmpeg_download_path = self . __sourcer_params . pop ( \"-ffmpeg_download_path\" , \"\" ) if not isinstance ( __ffmpeg_download_path , str ): # reset improper values __ffmpeg_download_path = \"\" # validate the FFmpeg assets and return location (also downloads static assets on windows) self . __ffmpeg = get_valid_ffmpeg_path ( str ( custom_ffmpeg ), True if self . __machine_OS == \"Windows\" else False , ffmpeg_download_path = __ffmpeg_download_path , verbose = self . __verbose_logs , ) # check if valid FFmpeg path returned if self . __ffmpeg : self . __verbose_logs and logger . debug ( \"Found valid FFmpeg executable: ` {} `.\" . format ( self . __ffmpeg ) ) else : # else raise error raise RuntimeError ( \"[DeFFcode:ERROR] :: Failed to find FFmpeg assets on this system. Kindly compile/install FFmpeg or provide a valid custom FFmpeg binary path!\" ) # sanitize externally accessible parameters and assign them # handles source demuxer if source is None : # first check if source value is empty # raise error if true raise ValueError ( \"Input `source` parameter is empty!\" ) elif isinstance ( source_demuxer , str ): # assign if valid demuxer value self . __source_demuxer = source_demuxer . strip () . lower () # assign if valid demuxer value assert self . __source_demuxer != \"auto\" or validate_device_index ( source ), \"Invalid `source_demuxer='auto'` value detected with source: ` {} `. Aborting!\" . format ( source ) else : # otherwise find valid default source demuxer value # enforce \"auto\" if valid index device self . __source_demuxer = \"auto\" if validate_device_index ( source ) else None # log if not valid index device and invalid type self . __verbose_logs and not self . __source_demuxer in [ \"auto\" , None , ] and logger . warning ( \"Discarding invalid `source_demuxer` parameter value of wrong type: ` {} `\" . format ( type ( source_demuxer ) . __name__ ) ) # log if not valid index device and invalid type self . __verbose_logs and self . __source_demuxer == \"auto\" and logger . critical ( \"Given source ` {} ` is a valid device index. Enforcing 'auto' demuxer.\" . format ( source ) ) # handles source stream self . __source = source # creates shallow copy for further usage #TODO self . __source_org = copy . copy ( self . __source ) self . __source_demuxer_org = copy . copy ( self . __source_demuxer ) # handles all extracted devices names/paths list # when source_demuxer = \"auto\" self . __extracted_devices_list = [] # various source stream params self . __default_video_resolution = \"\" # handles stream resolution self . __default_video_framerate = \"\" # handles stream framerate self . __default_video_bitrate = \"\" # handles stream's video bitrate self . __default_video_pixfmt = \"\" # handles stream's video pixfmt self . __default_video_decoder = \"\" # handles stream's video decoder self . __default_source_duration = \"\" # handles stream's video duration self . __approx_video_nframes = \"\" # handles approx stream frame number self . __default_audio_bitrate = \"\" # handles stream's audio bitrate self . __default_audio_samplerate = \"\" # handles stream's audio samplerate # handle various stream flags self . __contains_video = False # contains video self . __contains_audio = False # contains audio self . __contains_images = False # contains image-sequence # handles output parameters through filters self . __metadata_output = None # handles output stream metadata self . __output_frames_resolution = \"\" # handles output stream resolution self . __output_framerate = \"\" # handles output stream framerate self . __output_frames_pixfmt = \"\" # handles output frame pixel format # check whether metadata probed or not? self . __metadata_probed = False def probe_stream ( self , default_stream_indexes = ( 0 , 0 )): \"\"\" This method Parses/Probes FFmpeg `subprocess` pipe's Standard Output for given input source and Populates the information in private class variables. Parameters: default_stream_indexes (list, tuple): selects specific video and audio stream index in case of multiple ones. Value can be of format: `(int,int)`. For example `(0,1)` is (\"0th video stream\", \"1st audio stream\"). **Returns:** Reference to the instance object. \"\"\" assert ( isinstance ( default_stream_indexes , ( list , tuple )) and len ( default_stream_indexes ) == 2 and all ( isinstance ( x , int ) for x in default_stream_indexes ) ), \"Invalid default_stream_indexes value!\" # validate source and extract metadata self . __ffsp_output = self . __validate_source ( self . __source , source_demuxer = self . __source_demuxer , forced_validate = ( self . __forcevalidatesource if self . __source_demuxer is None else True ), ) # parse resolution and framerate video_rfparams = self . __extract_resolution_framerate ( default_stream = default_stream_indexes [ 0 ] ) if video_rfparams : self . __default_video_resolution = video_rfparams [ \"resolution\" ] self . __default_video_framerate = video_rfparams [ \"framerate\" ] # parse output parameters through filters (if available) if not ( self . __metadata_output is None ): # parse output resolution and framerate out_video_rfparams = self . __extract_resolution_framerate ( default_stream = default_stream_indexes [ 0 ], extract_output = True ) if out_video_rfparams : self . __output_frames_resolution = out_video_rfparams [ \"resolution\" ] self . __output_framerate = out_video_rfparams [ \"framerate\" ] # parse output pixel-format self . __output_frames_pixfmt = self . __extract_video_pixfmt ( default_stream = default_stream_indexes [ 0 ], extract_output = True ) # parse pixel-format self . __default_video_pixfmt = self . __extract_video_pixfmt ( default_stream = default_stream_indexes [ 0 ] ) # parse video decoder self . __default_video_decoder = self . __extract_video_decoder ( default_stream = default_stream_indexes [ 0 ] ) # parse rest of metadata if not self . __contains_images : # parse video bitrate self . __default_video_bitrate = self . __extract_video_bitrate ( default_stream = default_stream_indexes [ 0 ] ) # parse audio bitrate and samplerate audio_params = self . __extract_audio_bitrate_nd_samplerate ( default_stream = default_stream_indexes [ 1 ] ) if audio_params : self . __default_audio_bitrate = audio_params [ \"bitrate\" ] self . __default_audio_samplerate = audio_params [ \"samplerate\" ] # parse video duration self . __default_source_duration = self . __extract_duration () # calculate all flags if ( self . __default_video_bitrate or ( self . __default_video_framerate and self . __default_video_resolution ) ) and ( self . __default_audio_bitrate or self . __default_audio_samplerate ): self . __contains_video = True self . __contains_audio = True elif self . __default_video_bitrate or ( self . __default_video_framerate and self . __default_video_resolution ): self . __contains_video = True elif self . __default_audio_bitrate or self . __default_audio_samplerate : self . __contains_audio = True else : raise ValueError ( \"Invalid source with no decodable audio or video stream provided. Aborting!\" ) # calculate approximate number of video frame if self . __default_video_framerate and self . __default_source_duration : self . __approx_video_nframes = np . rint ( self . __default_video_framerate * self . __default_source_duration ) . astype ( int , casting = \"unsafe\" ) # signal metadata has been probed self . __metadata_probed = True # return reference to the instance object. return self def retrieve_metadata ( self , pretty_json = False , force_retrieve_missing = False ): \"\"\" This method returns Parsed/Probed Metadata of the given source. Parameters: pretty_json (bool): whether to return metadata as JSON string(if `True`) or Dictionary(if `False`) type? force_retrieve_output (bool): whether to also return metadata missing in current Pipeline. This method returns `(metadata, metadata_missing)` tuple if `force_retrieve_output=True` instead of `metadata`. **Returns:** `metadata` or `(metadata, metadata_missing)`, formatted as JSON string or python dictionary. \"\"\" # check if metadata has been probed or not assert ( self . __metadata_probed ), \"Source Metadata not been probed yet! Check if you called `probe_stream()` method.\" # log it self . __verbose_logs and logger . debug ( \"Extracting Metadata...\" ) # create metadata dictionary from information populated in private class variables metadata = { \"ffmpeg_binary_path\" : self . __ffmpeg , \"source\" : self . __source , } metadata_missing = {} # Only either `source_demuxer` or `source_extension` attribute can be # present in metadata. if self . __source_demuxer is None : metadata . update ({ \"source_extension\" : os . path . splitext ( self . __source )[ - 1 ]}) # update missing force_retrieve_missing and metadata_missing . update ({ \"source_demuxer\" : \"\" }) else : metadata . update ({ \"source_demuxer\" : self . __source_demuxer }) # update missing force_retrieve_missing and metadata_missing . update ({ \"source_extension\" : \"\" }) # add source video metadata properties metadata . update ( { \"source_video_resolution\" : self . __default_video_resolution , \"source_video_pixfmt\" : self . __default_video_pixfmt , \"source_video_framerate\" : self . __default_video_framerate , \"source_video_decoder\" : self . __default_video_decoder , \"source_duration_sec\" : self . __default_source_duration , \"approx_video_nframes\" : ( int ( self . __approx_video_nframes ) if self . __approx_video_nframes else None ), \"source_video_bitrate\" : self . __default_video_bitrate , \"source_audio_bitrate\" : self . __default_audio_bitrate , \"source_audio_samplerate\" : self . __default_audio_samplerate , \"source_has_video\" : self . __contains_video , \"source_has_audio\" : self . __contains_audio , \"source_has_image_sequence\" : self . __contains_images , } ) # add output metadata properties (if available) if not ( self . __metadata_output is None ): metadata . update ( { \"output_frames_resolution\" : self . __output_frames_resolution , \"output_frames_pixfmt\" : self . __output_frames_pixfmt , \"output_framerate\" : self . __output_framerate , } ) else : # since output stream metadata properties are only available when additional # FFmpeg parameters(such as filters) are defined manually, thereby missing # output stream properties are handled by assigning them counterpart source # stream metadata property values force_retrieve_missing and metadata_missing . update ( { \"output_frames_resolution\" : self . __default_video_resolution , \"output_frames_pixfmt\" : self . __default_video_pixfmt , \"output_framerate\" : self . __default_video_framerate , } ) # log it self . __verbose_logs and logger . debug ( \"Metadata Extraction completed successfully!\" ) # parse as JSON string(`json.dumps`), if defined metadata = json . dumps ( metadata , indent = 2 ) if pretty_json else metadata metadata_missing = ( json . dumps ( metadata_missing , indent = 2 ) if pretty_json else metadata_missing ) # return `metadata` or `(metadata, metadata_missing)` return metadata if not force_retrieve_missing else ( metadata , metadata_missing ) def __validate_source ( self , source , source_demuxer = None , forced_validate = False ): \"\"\" This Internal method validates source and extracts its metadata. Parameters: source_demuxer(str): specifies the demuxer(`-f`) for the input source. forced_validate (bool): whether to skip validation tests or not? **Returns:** `True` if passed tests else `False`. \"\"\" # validate source demuxer(if defined) if not ( source_demuxer is None ): # check if \"auto\" demuxer is specified if source_demuxer == \"auto\" : # integerise source to get index index = int ( source ) # extract devices list and actual demuxer value ( self . __extracted_devices_list , source_demuxer , ) = extract_device_n_demuxer ( self . __ffmpeg , machine_OS = self . __machine_OS , verbose = self . __verbose_logs , ) # valid indexes range valid_indexes = [ x for x in range ( - len ( self . __extracted_devices_list ), len ( self . __extracted_devices_list ), ) ] # check index is within valid range if self . __extracted_devices_list and index in valid_indexes : # overwrite actual source device name/path/index if self . __machine_OS == \"Windows\" : # Windows OS requires \"video=\" suffix self . __source = source = \"video= {} \" . format ( self . __extracted_devices_list [ index ] ) elif self . __machine_OS == \"Darwin\" : # Darwin OS requires only device indexes self . __source = source = ( str ( index ) if index >= 0 else str ( len ( self . __extracted_devices_list ) + index ) ) else : # Linux OS require /dev/video format self . __source = source = next ( iter ( self . __extracted_devices_list [ index ] . keys ()) ) # overwrite source_demuxer global variable self . __source_demuxer = source_demuxer self . __verbose_logs and logger . debug ( \"Successfully configured device ` {} ` at index ` {} ` with demuxer ` {} `.\" . format ( self . __extracted_devices_list [ index ] if self . __machine_OS != \"Linux\" else next ( iter ( self . __extracted_devices_list [ index ] . values ()) )[ 0 ], index if index >= 0 else len ( self . __extracted_devices_list ) + index , self . __source_demuxer , ) ) else : # raise error otherwise raise ValueError ( \"Given source ` {} ` is not a valid device index. Possible values index values can be: {} \" . format ( source , \",\" . join ( f \" { x } \" for x in valid_indexes ), ) ) # otherwise validate against supported demuxers elif not ( source_demuxer in get_supported_demuxers ( self . __ffmpeg )): # raise if fails raise ValueError ( \"Installed FFmpeg failed to recognize ` {} ` demuxer. Check `source_demuxer` parameter value again!\" . format ( source_demuxer ) ) else : pass # assert if valid source assert source and isinstance ( source , str ), \"Input `source` parameter is of invalid type!\" # Differentiate input if forced_validate : source_demuxer is None and logger . critical ( \"Forcefully passing validation test for given source!\" ) self . __source = source elif os . path . isfile ( source ): self . __source = os . path . abspath ( source ) elif is_valid_image_seq ( self . __ffmpeg , source = source , verbose = self . __verbose_logs ): self . __source = source self . __contains_images = True elif is_valid_url ( self . __ffmpeg , url = source , verbose = self . __verbose_logs ): self . __source = source else : logger . error ( \"`source` value is unusable or unsupported!\" ) # discard the value otherwise raise ValueError ( \"Input source is invalid. Aborting!\" ) # format command if self . __sourcer_params : # handle additional params separately meta_cmd = ( [ self . __ffmpeg ] + ([ \"-hide_banner\" ] if not self . __verbose_logs else []) + [ \"-t\" , \"0.0001\" ] + self . __ffmpeg_prefixes + ([ \"-f\" , source_demuxer ] if source_demuxer else []) + [ \"-i\" , source ] + dict2Args ( self . __sourcer_params ) + [ \"-f\" , \"null\" , \"-\" ] ) else : meta_cmd = ( [ self . __ffmpeg ] + ([ \"-hide_banner\" ] if not self . __verbose_logs else []) + self . __ffmpeg_prefixes + ([ \"-f\" , source_demuxer ] if source_demuxer else []) + [ \"-i\" , source ] ) # extract metadata, decode, and filter metadata = ( check_sp_output ( meta_cmd , force_retrieve_stderr = True , ) . decode ( \"utf-8\" ) . strip () ) # separate input and output metadata (if available) if \"Output #\" in metadata : ( metadata , self . __metadata_output ) = metadata . split ( \"Output #\" ) # return metadata based on params return metadata def __extract_video_bitrate ( self , default_stream = 0 ): \"\"\" This Internal method parses default video-stream bitrate from metadata. Parameters: default_stream (int): selects specific video-stream in case of multiple ones. **Returns:** Default Video bitrate as string value. \"\"\" identifiers = [ \"Video:\" , \"Stream #\" ] video_bitrate_text = [ line . strip () for line in self . __ffsp_output . split ( \" \\n \" ) if all ( x in line for x in identifiers ) ] if video_bitrate_text : selected_stream = video_bitrate_text [ default_stream if default_stream > 0 and default_stream < len ( video_bitrate_text ) else 0 ] filtered_bitrate = re . findall ( r \",\\s[0-9]+\\s\\w\\w[\\/]s\" , selected_stream . strip () ) if len ( filtered_bitrate ): default_video_bitrate = filtered_bitrate [ 0 ] . split ( \" \" )[ 1 : 3 ] final_bitrate = \" {}{} \" . format ( int ( default_video_bitrate [ 0 ] . strip ()), \"k\" if ( default_video_bitrate [ 1 ] . strip () . startswith ( \"k\" )) else \"M\" , ) return final_bitrate return \"\" def __extract_video_decoder ( self , default_stream = 0 ): \"\"\" This Internal method parses default video-stream decoder from metadata. Parameters: default_stream (int): selects specific video-stream in case of multiple ones. **Returns:** Default Video decoder as string value. \"\"\" assert isinstance ( default_stream , int ), \"Invalid input!\" identifiers = [ \"Video:\" , \"Stream #\" ] meta_text = [ line . strip () for line in self . __ffsp_output . split ( \" \\n \" ) if all ( x in line for x in identifiers ) ] if meta_text : selected_stream = meta_text [ default_stream if default_stream > 0 and default_stream < len ( meta_text ) else 0 ] filtered_pixfmt = re . findall ( r \"Video:\\s[a-z0-9_-]*\" , selected_stream . strip () ) if filtered_pixfmt : return filtered_pixfmt [ 0 ] . split ( \" \" )[ - 1 ] return \"\" def __extract_video_pixfmt ( self , default_stream = 0 , extract_output = False ): \"\"\" This Internal method parses default video-stream pixel-format from metadata. Parameters: default_stream (int): selects specific video-stream in case of multiple ones. **Returns:** Default Video pixel-format as string value. \"\"\" identifiers = [ \"Video:\" , \"Stream #\" ] meta_text = ( [ line . strip () for line in self . __ffsp_output . split ( \" \\n \" ) if all ( x in line for x in identifiers ) ] if not extract_output else [ line . strip () for line in self . __metadata_output . split ( \" \\n \" ) if all ( x in line for x in identifiers ) ] ) if meta_text : selected_stream = meta_text [ default_stream if default_stream > 0 and default_stream < len ( meta_text ) else 0 ] filtered_pixfmt = re . findall ( r \",\\s[a-z][a-z0-9_-]*\" , selected_stream . strip () ) if filtered_pixfmt : return filtered_pixfmt [ 0 ] . split ( \" \" )[ - 1 ] return \"\" def __extract_audio_bitrate_nd_samplerate ( self , default_stream = 0 ): \"\"\" This Internal method parses default audio-stream bitrate and sample-rate from metadata. Parameters: default_stream (int): selects specific audio-stream in case of multiple ones. **Returns:** Default Audio-stream bitrate and sample-rate as string value. \"\"\" identifiers = [ \"Audio:\" , \"Stream #\" ] meta_text = [ line . strip () for line in self . __ffsp_output . split ( \" \\n \" ) if all ( x in line for x in identifiers ) ] result = {} if meta_text : selected_stream = meta_text [ default_stream if default_stream > 0 and default_stream < len ( meta_text ) else 0 ] # filter data filtered_audio_bitrate = re . findall ( r \"fltp,\\s[0-9]+\\s\\w\\w[\\/]s\" , selected_stream . strip () ) filtered_audio_samplerate = re . findall ( r \",\\s[0-9]+\\sHz\" , selected_stream . strip () ) # get audio bitrate metadata if filtered_audio_bitrate : filtered = filtered_audio_bitrate [ 0 ] . split ( \" \" )[ 1 : 3 ] result [ \"bitrate\" ] = \" {}{} \" . format ( int ( filtered [ 0 ] . strip ()), \"k\" if ( filtered [ 1 ] . strip () . startswith ( \"k\" )) else \"M\" , ) else : result [ \"bitrate\" ] = \"\" # get audio samplerate metadata result [ \"samplerate\" ] = ( filtered_audio_samplerate [ 0 ] . split ( \", \" )[ 1 ] if filtered_audio_samplerate else \"\" ) return result if result and ( len ( result ) == 2 ) else {} def __extract_resolution_framerate ( self , default_stream = 0 , extract_output = False ): \"\"\" This Internal method parses default video-stream resolution and framerate from metadata. Parameters: default_stream (int): selects specific audio-stream in case of multiple ones. extract_output (bool): Whether to extract from output(if true) or input(if false) stream? **Returns:** Default Video resolution and framerate as dictionary value. \"\"\" identifiers = [ \"Video:\" , \"Stream #\" ] # use output metadata if available meta_text = ( [ line . strip () for line in self . __ffsp_output . split ( \" \\n \" ) if all ( x in line for x in identifiers ) ] if not extract_output else [ line . strip () for line in self . __metadata_output . split ( \" \\n \" ) if all ( x in line for x in identifiers ) ] ) result = {} if meta_text : selected_stream = meta_text [ default_stream if default_stream > 0 and default_stream < len ( meta_text ) else 0 ] # filter data filtered_resolution = re . findall ( r \"([1-9]\\d+)x([1-9]\\d+)\" , selected_stream . strip () ) filtered_framerate = re . findall ( r \"\\d+(?:\\.\\d+)?\\sfps\" , selected_stream . strip () ) filtered_tbr = re . findall ( r \"\\d+(?:\\.\\d+)?\\stbr\" , selected_stream . strip ()) # extract framerate metadata if filtered_framerate : # calculate actual framerate result [ \"framerate\" ] = float ( re . findall ( r \"[\\d\\.\\d]+\" , filtered_framerate [ 0 ])[ 0 ] ) elif filtered_tbr : # guess from TBR(if fps unavailable) result [ \"framerate\" ] = float ( re . findall ( r \"[\\d\\.\\d]+\" , filtered_tbr [ 0 ])[ 0 ] ) # extract resolution metadata if filtered_resolution : result [ \"resolution\" ] = [ int ( x ) for x in filtered_resolution [ 0 ]] return result if result and ( len ( result ) == 2 ) else {} def __extract_duration ( self , inseconds = True ): \"\"\" This Internal method parses stream duration from metadata. Parameters: inseconds (bool): whether to parse time in second(s) or `HH::mm::ss`? **Returns:** Default Stream duration as string value. \"\"\" identifiers = [ \"Duration:\" ] stripped_data = [ line . strip () for line in self . __ffsp_output . split ( \" \\n \" ) if all ( x in line for x in identifiers ) ] if stripped_data : t_duration = re . findall ( r \"(?:[01]\\d|2[0123]):(?:[012345]\\d):(?:[012345]\\d+(?:\\.\\d+)?)\" , stripped_data [ 0 ], ) if t_duration : return ( sum ( float ( x ) * 60 ** i for i , x in enumerate ( reversed ( t_duration [ 0 ] . split ( \":\" ))) ) if inseconds else t_duration ) return 0 __init__ ( self , source , source_demuxer = None , custom_ffmpeg = '' , verbose = False , ** sourcer_params ) special \u00b6 This constructor method initializes the object state and attributes of the Sourcer Class. Parameters: Name Type Description Default source str defines the input( -i ) source filename/URL/device-name/device-path. required source_demuxer str specifies the demuxer( -f ) for the input source. None custom_ffmpeg str assigns the location of custom path/directory for custom FFmpeg executable. '' verbose bool enables/disables verbose. False sourcer_params dict provides the flexibility to control supported internal and FFmpeg parameters. {} Source code in deffcode/sourcer.py def __init__ ( self , source , source_demuxer = None , custom_ffmpeg = \"\" , verbose = False , ** sourcer_params , ): \"\"\" This constructor method initializes the object state and attributes of the Sourcer Class. Parameters: source (str): defines the input(`-i`) source filename/URL/device-name/device-path. source_demuxer (str): specifies the demuxer(`-f`) for the input source. custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executable. verbose (bool): enables/disables verbose. sourcer_params (dict): provides the flexibility to control supported internal and FFmpeg parameters. \"\"\" # checks if machine in-use is running windows os or not self . __machine_OS = platform . system () # define internal parameters self . __verbose_logs = ( # enable verbose if specified verbose if ( verbose and isinstance ( verbose , bool )) else False ) # handle metadata received self . __ffsp_output = None # sanitize sourcer_params self . __sourcer_params = { str ( k ) . strip (): str ( v ) . strip () if not isinstance ( v , ( dict , list , int , float , tuple )) else v for k , v in sourcer_params . items () } # handle whether to force validate source self . __forcevalidatesource = self . __sourcer_params . pop ( \"-force_validate_source\" , False ) if not isinstance ( self . __forcevalidatesource , bool ): # reset improper values self . __forcevalidatesource = False # handle user defined ffmpeg pre-headers(parameters such as `-re`) parameters (must be a list) self . __ffmpeg_prefixes = self . __sourcer_params . pop ( \"-ffprefixes\" , []) if not isinstance ( self . __ffmpeg_prefixes , list ): # log it logger . warning ( \"Discarding invalid `-ffprefixes` value of wrong type ` {} `!\" . format ( type ( self . __ffmpeg_prefixes ) . __name__ ) ) # reset improper values self . __ffmpeg_prefixes = [] # handle where to save the downloaded FFmpeg Static assets on Windows(if specified) __ffmpeg_download_path = self . __sourcer_params . pop ( \"-ffmpeg_download_path\" , \"\" ) if not isinstance ( __ffmpeg_download_path , str ): # reset improper values __ffmpeg_download_path = \"\" # validate the FFmpeg assets and return location (also downloads static assets on windows) self . __ffmpeg = get_valid_ffmpeg_path ( str ( custom_ffmpeg ), True if self . __machine_OS == \"Windows\" else False , ffmpeg_download_path = __ffmpeg_download_path , verbose = self . __verbose_logs , ) # check if valid FFmpeg path returned if self . __ffmpeg : self . __verbose_logs and logger . debug ( \"Found valid FFmpeg executable: ` {} `.\" . format ( self . __ffmpeg ) ) else : # else raise error raise RuntimeError ( \"[DeFFcode:ERROR] :: Failed to find FFmpeg assets on this system. Kindly compile/install FFmpeg or provide a valid custom FFmpeg binary path!\" ) # sanitize externally accessible parameters and assign them # handles source demuxer if source is None : # first check if source value is empty # raise error if true raise ValueError ( \"Input `source` parameter is empty!\" ) elif isinstance ( source_demuxer , str ): # assign if valid demuxer value self . __source_demuxer = source_demuxer . strip () . lower () # assign if valid demuxer value assert self . __source_demuxer != \"auto\" or validate_device_index ( source ), \"Invalid `source_demuxer='auto'` value detected with source: ` {} `. Aborting!\" . format ( source ) else : # otherwise find valid default source demuxer value # enforce \"auto\" if valid index device self . __source_demuxer = \"auto\" if validate_device_index ( source ) else None # log if not valid index device and invalid type self . __verbose_logs and not self . __source_demuxer in [ \"auto\" , None , ] and logger . warning ( \"Discarding invalid `source_demuxer` parameter value of wrong type: ` {} `\" . format ( type ( source_demuxer ) . __name__ ) ) # log if not valid index device and invalid type self . __verbose_logs and self . __source_demuxer == \"auto\" and logger . critical ( \"Given source ` {} ` is a valid device index. Enforcing 'auto' demuxer.\" . format ( source ) ) # handles source stream self . __source = source # creates shallow copy for further usage #TODO self . __source_org = copy . copy ( self . __source ) self . __source_demuxer_org = copy . copy ( self . __source_demuxer ) # handles all extracted devices names/paths list # when source_demuxer = \"auto\" self . __extracted_devices_list = [] # various source stream params self . __default_video_resolution = \"\" # handles stream resolution self . __default_video_framerate = \"\" # handles stream framerate self . __default_video_bitrate = \"\" # handles stream's video bitrate self . __default_video_pixfmt = \"\" # handles stream's video pixfmt self . __default_video_decoder = \"\" # handles stream's video decoder self . __default_source_duration = \"\" # handles stream's video duration self . __approx_video_nframes = \"\" # handles approx stream frame number self . __default_audio_bitrate = \"\" # handles stream's audio bitrate self . __default_audio_samplerate = \"\" # handles stream's audio samplerate # handle various stream flags self . __contains_video = False # contains video self . __contains_audio = False # contains audio self . __contains_images = False # contains image-sequence # handles output parameters through filters self . __metadata_output = None # handles output stream metadata self . __output_frames_resolution = \"\" # handles output stream resolution self . __output_framerate = \"\" # handles output stream framerate self . __output_frames_pixfmt = \"\" # handles output frame pixel format # check whether metadata probed or not? self . __metadata_probed = False probe_stream ( self , default_stream_indexes = ( 0 , 0 )) \u00b6 This method Parses/Probes FFmpeg subprocess pipe's Standard Output for given input source and Populates the information in private class variables. Parameters: Name Type Description Default default_stream_indexes list, tuple selects specific video and audio stream index in case of multiple ones. Value can be of format: (int,int) . For example (0,1) is (\"0 th video stream\", \"1 st audio stream\"). (0, 0) Returns: Reference to the instance object. Source code in deffcode/sourcer.py def probe_stream ( self , default_stream_indexes = ( 0 , 0 )): \"\"\" This method Parses/Probes FFmpeg `subprocess` pipe's Standard Output for given input source and Populates the information in private class variables. Parameters: default_stream_indexes (list, tuple): selects specific video and audio stream index in case of multiple ones. Value can be of format: `(int,int)`. For example `(0,1)` is (\"0th video stream\", \"1st audio stream\"). **Returns:** Reference to the instance object. \"\"\" assert ( isinstance ( default_stream_indexes , ( list , tuple )) and len ( default_stream_indexes ) == 2 and all ( isinstance ( x , int ) for x in default_stream_indexes ) ), \"Invalid default_stream_indexes value!\" # validate source and extract metadata self . __ffsp_output = self . __validate_source ( self . __source , source_demuxer = self . __source_demuxer , forced_validate = ( self . __forcevalidatesource if self . __source_demuxer is None else True ), ) # parse resolution and framerate video_rfparams = self . __extract_resolution_framerate ( default_stream = default_stream_indexes [ 0 ] ) if video_rfparams : self . __default_video_resolution = video_rfparams [ \"resolution\" ] self . __default_video_framerate = video_rfparams [ \"framerate\" ] # parse output parameters through filters (if available) if not ( self . __metadata_output is None ): # parse output resolution and framerate out_video_rfparams = self . __extract_resolution_framerate ( default_stream = default_stream_indexes [ 0 ], extract_output = True ) if out_video_rfparams : self . __output_frames_resolution = out_video_rfparams [ \"resolution\" ] self . __output_framerate = out_video_rfparams [ \"framerate\" ] # parse output pixel-format self . __output_frames_pixfmt = self . __extract_video_pixfmt ( default_stream = default_stream_indexes [ 0 ], extract_output = True ) # parse pixel-format self . __default_video_pixfmt = self . __extract_video_pixfmt ( default_stream = default_stream_indexes [ 0 ] ) # parse video decoder self . __default_video_decoder = self . __extract_video_decoder ( default_stream = default_stream_indexes [ 0 ] ) # parse rest of metadata if not self . __contains_images : # parse video bitrate self . __default_video_bitrate = self . __extract_video_bitrate ( default_stream = default_stream_indexes [ 0 ] ) # parse audio bitrate and samplerate audio_params = self . __extract_audio_bitrate_nd_samplerate ( default_stream = default_stream_indexes [ 1 ] ) if audio_params : self . __default_audio_bitrate = audio_params [ \"bitrate\" ] self . __default_audio_samplerate = audio_params [ \"samplerate\" ] # parse video duration self . __default_source_duration = self . __extract_duration () # calculate all flags if ( self . __default_video_bitrate or ( self . __default_video_framerate and self . __default_video_resolution ) ) and ( self . __default_audio_bitrate or self . __default_audio_samplerate ): self . __contains_video = True self . __contains_audio = True elif self . __default_video_bitrate or ( self . __default_video_framerate and self . __default_video_resolution ): self . __contains_video = True elif self . __default_audio_bitrate or self . __default_audio_samplerate : self . __contains_audio = True else : raise ValueError ( \"Invalid source with no decodable audio or video stream provided. Aborting!\" ) # calculate approximate number of video frame if self . __default_video_framerate and self . __default_source_duration : self . __approx_video_nframes = np . rint ( self . __default_video_framerate * self . __default_source_duration ) . astype ( int , casting = \"unsafe\" ) # signal metadata has been probed self . __metadata_probed = True # return reference to the instance object. return self retrieve_metadata ( self , pretty_json = False , force_retrieve_missing = False ) \u00b6 This method returns Parsed/Probed Metadata of the given source. Parameters: Name Type Description Default pretty_json bool whether to return metadata as JSON string(if True ) or Dictionary(if False ) type? False force_retrieve_output bool whether to also return metadata missing in current Pipeline. This method returns (metadata, metadata_missing) tuple if force_retrieve_output=True instead of metadata . required Returns: metadata or (metadata, metadata_missing) , formatted as JSON string or python dictionary. Source code in deffcode/sourcer.py def retrieve_metadata ( self , pretty_json = False , force_retrieve_missing = False ): \"\"\" This method returns Parsed/Probed Metadata of the given source. Parameters: pretty_json (bool): whether to return metadata as JSON string(if `True`) or Dictionary(if `False`) type? force_retrieve_output (bool): whether to also return metadata missing in current Pipeline. This method returns `(metadata, metadata_missing)` tuple if `force_retrieve_output=True` instead of `metadata`. **Returns:** `metadata` or `(metadata, metadata_missing)`, formatted as JSON string or python dictionary. \"\"\" # check if metadata has been probed or not assert ( self . __metadata_probed ), \"Source Metadata not been probed yet! Check if you called `probe_stream()` method.\" # log it self . __verbose_logs and logger . debug ( \"Extracting Metadata...\" ) # create metadata dictionary from information populated in private class variables metadata = { \"ffmpeg_binary_path\" : self . __ffmpeg , \"source\" : self . __source , } metadata_missing = {} # Only either `source_demuxer` or `source_extension` attribute can be # present in metadata. if self . __source_demuxer is None : metadata . update ({ \"source_extension\" : os . path . splitext ( self . __source )[ - 1 ]}) # update missing force_retrieve_missing and metadata_missing . update ({ \"source_demuxer\" : \"\" }) else : metadata . update ({ \"source_demuxer\" : self . __source_demuxer }) # update missing force_retrieve_missing and metadata_missing . update ({ \"source_extension\" : \"\" }) # add source video metadata properties metadata . update ( { \"source_video_resolution\" : self . __default_video_resolution , \"source_video_pixfmt\" : self . __default_video_pixfmt , \"source_video_framerate\" : self . __default_video_framerate , \"source_video_decoder\" : self . __default_video_decoder , \"source_duration_sec\" : self . __default_source_duration , \"approx_video_nframes\" : ( int ( self . __approx_video_nframes ) if self . __approx_video_nframes else None ), \"source_video_bitrate\" : self . __default_video_bitrate , \"source_audio_bitrate\" : self . __default_audio_bitrate , \"source_audio_samplerate\" : self . __default_audio_samplerate , \"source_has_video\" : self . __contains_video , \"source_has_audio\" : self . __contains_audio , \"source_has_image_sequence\" : self . __contains_images , } ) # add output metadata properties (if available) if not ( self . __metadata_output is None ): metadata . update ( { \"output_frames_resolution\" : self . __output_frames_resolution , \"output_frames_pixfmt\" : self . __output_frames_pixfmt , \"output_framerate\" : self . __output_framerate , } ) else : # since output stream metadata properties are only available when additional # FFmpeg parameters(such as filters) are defined manually, thereby missing # output stream properties are handled by assigning them counterpart source # stream metadata property values force_retrieve_missing and metadata_missing . update ( { \"output_frames_resolution\" : self . __default_video_resolution , \"output_frames_pixfmt\" : self . __default_video_pixfmt , \"output_framerate\" : self . __default_video_framerate , } ) # log it self . __verbose_logs and logger . debug ( \"Metadata Extraction completed successfully!\" ) # parse as JSON string(`json.dumps`), if defined metadata = json . dumps ( metadata , indent = 2 ) if pretty_json else metadata metadata_missing = ( json . dumps ( metadata_missing , indent = 2 ) if pretty_json else metadata_missing ) # return `metadata` or `(metadata, metadata_missing)` return metadata if not force_retrieve_missing else ( metadata , metadata_missing )","title":"API"},{"location":"reference/sourcer/#sourcer-api","text":"Sourcer API acts as Source Probing Utility that unlike other FFmpeg Wrappers which mostly uses ffprobe module, attempts to open the given Input Source directly with FFmpeg inside a subprocess pipe, and parses/probes the standard output(stdout) employing various pattern matching methods in order to recognize all the properties(metadata) of each media stream contained in it. Sourcer API primarily acts as a backend for FFdecoder API for gathering, processing, and validating all multimedia streams metadata available in the given Input Source. Sourcer shares this information with FFdecoder API which helps in formulating its default FFmpeg pipeline parameters for real-time video-frames generation. Sourcer API is design as a standalone Metadata Extraction API for easily parsing information from multimedia streams available in the given Input Source and returns it in either Human-readable (JSON string) or Machine-readable (Dictionary object) type with its retrieve_metadata() method. All metadata attributes available with Sourcer API(On Windows) are discussed here \u27b6 . Furthermore, Sourcer's sourcer_params dictionary parameter can be used to define almost any FFmpeg parameter as well as alter internal API settings. For usage examples, kindly refer our Basic Recipes and Advanced Recipes Sourcer API parameters are explained here \u27b6 Source code in deffcode/sourcer.py class Sourcer : \"\"\" > Sourcer API acts as **Source Probing Utility** that unlike other FFmpeg Wrappers which mostly uses [`ffprobe`](https://ffmpeg.org/ffprobe.html) module, attempts to open the given Input Source directly with [**FFmpeg**](https://ffmpeg.org/) inside a [`subprocess`](https://docs.python.org/3/library/subprocess.html) pipe, and parses/probes the standard output(stdout) employing various pattern matching methods in order to recognize all the properties(metadata) of each media stream contained in it. Sourcer API primarily acts as a **backend for [FFdecoder API](../../reference/ffdecoder)** for gathering, processing, and validating all multimedia streams metadata available in the given Input Source. Sourcer shares this information with FFdecoder API which helps in formulating its default FFmpeg pipeline parameters for real-time video-frames generation. Sourcer API is design as a standalone **Metadata Extraction API** for easily parsing information from multimedia streams available in the given Input Source and returns it in either Human-readable _(JSON string)_ or Machine-readable _(Dictionary object)_ type with its [`retrieve_metadata()`](#deffcode.sourcer.Sourcer.retrieve_metadata) method. !!! info \"All metadata attributes available with Sourcer API(On :fontawesome-brands-windows: Windows) are discussed [here \u27b6](../../recipes/basic/#display-source-video-metadata).\" Furthermore, Sourcer's [`sourcer_params`](params/#sourcer_params) dictionary parameter can be used to define almost any FFmpeg parameter as well as alter internal API settings. !!! example \"For usage examples, kindly refer our **[Basic Recipes :cake:](../../recipes/basic)** and **[Advanced Recipes :croissant:](../../recipes/advanced)**\" !!! info \"Sourcer API parameters are explained [here \u27b6](params/)\" \"\"\" def __init__ ( self , source , source_demuxer = None , custom_ffmpeg = \"\" , verbose = False , ** sourcer_params , ): \"\"\" This constructor method initializes the object state and attributes of the Sourcer Class. Parameters: source (str): defines the input(`-i`) source filename/URL/device-name/device-path. source_demuxer (str): specifies the demuxer(`-f`) for the input source. custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executable. verbose (bool): enables/disables verbose. sourcer_params (dict): provides the flexibility to control supported internal and FFmpeg parameters. \"\"\" # checks if machine in-use is running windows os or not self . __machine_OS = platform . system () # define internal parameters self . __verbose_logs = ( # enable verbose if specified verbose if ( verbose and isinstance ( verbose , bool )) else False ) # handle metadata received self . __ffsp_output = None # sanitize sourcer_params self . __sourcer_params = { str ( k ) . strip (): str ( v ) . strip () if not isinstance ( v , ( dict , list , int , float , tuple )) else v for k , v in sourcer_params . items () } # handle whether to force validate source self . __forcevalidatesource = self . __sourcer_params . pop ( \"-force_validate_source\" , False ) if not isinstance ( self . __forcevalidatesource , bool ): # reset improper values self . __forcevalidatesource = False # handle user defined ffmpeg pre-headers(parameters such as `-re`) parameters (must be a list) self . __ffmpeg_prefixes = self . __sourcer_params . pop ( \"-ffprefixes\" , []) if not isinstance ( self . __ffmpeg_prefixes , list ): # log it logger . warning ( \"Discarding invalid `-ffprefixes` value of wrong type ` {} `!\" . format ( type ( self . __ffmpeg_prefixes ) . __name__ ) ) # reset improper values self . __ffmpeg_prefixes = [] # handle where to save the downloaded FFmpeg Static assets on Windows(if specified) __ffmpeg_download_path = self . __sourcer_params . pop ( \"-ffmpeg_download_path\" , \"\" ) if not isinstance ( __ffmpeg_download_path , str ): # reset improper values __ffmpeg_download_path = \"\" # validate the FFmpeg assets and return location (also downloads static assets on windows) self . __ffmpeg = get_valid_ffmpeg_path ( str ( custom_ffmpeg ), True if self . __machine_OS == \"Windows\" else False , ffmpeg_download_path = __ffmpeg_download_path , verbose = self . __verbose_logs , ) # check if valid FFmpeg path returned if self . __ffmpeg : self . __verbose_logs and logger . debug ( \"Found valid FFmpeg executable: ` {} `.\" . format ( self . __ffmpeg ) ) else : # else raise error raise RuntimeError ( \"[DeFFcode:ERROR] :: Failed to find FFmpeg assets on this system. Kindly compile/install FFmpeg or provide a valid custom FFmpeg binary path!\" ) # sanitize externally accessible parameters and assign them # handles source demuxer if source is None : # first check if source value is empty # raise error if true raise ValueError ( \"Input `source` parameter is empty!\" ) elif isinstance ( source_demuxer , str ): # assign if valid demuxer value self . __source_demuxer = source_demuxer . strip () . lower () # assign if valid demuxer value assert self . __source_demuxer != \"auto\" or validate_device_index ( source ), \"Invalid `source_demuxer='auto'` value detected with source: ` {} `. Aborting!\" . format ( source ) else : # otherwise find valid default source demuxer value # enforce \"auto\" if valid index device self . __source_demuxer = \"auto\" if validate_device_index ( source ) else None # log if not valid index device and invalid type self . __verbose_logs and not self . __source_demuxer in [ \"auto\" , None , ] and logger . warning ( \"Discarding invalid `source_demuxer` parameter value of wrong type: ` {} `\" . format ( type ( source_demuxer ) . __name__ ) ) # log if not valid index device and invalid type self . __verbose_logs and self . __source_demuxer == \"auto\" and logger . critical ( \"Given source ` {} ` is a valid device index. Enforcing 'auto' demuxer.\" . format ( source ) ) # handles source stream self . __source = source # creates shallow copy for further usage #TODO self . __source_org = copy . copy ( self . __source ) self . __source_demuxer_org = copy . copy ( self . __source_demuxer ) # handles all extracted devices names/paths list # when source_demuxer = \"auto\" self . __extracted_devices_list = [] # various source stream params self . __default_video_resolution = \"\" # handles stream resolution self . __default_video_framerate = \"\" # handles stream framerate self . __default_video_bitrate = \"\" # handles stream's video bitrate self . __default_video_pixfmt = \"\" # handles stream's video pixfmt self . __default_video_decoder = \"\" # handles stream's video decoder self . __default_source_duration = \"\" # handles stream's video duration self . __approx_video_nframes = \"\" # handles approx stream frame number self . __default_audio_bitrate = \"\" # handles stream's audio bitrate self . __default_audio_samplerate = \"\" # handles stream's audio samplerate # handle various stream flags self . __contains_video = False # contains video self . __contains_audio = False # contains audio self . __contains_images = False # contains image-sequence # handles output parameters through filters self . __metadata_output = None # handles output stream metadata self . __output_frames_resolution = \"\" # handles output stream resolution self . __output_framerate = \"\" # handles output stream framerate self . __output_frames_pixfmt = \"\" # handles output frame pixel format # check whether metadata probed or not? self . __metadata_probed = False def probe_stream ( self , default_stream_indexes = ( 0 , 0 )): \"\"\" This method Parses/Probes FFmpeg `subprocess` pipe's Standard Output for given input source and Populates the information in private class variables. Parameters: default_stream_indexes (list, tuple): selects specific video and audio stream index in case of multiple ones. Value can be of format: `(int,int)`. For example `(0,1)` is (\"0th video stream\", \"1st audio stream\"). **Returns:** Reference to the instance object. \"\"\" assert ( isinstance ( default_stream_indexes , ( list , tuple )) and len ( default_stream_indexes ) == 2 and all ( isinstance ( x , int ) for x in default_stream_indexes ) ), \"Invalid default_stream_indexes value!\" # validate source and extract metadata self . __ffsp_output = self . __validate_source ( self . __source , source_demuxer = self . __source_demuxer , forced_validate = ( self . __forcevalidatesource if self . __source_demuxer is None else True ), ) # parse resolution and framerate video_rfparams = self . __extract_resolution_framerate ( default_stream = default_stream_indexes [ 0 ] ) if video_rfparams : self . __default_video_resolution = video_rfparams [ \"resolution\" ] self . __default_video_framerate = video_rfparams [ \"framerate\" ] # parse output parameters through filters (if available) if not ( self . __metadata_output is None ): # parse output resolution and framerate out_video_rfparams = self . __extract_resolution_framerate ( default_stream = default_stream_indexes [ 0 ], extract_output = True ) if out_video_rfparams : self . __output_frames_resolution = out_video_rfparams [ \"resolution\" ] self . __output_framerate = out_video_rfparams [ \"framerate\" ] # parse output pixel-format self . __output_frames_pixfmt = self . __extract_video_pixfmt ( default_stream = default_stream_indexes [ 0 ], extract_output = True ) # parse pixel-format self . __default_video_pixfmt = self . __extract_video_pixfmt ( default_stream = default_stream_indexes [ 0 ] ) # parse video decoder self . __default_video_decoder = self . __extract_video_decoder ( default_stream = default_stream_indexes [ 0 ] ) # parse rest of metadata if not self . __contains_images : # parse video bitrate self . __default_video_bitrate = self . __extract_video_bitrate ( default_stream = default_stream_indexes [ 0 ] ) # parse audio bitrate and samplerate audio_params = self . __extract_audio_bitrate_nd_samplerate ( default_stream = default_stream_indexes [ 1 ] ) if audio_params : self . __default_audio_bitrate = audio_params [ \"bitrate\" ] self . __default_audio_samplerate = audio_params [ \"samplerate\" ] # parse video duration self . __default_source_duration = self . __extract_duration () # calculate all flags if ( self . __default_video_bitrate or ( self . __default_video_framerate and self . __default_video_resolution ) ) and ( self . __default_audio_bitrate or self . __default_audio_samplerate ): self . __contains_video = True self . __contains_audio = True elif self . __default_video_bitrate or ( self . __default_video_framerate and self . __default_video_resolution ): self . __contains_video = True elif self . __default_audio_bitrate or self . __default_audio_samplerate : self . __contains_audio = True else : raise ValueError ( \"Invalid source with no decodable audio or video stream provided. Aborting!\" ) # calculate approximate number of video frame if self . __default_video_framerate and self . __default_source_duration : self . __approx_video_nframes = np . rint ( self . __default_video_framerate * self . __default_source_duration ) . astype ( int , casting = \"unsafe\" ) # signal metadata has been probed self . __metadata_probed = True # return reference to the instance object. return self def retrieve_metadata ( self , pretty_json = False , force_retrieve_missing = False ): \"\"\" This method returns Parsed/Probed Metadata of the given source. Parameters: pretty_json (bool): whether to return metadata as JSON string(if `True`) or Dictionary(if `False`) type? force_retrieve_output (bool): whether to also return metadata missing in current Pipeline. This method returns `(metadata, metadata_missing)` tuple if `force_retrieve_output=True` instead of `metadata`. **Returns:** `metadata` or `(metadata, metadata_missing)`, formatted as JSON string or python dictionary. \"\"\" # check if metadata has been probed or not assert ( self . __metadata_probed ), \"Source Metadata not been probed yet! Check if you called `probe_stream()` method.\" # log it self . __verbose_logs and logger . debug ( \"Extracting Metadata...\" ) # create metadata dictionary from information populated in private class variables metadata = { \"ffmpeg_binary_path\" : self . __ffmpeg , \"source\" : self . __source , } metadata_missing = {} # Only either `source_demuxer` or `source_extension` attribute can be # present in metadata. if self . __source_demuxer is None : metadata . update ({ \"source_extension\" : os . path . splitext ( self . __source )[ - 1 ]}) # update missing force_retrieve_missing and metadata_missing . update ({ \"source_demuxer\" : \"\" }) else : metadata . update ({ \"source_demuxer\" : self . __source_demuxer }) # update missing force_retrieve_missing and metadata_missing . update ({ \"source_extension\" : \"\" }) # add source video metadata properties metadata . update ( { \"source_video_resolution\" : self . __default_video_resolution , \"source_video_pixfmt\" : self . __default_video_pixfmt , \"source_video_framerate\" : self . __default_video_framerate , \"source_video_decoder\" : self . __default_video_decoder , \"source_duration_sec\" : self . __default_source_duration , \"approx_video_nframes\" : ( int ( self . __approx_video_nframes ) if self . __approx_video_nframes else None ), \"source_video_bitrate\" : self . __default_video_bitrate , \"source_audio_bitrate\" : self . __default_audio_bitrate , \"source_audio_samplerate\" : self . __default_audio_samplerate , \"source_has_video\" : self . __contains_video , \"source_has_audio\" : self . __contains_audio , \"source_has_image_sequence\" : self . __contains_images , } ) # add output metadata properties (if available) if not ( self . __metadata_output is None ): metadata . update ( { \"output_frames_resolution\" : self . __output_frames_resolution , \"output_frames_pixfmt\" : self . __output_frames_pixfmt , \"output_framerate\" : self . __output_framerate , } ) else : # since output stream metadata properties are only available when additional # FFmpeg parameters(such as filters) are defined manually, thereby missing # output stream properties are handled by assigning them counterpart source # stream metadata property values force_retrieve_missing and metadata_missing . update ( { \"output_frames_resolution\" : self . __default_video_resolution , \"output_frames_pixfmt\" : self . __default_video_pixfmt , \"output_framerate\" : self . __default_video_framerate , } ) # log it self . __verbose_logs and logger . debug ( \"Metadata Extraction completed successfully!\" ) # parse as JSON string(`json.dumps`), if defined metadata = json . dumps ( metadata , indent = 2 ) if pretty_json else metadata metadata_missing = ( json . dumps ( metadata_missing , indent = 2 ) if pretty_json else metadata_missing ) # return `metadata` or `(metadata, metadata_missing)` return metadata if not force_retrieve_missing else ( metadata , metadata_missing ) def __validate_source ( self , source , source_demuxer = None , forced_validate = False ): \"\"\" This Internal method validates source and extracts its metadata. Parameters: source_demuxer(str): specifies the demuxer(`-f`) for the input source. forced_validate (bool): whether to skip validation tests or not? **Returns:** `True` if passed tests else `False`. \"\"\" # validate source demuxer(if defined) if not ( source_demuxer is None ): # check if \"auto\" demuxer is specified if source_demuxer == \"auto\" : # integerise source to get index index = int ( source ) # extract devices list and actual demuxer value ( self . __extracted_devices_list , source_demuxer , ) = extract_device_n_demuxer ( self . __ffmpeg , machine_OS = self . __machine_OS , verbose = self . __verbose_logs , ) # valid indexes range valid_indexes = [ x for x in range ( - len ( self . __extracted_devices_list ), len ( self . __extracted_devices_list ), ) ] # check index is within valid range if self . __extracted_devices_list and index in valid_indexes : # overwrite actual source device name/path/index if self . __machine_OS == \"Windows\" : # Windows OS requires \"video=\" suffix self . __source = source = \"video= {} \" . format ( self . __extracted_devices_list [ index ] ) elif self . __machine_OS == \"Darwin\" : # Darwin OS requires only device indexes self . __source = source = ( str ( index ) if index >= 0 else str ( len ( self . __extracted_devices_list ) + index ) ) else : # Linux OS require /dev/video format self . __source = source = next ( iter ( self . __extracted_devices_list [ index ] . keys ()) ) # overwrite source_demuxer global variable self . __source_demuxer = source_demuxer self . __verbose_logs and logger . debug ( \"Successfully configured device ` {} ` at index ` {} ` with demuxer ` {} `.\" . format ( self . __extracted_devices_list [ index ] if self . __machine_OS != \"Linux\" else next ( iter ( self . __extracted_devices_list [ index ] . values ()) )[ 0 ], index if index >= 0 else len ( self . __extracted_devices_list ) + index , self . __source_demuxer , ) ) else : # raise error otherwise raise ValueError ( \"Given source ` {} ` is not a valid device index. Possible values index values can be: {} \" . format ( source , \",\" . join ( f \" { x } \" for x in valid_indexes ), ) ) # otherwise validate against supported demuxers elif not ( source_demuxer in get_supported_demuxers ( self . __ffmpeg )): # raise if fails raise ValueError ( \"Installed FFmpeg failed to recognize ` {} ` demuxer. Check `source_demuxer` parameter value again!\" . format ( source_demuxer ) ) else : pass # assert if valid source assert source and isinstance ( source , str ), \"Input `source` parameter is of invalid type!\" # Differentiate input if forced_validate : source_demuxer is None and logger . critical ( \"Forcefully passing validation test for given source!\" ) self . __source = source elif os . path . isfile ( source ): self . __source = os . path . abspath ( source ) elif is_valid_image_seq ( self . __ffmpeg , source = source , verbose = self . __verbose_logs ): self . __source = source self . __contains_images = True elif is_valid_url ( self . __ffmpeg , url = source , verbose = self . __verbose_logs ): self . __source = source else : logger . error ( \"`source` value is unusable or unsupported!\" ) # discard the value otherwise raise ValueError ( \"Input source is invalid. Aborting!\" ) # format command if self . __sourcer_params : # handle additional params separately meta_cmd = ( [ self . __ffmpeg ] + ([ \"-hide_banner\" ] if not self . __verbose_logs else []) + [ \"-t\" , \"0.0001\" ] + self . __ffmpeg_prefixes + ([ \"-f\" , source_demuxer ] if source_demuxer else []) + [ \"-i\" , source ] + dict2Args ( self . __sourcer_params ) + [ \"-f\" , \"null\" , \"-\" ] ) else : meta_cmd = ( [ self . __ffmpeg ] + ([ \"-hide_banner\" ] if not self . __verbose_logs else []) + self . __ffmpeg_prefixes + ([ \"-f\" , source_demuxer ] if source_demuxer else []) + [ \"-i\" , source ] ) # extract metadata, decode, and filter metadata = ( check_sp_output ( meta_cmd , force_retrieve_stderr = True , ) . decode ( \"utf-8\" ) . strip () ) # separate input and output metadata (if available) if \"Output #\" in metadata : ( metadata , self . __metadata_output ) = metadata . split ( \"Output #\" ) # return metadata based on params return metadata def __extract_video_bitrate ( self , default_stream = 0 ): \"\"\" This Internal method parses default video-stream bitrate from metadata. Parameters: default_stream (int): selects specific video-stream in case of multiple ones. **Returns:** Default Video bitrate as string value. \"\"\" identifiers = [ \"Video:\" , \"Stream #\" ] video_bitrate_text = [ line . strip () for line in self . __ffsp_output . split ( \" \\n \" ) if all ( x in line for x in identifiers ) ] if video_bitrate_text : selected_stream = video_bitrate_text [ default_stream if default_stream > 0 and default_stream < len ( video_bitrate_text ) else 0 ] filtered_bitrate = re . findall ( r \",\\s[0-9]+\\s\\w\\w[\\/]s\" , selected_stream . strip () ) if len ( filtered_bitrate ): default_video_bitrate = filtered_bitrate [ 0 ] . split ( \" \" )[ 1 : 3 ] final_bitrate = \" {}{} \" . format ( int ( default_video_bitrate [ 0 ] . strip ()), \"k\" if ( default_video_bitrate [ 1 ] . strip () . startswith ( \"k\" )) else \"M\" , ) return final_bitrate return \"\" def __extract_video_decoder ( self , default_stream = 0 ): \"\"\" This Internal method parses default video-stream decoder from metadata. Parameters: default_stream (int): selects specific video-stream in case of multiple ones. **Returns:** Default Video decoder as string value. \"\"\" assert isinstance ( default_stream , int ), \"Invalid input!\" identifiers = [ \"Video:\" , \"Stream #\" ] meta_text = [ line . strip () for line in self . __ffsp_output . split ( \" \\n \" ) if all ( x in line for x in identifiers ) ] if meta_text : selected_stream = meta_text [ default_stream if default_stream > 0 and default_stream < len ( meta_text ) else 0 ] filtered_pixfmt = re . findall ( r \"Video:\\s[a-z0-9_-]*\" , selected_stream . strip () ) if filtered_pixfmt : return filtered_pixfmt [ 0 ] . split ( \" \" )[ - 1 ] return \"\" def __extract_video_pixfmt ( self , default_stream = 0 , extract_output = False ): \"\"\" This Internal method parses default video-stream pixel-format from metadata. Parameters: default_stream (int): selects specific video-stream in case of multiple ones. **Returns:** Default Video pixel-format as string value. \"\"\" identifiers = [ \"Video:\" , \"Stream #\" ] meta_text = ( [ line . strip () for line in self . __ffsp_output . split ( \" \\n \" ) if all ( x in line for x in identifiers ) ] if not extract_output else [ line . strip () for line in self . __metadata_output . split ( \" \\n \" ) if all ( x in line for x in identifiers ) ] ) if meta_text : selected_stream = meta_text [ default_stream if default_stream > 0 and default_stream < len ( meta_text ) else 0 ] filtered_pixfmt = re . findall ( r \",\\s[a-z][a-z0-9_-]*\" , selected_stream . strip () ) if filtered_pixfmt : return filtered_pixfmt [ 0 ] . split ( \" \" )[ - 1 ] return \"\" def __extract_audio_bitrate_nd_samplerate ( self , default_stream = 0 ): \"\"\" This Internal method parses default audio-stream bitrate and sample-rate from metadata. Parameters: default_stream (int): selects specific audio-stream in case of multiple ones. **Returns:** Default Audio-stream bitrate and sample-rate as string value. \"\"\" identifiers = [ \"Audio:\" , \"Stream #\" ] meta_text = [ line . strip () for line in self . __ffsp_output . split ( \" \\n \" ) if all ( x in line for x in identifiers ) ] result = {} if meta_text : selected_stream = meta_text [ default_stream if default_stream > 0 and default_stream < len ( meta_text ) else 0 ] # filter data filtered_audio_bitrate = re . findall ( r \"fltp,\\s[0-9]+\\s\\w\\w[\\/]s\" , selected_stream . strip () ) filtered_audio_samplerate = re . findall ( r \",\\s[0-9]+\\sHz\" , selected_stream . strip () ) # get audio bitrate metadata if filtered_audio_bitrate : filtered = filtered_audio_bitrate [ 0 ] . split ( \" \" )[ 1 : 3 ] result [ \"bitrate\" ] = \" {}{} \" . format ( int ( filtered [ 0 ] . strip ()), \"k\" if ( filtered [ 1 ] . strip () . startswith ( \"k\" )) else \"M\" , ) else : result [ \"bitrate\" ] = \"\" # get audio samplerate metadata result [ \"samplerate\" ] = ( filtered_audio_samplerate [ 0 ] . split ( \", \" )[ 1 ] if filtered_audio_samplerate else \"\" ) return result if result and ( len ( result ) == 2 ) else {} def __extract_resolution_framerate ( self , default_stream = 0 , extract_output = False ): \"\"\" This Internal method parses default video-stream resolution and framerate from metadata. Parameters: default_stream (int): selects specific audio-stream in case of multiple ones. extract_output (bool): Whether to extract from output(if true) or input(if false) stream? **Returns:** Default Video resolution and framerate as dictionary value. \"\"\" identifiers = [ \"Video:\" , \"Stream #\" ] # use output metadata if available meta_text = ( [ line . strip () for line in self . __ffsp_output . split ( \" \\n \" ) if all ( x in line for x in identifiers ) ] if not extract_output else [ line . strip () for line in self . __metadata_output . split ( \" \\n \" ) if all ( x in line for x in identifiers ) ] ) result = {} if meta_text : selected_stream = meta_text [ default_stream if default_stream > 0 and default_stream < len ( meta_text ) else 0 ] # filter data filtered_resolution = re . findall ( r \"([1-9]\\d+)x([1-9]\\d+)\" , selected_stream . strip () ) filtered_framerate = re . findall ( r \"\\d+(?:\\.\\d+)?\\sfps\" , selected_stream . strip () ) filtered_tbr = re . findall ( r \"\\d+(?:\\.\\d+)?\\stbr\" , selected_stream . strip ()) # extract framerate metadata if filtered_framerate : # calculate actual framerate result [ \"framerate\" ] = float ( re . findall ( r \"[\\d\\.\\d]+\" , filtered_framerate [ 0 ])[ 0 ] ) elif filtered_tbr : # guess from TBR(if fps unavailable) result [ \"framerate\" ] = float ( re . findall ( r \"[\\d\\.\\d]+\" , filtered_tbr [ 0 ])[ 0 ] ) # extract resolution metadata if filtered_resolution : result [ \"resolution\" ] = [ int ( x ) for x in filtered_resolution [ 0 ]] return result if result and ( len ( result ) == 2 ) else {} def __extract_duration ( self , inseconds = True ): \"\"\" This Internal method parses stream duration from metadata. Parameters: inseconds (bool): whether to parse time in second(s) or `HH::mm::ss`? **Returns:** Default Stream duration as string value. \"\"\" identifiers = [ \"Duration:\" ] stripped_data = [ line . strip () for line in self . __ffsp_output . split ( \" \\n \" ) if all ( x in line for x in identifiers ) ] if stripped_data : t_duration = re . findall ( r \"(?:[01]\\d|2[0123]):(?:[012345]\\d):(?:[012345]\\d+(?:\\.\\d+)?)\" , stripped_data [ 0 ], ) if t_duration : return ( sum ( float ( x ) * 60 ** i for i , x in enumerate ( reversed ( t_duration [ 0 ] . split ( \":\" ))) ) if inseconds else t_duration ) return 0","title":"Sourcer API"},{"location":"reference/sourcer/#deffcode.sourcer.Sourcer.__init__","text":"This constructor method initializes the object state and attributes of the Sourcer Class. Parameters: Name Type Description Default source str defines the input( -i ) source filename/URL/device-name/device-path. required source_demuxer str specifies the demuxer( -f ) for the input source. None custom_ffmpeg str assigns the location of custom path/directory for custom FFmpeg executable. '' verbose bool enables/disables verbose. False sourcer_params dict provides the flexibility to control supported internal and FFmpeg parameters. {} Source code in deffcode/sourcer.py def __init__ ( self , source , source_demuxer = None , custom_ffmpeg = \"\" , verbose = False , ** sourcer_params , ): \"\"\" This constructor method initializes the object state and attributes of the Sourcer Class. Parameters: source (str): defines the input(`-i`) source filename/URL/device-name/device-path. source_demuxer (str): specifies the demuxer(`-f`) for the input source. custom_ffmpeg (str): assigns the location of custom path/directory for custom FFmpeg executable. verbose (bool): enables/disables verbose. sourcer_params (dict): provides the flexibility to control supported internal and FFmpeg parameters. \"\"\" # checks if machine in-use is running windows os or not self . __machine_OS = platform . system () # define internal parameters self . __verbose_logs = ( # enable verbose if specified verbose if ( verbose and isinstance ( verbose , bool )) else False ) # handle metadata received self . __ffsp_output = None # sanitize sourcer_params self . __sourcer_params = { str ( k ) . strip (): str ( v ) . strip () if not isinstance ( v , ( dict , list , int , float , tuple )) else v for k , v in sourcer_params . items () } # handle whether to force validate source self . __forcevalidatesource = self . __sourcer_params . pop ( \"-force_validate_source\" , False ) if not isinstance ( self . __forcevalidatesource , bool ): # reset improper values self . __forcevalidatesource = False # handle user defined ffmpeg pre-headers(parameters such as `-re`) parameters (must be a list) self . __ffmpeg_prefixes = self . __sourcer_params . pop ( \"-ffprefixes\" , []) if not isinstance ( self . __ffmpeg_prefixes , list ): # log it logger . warning ( \"Discarding invalid `-ffprefixes` value of wrong type ` {} `!\" . format ( type ( self . __ffmpeg_prefixes ) . __name__ ) ) # reset improper values self . __ffmpeg_prefixes = [] # handle where to save the downloaded FFmpeg Static assets on Windows(if specified) __ffmpeg_download_path = self . __sourcer_params . pop ( \"-ffmpeg_download_path\" , \"\" ) if not isinstance ( __ffmpeg_download_path , str ): # reset improper values __ffmpeg_download_path = \"\" # validate the FFmpeg assets and return location (also downloads static assets on windows) self . __ffmpeg = get_valid_ffmpeg_path ( str ( custom_ffmpeg ), True if self . __machine_OS == \"Windows\" else False , ffmpeg_download_path = __ffmpeg_download_path , verbose = self . __verbose_logs , ) # check if valid FFmpeg path returned if self . __ffmpeg : self . __verbose_logs and logger . debug ( \"Found valid FFmpeg executable: ` {} `.\" . format ( self . __ffmpeg ) ) else : # else raise error raise RuntimeError ( \"[DeFFcode:ERROR] :: Failed to find FFmpeg assets on this system. Kindly compile/install FFmpeg or provide a valid custom FFmpeg binary path!\" ) # sanitize externally accessible parameters and assign them # handles source demuxer if source is None : # first check if source value is empty # raise error if true raise ValueError ( \"Input `source` parameter is empty!\" ) elif isinstance ( source_demuxer , str ): # assign if valid demuxer value self . __source_demuxer = source_demuxer . strip () . lower () # assign if valid demuxer value assert self . __source_demuxer != \"auto\" or validate_device_index ( source ), \"Invalid `source_demuxer='auto'` value detected with source: ` {} `. Aborting!\" . format ( source ) else : # otherwise find valid default source demuxer value # enforce \"auto\" if valid index device self . __source_demuxer = \"auto\" if validate_device_index ( source ) else None # log if not valid index device and invalid type self . __verbose_logs and not self . __source_demuxer in [ \"auto\" , None , ] and logger . warning ( \"Discarding invalid `source_demuxer` parameter value of wrong type: ` {} `\" . format ( type ( source_demuxer ) . __name__ ) ) # log if not valid index device and invalid type self . __verbose_logs and self . __source_demuxer == \"auto\" and logger . critical ( \"Given source ` {} ` is a valid device index. Enforcing 'auto' demuxer.\" . format ( source ) ) # handles source stream self . __source = source # creates shallow copy for further usage #TODO self . __source_org = copy . copy ( self . __source ) self . __source_demuxer_org = copy . copy ( self . __source_demuxer ) # handles all extracted devices names/paths list # when source_demuxer = \"auto\" self . __extracted_devices_list = [] # various source stream params self . __default_video_resolution = \"\" # handles stream resolution self . __default_video_framerate = \"\" # handles stream framerate self . __default_video_bitrate = \"\" # handles stream's video bitrate self . __default_video_pixfmt = \"\" # handles stream's video pixfmt self . __default_video_decoder = \"\" # handles stream's video decoder self . __default_source_duration = \"\" # handles stream's video duration self . __approx_video_nframes = \"\" # handles approx stream frame number self . __default_audio_bitrate = \"\" # handles stream's audio bitrate self . __default_audio_samplerate = \"\" # handles stream's audio samplerate # handle various stream flags self . __contains_video = False # contains video self . __contains_audio = False # contains audio self . __contains_images = False # contains image-sequence # handles output parameters through filters self . __metadata_output = None # handles output stream metadata self . __output_frames_resolution = \"\" # handles output stream resolution self . __output_framerate = \"\" # handles output stream framerate self . __output_frames_pixfmt = \"\" # handles output frame pixel format # check whether metadata probed or not? self . __metadata_probed = False","title":"__init__()"},{"location":"reference/sourcer/#deffcode.sourcer.Sourcer.probe_stream","text":"This method Parses/Probes FFmpeg subprocess pipe's Standard Output for given input source and Populates the information in private class variables. Parameters: Name Type Description Default default_stream_indexes list, tuple selects specific video and audio stream index in case of multiple ones. Value can be of format: (int,int) . For example (0,1) is (\"0 th video stream\", \"1 st audio stream\"). (0, 0) Returns: Reference to the instance object. Source code in deffcode/sourcer.py def probe_stream ( self , default_stream_indexes = ( 0 , 0 )): \"\"\" This method Parses/Probes FFmpeg `subprocess` pipe's Standard Output for given input source and Populates the information in private class variables. Parameters: default_stream_indexes (list, tuple): selects specific video and audio stream index in case of multiple ones. Value can be of format: `(int,int)`. For example `(0,1)` is (\"0th video stream\", \"1st audio stream\"). **Returns:** Reference to the instance object. \"\"\" assert ( isinstance ( default_stream_indexes , ( list , tuple )) and len ( default_stream_indexes ) == 2 and all ( isinstance ( x , int ) for x in default_stream_indexes ) ), \"Invalid default_stream_indexes value!\" # validate source and extract metadata self . __ffsp_output = self . __validate_source ( self . __source , source_demuxer = self . __source_demuxer , forced_validate = ( self . __forcevalidatesource if self . __source_demuxer is None else True ), ) # parse resolution and framerate video_rfparams = self . __extract_resolution_framerate ( default_stream = default_stream_indexes [ 0 ] ) if video_rfparams : self . __default_video_resolution = video_rfparams [ \"resolution\" ] self . __default_video_framerate = video_rfparams [ \"framerate\" ] # parse output parameters through filters (if available) if not ( self . __metadata_output is None ): # parse output resolution and framerate out_video_rfparams = self . __extract_resolution_framerate ( default_stream = default_stream_indexes [ 0 ], extract_output = True ) if out_video_rfparams : self . __output_frames_resolution = out_video_rfparams [ \"resolution\" ] self . __output_framerate = out_video_rfparams [ \"framerate\" ] # parse output pixel-format self . __output_frames_pixfmt = self . __extract_video_pixfmt ( default_stream = default_stream_indexes [ 0 ], extract_output = True ) # parse pixel-format self . __default_video_pixfmt = self . __extract_video_pixfmt ( default_stream = default_stream_indexes [ 0 ] ) # parse video decoder self . __default_video_decoder = self . __extract_video_decoder ( default_stream = default_stream_indexes [ 0 ] ) # parse rest of metadata if not self . __contains_images : # parse video bitrate self . __default_video_bitrate = self . __extract_video_bitrate ( default_stream = default_stream_indexes [ 0 ] ) # parse audio bitrate and samplerate audio_params = self . __extract_audio_bitrate_nd_samplerate ( default_stream = default_stream_indexes [ 1 ] ) if audio_params : self . __default_audio_bitrate = audio_params [ \"bitrate\" ] self . __default_audio_samplerate = audio_params [ \"samplerate\" ] # parse video duration self . __default_source_duration = self . __extract_duration () # calculate all flags if ( self . __default_video_bitrate or ( self . __default_video_framerate and self . __default_video_resolution ) ) and ( self . __default_audio_bitrate or self . __default_audio_samplerate ): self . __contains_video = True self . __contains_audio = True elif self . __default_video_bitrate or ( self . __default_video_framerate and self . __default_video_resolution ): self . __contains_video = True elif self . __default_audio_bitrate or self . __default_audio_samplerate : self . __contains_audio = True else : raise ValueError ( \"Invalid source with no decodable audio or video stream provided. Aborting!\" ) # calculate approximate number of video frame if self . __default_video_framerate and self . __default_source_duration : self . __approx_video_nframes = np . rint ( self . __default_video_framerate * self . __default_source_duration ) . astype ( int , casting = \"unsafe\" ) # signal metadata has been probed self . __metadata_probed = True # return reference to the instance object. return self","title":"probe_stream()"},{"location":"reference/sourcer/#deffcode.sourcer.Sourcer.retrieve_metadata","text":"This method returns Parsed/Probed Metadata of the given source. Parameters: Name Type Description Default pretty_json bool whether to return metadata as JSON string(if True ) or Dictionary(if False ) type? False force_retrieve_output bool whether to also return metadata missing in current Pipeline. This method returns (metadata, metadata_missing) tuple if force_retrieve_output=True instead of metadata . required Returns: metadata or (metadata, metadata_missing) , formatted as JSON string or python dictionary. Source code in deffcode/sourcer.py def retrieve_metadata ( self , pretty_json = False , force_retrieve_missing = False ): \"\"\" This method returns Parsed/Probed Metadata of the given source. Parameters: pretty_json (bool): whether to return metadata as JSON string(if `True`) or Dictionary(if `False`) type? force_retrieve_output (bool): whether to also return metadata missing in current Pipeline. This method returns `(metadata, metadata_missing)` tuple if `force_retrieve_output=True` instead of `metadata`. **Returns:** `metadata` or `(metadata, metadata_missing)`, formatted as JSON string or python dictionary. \"\"\" # check if metadata has been probed or not assert ( self . __metadata_probed ), \"Source Metadata not been probed yet! Check if you called `probe_stream()` method.\" # log it self . __verbose_logs and logger . debug ( \"Extracting Metadata...\" ) # create metadata dictionary from information populated in private class variables metadata = { \"ffmpeg_binary_path\" : self . __ffmpeg , \"source\" : self . __source , } metadata_missing = {} # Only either `source_demuxer` or `source_extension` attribute can be # present in metadata. if self . __source_demuxer is None : metadata . update ({ \"source_extension\" : os . path . splitext ( self . __source )[ - 1 ]}) # update missing force_retrieve_missing and metadata_missing . update ({ \"source_demuxer\" : \"\" }) else : metadata . update ({ \"source_demuxer\" : self . __source_demuxer }) # update missing force_retrieve_missing and metadata_missing . update ({ \"source_extension\" : \"\" }) # add source video metadata properties metadata . update ( { \"source_video_resolution\" : self . __default_video_resolution , \"source_video_pixfmt\" : self . __default_video_pixfmt , \"source_video_framerate\" : self . __default_video_framerate , \"source_video_decoder\" : self . __default_video_decoder , \"source_duration_sec\" : self . __default_source_duration , \"approx_video_nframes\" : ( int ( self . __approx_video_nframes ) if self . __approx_video_nframes else None ), \"source_video_bitrate\" : self . __default_video_bitrate , \"source_audio_bitrate\" : self . __default_audio_bitrate , \"source_audio_samplerate\" : self . __default_audio_samplerate , \"source_has_video\" : self . __contains_video , \"source_has_audio\" : self . __contains_audio , \"source_has_image_sequence\" : self . __contains_images , } ) # add output metadata properties (if available) if not ( self . __metadata_output is None ): metadata . update ( { \"output_frames_resolution\" : self . __output_frames_resolution , \"output_frames_pixfmt\" : self . __output_frames_pixfmt , \"output_framerate\" : self . __output_framerate , } ) else : # since output stream metadata properties are only available when additional # FFmpeg parameters(such as filters) are defined manually, thereby missing # output stream properties are handled by assigning them counterpart source # stream metadata property values force_retrieve_missing and metadata_missing . update ( { \"output_frames_resolution\" : self . __default_video_resolution , \"output_frames_pixfmt\" : self . __default_video_pixfmt , \"output_framerate\" : self . __default_video_framerate , } ) # log it self . __verbose_logs and logger . debug ( \"Metadata Extraction completed successfully!\" ) # parse as JSON string(`json.dumps`), if defined metadata = json . dumps ( metadata , indent = 2 ) if pretty_json else metadata metadata_missing = ( json . dumps ( metadata_missing , indent = 2 ) if pretty_json else metadata_missing ) # return `metadata` or `(metadata, metadata_missing)` return metadata if not force_retrieve_missing else ( metadata , metadata_missing )","title":"retrieve_metadata()"},{"location":"reference/sourcer/params/","text":"Sourcer API Parameters \u00b6 source \u00b6 This parameter defines the input source ( -i ) for probing. Sourcer API will throw AssertionError if source provided is invalid or missing. Sourcer API checks for video bitrate or frame-size and framerate in video's metadata to ensure given input source has usable video stream available. Thereby, it will throw ValueError if it fails to find those parameters. Multiple video inputs are not yet supported! Data-Type: String. Its valid input can be one of the following: Filepath: Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: # initialize the sourcer and probe it sourcer = Sourcer ( '/home/foo.mp4' ) . probe_stream () Image Sequence: Valid image sequence such as sequential( 'img%03d.png' ) or glob pattern( '*.png' ) or single (looping) image as input: Sequential Glob pattern Single (loop) image How to start with specific number image? You can use -start_number FFmpeg parameter if you want to start with specific number image: # define `-start_number` such as `5` sourcer_params = { \"-ffprefixes\" :[ \"-start_number\" , \"5\" ]} # initialize the sourcer with define parameters sourcer = Sourcer ( 'img %03d .png' , verbose = True , ** sourcer_params ) . probe_stream () # initialize the sourcer and probe it sourcer = Sourcer ( 'img %03d .png' , verbose = True ) . probe_stream () Bash-style globbing ( * represents any number of any characters) is useful if your images are sequential but not necessarily in a numerically sequential order. The glob pattern is not available on Windows builds. # define `-pattern_type glob` for accepting glob pattern sourcer_params = { \"-ffprefixes\" :[ \"-pattern_type\" , \"glob\" ]} # initialize the sourcer with define parameters and probe it sourcer = Sourcer ( 'img*.png' , verbose = True , ** sourcer_params ) . probe_stream () # define `-loop 1` for looping sourcer_params = { \"-ffprefixes\" :[ \"-loop\" , \"1\" ]} # initialize the sourcer with define parameters and probe it sourcer = Sourcer ( 'img.jpg' , verbose = True , ** sourcer_params ) . probe_stream () Network Address: Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://xx:yy@192.168.1.ee:fd/av0_0' as input: # define `rtsp_transport` or necessary parameters sourcer_params = { \"-ffprefixes\" :[ \"-rtsp_transport\" , \"tcp\" ]} # initialize the sourcer with define parameters and probe it sourcer = Sourcer ( 'rtsp://xx:yy@192.168.1.ee:fd/av0_0' , verbose = True , ** sourcer_params ) . probe_stream () Video Capture Devices (Webcams): Valid video probe device's name (e.g. \"USB2.0 Camera\" ) or its path (e.g. \"/dev/video0\" on linux) or its index (e.g. \"0\" ) as input w.r.t source_demuxer parameter value in use. For example, for probing \"USB2.0 Camera\" named device with dshow source demuxer on Windows, we can do as follows in Sourcer API: Identifying and Specifying Device name/path/index and suitable Demuxer on different OSes Windows Linux MacOS Windows OS users can use the dshow (DirectShow) to list video input device which is the preferred option for Windows users. You can refer following steps to identify and specify your input video device's name: Identify Video Devices: You can locate your video device's name (already connected to your system) using dshow as follows: c: \\> ffmpeg.exe -list_devices true -f dshow -i dummy ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ dshow @ 03ACF580 ] DirectShow video devices [ dshow @ 03ACF580 ] \"Integrated Camera\" [ dshow @ 03ACF580 ] \"USB2.0 Camera\" [ dshow @ 03ACF580 ] DirectShow audio devices [ dshow @ 03ACF580 ] \"Microphone (Realtek High Definition Audio)\" [ dshow @ 03ACF580 ] \"Microphone (USB2.0 Camera)\" dummy: Immediate exit requested Specify Video Device's name: Then, you can specify and initialize your located Video device's name in Sourcer API as follows: # initialize the sourcer with \"USB2.0 Camera\" source and probe it sourcer = Sourcer ( \"USB2.0 Camera\" , source_demuxer = \"dshow\" , verbose = True ) . probe_stream () [OPTIONAL] Specify Video Device's index along with name: If there are multiple Video devices with similar name, then you can use -video_device_number parameter to specify the arbitrary index of the particular device. For instance, to open second video device with name \"Camera\" you can do as follows: # define video_device_number as 1 (numbering start from 0) sourcer_params = { \"-ffprefixes\" :[ \"-video_device_number\" , \"1\" ]} # initialize the sourcer with \"Camera\" source and probe it sourcer = Sourcer ( \"Camera\" , source_demuxer = \"dshow\" , verbose = True , ** sourcer_params ) . probe_stream () Linux OS users can use the video4linux2 (or its alias v4l2 ) to list to all video capture devices such as from an USB webcam. You can refer following steps to identify and specify your probe video device's path: Identify Video Devices: Linux systems tend to automatically create file device node/path when the device (e.g. an USB webcam) is plugged into the system, and has a name of the kind '/dev/videoN' , where N is a index associated to the device. To get the list of all available file device node/path on your Linux machine, you can use the v4l-ctl command. You can use sudo apt install v4l-utils APT command to install v4l-ctl tool on Debian-based Linux distros. $ v4l2-ctl --list-devices USB2.0 PC CAMERA ( usb-0000:00:1d.7-1 ) : /dev/video1 UVC Camera ( 046d:0819 ) ( usb-0000:00:1d.7-2 ) : /dev/video0 Specify Video Device's path: Then, you can specify and initialize your located Video device's path in Sourcer API as follows: # initialize the sourcer with \"/dev/video0\" source and probe it sourcer = Sourcer ( \"/dev/video0\" , source_demuxer = \"v4l2\" , verbose = True ) . probe_stream () MacOS users can use the AVFoundation to list input devices and is the currently recommended framework by Apple for streamgrabbing on Mac OSX-10.7 (Lion) and later as well as on iOS. You can refer following steps to identify and specify your probe video device's name or index on MacOS/OSX machines: QTKit is also available for streamgrabbing on Mac OS X 10.4 (Tiger) and later, but has been marked deprecated since OS X 10.7 (Lion) and may not be available on future releases. Identify Video Devices: Then, You can locate your Video device's name and index using avfoundation as follows: $ ffmpeg -f avfoundation -list_devices true -i \"\" ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation video devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] FaceTime HD camera ( built-in ) [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Capture screen 0 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation audio devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] Blackmagic Audio [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Built-in Microphone Specify Video Device's name or index: Then, you can specify and initialize your located Video device in Sourcer API using its either the name or the index shown in the device listing: Using device's index Using device's name # initialize the sourcer with `1` index source and probe it sourcer = Sourcer ( \"1\" , source_demuxer = \"avfoundation\" , verbose = True ) . probe_stream () When specifying device's name, abbreviations using just the beginning of the device name are possible. Thus, to probe from a device named \"Integrated iSight-camera\" just \"Integrated\" is sufficient: # initialize the sourcer with \"Integrated iSight-camera\" source sourcer = Sourcer ( \"Integrated\" , source_demuxer = \"avfoundation\" , verbose = True ) . probe_stream () If these steps doesn't work for you then reach us out on Gitter \u27b6 Community channel # initialize the sourcer with \"USB2.0 Camera\" source sourcer = Sourcer ( \"USB2.0 Camera\" , source_demuxer = \"dshow\" , verbose = True ) . probe_stream () Screen Capturing/Recording: Valid screen probe device's name (e.g. \"desktop\" ) or its index (e.g. \":0.0\" ) as input w.r.t source_demuxer parameter value in use. For example, for probing \"0:\" indexed device with avfoundation source demuxer on MacOS, we can do as follows in Sourcer API: Specifying suitable Parameter(s) and Demuxer for Capturing your Desktop on different OSes Windows Linux MacOS Windows OS users can use the gdigrab to grab video from the Windows screen. You can refer following steps to specify source for probing: For Windows OS users dshow is also available for grabbing frames from your desktop. But it is highly unreliable and don't works most of the times. # define framerate sourcer_params = { \"-framerate\" : \"30\" } # initialize the sourcer with \"desktop\" source and probe it sourcer = Sourcer ( \"desktop\" , source_demuxer = \"gdigrab\" , verbose = True , ** sourcer_params ) . probe_stream () Linux OS users can use the x11grab to probe an X11 display. You can refer following steps to specify source for probing: # initialize the sourcer with \":0.0\" desktop source and probe it sourcer = Sourcer ( \":0.0\" , source_demuxer = \"x11grab\" , verbose = True ) . probe_stream () MacOS users can use the AVFoundation to list input devices and is the currently recommended framework by Apple for streamgrabbing on Mac OSX-10.7 (Lion) and later as well as on iOS. You can refer following steps to identify and specify your probe video device's name or index in Sourcer API: QTKit is also available for streamgrabbing on Mac OS X 10.4 (Tiger) and later, but has been marked deprecated since OS X 10.7 (Lion) and may not be available on future releases. You can enumerate all the available input devices including screens ready to be probed using avfoundation as follows: $ ffmpeg -f avfoundation -list_devices true -i \"\" ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation video devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] FaceTime HD camera ( built-in ) [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Capture screen 0 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation audio devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] Blackmagic Audio [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Built-in Microphone Then, you can specify and initialize your located screens in Sourcer API using its index shown: # initialize the sourcer with `0:` index desktop screen and probe it sourcer = Sourcer ( \"0:\" , source_demuxer = \"avfoundation\" , verbose = True ) . probe_stream () If these steps doesn't work for you then reach us out on Gitter \u27b6 Community channel # initialize the sourcer with \"0:\" source and probe it sourcer = Sourcer ( \"0:\" , source_demuxer = \"avfoundation\" , verbose = True ) . probe_stream () Virtual Sources: Valid filtergraph to use as input with lavfi ( Libavfilter input virtual device) source that reads data from the open output pads of a libavfilter filtergraph. For example, for generating and probing Mandelbrot graph of 1280x720 frame size and 30 framerate using lavfi input virtual device, we can do as follows in Sourcer API: # initialize the sourcer with \"mandelbrot\" source of # `1280x720` frame size and `30` framerate and probe it sourcer = Sourcer ( \"mandelbrot=size=1280x720:rate=30\" , source_demuxer = \"lavfi\" , frame_format = \"bgr24\" , ) . probe_stream () source_demuxer \u00b6 This parameter specifies the demuxer( -f ) for the input source (such as dshow , v4l2 , gdigrab etc.) to support Live Feed Devices, as well as lavfi (Libavfilter input virtual device) that reads data from the open output pads of a libavfilter filtergraph. Any invalid or unsupported value to source_demuxer parameter value will raise Assertion error! Use ffmpeg -demuxers terminal command to lists all FFmpeg supported demuxers. Data-Type: String Default Value: Its default value is None . Usage: # initialize the sourcer with `dshow` demuxer and probe it sourcer = Sourcer ( \"foo.mp4\" , source_demuxer = \"dshow\" ) . probe_stream () custom_ffmpeg \u00b6 This parameter can be used to manually assigns the system file-path/directory where the custom or downloaded FFmpeg executable is located. Behavior on Windows If custom FFmpeg executable binary file-path/directory is not assigned through custom_ffmpeg parameter on Windows machine, then Sourcer API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine . More information can be found here \u27b6 . How to change FFmpeg Static Binaries download directory? You can use -ffmpeg_download_path exclusive parameter in Sourcer API to set the custom directory for downloading FFmpeg Static Binaries during the Auto-Installation step on Windows Machines. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. C:/User/temp ) on your windows machine. It can be used as follows in Sourcer API: # # define suitable parameter to download at \"C:/User/foo/foo1\" sourcer_params = { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" } # initialize the sourcer Sourcer ( \"foo.mp4\" , verbose = True , ** sourcer_params ) . probe_stream () If binaries were not found at the manually specified path, DeFFcode APIs will throw RuntimeError ! Data-Type: String Default Value: Its default value is None . Usage: # If ffmpeg executables are located at \"/foo/foo1/ffmpeg\" Sourcer ( \"foo.mp4\" , custom_ffmpeg = \"/foo/foo1/ffmpeg\" ) . probe_stream () verbose \u00b6 This parameter enables verbose logs (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: # initialize the sourcer with verbose logs Sourcer ( \"foo.mp4\" , verbose = True ) . probe_stream () sourcer_params \u00b6 This dictionary parameter accepts all Exclusive Parameters formatted as its attributes: Additional FFmpeg parameters In addition to Exclusive Parameters, Sourcer API supports almost any FFmpeg parameter (supported by installed FFmpeg) , and thereby can be passed as dictionary attributes in sourcer_params parameter. Kindly read FFmpeg Docs carefully before passing any additional values to sourcer_params parameter. Wrong invalid values may result in undesired errors or no output at all. All FFmpeg parameters are case-sensitive. Remember to double check every parameter if any error(s) occurred. Data-Type: Dictionary Default Value: Its default value is {} . Exclusive Parameters \u00b6 Sourcer API supports few Exclusive Parameters to allow users to flexibly change its probing properties and handle some special FFmpeg parameters. These parameters are discussed below: -ffprefixes (list) : This attribute sets the special FFmpeg parameters that generally occurs at the very beginning (such as -re ) before input ( -i ) source. The FFmpeg parameters defined with this attribute can repeated more than once and maintains its original order in the FFmpeg command. Its value can be of datatype list only and its usage is as follows: Turn on verbose parameter ( verbose = True ) to see the FFmpeg command that is being executed in Sourcer's pipeline. This helps you debug/address any issues and make adjustments accordingly. # define suitable parameter sourcer_params = { \"-ffprefixes\" : [ '-re' ]} # executes as `ffmpeg -re <rest of command>` \u2002 -ffmpeg_download_path (string) : sets the custom directory for downloading FFmpeg Static Binaries in Compression Mode, during the Auto-Installation on Windows Machines Only. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. C:/User/temp ) on your windows machine. It can be used as follows: sourcer_params = { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" } # will be saved to \"C:/User/foo/foo1\" \u2002 -force_validate_source (bool) : forcefully passes validation test for given source which is required for some special cases with unusual input. It can be used as follows: sourcer_params = { \"-force_validate_source\" : True } # will pass validation test forcefully","title":"API Parameters"},{"location":"reference/sourcer/params/#sourcer-api-parameters","text":"","title":"Sourcer API Parameters"},{"location":"reference/sourcer/params/#source","text":"This parameter defines the input source ( -i ) for probing. Sourcer API will throw AssertionError if source provided is invalid or missing. Sourcer API checks for video bitrate or frame-size and framerate in video's metadata to ensure given input source has usable video stream available. Thereby, it will throw ValueError if it fails to find those parameters. Multiple video inputs are not yet supported! Data-Type: String. Its valid input can be one of the following: Filepath: Valid path of the video file, for e.g \"/home/foo.mp4\" as follows: # initialize the sourcer and probe it sourcer = Sourcer ( '/home/foo.mp4' ) . probe_stream () Image Sequence: Valid image sequence such as sequential( 'img%03d.png' ) or glob pattern( '*.png' ) or single (looping) image as input: Sequential Glob pattern Single (loop) image How to start with specific number image? You can use -start_number FFmpeg parameter if you want to start with specific number image: # define `-start_number` such as `5` sourcer_params = { \"-ffprefixes\" :[ \"-start_number\" , \"5\" ]} # initialize the sourcer with define parameters sourcer = Sourcer ( 'img %03d .png' , verbose = True , ** sourcer_params ) . probe_stream () # initialize the sourcer and probe it sourcer = Sourcer ( 'img %03d .png' , verbose = True ) . probe_stream () Bash-style globbing ( * represents any number of any characters) is useful if your images are sequential but not necessarily in a numerically sequential order. The glob pattern is not available on Windows builds. # define `-pattern_type glob` for accepting glob pattern sourcer_params = { \"-ffprefixes\" :[ \"-pattern_type\" , \"glob\" ]} # initialize the sourcer with define parameters and probe it sourcer = Sourcer ( 'img*.png' , verbose = True , ** sourcer_params ) . probe_stream () # define `-loop 1` for looping sourcer_params = { \"-ffprefixes\" :[ \"-loop\" , \"1\" ]} # initialize the sourcer with define parameters and probe it sourcer = Sourcer ( 'img.jpg' , verbose = True , ** sourcer_params ) . probe_stream () Network Address: Valid ( http(s) , rtp , rstp , rtmp , mms , etc.) incoming network stream address such as 'rtsp://xx:yy@192.168.1.ee:fd/av0_0' as input: # define `rtsp_transport` or necessary parameters sourcer_params = { \"-ffprefixes\" :[ \"-rtsp_transport\" , \"tcp\" ]} # initialize the sourcer with define parameters and probe it sourcer = Sourcer ( 'rtsp://xx:yy@192.168.1.ee:fd/av0_0' , verbose = True , ** sourcer_params ) . probe_stream () Video Capture Devices (Webcams): Valid video probe device's name (e.g. \"USB2.0 Camera\" ) or its path (e.g. \"/dev/video0\" on linux) or its index (e.g. \"0\" ) as input w.r.t source_demuxer parameter value in use. For example, for probing \"USB2.0 Camera\" named device with dshow source demuxer on Windows, we can do as follows in Sourcer API: Identifying and Specifying Device name/path/index and suitable Demuxer on different OSes Windows Linux MacOS Windows OS users can use the dshow (DirectShow) to list video input device which is the preferred option for Windows users. You can refer following steps to identify and specify your input video device's name: Identify Video Devices: You can locate your video device's name (already connected to your system) using dshow as follows: c: \\> ffmpeg.exe -list_devices true -f dshow -i dummy ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ dshow @ 03ACF580 ] DirectShow video devices [ dshow @ 03ACF580 ] \"Integrated Camera\" [ dshow @ 03ACF580 ] \"USB2.0 Camera\" [ dshow @ 03ACF580 ] DirectShow audio devices [ dshow @ 03ACF580 ] \"Microphone (Realtek High Definition Audio)\" [ dshow @ 03ACF580 ] \"Microphone (USB2.0 Camera)\" dummy: Immediate exit requested Specify Video Device's name: Then, you can specify and initialize your located Video device's name in Sourcer API as follows: # initialize the sourcer with \"USB2.0 Camera\" source and probe it sourcer = Sourcer ( \"USB2.0 Camera\" , source_demuxer = \"dshow\" , verbose = True ) . probe_stream () [OPTIONAL] Specify Video Device's index along with name: If there are multiple Video devices with similar name, then you can use -video_device_number parameter to specify the arbitrary index of the particular device. For instance, to open second video device with name \"Camera\" you can do as follows: # define video_device_number as 1 (numbering start from 0) sourcer_params = { \"-ffprefixes\" :[ \"-video_device_number\" , \"1\" ]} # initialize the sourcer with \"Camera\" source and probe it sourcer = Sourcer ( \"Camera\" , source_demuxer = \"dshow\" , verbose = True , ** sourcer_params ) . probe_stream () Linux OS users can use the video4linux2 (or its alias v4l2 ) to list to all video capture devices such as from an USB webcam. You can refer following steps to identify and specify your probe video device's path: Identify Video Devices: Linux systems tend to automatically create file device node/path when the device (e.g. an USB webcam) is plugged into the system, and has a name of the kind '/dev/videoN' , where N is a index associated to the device. To get the list of all available file device node/path on your Linux machine, you can use the v4l-ctl command. You can use sudo apt install v4l-utils APT command to install v4l-ctl tool on Debian-based Linux distros. $ v4l2-ctl --list-devices USB2.0 PC CAMERA ( usb-0000:00:1d.7-1 ) : /dev/video1 UVC Camera ( 046d:0819 ) ( usb-0000:00:1d.7-2 ) : /dev/video0 Specify Video Device's path: Then, you can specify and initialize your located Video device's path in Sourcer API as follows: # initialize the sourcer with \"/dev/video0\" source and probe it sourcer = Sourcer ( \"/dev/video0\" , source_demuxer = \"v4l2\" , verbose = True ) . probe_stream () MacOS users can use the AVFoundation to list input devices and is the currently recommended framework by Apple for streamgrabbing on Mac OSX-10.7 (Lion) and later as well as on iOS. You can refer following steps to identify and specify your probe video device's name or index on MacOS/OSX machines: QTKit is also available for streamgrabbing on Mac OS X 10.4 (Tiger) and later, but has been marked deprecated since OS X 10.7 (Lion) and may not be available on future releases. Identify Video Devices: Then, You can locate your Video device's name and index using avfoundation as follows: $ ffmpeg -f avfoundation -list_devices true -i \"\" ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation video devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] FaceTime HD camera ( built-in ) [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Capture screen 0 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation audio devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] Blackmagic Audio [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Built-in Microphone Specify Video Device's name or index: Then, you can specify and initialize your located Video device in Sourcer API using its either the name or the index shown in the device listing: Using device's index Using device's name # initialize the sourcer with `1` index source and probe it sourcer = Sourcer ( \"1\" , source_demuxer = \"avfoundation\" , verbose = True ) . probe_stream () When specifying device's name, abbreviations using just the beginning of the device name are possible. Thus, to probe from a device named \"Integrated iSight-camera\" just \"Integrated\" is sufficient: # initialize the sourcer with \"Integrated iSight-camera\" source sourcer = Sourcer ( \"Integrated\" , source_demuxer = \"avfoundation\" , verbose = True ) . probe_stream () If these steps doesn't work for you then reach us out on Gitter \u27b6 Community channel # initialize the sourcer with \"USB2.0 Camera\" source sourcer = Sourcer ( \"USB2.0 Camera\" , source_demuxer = \"dshow\" , verbose = True ) . probe_stream () Screen Capturing/Recording: Valid screen probe device's name (e.g. \"desktop\" ) or its index (e.g. \":0.0\" ) as input w.r.t source_demuxer parameter value in use. For example, for probing \"0:\" indexed device with avfoundation source demuxer on MacOS, we can do as follows in Sourcer API: Specifying suitable Parameter(s) and Demuxer for Capturing your Desktop on different OSes Windows Linux MacOS Windows OS users can use the gdigrab to grab video from the Windows screen. You can refer following steps to specify source for probing: For Windows OS users dshow is also available for grabbing frames from your desktop. But it is highly unreliable and don't works most of the times. # define framerate sourcer_params = { \"-framerate\" : \"30\" } # initialize the sourcer with \"desktop\" source and probe it sourcer = Sourcer ( \"desktop\" , source_demuxer = \"gdigrab\" , verbose = True , ** sourcer_params ) . probe_stream () Linux OS users can use the x11grab to probe an X11 display. You can refer following steps to specify source for probing: # initialize the sourcer with \":0.0\" desktop source and probe it sourcer = Sourcer ( \":0.0\" , source_demuxer = \"x11grab\" , verbose = True ) . probe_stream () MacOS users can use the AVFoundation to list input devices and is the currently recommended framework by Apple for streamgrabbing on Mac OSX-10.7 (Lion) and later as well as on iOS. You can refer following steps to identify and specify your probe video device's name or index in Sourcer API: QTKit is also available for streamgrabbing on Mac OS X 10.4 (Tiger) and later, but has been marked deprecated since OS X 10.7 (Lion) and may not be available on future releases. You can enumerate all the available input devices including screens ready to be probed using avfoundation as follows: $ ffmpeg -f avfoundation -list_devices true -i \"\" ffmpeg version N-45279-g6b86dd5... --enable-runtime-cpudetect libavutil 51 . 74 .100 / 51 . 74 .100 libavcodec 54 . 65 .100 / 54 . 65 .100 libavformat 54 . 31 .100 / 54 . 31 .100 libavdevice 54 . 3 .100 / 54 . 3 .100 libavfilter 3 . 19 .102 / 3 . 19 .102 libswscale 2 . 1 .101 / 2 . 1 .101 libswresample 0 . 16 .100 / 0 . 16 .100 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation video devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] FaceTime HD camera ( built-in ) [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Capture screen 0 [ AVFoundation input device @ 0x7f8e2540ef20 ] AVFoundation audio devices: [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 0 ] Blackmagic Audio [ AVFoundation input device @ 0x7f8e2540ef20 ] [ 1 ] Built-in Microphone Then, you can specify and initialize your located screens in Sourcer API using its index shown: # initialize the sourcer with `0:` index desktop screen and probe it sourcer = Sourcer ( \"0:\" , source_demuxer = \"avfoundation\" , verbose = True ) . probe_stream () If these steps doesn't work for you then reach us out on Gitter \u27b6 Community channel # initialize the sourcer with \"0:\" source and probe it sourcer = Sourcer ( \"0:\" , source_demuxer = \"avfoundation\" , verbose = True ) . probe_stream () Virtual Sources: Valid filtergraph to use as input with lavfi ( Libavfilter input virtual device) source that reads data from the open output pads of a libavfilter filtergraph. For example, for generating and probing Mandelbrot graph of 1280x720 frame size and 30 framerate using lavfi input virtual device, we can do as follows in Sourcer API: # initialize the sourcer with \"mandelbrot\" source of # `1280x720` frame size and `30` framerate and probe it sourcer = Sourcer ( \"mandelbrot=size=1280x720:rate=30\" , source_demuxer = \"lavfi\" , frame_format = \"bgr24\" , ) . probe_stream ()","title":"source"},{"location":"reference/sourcer/params/#source_demuxer","text":"This parameter specifies the demuxer( -f ) for the input source (such as dshow , v4l2 , gdigrab etc.) to support Live Feed Devices, as well as lavfi (Libavfilter input virtual device) that reads data from the open output pads of a libavfilter filtergraph. Any invalid or unsupported value to source_demuxer parameter value will raise Assertion error! Use ffmpeg -demuxers terminal command to lists all FFmpeg supported demuxers. Data-Type: String Default Value: Its default value is None . Usage: # initialize the sourcer with `dshow` demuxer and probe it sourcer = Sourcer ( \"foo.mp4\" , source_demuxer = \"dshow\" ) . probe_stream ()","title":"source_demuxer"},{"location":"reference/sourcer/params/#custom_ffmpeg","text":"This parameter can be used to manually assigns the system file-path/directory where the custom or downloaded FFmpeg executable is located. Behavior on Windows If custom FFmpeg executable binary file-path/directory is not assigned through custom_ffmpeg parameter on Windows machine, then Sourcer API will automatically attempt to download and extract suitable Static FFmpeg binaries at suitable location on your windows machine . More information can be found here \u27b6 . How to change FFmpeg Static Binaries download directory? You can use -ffmpeg_download_path exclusive parameter in Sourcer API to set the custom directory for downloading FFmpeg Static Binaries during the Auto-Installation step on Windows Machines. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. C:/User/temp ) on your windows machine. It can be used as follows in Sourcer API: # # define suitable parameter to download at \"C:/User/foo/foo1\" sourcer_params = { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" } # initialize the sourcer Sourcer ( \"foo.mp4\" , verbose = True , ** sourcer_params ) . probe_stream () If binaries were not found at the manually specified path, DeFFcode APIs will throw RuntimeError ! Data-Type: String Default Value: Its default value is None . Usage: # If ffmpeg executables are located at \"/foo/foo1/ffmpeg\" Sourcer ( \"foo.mp4\" , custom_ffmpeg = \"/foo/foo1/ffmpeg\" ) . probe_stream ()","title":"custom_ffmpeg"},{"location":"reference/sourcer/params/#verbose","text":"This parameter enables verbose logs (if True ) , essential for debugging. Data-Type: Boolean Default Value: Its default value is False . Usage: # initialize the sourcer with verbose logs Sourcer ( \"foo.mp4\" , verbose = True ) . probe_stream ()","title":"verbose"},{"location":"reference/sourcer/params/#sourcer_params","text":"This dictionary parameter accepts all Exclusive Parameters formatted as its attributes: Additional FFmpeg parameters In addition to Exclusive Parameters, Sourcer API supports almost any FFmpeg parameter (supported by installed FFmpeg) , and thereby can be passed as dictionary attributes in sourcer_params parameter. Kindly read FFmpeg Docs carefully before passing any additional values to sourcer_params parameter. Wrong invalid values may result in undesired errors or no output at all. All FFmpeg parameters are case-sensitive. Remember to double check every parameter if any error(s) occurred. Data-Type: Dictionary Default Value: Its default value is {} .","title":"sourcer_params"},{"location":"reference/sourcer/params/#exclusive-parameters","text":"Sourcer API supports few Exclusive Parameters to allow users to flexibly change its probing properties and handle some special FFmpeg parameters. These parameters are discussed below: -ffprefixes (list) : This attribute sets the special FFmpeg parameters that generally occurs at the very beginning (such as -re ) before input ( -i ) source. The FFmpeg parameters defined with this attribute can repeated more than once and maintains its original order in the FFmpeg command. Its value can be of datatype list only and its usage is as follows: Turn on verbose parameter ( verbose = True ) to see the FFmpeg command that is being executed in Sourcer's pipeline. This helps you debug/address any issues and make adjustments accordingly. # define suitable parameter sourcer_params = { \"-ffprefixes\" : [ '-re' ]} # executes as `ffmpeg -re <rest of command>` \u2002 -ffmpeg_download_path (string) : sets the custom directory for downloading FFmpeg Static Binaries in Compression Mode, during the Auto-Installation on Windows Machines Only. If this parameter is not altered, then these binaries will auto-save to the default temporary directory (for e.g. C:/User/temp ) on your windows machine. It can be used as follows: sourcer_params = { \"-ffmpeg_download_path\" : \"C:/User/foo/foo1\" } # will be saved to \"C:/User/foo/foo1\" \u2002 -force_validate_source (bool) : forcefully passes validation test for given source which is required for some special cases with unusual input. It can be used as follows: sourcer_params = { \"-force_validate_source\" : True } # will pass validation test forcefully","title":"Exclusive Parameters"}]}